"""
è½¬å½•å¤„ç†æœåŠ¡
æ•´åˆäº†processor.pyå’ŒåŸtranscription_service.pyçš„æ‰€æœ‰åŠŸèƒ½
"""
import os, subprocess, uuid, threading, json, math, gc, logging
from pathlib import Path
from typing import List, Dict, Optional, Tuple
from pydub import AudioSegment, silence
import whisperx
import torch
import shutil

from models.job_models import JobSettings, JobState
from models.hardware_models import HardwareInfo, OptimizationConfig
from services.hardware_service import get_hardware_detector, get_hardware_optimizer
from services.cpu_affinity_service import CPUAffinityManager, CPUAffinityConfig

# å…¨å±€æ¨¡å‹ç¼“å­˜ (æŒ‰ (model, compute_type, device) é”®)
_model_cache: Dict[Tuple[str, str, str], object] = {}
_align_model_cache: Dict[str, Tuple[object, object]] = {}
_model_lock = threading.Lock()
_align_lock = threading.Lock()

# éŸ³é¢‘å¤„ç†é…ç½®
SEGMENT_LEN_MS = 60_000
SILENCE_SEARCH_MS = 2_000
MIN_SILENCE_LEN_MS = 300
SILENCE_THRESH_DBFS = -40

# è¿›åº¦æƒé‡é…ç½®
PHASE_WEIGHTS = {
    "extract": 5,
    "split": 10,
    "transcribe": 80,
    "srt": 5
}
TOTAL_WEIGHT = sum(PHASE_WEIGHTS.values())


class TranscriptionService:
    """
    è½¬å½•å¤„ç†æœåŠ¡
    æ•´åˆäº†æ‰€æœ‰è½¬å½•ç›¸å…³åŠŸèƒ½
    """

    def __init__(self, jobs_root: str):
        """
        åˆå§‹åŒ–è½¬å½•æœåŠ¡

        Args:
            jobs_root: ä»»åŠ¡å·¥ä½œç›®å½•æ ¹è·¯å¾„
        """
        self.jobs_root = Path(jobs_root)
        self.jobs_root.mkdir(parents=True, exist_ok=True)

        self.jobs: Dict[str, JobState] = {}
        self.lock = threading.Lock()
        self.logger = logging.getLogger(__name__)

        # é›†æˆCPUäº²å’Œæ€§ç®¡ç†å™¨
        self.cpu_manager = CPUAffinityManager()

        # é›†æˆç¡¬ä»¶æ£€æµ‹
        self.hardware_detector = get_hardware_detector()
        self.hardware_optimizer = get_hardware_optimizer()
        self._hardware_info: Optional[HardwareInfo] = None
        self._optimization_config: Optional[OptimizationConfig] = None

        # è®°å½•CPUä¿¡æ¯
        sys_info = self.cpu_manager.get_system_info()
        if sys_info.get('supported', False):
            self.logger.info(
                f"ğŸ’» CPUä¿¡æ¯: {sys_info['logical_cores']}ä¸ªé€»è¾‘æ ¸å¿ƒ, "
                f"{sys_info.get('physical_cores', '?')}ä¸ªç‰©ç†æ ¸å¿ƒ, "
                f"å¹³å°: {sys_info.get('platform', '?')}"
            )
        else:
            self.logger.warning("âš ï¸ CPUäº²å’Œæ€§åŠŸèƒ½ä¸å¯ç”¨")

        # æ‰§è¡Œç¡¬ä»¶æ£€æµ‹
        self._detect_hardware()

    def _detect_hardware(self):
        """æ‰§è¡Œç¡¬ä»¶æ£€æµ‹å¹¶ç”Ÿæˆä¼˜åŒ–é…ç½®"""
        try:
            self.logger.info("å¼€å§‹ç¡¬ä»¶æ£€æµ‹...")
            self._hardware_info = self.hardware_detector.detect()
            self._optimization_config = self.hardware_optimizer.get_optimization_config(self._hardware_info)
            
            # è®°å½•æ£€æµ‹ç»“æœ
            hw = self._hardware_info
            opt = self._optimization_config
            self.logger.info(f"ç¡¬ä»¶æ£€æµ‹å®Œæˆ - GPU: {'âœ“' if hw.cuda_available else 'âœ—'}, "
                           f"CPU: {hw.cpu_cores}æ ¸/{hw.cpu_threads}çº¿ç¨‹, "
                           f"å†…å­˜: {hw.memory_total_mb}MB, "
                           f"ä¼˜åŒ–é…ç½®: batch={opt.batch_size}, device={opt.recommended_device}")
        except Exception as e:
            self.logger.error(f"ç¡¬ä»¶æ£€æµ‹å¤±è´¥: {e}")
    
    def get_hardware_info(self) -> Optional[HardwareInfo]:
        """è·å–ç¡¬ä»¶ä¿¡æ¯"""
        return self._hardware_info
    
    def get_optimization_config(self) -> Optional[OptimizationConfig]:
        """è·å–ä¼˜åŒ–é…ç½®"""  
        return self._optimization_config
    
    def get_optimized_job_settings(self, base_settings: Optional[JobSettings] = None) -> JobSettings:
        """è·å–åŸºäºç¡¬ä»¶ä¼˜åŒ–çš„ä»»åŠ¡è®¾ç½®"""
        # ä½¿ç”¨ç¡¬ä»¶ä¼˜åŒ–é…ç½®ä½œä¸ºé»˜è®¤å€¼
        if self._optimization_config:
            optimized = JobSettings(
                model=base_settings.model if base_settings else "medium",
                compute_type=base_settings.compute_type if base_settings else "float16",
                device=self._optimization_config.recommended_device,
                batch_size=self._optimization_config.batch_size,
                word_timestamps=base_settings.word_timestamps if base_settings else False
            )
            return optimized
        
        # å¦‚æœæ²¡æœ‰ç¡¬ä»¶ä¿¡æ¯ï¼Œä½¿ç”¨ä¼ å…¥çš„è®¾ç½®æˆ–é»˜è®¤è®¾ç½®
        return base_settings or JobSettings()

    def create_job(
        self,
        filename: str,
        src_path: str,
        settings: JobSettings,
        job_id: Optional[str] = None
    ) -> JobState:
        """
        åˆ›å»ºè½¬å½•ä»»åŠ¡

        Args:
            filename: æ–‡ä»¶å
            src_path: æºæ–‡ä»¶è·¯å¾„
            settings: ä»»åŠ¡è®¾ç½®
            job_id: ä»»åŠ¡IDï¼ˆå¯é€‰ï¼Œä¸æä¾›åˆ™è‡ªåŠ¨ç”Ÿæˆï¼‰

        Returns:
            JobState: åˆ›å»ºçš„ä»»åŠ¡çŠ¶æ€å¯¹è±¡
        """
        job_id = job_id or uuid.uuid4().hex
        job_dir = self.jobs_root / job_id
        job_dir.mkdir(parents=True, exist_ok=True)

        dest_path = job_dir / filename

        # å¤åˆ¶æ–‡ä»¶åˆ°ä»»åŠ¡ç›®å½•
        if os.path.abspath(src_path) != os.path.abspath(dest_path):
            try:
                shutil.copyfile(src_path, dest_path)
                self.logger.debug(f"æ–‡ä»¶å·²å¤åˆ¶: {src_path} -> {dest_path}")
            except Exception as e:
                self.logger.warning(f"æ–‡ä»¶å¤åˆ¶å¤±è´¥: {e}")

        # åˆ›å»ºä»»åŠ¡çŠ¶æ€å¯¹è±¡
        job = JobState(
            job_id=job_id,
            filename=filename,
            dir=str(job_dir),
            input_path=src_path,
            settings=settings,
            status="uploaded",
            phase="pending",
            message="æ–‡ä»¶å·²ä¸Šä¼ "
        )

        with self.lock:
            self.jobs[job_id] = job

        self.logger.info(f"âœ… ä»»åŠ¡å·²åˆ›å»º: {job_id} - {filename}")
        return job

    def get_job(self, job_id: str) -> Optional[JobState]:
        """
        è·å–ä»»åŠ¡çŠ¶æ€

        Args:
            job_id: ä»»åŠ¡ID

        Returns:
            Optional[JobState]: ä»»åŠ¡çŠ¶æ€å¯¹è±¡ï¼Œä¸å­˜åœ¨åˆ™è¿”å›None
        """
        with self.lock:
            return self.jobs.get(job_id)

    def start_job(self, job_id: str):
        """
        å¯åŠ¨è½¬å½•ä»»åŠ¡

        Args:
            job_id: ä»»åŠ¡ID
        """
        job = self.get_job(job_id)
        if not job or job.status not in ("uploaded", "failed"):
            self.logger.warning(f"ä»»åŠ¡æ— æ³•å¯åŠ¨: {job_id}, çŠ¶æ€: {job.status if job else 'not found'}")
            return

        job.canceled = False
        job.error = None
        job.status = "processing"
        job.message = "å¼€å§‹å¤„ç†"

        # åœ¨ç‹¬ç«‹çº¿ç¨‹ä¸­æ‰§è¡Œè½¬å½•
        threading.Thread(
            target=self._run_pipeline,
            args=(job,),
            daemon=True,
            name=f"Transcription-{job_id[:8]}"
        ).start()

        self.logger.info(f"ğŸš€ ä»»åŠ¡å·²å¯åŠ¨: {job_id}")

    def cancel_job(self, job_id: str) -> bool:
        """
        å–æ¶ˆè½¬å½•ä»»åŠ¡

        Args:
            job_id: ä»»åŠ¡ID

        Returns:
            bool: æ˜¯å¦æˆåŠŸè®¾ç½®å–æ¶ˆæ ‡å¿—
        """
        job = self.get_job(job_id)
        if not job:
            return False

        job.canceled = True
        job.message = "å–æ¶ˆä¸­..."
        self.logger.info(f"ğŸ›‘ ä»»åŠ¡å–æ¶ˆè¯·æ±‚: {job_id}")
        return True

    def _update_progress(
        self,
        job: JobState,
        phase: str,
        phase_ratio: float,
        message: str = ""
    ):
        """
        æ›´æ–°ä»»åŠ¡è¿›åº¦

        Args:
            job: ä»»åŠ¡çŠ¶æ€å¯¹è±¡
            phase: å½“å‰é˜¶æ®µ (extract/split/transcribe/srt)
            phase_ratio: å½“å‰é˜¶æ®µå®Œæˆæ¯”ä¾‹ (0.0-1.0)
            message: è¿›åº¦æ¶ˆæ¯
        """
        job.phase = phase

        # è®¡ç®—ç´¯è®¡è¿›åº¦
        done_weight = 0
        for p, w in PHASE_WEIGHTS.items():
            if p == phase:
                break
            done_weight += w

        current_weight = PHASE_WEIGHTS.get(phase, 0) * max(0.0, min(1.0, phase_ratio))
        job.progress = round((done_weight + current_weight) / TOTAL_WEIGHT * 100, 2)

        if message:
            job.message = message

    def _run_pipeline(self, job: JobState):
        """
        æ‰§è¡Œè½¬å½•å¤„ç†ç®¡é“

        Args:
            job: ä»»åŠ¡çŠ¶æ€å¯¹è±¡
        """
        # åº”ç”¨CPUäº²å’Œæ€§è®¾ç½®
        cpu_applied = False
        if job.settings.cpu_affinity.enabled:
            cpu_applied = self.cpu_manager.apply_cpu_affinity(
                job.settings.cpu_affinity
            )
            if cpu_applied:
                self.logger.info(f"ğŸ“Œ ä»»åŠ¡ {job.job_id} å·²åº”ç”¨CPUäº²å’Œæ€§è®¾ç½®")

        try:
            # æ£€æŸ¥å–æ¶ˆæ ‡å¿—
            if job.canceled:
                job.status = 'canceled'
                job.message = 'å·²å–æ¶ˆ'
                return

            job_dir = Path(job.dir)
            input_path = job_dir / job.filename
            audio_path = job_dir / 'audio.wav'

            # ========== é˜¶æ®µ1: æå–éŸ³é¢‘ ==========
            self._update_progress(job, 'extract', 0, 'æå–éŸ³é¢‘ä¸­')
            if job.canceled:
                raise RuntimeError('ä»»åŠ¡å·²å–æ¶ˆ')

            if not self._extract_audio(str(input_path), str(audio_path)):
                raise RuntimeError('FFmpeg æå–éŸ³é¢‘å¤±è´¥')

            self._update_progress(job, 'extract', 1, 'éŸ³é¢‘æå–å®Œæˆ')
            if job.canceled:
                raise RuntimeError('ä»»åŠ¡å·²å–æ¶ˆ')

            # ========== é˜¶æ®µ2: æ™ºèƒ½åˆ†æ®µ ==========
            self._update_progress(job, 'split', 0, 'éŸ³é¢‘åˆ†æ®µä¸­')
            segments = self._split_audio(str(audio_path))
            if job.canceled:
                raise RuntimeError('ä»»åŠ¡å·²å–æ¶ˆ')

            job.segments = segments
            job.total = len(segments)
            self._update_progress(job, 'split', 1, f'åˆ†æ®µå®Œæˆ å…±{job.total}æ®µ')

            # ========== é˜¶æ®µ3: è½¬å½•å¤„ç† ==========
            self._update_progress(job, 'transcribe', 0, 'åŠ è½½æ¨¡å‹ä¸­')
            if job.canceled:
                raise RuntimeError('ä»»åŠ¡å·²å–æ¶ˆ')

            model = self._get_model(job.settings)
            align_cache = {}
            processed_results = []

            for idx, seg in enumerate(segments):
                if job.canceled:
                    raise RuntimeError('ä»»åŠ¡å·²å–æ¶ˆ')

                ratio = idx / max(1, len(segments))
                self._update_progress(
                    job,
                    'transcribe',
                    ratio,
                    f'è½¬å½• {idx+1}/{len(segments)}'
                )

                seg_result = self._transcribe_segment(seg, model, job, align_cache)
                if seg_result:
                    processed_results.append(seg_result)

                job.processed = idx + 1

            self._update_progress(job, 'transcribe', 1, 'è½¬å½•å®Œæˆ ç”Ÿæˆå­—å¹•ä¸­')
            if job.canceled:
                raise RuntimeError('ä»»åŠ¡å·²å–æ¶ˆ')

            # ========== é˜¶æ®µ4: ç”ŸæˆSRT ==========
            base_name = os.path.splitext(job.filename)[0]
            srt_path = job_dir / f'{base_name}.srt'
            self._update_progress(job, 'srt', 0, 'å†™å…¥ SRT...')
            self._generate_srt(
                processed_results,
                str(srt_path),
                job.settings.word_timestamps
            )
            self._update_progress(job, 'srt', 1, 'å¤„ç†å®Œæˆ')

            job.srt_path = str(srt_path)

            if job.canceled:
                job.status = 'canceled'
                job.message = 'å·²å–æ¶ˆ'
            else:
                job.status = 'finished'
                job.message = 'å®Œæˆ'
                self.logger.info(f"âœ… ä»»åŠ¡å®Œæˆ: {job.job_id}")

        except Exception as e:
            if job.canceled and 'å–æ¶ˆ' in str(e):
                job.status = 'canceled'
                job.message = 'å·²å–æ¶ˆ'
                self.logger.info(f"ğŸ›‘ ä»»åŠ¡å·²å–æ¶ˆ: {job.job_id}")
            else:
                job.status = 'failed'
                job.message = f'å¤±è´¥: {e}'
                job.error = str(e)
                self.logger.error(f"âŒ ä»»åŠ¡å¤±è´¥: {job.job_id} - {e}", exc_info=True)

        finally:
            # æ¢å¤CPUäº²å’Œæ€§è®¾ç½®
            if cpu_applied:
                restored = self.cpu_manager.restore_cpu_affinity()
                if restored:
                    self.logger.info(f"ğŸ”„ ä»»åŠ¡ {job.job_id} å·²æ¢å¤CPUäº²å’Œæ€§è®¾ç½®")

            # é‡Šæ”¾å†…å­˜
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()

    # ========== æ ¸å¿ƒå¤„ç†æ–¹æ³• ==========

    def _extract_audio(self, input_file: str, audio_out: str) -> bool:
        """
        ä½¿ç”¨FFmpegæå–éŸ³é¢‘

        Args:
            input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„
            audio_out: è¾“å‡ºéŸ³é¢‘è·¯å¾„

        Returns:
            bool: æ˜¯å¦æå–æˆåŠŸ
        """
        if os.path.exists(audio_out):
            self.logger.debug(f"éŸ³é¢‘æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡æå–: {audio_out}")
            return True

        # ä¼˜å…ˆä½¿ç”¨é¡¹ç›®å†…çš„FFmpegï¼ˆæ”¯æŒç‹¬ç«‹æ‰“åŒ…ï¼‰
        project_root = Path(__file__).parent.parent.parent
        local_ffmpeg = project_root / "ffmpeg" / "bin" / "ffmpeg.exe"

        if local_ffmpeg.exists():
            ffmpeg_cmd = str(local_ffmpeg)
            self.logger.debug(f"ä½¿ç”¨é¡¹ç›®å†…FFmpeg: {ffmpeg_cmd}")
        else:
            ffmpeg_cmd = 'ffmpeg'
            self.logger.debug("ä½¿ç”¨ç³»ç»ŸFFmpeg")

        cmd = [
            ffmpeg_cmd, '-y', '-i', input_file,
            '-vn',                    # ä»…éŸ³é¢‘
            '-ac', '1',               # å•å£°é“
            '-ar', '16000',           # 16kHz é‡‡æ ·ç‡
            '-acodec', 'pcm_s16le',   # PCM ç¼–ç 
            audio_out
        ]

        try:
            proc = subprocess.run(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                timeout=600  # 10åˆ†é’Ÿè¶…æ—¶
            )

            if proc.returncode == 0 and os.path.exists(audio_out):
                self.logger.debug(f"âœ… éŸ³é¢‘æå–æˆåŠŸ: {audio_out}")
                return True
            else:
                error_msg = proc.stderr.decode('utf-8', errors='ignore')
                self.logger.error(f"âŒ FFmpegæ‰§è¡Œå¤±è´¥: {error_msg}")
                return False

        except subprocess.TimeoutExpired:
            self.logger.error("âŒ FFmpegè¶…æ—¶")
            return False
        except Exception as e:
            self.logger.error(f"âŒ éŸ³é¢‘æå–å¤±è´¥: {e}")
            return False

    def _split_audio(self, audio_path: str) -> List[Dict]:
        """
        æ™ºèƒ½åˆ†æ®µéŸ³é¢‘ï¼ˆåŸºäºé™éŸ³æ£€æµ‹ï¼‰

        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„

        Returns:
            List[Dict]: æ®µä¿¡æ¯åˆ—è¡¨ï¼Œæ¯é¡¹åŒ…å« file å’Œ start_ms
        """
        self.logger.debug(f"å¼€å§‹éŸ³é¢‘åˆ†æ®µ: {audio_path}")

        audio = AudioSegment.from_wav(audio_path)
        length = len(audio)
        segments = []
        pos = 0
        idx = 0

        while pos < length:
            end = min(pos + SEGMENT_LEN_MS, length)

            # æ™ºèƒ½å¯»æ‰¾é™éŸ³ç‚¹ï¼ˆé¿å…åœ¨å¥å­ä¸­é—´åˆ†å‰²ï¼‰
            if end < length and (end - pos) > SILENCE_SEARCH_MS:
                search_start = max(pos, end - SILENCE_SEARCH_MS)
                search_chunk = audio[search_start:end]

                try:
                    silences = silence.detect_silence(
                        search_chunk,
                        min_silence_len=MIN_SILENCE_LEN_MS,
                        silence_thresh=SILENCE_THRESH_DBFS
                    )

                    if silences:
                        # ä½¿ç”¨ç¬¬ä¸€ä¸ªé™éŸ³ç‚¹
                        silence_start = silences[0][0]
                        new_end = search_start + silence_start
                        if new_end - pos > MIN_SILENCE_LEN_MS:
                            end = new_end
                except Exception as e:
                    self.logger.warning(f"é™éŸ³æ£€æµ‹å¤±è´¥: {e}")

            # å¯¼å‡ºåˆ†æ®µ
            chunk = audio[pos:end]
            seg_file = os.path.join(os.path.dirname(audio_path), f'segment_{idx}.wav')
            chunk.export(seg_file, format='wav')

            segments.append({
                'file': seg_file,
                'start_ms': pos,
                'duration_ms': end - pos
            })

            pos = end
            idx += 1

        self.logger.debug(f"âœ… éŸ³é¢‘åˆ†æ®µå®Œæˆ: å…±{len(segments)}æ®µ")
        return segments

    def _get_model(self, settings: JobSettings):
        """
        è·å–WhisperXæ¨¡å‹ï¼ˆå¸¦ç¼“å­˜ï¼‰

        ä¼˜å…ˆä½¿ç”¨æ¨¡å‹ç®¡ç†å™¨ï¼Œå¦åˆ™ä½¿ç”¨ç®€å•ç¼“å­˜

        Args:
            settings: ä»»åŠ¡è®¾ç½®

        Returns:
            æ¨¡å‹å¯¹è±¡
        """
        # å°è¯•ä½¿ç”¨æ¨¡å‹ç®¡ç†å™¨
        try:
            from services.model_preload_manager import get_model_manager
            model_manager = get_model_manager()
            if model_manager:
                return model_manager.get_model(settings)
        except ImportError:
            pass

        # å›é€€åˆ°ç®€å•ç¼“å­˜æœºåˆ¶
        key = (settings.model, settings.compute_type, settings.device)
        with _model_lock:
            if key in _model_cache:
                self.logger.debug(f"âœ… å‘½ä¸­æ¨¡å‹ç¼“å­˜: {key}")
                return _model_cache[key]

            self.logger.info(f"ğŸ” åŠ è½½æ¨¡å‹: {key}")
            m = whisperx.load_model(
                settings.model,
                settings.device,
                compute_type=settings.compute_type
            )
            _model_cache[key] = m
            return m

    def _get_align_model(self, lang: str, device: str):
        """
        è·å–å¯¹é½æ¨¡å‹ï¼ˆå¸¦ç¼“å­˜ï¼‰

        Args:
            lang: è¯­è¨€ä»£ç 
            device: è®¾å¤‡ (cuda/cpu)

        Returns:
            Tuple[model, metadata]: å¯¹é½æ¨¡å‹å’Œå…ƒæ•°æ®
        """
        with _align_lock:
            if lang in _align_model_cache:
                self.logger.debug(f"âœ… å‘½ä¸­å¯¹é½æ¨¡å‹ç¼“å­˜: {lang}")
                return _align_model_cache[lang]

            self.logger.info(f"ğŸ” åŠ è½½å¯¹é½æ¨¡å‹: {lang}")
            am, meta = whisperx.load_align_model(language_code=lang, device=device)
            _align_model_cache[lang] = (am, meta)
            return am, meta

    def _transcribe_segment(
        self,
        seg: Dict,
        model,
        job: JobState,
        align_cache: Dict
    ):
        """
        è½¬å½•å•ä¸ªéŸ³é¢‘æ®µ

        Args:
            seg: æ®µä¿¡æ¯ {file, start_ms, duration_ms}
            model: Whisperæ¨¡å‹
            job: ä»»åŠ¡çŠ¶æ€
            align_cache: å¯¹é½æ¨¡å‹ç¼“å­˜

        Returns:
            Dict: è½¬å½•ç»“æœï¼ˆåŒ…å«segmentså’Œword_segmentsï¼‰
        """
        audio = whisperx.load_audio(seg['file'])

        try:
            # Whisperè½¬å½•
            rs = model.transcribe(
                audio,
                batch_size=job.settings.batch_size,
                verbose=False,
                language=job.language
            )

            if not rs or 'segments' not in rs:
                return None

            # æ£€æµ‹è¯­è¨€
            if not job.language and 'language' in rs:
                job.language = rs['language']
                self.logger.info(f"ğŸŒ æ£€æµ‹åˆ°è¯­è¨€: {job.language}")

            lang = job.language or rs.get('language')

            # åŠ è½½å¯¹é½æ¨¡å‹
            if lang not in align_cache:
                am, meta = self._get_align_model(lang, job.settings.device)
                align_cache[lang] = (am, meta)

            am, meta = align_cache[lang]

            # è¯çº§å¯¹é½
            aligned = whisperx.align(
                rs['segments'],
                am,
                meta,
                audio,
                job.settings.device
            )

            # æ—¶é—´åç§»æ ¡æ­£ï¼ˆé‡è¦ï¼ï¼‰
            start_offset = seg['start_ms'] / 1000.0
            final = {'segments': []}

            if 'segments' in aligned:
                for s in aligned['segments']:
                    if 'start' in s:
                        s['start'] += start_offset
                    if 'end' in s:
                        s['end'] += start_offset
                    final['segments'].append(s)

            if 'word_segments' in aligned:
                final['word_segments'] = []
                for w in aligned['word_segments']:
                    if 'start' in w:
                        w['start'] += start_offset
                    if 'end' in w:
                        w['end'] += start_offset
                    final['word_segments'].append(w)

            return final

        finally:
            del audio
            gc.collect()

    def _format_ts(self, sec: float) -> str:
        """
        æ ¼å¼åŒ–æ—¶é—´æˆ³ä¸ºSRTæ ¼å¼

        Args:
            sec: ç§’æ•°

        Returns:
            str: SRTæ—¶é—´æˆ³ (HH:MM:SS,mmm)
        """
        if sec < 0:
            sec = 0

        ms = int(round(sec * 1000))
        h = ms // 3600000
        ms %= 3600000
        m = ms // 60000
        ms %= 60000
        s = ms // 1000
        ms %= 1000

        return f"{h:02}:{m:02}:{s:02},{ms:03}"

    def _generate_srt(self, results: List[Dict], path: str, word_level: bool):
        """
        ç”ŸæˆSRTå­—å¹•æ–‡ä»¶

        Args:
            results: è½¬å½•ç»“æœåˆ—è¡¨
            path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            word_level: æ˜¯å¦ä½¿ç”¨è¯çº§æ—¶é—´æˆ³
        """
        lines = []
        n = 1  # å­—å¹•åºå·

        for r in results:
            if not r:
                continue

            entries = []

            # è¯çº§æ—¶é—´æˆ³æ¨¡å¼
            if word_level and r.get('word_segments'):
                for w in r['word_segments']:
                    if w.get('start') is not None and w.get('end') is not None:
                        txt = (w.get('word') or '').strip()
                        if txt:
                            entries.append({
                                'start': w['start'],
                                'end': w['end'],
                                'text': txt
                            })

            # å¥å­çº§æ—¶é—´æˆ³æ¨¡å¼ï¼ˆé»˜è®¤ï¼‰
            elif r.get('segments'):
                for s in r['segments']:
                    if s.get('start') is not None and s.get('end') is not None:
                        txt = (s.get('text') or '').strip()
                        if txt:
                            entries.append({
                                'start': s['start'],
                                'end': s['end'],
                                'text': txt
                            })

            # å†™å…¥SRTæ ¼å¼
            for e in entries:
                if e['end'] <= e['start']:
                    continue  # è·³è¿‡æ— æ•ˆæ—¶é—´æˆ³

                lines.append(str(n))  # åºå·
                lines.append(
                    f"{self._format_ts(e['start'])} --> {self._format_ts(e['end'])}"
                )  # æ—¶é—´æˆ³
                lines.append(e['text'])  # å­—å¹•æ–‡æœ¬
                lines.append("")  # ç©ºè¡Œ
                n += 1

        # å†™å…¥æ–‡ä»¶
        with open(path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(lines))

        self.logger.info(f"âœ… SRTæ–‡ä»¶å·²ç”Ÿæˆ: {path}, å…±{n-1}æ¡å­—å¹•")


# å•ä¾‹å¤„ç†å™¨
_service_instance: Optional[TranscriptionService] = None


def get_transcription_service(root: str) -> TranscriptionService:
    """è·å–è½¬å½•æœåŠ¡å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰"""
    global _service_instance
    if _service_instance is None:
        _service_instance = TranscriptionService(root)
    return _service_instance