"""
è½¬å½•å¤„ç†æœåŠ¡
æ•´åˆäº†processor.pyå’ŒåŽŸtranscription_service.pyçš„æ‰€æœ‰åŠŸèƒ½
"""
import os, subprocess, uuid, threading, json, math, gc, logging
from pathlib import Path
from typing import List, Dict, Optional, Tuple
from enum import Enum
from dataclasses import dataclass, field
from collections import OrderedDict  # æ–°å¢žå¯¼å…¥
from pydub import AudioSegment, silence
import whisperx
import torch
import shutil
import psutil
import numpy as np


class ProcessingMode(Enum):
    """
    å¤„ç†æ¨¡å¼æžšä¸¾
    ç”¨äºŽæ™ºèƒ½å†³ç­–ä½¿ç”¨å†…å­˜æ¨¡å¼è¿˜æ˜¯ç¡¬ç›˜æ¨¡å¼è¿›è¡ŒéŸ³é¢‘å¤„ç†
    """
    MEMORY = "memory"  # å†…å­˜æ¨¡å¼ï¼ˆé»˜è®¤ï¼Œé«˜æ€§èƒ½ï¼‰
    DISK = "disk"      # ç¡¬ç›˜æ¨¡å¼ï¼ˆé™çº§ï¼Œç¨³å®šæ€§ä¼˜å…ˆï¼‰


class VADMethod(Enum):
    """
    VADæ¨¡åž‹é€‰æ‹©æžšä¸¾
    ç”¨äºŽé€‰æ‹©è¯­éŸ³æ´»åŠ¨æ£€æµ‹ï¼ˆVoice Activity Detectionï¼‰æ¨¡åž‹
    """
    SILERO = "silero"      # é»˜è®¤ï¼Œæ— éœ€è®¤è¯ï¼Œé€Ÿåº¦å¿«
    PYANNOTE = "pyannote"  # å¯é€‰ï¼Œéœ€è¦HF Tokenï¼Œç²¾åº¦æ›´é«˜


@dataclass
class VADConfig:
    """
    VADé…ç½®æ•°æ®ç±»
    ç”¨äºŽé…ç½®è¯­éŸ³æ´»åŠ¨æ£€æµ‹çš„å‚æ•°
    """
    method: VADMethod = VADMethod.SILERO  # é»˜è®¤ä½¿ç”¨Silero
    hf_token: Optional[str] = None         # Pyannoteéœ€è¦çš„HF Token
    onset: float = 0.5                     # è¯­éŸ³å¼€å§‹é˜ˆå€¼
    offset: float = 0.363                  # è¯­éŸ³ç»“æŸé˜ˆå€¼
    chunk_size: int = 30                   # æœ€å¤§æ®µé•¿ï¼ˆç§’ï¼‰

    def validate(self) -> bool:
        """éªŒè¯é…ç½®æœ‰æ•ˆæ€§"""
        if self.method == VADMethod.PYANNOTE and not self.hf_token:
            return False  # Pyannoteéœ€è¦Token
        return True

from models.job_models import JobSettings, JobState
from models.hardware_models import HardwareInfo, OptimizationConfig
from services.hardware_service import get_hardware_detector, get_hardware_optimizer
from services.cpu_affinity_service import CPUAffinityManager, CPUAffinityConfig
from services.job_index_service import get_job_index_service
from core.config import config  # å¯¼å…¥ç»Ÿä¸€é…ç½®

# å…¨å±€æ¨¡åž‹ç¼“å­˜ (æŒ‰ (model, compute_type, device) é”®)
_model_cache: Dict[Tuple[str, str, str], object] = {}

# å¯¹é½æ¨¡åž‹ç¼“å­˜ï¼ˆæ”¹ä¸ºOrderedDictï¼Œæ”¯æŒLRUï¼‰
_align_model_cache: OrderedDict[str, Tuple[object, object]] = OrderedDict()
_MAX_ALIGN_MODELS = 3  # æœ€å¤šç¼“å­˜3ç§è¯­è¨€çš„å¯¹é½æ¨¡åž‹

_model_lock = threading.Lock()
_align_lock = threading.Lock()


class TranscriptionService:
    """
    è½¬å½•å¤„ç†æœåŠ¡
    æ•´åˆäº†æ‰€æœ‰è½¬å½•ç›¸å…³åŠŸèƒ½
    """

    def __init__(self, jobs_root: str):
        """
        åˆå§‹åŒ–è½¬å½•æœåŠ¡

        Args:
            jobs_root: ä»»åŠ¡å·¥ä½œç›®å½•æ ¹è·¯å¾„
        """
        self.jobs_root = Path(jobs_root)
        self.jobs_root.mkdir(parents=True, exist_ok=True)

        self.jobs: Dict[str, JobState] = {}
        self.lock = threading.Lock()
        self.logger = logging.getLogger(__name__)

        # é›†æˆCPUäº²å’Œæ€§ç®¡ç†å™¨
        self.cpu_manager = CPUAffinityManager()

        # é›†æˆç¡¬ä»¶æ£€æµ‹
        self.hardware_detector = get_hardware_detector()
        self.hardware_optimizer = get_hardware_optimizer()
        self._hardware_info: Optional[HardwareInfo] = None
        self._optimization_config: Optional[OptimizationConfig] = None

        # é›†æˆä»»åŠ¡ç´¢å¼•æœåŠ¡
        self.job_index = get_job_index_service(jobs_root)
        # å¯åŠ¨æ—¶æ¸…ç†æ— æ•ˆæ˜ å°„
        self.job_index.cleanup_invalid_mappings()

        # é›†æˆSSEç®¡ç†å™¨ï¼ˆç”¨äºŽå®žæ—¶è¿›åº¦æŽ¨é€ï¼‰
        from services.sse_service import get_sse_manager
        self.sse_manager = get_sse_manager()
        self.logger.info("SSEç®¡ç†å™¨å·²é›†æˆ")

        # è®°å½•CPUä¿¡æ¯
        sys_info = self.cpu_manager.get_system_info()
        if sys_info.get('supported', False):
            self.logger.info(
                f" CPUä¿¡æ¯: {sys_info['logical_cores']}ä¸ªé€»è¾‘æ ¸å¿ƒ, "
                f"{sys_info.get('physical_cores', '?')}ä¸ªç‰©ç†æ ¸å¿ƒ, "
                f"å¹³å°: {sys_info.get('platform', '?')}"
            )
        else:
            self.logger.warning("CPUäº²å’Œæ€§åŠŸèƒ½ä¸å¯ç”¨")

        # æ‰§è¡Œç¡¬ä»¶æ£€æµ‹
        self._detect_hardware()

    def _detect_hardware(self):
        """æ‰§è¡Œç¡¬ä»¶æ£€æµ‹å¹¶ç”Ÿæˆä¼˜åŒ–é…ç½®"""
        try:
            self.logger.info("å¼€å§‹ç¡¬ä»¶æ£€æµ‹...")
            self._hardware_info = self.hardware_detector.detect()
            self._optimization_config = self.hardware_optimizer.get_optimization_config(self._hardware_info)
            
            # è®°å½•æ£€æµ‹ç»“æžœ
            hw = self._hardware_info
            opt = self._optimization_config
            self.logger.info(f"ç¡¬ä»¶æ£€æµ‹å®ŒæˆGPU: {'' if hw.cuda_available else ''}, "
                           f"CPU: {hw.cpu_cores}æ ¸/{hw.cpu_threads}çº¿ç¨‹, "
                           f"å†…å­˜: {hw.memory_total_mb}MB, "
                           f"ä¼˜åŒ–é…ç½®: batch={opt.batch_size}, device={opt.recommended_device}")
        except Exception as e:
            self.logger.error(f"ç¡¬ä»¶æ£€æµ‹å¤±è´¥: {e}")
    
    def get_hardware_info(self) -> Optional[HardwareInfo]:
        """èŽ·å–ç¡¬ä»¶ä¿¡æ¯"""
        return self._hardware_info
    
    def get_optimization_config(self) -> Optional[OptimizationConfig]:
        """èŽ·å–ä¼˜åŒ–é…ç½®"""  
        return self._optimization_config
    
    def get_optimized_job_settings(self, base_settings: Optional[JobSettings] = None) -> JobSettings:
        """èŽ·å–åŸºäºŽç¡¬ä»¶ä¼˜åŒ–çš„ä»»åŠ¡è®¾ç½®"""
        # ä½¿ç”¨ç¡¬ä»¶ä¼˜åŒ–é…ç½®ä½œä¸ºé»˜è®¤å€¼
        if self._optimization_config:
            optimized = JobSettings(
                model=base_settings.model if base_settings else "medium",
                compute_type=base_settings.compute_type if base_settings else "float16",
                device=self._optimization_config.recommended_device,
                batch_size=self._optimization_config.batch_size,
                word_timestamps=base_settings.word_timestamps if base_settings else False
            )
            return optimized
        
        # å¦‚æžœæ²¡æœ‰ç¡¬ä»¶ä¿¡æ¯ï¼Œä½¿ç”¨ä¼ å…¥çš„è®¾ç½®æˆ–é»˜è®¤è®¾ç½®
        return base_settings or JobSettings()

    def create_job(
        self,
        filename: str,
        src_path: str,
        settings: JobSettings,
        job_id: Optional[str] = None
    ) -> JobState:
        """
        åˆ›å»ºè½¬å½•ä»»åŠ¡

        Args:
            filename: æ–‡ä»¶å
            src_path: æºæ–‡ä»¶è·¯å¾„
            settings: ä»»åŠ¡è®¾ç½®
            job_id: ä»»åŠ¡IDï¼ˆå¯é€‰ï¼Œä¸æä¾›åˆ™è‡ªåŠ¨ç”Ÿæˆï¼‰

        Returns:
            JobState: åˆ›å»ºçš„ä»»åŠ¡çŠ¶æ€å¯¹è±¡
        """
        job_id = job_id or uuid.uuid4().hex
        job_dir = self.jobs_root / job_id
        job_dir.mkdir(parents=True, exist_ok=True)

        dest_path = job_dir / filename

        # å¤åˆ¶æ–‡ä»¶åˆ°ä»»åŠ¡ç›®å½•
        if os.path.abspath(src_path) != os.path.abspath(dest_path):
            try:
                shutil.copyfile(src_path, dest_path)
                self.logger.debug(f"æ–‡ä»¶å·²å¤åˆ¶: {src_path} -> {dest_path}")
            except Exception as e:
                self.logger.warning(f"æ–‡ä»¶å¤åˆ¶å¤±è´¥: {e}")

        # åˆ›å»ºä»»åŠ¡çŠ¶æ€å¯¹è±¡
        job = JobState(
            job_id=job_id,
            filename=filename,
            dir=str(job_dir),
            input_path=src_path,
            settings=settings,
            status="uploaded",
            phase="pending",
            message="æ–‡ä»¶å·²ä¸Šä¼ "
        )

        with self.lock:
            self.jobs[job_id] = job

        # æ·»åŠ æ–‡ä»¶è·¯å¾„åˆ°ä»»åŠ¡IDçš„æ˜ å°„
        self.job_index.add_mapping(src_path, job_id)

        self.logger.info(f"ä»»åŠ¡å·²åˆ›å»º: {job_id} - {filename}")
        return job

    def get_job(self, job_id: str) -> Optional[JobState]:
        """
        èŽ·å–ä»»åŠ¡çŠ¶æ€

        Args:
            job_id: ä»»åŠ¡ID

        Returns:
            Optional[JobState]: ä»»åŠ¡çŠ¶æ€å¯¹è±¡ï¼Œä¸å­˜åœ¨åˆ™è¿”å›žNone
        """
        with self.lock:
            return self.jobs.get(job_id)

    def scan_incomplete_jobs(self) -> List[Dict]:
        """
        æ‰«ææ‰€æœ‰æœªå®Œæˆçš„ä»»åŠ¡ï¼ˆæœ‰checkpoint.jsonçš„ä»»åŠ¡ï¼‰

        Returns:
            List[Dict]: æœªå®Œæˆä»»åŠ¡åˆ—è¡¨
        """
        incomplete_jobs = []

        try:
            # éåŽ†æ‰€æœ‰ä»»åŠ¡ç›®å½•
            for job_dir in self.jobs_root.iterdir():
                if not job_dir.is_dir():
                    continue

                checkpoint_path = job_dir / "checkpoint.json"
                if not checkpoint_path.exists():
                    continue

                try:
                    # åŠ è½½æ£€æŸ¥ç‚¹æ•°æ®
                    with open(checkpoint_path, 'r', encoding='utf-8') as f:
                        checkpoint_data = json.load(f)

                    job_id = checkpoint_data.get('job_id') or job_dir.name
                    total_segments = checkpoint_data.get('total_segments', 0)
                    processed_indices = checkpoint_data.get('processed_indices', [])
                    processed_count = len(processed_indices)

                    # è®¡ç®—è¿›åº¦
                    if total_segments > 0:
                        progress = (processed_count / total_segments) * 100
                    else:
                        progress = 0

                    # ä»Žç´¢å¼•ä¸­æŸ¥æ‰¾æ–‡ä»¶å
                    file_path = self.job_index.get_file_path(job_id)
                    filename = os.path.basename(file_path) if file_path else "æœªçŸ¥æ–‡ä»¶"

                    incomplete_jobs.append({
                        'job_id': job_id,
                        'filename': filename,
                        'file_path': file_path,  # æ·»åŠ æ–‡ä»¶è·¯å¾„
                        'progress': round(progress, 2),
                        'processed_segments': processed_count,
                        'total_segments': total_segments,
                        'phase': checkpoint_data.get('phase', 'unknown'),
                        'dir': str(job_dir)
                    })

                except Exception as e:
                    self.logger.warning(f"è¯»å–æ£€æŸ¥ç‚¹å¤±è´¥ {checkpoint_path}: {e}")
                    continue

            self.logger.info(f"æ‰«æåˆ° {len(incomplete_jobs)} ä¸ªæœªå®Œæˆä»»åŠ¡")
            return incomplete_jobs

        except Exception as e:
            self.logger.error(f"æ‰«ææœªå®Œæˆä»»åŠ¡å¤±è´¥: {e}")
            return []

    def restore_job_from_checkpoint(self, job_id: str) -> Optional[JobState]:
        """
        ä»Žæ£€æŸ¥ç‚¹æ¢å¤ä»»åŠ¡çŠ¶æ€

        Args:
            job_id: ä»»åŠ¡ID

        Returns:
            Optional[JobState]: æ¢å¤çš„ä»»åŠ¡çŠ¶æ€å¯¹è±¡
        """
        job_dir = self.jobs_root / job_id
        if not job_dir.exists():
            return None

        checkpoint = self._load_checkpoint(job_dir)
        if not checkpoint:
            return None

        try:
            # æŸ¥æ‰¾åŽŸæ–‡ä»¶
            filename = "unknown"
            input_path = None

            # ä»Žç›®å½•ä¸­æŸ¥æ‰¾è§†é¢‘/éŸ³é¢‘æ–‡ä»¶
            for ext in ['.mp4', '.avi', '.mkv', '.mov', '.flv', '.wmv', '.mp3', '.wav', '.m4a']:
                matches = list(job_dir.glob(f"*{ext}"))
                if matches:
                    filename = matches[0].name
                    input_path = str(matches[0])
                    break

            if not input_path:
                self.logger.warning(f"æ— æ³•æ‰¾åˆ°ä»»åŠ¡ {job_id} çš„è¾“å…¥æ–‡ä»¶")
                return None

            # åˆ›å»ºé»˜è®¤çš„CPUäº²å’Œæ€§é…ç½®
            from services.cpu_affinity_service import CPUAffinityConfig
            default_cpu_config = CPUAffinityConfig(
                enabled=True,
                strategy="auto",
                custom_cores=None,
                exclude_cores=None
            )

            # åˆ›å»ºä»»åŠ¡çŠ¶æ€å¯¹è±¡
            job = JobState(
                job_id=job_id,
                filename=filename,
                dir=str(job_dir),
                input_path=input_path,
                settings=JobSettings(cpu_affinity=default_cpu_config),  # æä¾›é»˜è®¤çš„cpu_affinity
                status="paused",
                phase=checkpoint.get('phase', 'pending'),
                message=f"å·²æš‚åœ ({len(checkpoint.get('processed_indices', []))}/{checkpoint.get('total_segments', 0)}æ®µ)",
                total=checkpoint.get('total_segments', 0),
                processed=len(checkpoint.get('processed_indices', [])),
                progress=round((len(checkpoint.get('processed_indices', [])) / max(1, checkpoint.get('total_segments', 1))) * 100, 2)
            )

            with self.lock:
                self.jobs[job_id] = job

            self.logger.info(f"ä»Žæ£€æŸ¥ç‚¹æ¢å¤ä»»åŠ¡: {job_id}")
            return job

        except Exception as e:
            self.logger.error(f"ä»Žæ£€æŸ¥ç‚¹æ¢å¤ä»»åŠ¡å¤±è´¥: {e}")
            return None

    def check_file_checkpoint(self, file_path: str) -> Optional[Dict]:
        """
        æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æœ‰å¯ç”¨çš„æ–­ç‚¹

        Args:
            file_path: æ–‡ä»¶è·¯å¾„

        Returns:
            Optional[Dict]: æ–­ç‚¹ä¿¡æ¯ï¼Œæ— æ–­ç‚¹åˆ™è¿”å›žNone
        """
        # ä»Žç´¢å¼•ä¸­æŸ¥æ‰¾ä»»åŠ¡ID
        job_id = self.job_index.get_job_id(file_path)
        if not job_id:
            return None

        # æ£€æŸ¥ä»»åŠ¡ç›®å½•å’Œcheckpointæ˜¯å¦å­˜åœ¨
        job_dir = self.jobs_root / job_id
        if not job_dir.exists():
            # æ¸…ç†æ— æ•ˆæ˜ å°„
            self.job_index.remove_mapping(file_path)
            return None

        checkpoint = self._load_checkpoint(job_dir)
        if not checkpoint:
            return None

        # è¿”å›žæ–­ç‚¹ä¿¡æ¯
        total_segments = checkpoint.get('total_segments', 0)
        processed_indices = checkpoint.get('processed_indices', [])
        processed_count = len(processed_indices)

        if total_segments > 0:
            progress = (processed_count / total_segments) * 100
        else:
            progress = 0

        return {
            'job_id': job_id,
            'progress': round(progress, 2),
            'processed_segments': processed_count,
            'total_segments': total_segments,
            'phase': checkpoint.get('phase', 'unknown'),
            'can_resume': True
        }

    def start_job(self, job_id: str):
        """
        å¯åŠ¨è½¬å½•ä»»åŠ¡ï¼ˆV2.2: åºŸå¼ƒï¼Œç”±é˜Ÿåˆ—æœåŠ¡è°ƒç”¨_run_pipelineï¼‰

        æ³¨æ„: æ­¤æ–¹æ³•ä¿ç•™æ˜¯ä¸ºäº†å‘åŽå…¼å®¹ï¼Œä½†ä¸å†è‡ªåŠ¨åˆ›å»ºçº¿ç¨‹

        Args:
            job_id: ä»»åŠ¡ID
        """
        #  å…³é”®æ”¹åŠ¨: ä¸å†è‡ªåŠ¨åˆ›å»ºçº¿ç¨‹ï¼Œç”±é˜Ÿåˆ—æœåŠ¡ç»Ÿä¸€ç®¡ç†
        # åŽŸæœ‰ä»£ç :
        # threading.Thread(target=self._run_pipeline, args=(job,), daemon=True).start()

        # æ–°é€»è¾‘: åªæ›´æ–°çŠ¶æ€ï¼Œå®žé™…æ‰§è¡Œç”±é˜Ÿåˆ—æœåŠ¡æŽ§åˆ¶
        job = self.get_job(job_id)
        if not job:
            self.logger.warning(f"ä»»åŠ¡æœªæ‰¾åˆ°: {job_id}")
            return

        if job.status not in ("uploaded", "failed", "paused", "created"):
            self.logger.warning(f"ä»»åŠ¡æ— æ³•å¯åŠ¨: {job_id}, çŠ¶æ€: {job.status}")
            return

        job.canceled = False
        job.paused = False
        job.error = None
        # çŠ¶æ€ç”±é˜Ÿåˆ—æœåŠ¡è®¾ç½®ï¼Œè¿™é‡Œä¸æ”¹

        self.logger.warning(f"start_jobå·²åºŸå¼ƒï¼Œè¯·ä½¿ç”¨é˜Ÿåˆ—æœåŠ¡: {job_id}")

    def pause_job(self, job_id: str) -> bool:
        """
        æš‚åœè½¬å½•ä»»åŠ¡ï¼ˆä¿å­˜æ–­ç‚¹ï¼‰

        Args:
            job_id: ä»»åŠ¡ID

        Returns:
            bool: æ˜¯å¦æˆåŠŸè®¾ç½®æš‚åœæ ‡å¿—
        """
        job = self.get_job(job_id)
        if not job:
            return False

        job.paused = True
        job.message = "æš‚åœä¸­..."
        self.logger.info(f"â¸ï¸ ä»»åŠ¡æš‚åœè¯·æ±‚: {job_id}")
        return True

    def cancel_job(self, job_id: str, delete_data: bool = False) -> bool:
        """
        å–æ¶ˆè½¬å½•ä»»åŠ¡

        Args:
            job_id: ä»»åŠ¡ID
            delete_data: æ˜¯å¦åˆ é™¤ä»»åŠ¡æ•°æ®

        Returns:
            bool: æ˜¯å¦æˆåŠŸè®¾ç½®å–æ¶ˆæ ‡å¿—
        """
        job = self.get_job(job_id)
        if not job:
            return False

        job.canceled = True
        job.message = "å–æ¶ˆä¸­..."
        self.logger.info(f"ðŸ›‘ ä»»åŠ¡å–æ¶ˆè¯·æ±‚: {job_id}, åˆ é™¤æ•°æ®: {delete_data}")

        # å¦‚æžœéœ€è¦åˆ é™¤æ•°æ®
        if delete_data:
            try:
                job_dir = Path(job.dir)
                # ç§»é™¤æ–‡ä»¶è·¯å¾„æ˜ å°„
                if job.input_path:
                    self.job_index.remove_mapping(job.input_path)

                if job_dir.exists():
                    # åˆ é™¤æ•´ä¸ªä»»åŠ¡ç›®å½•
                    shutil.rmtree(job_dir)
                    self.logger.info(f"å·²åˆ é™¤ä»»åŠ¡æ•°æ®: {job_id}")
                    # ä»Žå†…å­˜ä¸­ç§»é™¤ä»»åŠ¡
                    with self.lock:
                        if job_id in self.jobs:
                            del self.jobs[job_id]
            except Exception as e:
                self.logger.error(f"åˆ é™¤ä»»åŠ¡æ•°æ®å¤±è´¥: {e}")

        return True

    def _update_progress(
        self,
        job: JobState,
        phase: str,
        phase_ratio: float,
        message: str = ""
    ):
        """
        æ›´æ–°ä»»åŠ¡è¿›åº¦

        Args:
            job: ä»»åŠ¡çŠ¶æ€å¯¹è±¡
            phase: å½“å‰é˜¶æ®µ (extract/split/transcribe/srt)
            phase_ratio: å½“å‰é˜¶æ®µå®Œæˆæ¯”ä¾‹ (0.0-1.0)
            message: è¿›åº¦æ¶ˆæ¯
        """
        job.phase = phase

        # ä½¿ç”¨é…ç½®ä¸­çš„è¿›åº¦æƒé‡
        phase_weights = config.PHASE_WEIGHTS
        total_weight = config.TOTAL_WEIGHT

        # è®¡ç®—ç´¯è®¡è¿›åº¦
        done_weight = 0
        for p, w in phase_weights.items():
            if p == phase:
                break
            done_weight += w

        current_weight = phase_weights.get(phase, 0) * max(0.0, min(1.0, phase_ratio))
        job.progress = round((done_weight + current_weight) / total_weight * 100, 2)

        if message:
            job.message = message

        # æŽ¨é€SSEè¿›åº¦æ›´æ–°ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
        self._push_sse_progress(job)

    def _push_sse_progress(self, job: JobState):
        """
        æŽ¨é€SSEè¿›åº¦æ›´æ–°ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰

        Args:
            job: ä»»åŠ¡çŠ¶æ€å¯¹è±¡
        """
        try:
            # åŠ¨æ€èŽ·å–SSEç®¡ç†å™¨ï¼ˆç¡®ä¿èŽ·å–åˆ°å·²è®¾ç½®loopçš„å®žä¾‹ï¼‰
            from services.sse_service import get_sse_manager
            sse_manager = get_sse_manager()

            channel_id = f"job:{job.job_id}"

            sse_manager.broadcast_sync(
                channel_id,
                "progress",
                {
                    "job_id": job.job_id,
                    "phase": job.phase,
                    "percent": job.progress,
                    "message": job.message,
                    "status": job.status,
                    "processed": job.processed,
                    "total": job.total,
                    "language": job.language or ""
                }
            )
        except Exception as e:
            # SSEæŽ¨é€å¤±è´¥ä¸åº”å½±å“è½¬å½•æµç¨‹
            self.logger.debug(f"SSEæŽ¨é€å¤±è´¥: {e}")

    def _push_sse_signal(self, job: JobState, signal_code: str, message: str = ""):
        """
        æŽ¨é€SSEä¿¡å·äº‹ä»¶ï¼ˆç”¨äºŽå…³é”®èŠ‚ç‚¹é€šçŸ¥ï¼‰

        Args:
            job: ä»»åŠ¡çŠ¶æ€å¯¹è±¡
            signal_code: ä¿¡å·ä»£ç ï¼ˆå¦‚ "job_complete", "job_failed", "job_canceled"ï¼‰
            message: é™„åŠ æ¶ˆæ¯
        """
        try:
            # åŠ¨æ€èŽ·å–SSEç®¡ç†å™¨ï¼ˆç¡®ä¿èŽ·å–åˆ°å·²è®¾ç½®loopçš„å®žä¾‹ï¼‰
            from services.sse_service import get_sse_manager
            sse_manager = get_sse_manager()

            channel_id = f"job:{job.job_id}"
            sse_manager.broadcast_sync(
                channel_id,
                "signal",
                {
                    "job_id": job.job_id,
                    "code": signal_code,
                    "message": message or job.message,
                    "status": job.status,
                    "progress": job.progress
                }
            )
        except Exception as e:
            self.logger.debug(f"SSEä¿¡å·æŽ¨é€å¤±è´¥ï¼ˆéžè‡´å‘½ï¼‰: {e}")

    def _push_sse_segment(self, job: JobState, segment_result: dict, processed: int, total: int):
        """
        æŽ¨é€å•ä¸ªsegmentçš„è½¬å½•ç»“æžœï¼ˆæµå¼è¾“å‡ºï¼‰

        Args:
            job: ä»»åŠ¡çŠ¶æ€å¯¹è±¡
            segment_result: å•ä¸ªsegmentçš„è½¬å½•ç»“æžœï¼ˆæœªå¯¹é½ï¼‰
            processed: å·²å¤„ç†çš„segmentæ•°é‡
            total: æ€»segmentæ•°é‡
        """
        try:
            # åŠ¨æ€èŽ·å–SSEç®¡ç†å™¨
            from services.sse_service import get_sse_manager
            sse_manager = get_sse_manager()

            channel_id = f"job:{job.job_id}"
            sse_manager.broadcast_sync(
                channel_id,
                "segment",
                {
                    "segment_index": segment_result.get('segment_index', 0),
                    "segments": segment_result.get('segments', []),
                    "language": segment_result.get('language', job.language),
                    "progress": {
                        "processed": processed,
                        "total": total,
                        "percentage": round(processed / max(1, total) * 100, 2)
                    }
                }
            )
            self.logger.debug(f"æŽ¨é€segment #{segment_result.get('segment_index', 0)} è½¬å½•ç»“æžœ")
        except Exception as e:
            # SSEæŽ¨é€å¤±è´¥ä¸åº”å½±å“è½¬å½•æµç¨‹
            self.logger.debug(f"SSE segmentæŽ¨é€å¤±è´¥ï¼ˆéžè‡´å‘½ï¼‰: {e}")

    def _push_sse_aligned(self, job: JobState, aligned_results: List[Dict]):
        """
        æŽ¨é€å¯¹é½å®Œæˆäº‹ä»¶ï¼ˆæµå¼è¾“å‡ºï¼‰

        Args:
            job: ä»»åŠ¡çŠ¶æ€å¯¹è±¡
            aligned_results: å¯¹é½åŽçš„ç»“æžœåˆ—è¡¨
        """
        try:
            # åŠ¨æ€èŽ·å–SSEç®¡ç†å™¨
            from services.sse_service import get_sse_manager
            sse_manager = get_sse_manager()

            channel_id = f"job:{job.job_id}"

            # æå–å¯¹é½åŽçš„segments
            segments = []
            word_segments = []
            if aligned_results and len(aligned_results) > 0:
                segments = aligned_results[0].get('segments', [])
                word_segments = aligned_results[0].get('word_segments', [])

            sse_manager.broadcast_sync(
                channel_id,
                "aligned",
                {
                    "segments": segments,
                    "word_segments": word_segments,
                    "message": "å¯¹é½å®Œæˆ"
                }
            )
            self.logger.info(f"æŽ¨é€å¯¹é½å®Œæˆäº‹ä»¶ï¼Œå…± {len(segments)} æ¡å­—å¹•")
        except Exception as e:
            # SSEæŽ¨é€å¤±è´¥ä¸åº”å½±å“è½¬å½•æµç¨‹
            self.logger.debug(f"SSE alignedæŽ¨é€å¤±è´¥ï¼ˆéžè‡´å‘½ï¼‰: {e}")

    def _save_checkpoint(self, job_dir: Path, data: dict, job: JobState):
        """
        åŽŸå­æ€§ä¿å­˜æ£€æŸ¥ç‚¹
        ä½¿ç”¨"å†™ä¸´æ—¶æ–‡ä»¶ -> é‡å‘½å"ç­–ç•¥ï¼Œç¡®ä¿æ–‡ä»¶è¦ä¹ˆå®Œæ•´å†™å…¥ï¼Œè¦ä¹ˆä¿æŒåŽŸæ ·

        Args:
            job_dir: ä»»åŠ¡ç›®å½•
            data: æ£€æŸ¥ç‚¹æ•°æ®
            job: ä»»åŠ¡çŠ¶æ€å¯¹è±¡ï¼ˆç”¨äºŽèŽ·å–settingsï¼‰
        """
        # æ·»åŠ åŽŸå§‹è®¾ç½®åˆ°checkpointï¼ˆç”¨äºŽæ ¡éªŒå‚æ•°å…¼å®¹æ€§ï¼‰
        data["original_settings"] = {
            "model": job.settings.model,
            "device": job.settings.device,
            "word_timestamps": job.settings.word_timestamps,
            "compute_type": job.settings.compute_type,
            "batch_size": job.settings.batch_size
        }

        checkpoint_path = job_dir / "checkpoint.json"
        temp_path = checkpoint_path.with_suffix(".tmp")

        try:
            # 1. å†™å…¥ä¸´æ—¶æ–‡ä»¶
            with open(temp_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)

            # 2. åŽŸå­æ›¿æ¢ï¼ˆWindows/Linux/macOS å‡æ”¯æŒï¼‰
            # å¦‚æžœç¨‹åºåœ¨è¿™é‡Œå´©æºƒï¼Œcheckpoint.json ä¾ç„¶æ˜¯æ—§ç‰ˆæœ¬ï¼Œä¸ä¼šæŸå
            os.replace(temp_path, checkpoint_path)

        except Exception as e:
            self.logger.error(f"ä¿å­˜æ£€æŸ¥ç‚¹å¤±è´¥: {e}")
            # ä¿å­˜å¤±è´¥ä¸åº”ä¸­æ–­ä¸»æµç¨‹ï¼Œä»…è®°å½•æ—¥å¿—

    def _load_checkpoint(self, job_dir: Path) -> Optional[dict]:
        """
        åŠ è½½æ£€æŸ¥ç‚¹ï¼Œå¦‚æžœæ–‡ä»¶æŸååˆ™è¿”å›ž None

        Args:
            job_dir: ä»»åŠ¡ç›®å½•

        Returns:
            Optional[dict]: æ£€æŸ¥ç‚¹æ•°æ®ï¼Œä¸å­˜åœ¨æˆ–æŸååˆ™è¿”å›ž None
        """
        checkpoint_path = job_dir / "checkpoint.json"
        if not checkpoint_path.exists():
            return None

        try:
            with open(checkpoint_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except (json.JSONDecodeError, OSError) as e:
            self.logger.warning(f"æ£€æŸ¥ç‚¹æ–‡ä»¶æŸåï¼Œå°†é‡æ–°å¼€å§‹ä»»åŠ¡: {checkpoint_path} - {e}")
            return None

    def _flush_checkpoint_after_split(
        self,
        job_dir: Path,
        job: JobState,
        segments: List[Dict],
        processing_mode: ProcessingMode
    ):
        """
        åˆ†æ®µå®ŒæˆåŽå¼ºåˆ¶åˆ·æ–°checkpointï¼ˆç¡®ä¿æ–­ç‚¹ç»­ä¼ ä¸€è‡´æ€§ï¼‰

        è¿™æ˜¯æ–­ç‚¹ç»­ä¼ çš„å…³é”®èŠ‚ç‚¹ï¼
        åªæœ‰åˆ†æ®µå…ƒæ•°æ®è¢«æŒä¹…åŒ–åŽï¼ŒåŽç»­çš„è½¬å½•ç´¢å¼•æ‰æœ‰æ„ä¹‰ã€‚

        Args:
            job_dir: ä»»åŠ¡ç›®å½•
            job: ä»»åŠ¡çŠ¶æ€å¯¹è±¡
            segments: åˆ†æ®µå…ƒæ•°æ®åˆ—è¡¨
            processing_mode: å½“å‰å¤„ç†æ¨¡å¼
        """
        import time

        checkpoint_data = {
            "job_id": job.job_id,
            "phase": "split_complete",  # æ˜Žç¡®æ ‡è®°åˆ†æ®µå®Œæˆ
            "processing_mode": processing_mode.value,  # è®°å½•æ¨¡å¼
            "total_segments": len(segments),
            "processed_indices": [],
            "segments": segments,
            "unaligned_results": [],
            "timestamp": time.time()  # æ—¶é—´æˆ³ç”¨äºŽè°ƒè¯•
        }

        # å¼ºåˆ¶åŒæ­¥å†™å…¥ï¼ˆç¡®ä¿æ•°æ®è½ç›˜ï¼‰
        self._save_checkpoint(job_dir, checkpoint_data, job)

        # éªŒè¯å†™å…¥æˆåŠŸ
        saved_checkpoint = self._load_checkpoint(job_dir)
        if saved_checkpoint is None:
            raise RuntimeError("checkpoint write verification failed: file not readable")

        if saved_checkpoint.get('phase') != 'split_complete':
            raise RuntimeError("checkpoint write verification failed: phase mismatch")

        if len(saved_checkpoint.get('segments', [])) != len(segments):
            raise RuntimeError("checkpoint write verification failed: segments count mismatch")

        self.logger.info(f"checkpoint flushed and verified after split (mode: {processing_mode.value}, segments: {len(segments)})")

    def _run_pipeline(self, job: JobState):
        """
        æ‰§è¡Œè½¬å½•å¤„ç†ç®¡é“ï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰

        Args:
            job: ä»»åŠ¡çŠ¶æ€å¯¹è±¡
        """
        # åº”ç”¨CPUäº²å’Œæ€§è®¾ç½®
        cpu_applied = False
        if job.settings.cpu_affinity and job.settings.cpu_affinity.enabled:
            cpu_applied = self.cpu_manager.apply_cpu_affinity(
                job.settings.cpu_affinity
            )
            if cpu_applied:
                self.logger.info(f"ðŸ“Œ ä»»åŠ¡ {job.job_id} å·²åº”ç”¨CPUäº²å’Œæ€§è®¾ç½®")

        try:
            # æ£€æŸ¥å–æ¶ˆå’Œæš‚åœæ ‡å¿—
            if job.canceled:
                job.status = 'canceled'
                job.message = 'å·²å–æ¶ˆ'
                return

            if job.paused:
                job.status = 'paused'
                job.message = 'å·²æš‚åœ'
                self.logger.info(f"â¸ï¸ ä»»åŠ¡å·²æš‚åœ: {job.job_id}")
                return

            job_dir = Path(job.dir)
            input_path = job_dir / job.filename
            audio_path = job_dir / 'audio.wav'

            # ==========================================
            # 1. å°è¯•æ¢å¤çŠ¶æ€ï¼ˆæ–­ç‚¹ç»­ä¼ æ ¸å¿ƒï¼‰
            # ==========================================
            checkpoint = self._load_checkpoint(job_dir)

            # åˆå§‹åŒ–å†…å­˜çŠ¶æ€
            processed_indices = set()
            unaligned_results = []  # æœªå¯¹é½çš„è½¬å½•ç»“æžœ
            current_segments = []

            if checkpoint:
                self.logger.info(f"å‘çŽ°æ£€æŸ¥ç‚¹ï¼Œä»Ž {checkpoint.get('phase', 'unknown')} é˜¶æ®µæ¢å¤")
                # æ¢å¤æ•°æ®åˆ°å†…å­˜
                processed_indices = set(checkpoint.get('processed_indices', []))

                # ã€å…¼å®¹æ€§å¤„ç†ã€‘æ”¯æŒæ—§æ ¼å¼checkpoint
                if 'unaligned_results' in checkpoint:
                    # æ–°æ ¼å¼ï¼šunaligned_resultså­—æ®µ
                    unaligned_results = checkpoint.get('unaligned_results', [])
                    self.logger.info("æ£€æµ‹åˆ°æ–°æ ¼å¼checkpointï¼ˆæœªå¯¹é½ç»“æžœï¼‰")
                elif 'results' in checkpoint:
                    # æ—§æ ¼å¼ï¼šresultså­—æ®µï¼ˆå·²å¯¹é½ï¼‰
                    self.logger.warning("æ£€æµ‹åˆ°æ—§ç‰ˆcheckpointæ ¼å¼ï¼Œå°†ç›´æŽ¥ä½¿ç”¨å·²å¯¹é½ç»“æžœ")
                    # å°†æ—§æ ¼å¼è½¬æ¢ä¸ºæ–°æ ¼å¼ï¼ˆè·³è¿‡å¯¹é½é˜¶æ®µï¼‰
                    # è¿™ç§æƒ…å†µä¸‹æˆ‘ä»¬ç›´æŽ¥ä½¿ç”¨resultsä½œä¸ºæœ€ç»ˆç»“æžœ
                    pass

                current_segments = checkpoint.get('segments', [])
                # æ¢å¤ä»»åŠ¡åŸºæœ¬ä¿¡æ¯
                job.total = checkpoint.get('total_segments', 0)
                job.processed = len(processed_indices)
                self.logger.info(f"å·²å¤„ç† {job.processed}/{job.total} æ®µ")

            # ==========================================
            # 2. é˜¶æ®µ1: æå–éŸ³é¢‘
            # ==========================================
            # åªæœ‰å½“éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæˆ–è€…ä»Žå¤´å¼€å§‹æ—¶ï¼Œæ‰æ‰§è¡Œæå–
            if not audio_path.exists() or (checkpoint is None):
                self._update_progress(job, 'extract', 0, 'æå–éŸ³é¢‘ä¸­')
                if job.canceled:
                    raise RuntimeError('ä»»åŠ¡å·²å–æ¶ˆ')

                if not self._extract_audio(str(input_path), str(audio_path)):
                    raise RuntimeError('FFmpeg æå–éŸ³é¢‘å¤±è´¥')

                self._update_progress(job, 'extract', 1, 'éŸ³é¢‘æå–å®Œæˆ')
            else:
                self.logger.info("è·³è¿‡éŸ³é¢‘æå–ï¼Œä½¿ç”¨å·²æœ‰æ–‡ä»¶")

            if job.canceled:
                raise RuntimeError('ä»»åŠ¡å·²å–æ¶ˆ')

            # ==========================================
            # 3. é˜¶æ®µ1.5: æ™ºèƒ½æ¨¡å¼å†³ç­–ï¼ˆæ–°å¢žï¼‰
            # ==========================================
            processing_mode = None
            audio_array = None  # å†…å­˜æ¨¡å¼ä¸‹çš„éŸ³é¢‘æ•°ç»„

            # ä»Žcheckpointæ¢å¤æ¨¡å¼ï¼ˆå¦‚æžœå­˜åœ¨ï¼‰
            if checkpoint and 'processing_mode' in checkpoint:
                mode_value = checkpoint['processing_mode']
                processing_mode = ProcessingMode(mode_value)
                self.logger.info(f"ä»Žæ£€æŸ¥ç‚¹æ¢å¤å¤„ç†æ¨¡å¼: {processing_mode.value}")

            # å¦‚æžœæ²¡æœ‰æ£€æŸ¥ç‚¹æˆ–æ²¡æœ‰æ¨¡å¼ä¿¡æ¯ï¼Œè¿›è¡Œæ™ºèƒ½å†³ç­–
            if processing_mode is None:
                processing_mode = self._decide_processing_mode(str(audio_path), job)
                self.logger.info(f"æ™ºèƒ½é€‰æ‹©å¤„ç†æ¨¡å¼: {processing_mode.value}")

            # ==========================================
            # 4. é˜¶æ®µ1.6: éŸ³é¢‘åŠ è½½ï¼ˆå†…å­˜æ¨¡å¼ï¼‰
            # ==========================================
            if processing_mode == ProcessingMode.MEMORY:
                # å†…å­˜æ¨¡å¼ï¼šå°è¯•åŠ è½½å®Œæ•´éŸ³é¢‘åˆ°å†…å­˜
                try:
                    audio_array = self._safe_load_audio(str(audio_path), job)
                    self.logger.info("éŸ³é¢‘å·²åŠ è½½åˆ°å†…å­˜ï¼ˆå†…å­˜æ¨¡å¼ï¼‰")
                except RuntimeError as e:
                    # åŠ è½½å¤±è´¥ï¼Œé™çº§åˆ°ç¡¬ç›˜æ¨¡å¼
                    self.logger.warning(f"å†…å­˜åŠ è½½å¤±è´¥ï¼Œé™çº§åˆ°ç¡¬ç›˜æ¨¡å¼: {e}")
                    processing_mode = ProcessingMode.DISK
                    audio_array = None

            # ==========================================
            # 5. é˜¶æ®µ2: æ™ºèƒ½åˆ†æ®µï¼ˆæ¨¡å¼æ„ŸçŸ¥ï¼‰
            # ==========================================
            # å¦‚æžœæ£€æŸ¥ç‚¹é‡Œæ²¡æœ‰åˆ†æ®µä¿¡æ¯ï¼Œè¯´æ˜Žä¸Šæ¬¡æ²¡è·‘åˆ°åˆ†æ®µå®Œæˆ
            if not current_segments:
                self._update_progress(job, 'split', 0, 'éŸ³é¢‘åˆ†æ®µä¸­')

                # æ ¹æ®æ¨¡å¼é€‰æ‹©åˆ†æ®µæ–¹æ³•
                if processing_mode == ProcessingMode.MEMORY and audio_array is not None:
                    # å†…å­˜æ¨¡å¼ï¼šVADåˆ†æ®µï¼ˆä¸äº§ç”Ÿç£ç›˜IOï¼‰
                    self.logger.info("ä½¿ç”¨å†…å­˜VADåˆ†æ®µï¼ˆé«˜æ€§èƒ½æ¨¡å¼ï¼‰")
                    from services.transcription_service import VADConfig
                    current_segments = self._split_audio_in_memory(
                        audio_array,
                        sr=16000,
                        vad_config=VADConfig()  # ä½¿ç”¨é»˜è®¤Silero VAD
                    )
                else:
                    # ç¡¬ç›˜æ¨¡å¼ï¼šä¼ ç»Ÿpydubåˆ†æ®µ
                    self.logger.info("ä½¿ç”¨ç¡¬ç›˜åˆ†æ®µï¼ˆç¨³å®šæ¨¡å¼ï¼‰")
                    current_segments = self._split_audio_to_disk(str(audio_path))

                if job.canceled:
                    raise RuntimeError('ä»»åŠ¡å·²å–æ¶ˆ')

                job.segments = current_segments
                job.total = len(current_segments)
                self._update_progress(job, 'split', 1, f'åˆ†æ®µå®Œæˆ å…±{job.total}æ®µ')

                # ã€å…³é”®åŸ‹ç‚¹1ã€‘åˆ†æ®µå®ŒæˆåŽå¼ºåˆ¶åˆ·æ–°checkpointï¼ˆä½¿ç”¨æ–°æ–¹æ³•ï¼‰
                self._flush_checkpoint_after_split(
                    job_dir,
                    job,
                    current_segments,
                    processing_mode
                )
                self.logger.info("æ£€æŸ¥ç‚¹å·²å¼ºåˆ¶åˆ·æ–°: åˆ†æ®µå®Œæˆ")
            else:
                self.logger.info(f"è·³è¿‡åˆ†æ®µï¼Œä½¿ç”¨æ£€æŸ¥ç‚¹æ•°æ®ï¼ˆå…±{len(current_segments)}æ®µï¼‰")
                job.segments = current_segments  # æ¢å¤åˆ° job å¯¹è±¡
                job.total = len(current_segments)

            # ==========================================
            # 6. é˜¶æ®µ3: è½¬å½•å¤„ç†ï¼ˆåŒæ¨¡å¼ç»Ÿä¸€å¾ªçŽ¯ï¼‰
            # ==========================================
            self._update_progress(job, 'transcribe', 0, 'åŠ è½½æ¨¡åž‹ä¸­')
            if job.canceled:
                raise RuntimeError('ä»»åŠ¡å·²å–æ¶ˆ')

            model = self._get_model(job.settings, job)

            # è¿‡æ»¤å‡ºéœ€è¦å¤„ç†çš„æ®µ
            todo_segments = [
                seg for i, seg in enumerate(current_segments)
                if i not in processed_indices
            ]

            self.logger.info(f"å‰©ä½™ {len(todo_segments)}/{len(current_segments)} æ®µéœ€è¦è½¬å½•")
            self.logger.info(f"å¤„ç†æ¨¡å¼: {processing_mode.value}")

            for idx, seg in enumerate(current_segments):
                # å¦‚æžœå·²ç»åœ¨ processed_indices é‡Œï¼Œç›´æŽ¥è·³è¿‡
                if idx in processed_indices:
                    self.logger.debug(f"â­ï¸ è·³è¿‡å·²å¤„ç†æ®µ {idx}")
                    continue

                # æ£€æŸ¥å–æ¶ˆå’Œæš‚åœæ ‡å¿—
                if job.canceled:
                    raise RuntimeError('ä»»åŠ¡å·²å–æ¶ˆ')

                if job.paused:
                    raise RuntimeError('ä»»åŠ¡å·²æš‚åœ')

                # ã€å†…å­˜ç›‘æŽ§ã€‘å®šæœŸæ£€æŸ¥å†…å­˜çŠ¶æ€ï¼ˆæ¯10æ®µæ£€æŸ¥ä¸€æ¬¡ï¼‰
                if idx % 10 == 0 and processing_mode == ProcessingMode.MEMORY:
                    if not self._check_memory_during_transcription(job):
                        # å†…å­˜ä¸¥é‡ä¸è¶³ï¼Œä»»åŠ¡å·²æš‚åœ
                        raise RuntimeError('å†…å­˜ä¸è¶³ï¼Œä»»åŠ¡å·²æš‚åœ')

                ratio = len(processed_indices) / max(1, len(current_segments))
                self._update_progress(
                    job,
                    'transcribe',
                    ratio,
                    f'è½¬å½• {len(processed_indices)+1}/{len(current_segments)}'
                )

                # ç¡®ä¿segmentæœ‰indexå­—æ®µ
                if 'index' not in seg:
                    seg['index'] = idx

                # ã€ç»Ÿä¸€å…¥å£ã€‘ä½¿ç”¨åŒæ¨¡å¼è½¬å½•ï¼ˆè‡ªåŠ¨æ ¹æ®modeå­—æ®µé€‰æ‹©ï¼‰
                seg_result = self._transcribe_segment(
                    seg,
                    model,
                    job,
                    audio_array=audio_array  # å†…å­˜æ¨¡å¼ä¼ æ•°ç»„ï¼Œç¡¬ç›˜æ¨¡å¼ä¸ºNone
                )

                # --- æ›´æ–°å†…å­˜çŠ¶æ€ ---
                if seg_result:
                    unaligned_results.append(seg_result)
                processed_indices.add(idx)
                job.processed = len(processed_indices)

                # --- æ›´æ–°è¿›åº¦æ¡ ---
                progress = len(processed_indices) / len(current_segments)
                self._update_progress(
                    job,
                    'transcribe',
                    progress,
                    f'è½¬å½•ä¸­ {len(processed_indices)}/{len(current_segments)}'
                )

                # ã€æµå¼è¾“å‡ºã€‘ç«‹å³æŽ¨é€å•ä¸ªsegmentçš„è½¬å½•ç»“æžœ
                if seg_result:
                    self._push_sse_segment(job, seg_result, len(processed_indices), len(current_segments))

                # ã€å…³é”®åŸ‹ç‚¹2ã€‘æ¯å¤„ç†ä¸€æ®µä¿å­˜ä¸€æ¬¡ï¼ˆä¿å­˜æœªå¯¹é½ç»“æžœï¼‰
                checkpoint_data = {
                    "job_id": job.job_id,
                    "phase": "transcribe",
                    "processing_mode": processing_mode.value,  # ä¿å­˜æ¨¡å¼ä¿¡æ¯
                    "total_segments": len(current_segments),
                    "processed_indices": list(processed_indices),  # setè½¬list
                    "segments": current_segments,
                    "unaligned_results": unaligned_results  # ä¿å­˜æœªå¯¹é½ç»“æžœ
                }
                self._save_checkpoint(job_dir, checkpoint_data, job)
                self.logger.debug(f"æ£€æŸ¥ç‚¹å·²ä¿å­˜: {len(processed_indices)}/{len(current_segments)}")

            self._update_progress(job, 'transcribe', 1, 'è½¬å½•å®Œæˆ')
            if job.canceled:
                raise RuntimeError('ä»»åŠ¡å·²å–æ¶ˆ')

            # ==========================================
            # 7. é˜¶æ®µ4: æ‰¹æ¬¡å¯¹é½ï¼ˆä½¿ç”¨æ‰¹æ¬¡å¯¹é½+SSEè¿›åº¦æŽ¨é€ï¼‰
            # ==========================================
            self._update_progress(job, 'align', 0, 'å‡†å¤‡å¯¹é½...')

            # æ ¹æ®å¤„ç†æ¨¡å¼é€‰æ‹©éŸ³é¢‘æº
            if processing_mode == ProcessingMode.MEMORY and audio_array is not None:
                # å†…å­˜æ¨¡å¼ï¼šå¤ç”¨å†…å­˜æ•°ç»„ï¼ˆé¿å…é‡æ–°åŠ è½½ï¼‰
                audio_source = audio_array
                self.logger.info("å¯¹é½é˜¶æ®µï¼šå¤ç”¨å†…å­˜éŸ³é¢‘æ•°ç»„")
            else:
                # ç¡¬ç›˜æ¨¡å¼ï¼šä¼ é€’éŸ³é¢‘æ–‡ä»¶è·¯å¾„
                audio_source = str(audio_path)
                self.logger.info("å¯¹é½é˜¶æ®µï¼šä»Žç£ç›˜åŠ è½½éŸ³é¢‘")

            # ä½¿ç”¨æ‰¹æ¬¡å¯¹é½æ–¹æ³•ï¼ˆæ”¯æŒSSEè¿›åº¦æŽ¨é€ï¼‰
            aligned_results = self._align_all_results_batched(
                unaligned_results,
                job,
                audio_source,
                processing_mode
            )

            # ã€æµå¼è¾“å‡ºã€‘æŽ¨é€å¯¹é½å®Œæˆäº‹ä»¶
            self._push_sse_aligned(job, aligned_results)

            if job.canceled:
                raise RuntimeError('ä»»åŠ¡å·²å–æ¶ˆ')

            # ==========================================
            # 6. é˜¶æ®µ5: ç”ŸæˆSRT
            # ==========================================
            base_name = os.path.splitext(job.filename)[0]
            srt_path = job_dir / f'{base_name}.srt'
            self._update_progress(job, 'srt', 0, 'å†™å…¥ SRT...')
            self._generate_srt(
                aligned_results,
                str(srt_path),
                job.settings.word_timestamps
            )
            self._update_progress(job, 'srt', 1, 'å¤„ç†å®Œæˆ')

            job.srt_path = str(srt_path)

            # ã€æ¸…ç†ã€‘ä»»åŠ¡æˆåŠŸå®ŒæˆåŽï¼Œåˆ é™¤ checkpoint
            try:
                checkpoint_file = job_dir / "checkpoint.json"
                checkpoint_file.unlink(missing_ok=True)
                self.logger.info("æ£€æŸ¥ç‚¹å·²æ¸…ç†")
            except Exception as e:
                self.logger.warning(f"æ¸…ç†æ£€æŸ¥ç‚¹å¤±è´¥: {e}")

            if job.canceled:
                job.status = 'canceled'
                job.message = 'å·²å–æ¶ˆ'
                # æŽ¨é€å–æ¶ˆä¿¡å·
                self._push_sse_signal(job, "job_canceled", "ä»»åŠ¡å·²å–æ¶ˆ")
            else:
                job.status = 'finished'
                job.message = 'å®Œæˆ'
                self.logger.info(f"ä»»åŠ¡å®Œæˆ: {job.job_id}")
                # æŽ¨é€å®Œæˆä¿¡å·
                self._push_sse_signal(job, "job_complete", "è½¬å½•å®Œæˆ")

        except Exception as e:
            if job.canceled and 'å–æ¶ˆ' in str(e):
                job.status = 'canceled'
                job.message = 'å·²å–æ¶ˆ'
                self.logger.info(f"ðŸ›‘ ä»»åŠ¡å·²å–æ¶ˆ: {job.job_id}")
                # æŽ¨é€å–æ¶ˆä¿¡å·
                self._push_sse_signal(job, "job_canceled", "ä»»åŠ¡å·²å–æ¶ˆ")
            elif job.paused and 'æš‚åœ' in str(e):
                job.status = 'paused'
                job.message = 'å·²æš‚åœ'
                self.logger.info(f"â¸ï¸ ä»»åŠ¡å·²æš‚åœ: {job.job_id}")
                # æŽ¨é€æš‚åœä¿¡å·
                self._push_sse_signal(job, "job_paused", "ä»»åŠ¡å·²æš‚åœ")
            else:
                job.status = 'failed'
                job.message = f'å¤±è´¥: {e}'
                job.error = str(e)
                self.logger.error(f"ä»»åŠ¡å¤±è´¥: {job.job_id} - {e}", exc_info=True)
                # æŽ¨é€å¤±è´¥ä¿¡å·
                self._push_sse_signal(job, "job_failed", f"ä»»åŠ¡å¤±è´¥: {e}")

        finally:
            # æ¢å¤CPUäº²å’Œæ€§è®¾ç½®
            if cpu_applied:
                restored = self.cpu_manager.restore_cpu_affinity()
                if restored:
                    self.logger.info(f"ä»»åŠ¡ {job.job_id} å·²æ¢å¤CPUäº²å’Œæ€§è®¾ç½®")

            # é‡Šæ”¾å†…å­˜
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()

    # ========== æ ¸å¿ƒå¤„ç†æ–¹æ³• ==========

    def _get_audio_duration(self, audio_path: str) -> float:
        """
        èŽ·å–éŸ³é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰

        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„

        Returns:
            float: éŸ³é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰
        """
        try:
            # æ–¹æ³•1: ä½¿ç”¨pydubï¼ˆç²¾ç¡®ä½†è¾ƒæ…¢ï¼‰
            audio = AudioSegment.from_wav(audio_path)
            duration = len(audio) / 1000.0
            self.logger.debug(f"éŸ³é¢‘æ—¶é•¿ï¼ˆpydubï¼‰: {duration:.1f}ç§’")
            return duration
        except Exception as e:
            self.logger.warning(f"pydubèŽ·å–æ—¶é•¿å¤±è´¥ï¼Œä½¿ç”¨æ–‡ä»¶å¤§å°ä¼°ç®—: {e}")
            # æ–¹æ³•2: æ ¹æ®æ–‡ä»¶å¤§å°ä¼°ç®—ï¼ˆ16kHz, 16bit, mono â‰ˆ 32KB/ç§’ï¼‰
            try:
                file_size = os.path.getsize(audio_path)
                duration = file_size / 32000
                self.logger.debug(f"éŸ³é¢‘æ—¶é•¿ï¼ˆä¼°ç®—ï¼‰: {duration:.1f}ç§’")
                return duration
            except Exception as e2:
                self.logger.error(f"èŽ·å–éŸ³é¢‘æ—¶é•¿å¤±è´¥: {e2}")
                return 0.0

    def _decide_processing_mode(self, audio_path: str, job: JobState) -> ProcessingMode:
        """
        æ™ºèƒ½å†³ç­–å¤„ç†æ¨¡å¼ï¼ˆå†…å­˜æ¨¡å¼ vs ç¡¬ç›˜æ¨¡å¼ï¼‰

        å†³ç­–é€»è¾‘ï¼š
        1. ä¼°ç®—éŸ³é¢‘å†…å­˜éœ€æ±‚
        2. æ£€æµ‹ç³»ç»Ÿå¯ç”¨å†…å­˜
        3. é¢„ç•™å®‰å…¨ä½™é‡ï¼ˆæ¨¡åž‹ã€è½¬å½•ä¸­é—´å˜é‡ç­‰ï¼‰
        4. å†³å®šä½¿ç”¨å“ªç§æ¨¡å¼

        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            job: ä»»åŠ¡çŠ¶æ€å¯¹è±¡

        Returns:
            ProcessingMode: å¤„ç†æ¨¡å¼
        """
        # èŽ·å–éŸ³é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰
        audio_duration_sec = self._get_audio_duration(audio_path)

        # ä¼°ç®—éŸ³é¢‘å†…å­˜éœ€æ±‚ (16kHz, float32)
        # å…¬å¼: duration * 16000 * 4 bytes
        estimated_audio_mb = (audio_duration_sec * 16000 * 4) / (1024 * 1024)

        # é¢„ç•™é¢å¤–å†…å­˜ï¼ˆæ¨¡åž‹åŠ è½½ã€VADå¤„ç†ã€è½¬å½•ä¸­é—´å˜é‡ç­‰ï¼‰
        # ä¿å®ˆä¼°è®¡ï¼šéŸ³é¢‘å†…å­˜çš„2å€ + 500MBåŸºç¡€å¼€é”€
        total_estimated_mb = estimated_audio_mb * 2 + 500

        # èŽ·å–ç³»ç»Ÿå¯ç”¨å†…å­˜
        mem_info = psutil.virtual_memory()
        available_mb = mem_info.available / (1024 * 1024)
        total_mb = mem_info.total / (1024 * 1024)

        # å®‰å…¨é˜ˆå€¼ï¼šè‡³å°‘ä¿ç•™ç³»ç»Ÿæ€»å†…å­˜çš„20%æˆ–2GBï¼ˆå–è¾ƒå¤§å€¼ï¼‰
        safety_reserve_mb = max(total_mb * 0.2, 2048)
        usable_mb = available_mb - safety_reserve_mb

        self.logger.info(f"å†…å­˜è¯„ä¼°:")
        self.logger.info(f"éŸ³é¢‘æ—¶é•¿: {audio_duration_sec/60:.1f}åˆ†é’Ÿ")
        self.logger.info(f"é¢„ä¼°éœ€æ±‚: {total_estimated_mb:.0f}MB")
        self.logger.info(f"å¯ç”¨å†…å­˜: {available_mb:.0f}MB")
        self.logger.info(f"å®‰å…¨ä½™é‡: {safety_reserve_mb:.0f}MB")
        self.logger.info(f"å¯ç”¨äºŽå¤„ç†: {usable_mb:.0f}MB")

        # å†³ç­–
        if usable_mb >= total_estimated_mb:
            self.logger.info("é€‰æ‹©ã€å†…å­˜æ¨¡å¼ã€‘- å†…å­˜å……è¶³ï¼Œä½¿ç”¨é«˜æ€§èƒ½æ¨¡å¼")
            job.message = "å†…å­˜å……è¶³ï¼Œä½¿ç”¨é«˜æ€§èƒ½æ¨¡å¼"
            return ProcessingMode.MEMORY
        else:
            self.logger.warning(f"é€‰æ‹©ã€ç¡¬ç›˜æ¨¡å¼ã€‘- å†…å­˜ä¸è¶³ï¼ˆéœ€è¦{total_estimated_mb:.0f}MBï¼Œå¯ç”¨{usable_mb:.0f}MBï¼‰")
            job.message = "å†…å­˜å—é™ï¼Œä½¿ç”¨ç¨³å®šæ¨¡å¼"
            return ProcessingMode.DISK

    def _safe_load_audio(self, audio_path: str, job: JobState) -> np.ndarray:
        """
        å®‰å…¨åŠ è½½éŸ³é¢‘åˆ°å†…å­˜ï¼ˆå¸¦å¼‚å¸¸å¤„ç†ï¼‰

        ç”¨äºŽå†…å­˜æ¨¡å¼ä¸‹å°†å®Œæ•´éŸ³é¢‘ä¸€æ¬¡æ€§åŠ è½½åˆ°å†…å­˜ä¸­ã€‚
        åŒ…å«åŠ è½½éªŒè¯å’Œè¯¦ç»†çš„å¼‚å¸¸å¤„ç†ï¼ŒåŠ è½½å¤±è´¥æ—¶æŠ›å‡ºRuntimeErrorè§¦å‘é™çº§ã€‚

        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            job: ä»»åŠ¡çŠ¶æ€å¯¹è±¡ï¼ˆç”¨äºŽæ›´æ–°çŠ¶æ€æ¶ˆæ¯ï¼‰

        Returns:
            np.ndarray: éŸ³é¢‘æ•°ç»„ï¼ˆfloat32, 16kHzé‡‡æ ·çŽ‡ï¼‰

        Raises:
            RuntimeError: éŸ³é¢‘åŠ è½½å¤±è´¥æ—¶æŠ›å‡ºï¼Œè°ƒç”¨æ–¹å¯æ®æ­¤è§¦å‘ç¡¬ç›˜æ¨¡å¼é™çº§
        """
        try:
            self.logger.info(f"åŠ è½½éŸ³é¢‘åˆ°å†…å­˜: {audio_path}")
            audio_array = whisperx.load_audio(audio_path)

            # éªŒè¯åŠ è½½ç»“æžœ
            if audio_array is None or len(audio_array) == 0:
                raise ValueError("éŸ³é¢‘æ•°ç»„ä¸ºç©º")

            # è®°å½•åŠ è½½ä¿¡æ¯
            duration_sec = len(audio_array) / 16000
            memory_mb = audio_array.nbytes / (1024 * 1024)
            # Audio loaded: {duration_sec/60:.1f}åˆ†é’Ÿ")
            self.logger.info(f"å†…å­˜å ç”¨: {memory_mb:.1f}MB")
            self.logger.info(f"é‡‡æ ·ç‚¹æ•°: {len(audio_array):,}")

            return audio_array

        except MemoryError as e:
            self.logger.error(f"å†…å­˜ä¸è¶³ï¼Œæ— æ³•åŠ è½½éŸ³é¢‘: {e}")
            job.message = "å†…å­˜ä¸è¶³ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°ç¡¬ç›˜æ¨¡å¼"
            raise RuntimeError(f"å†…å­˜ä¸è¶³: {e}")

        except Exception as e:
            self.logger.error(f"éŸ³é¢‘åŠ è½½å¤±è´¥: {e}")
            job.message = f"éŸ³é¢‘åŠ è½½å¤±è´¥: {e}"
            raise RuntimeError(f"éŸ³é¢‘åŠ è½½å¤±è´¥ï¼ˆå¯èƒ½æ–‡ä»¶æŸåï¼‰: {e}")

    def _split_audio_in_memory(
        self,
        audio_array: np.ndarray,
        sr: int = 16000,
        vad_config: Optional[VADConfig] = None
    ) -> List[Dict]:
        """
        å†…å­˜VADåˆ†æ®µï¼ˆä¸äº§ç”Ÿç£ç›˜IOï¼‰

        é»˜è®¤ä½¿ç”¨Silero VADï¼ˆæ— éœ€è®¤è¯ï¼‰ï¼Œå¯é€šè¿‡é…ç½®åˆ‡æ¢åˆ°Pyannote VADã€‚
        å½“VADæ¨¡åž‹åŠ è½½å¤±è´¥æ—¶ï¼Œè‡ªåŠ¨é™çº§åˆ°åŸºäºŽèƒ½é‡çš„ç®€æ˜“åˆ†æ®µã€‚

        Args:
            audio_array: å®Œæ•´éŸ³é¢‘æ•°ç»„ (np.ndarray, float32, 16kHz)
            sr: é‡‡æ ·çŽ‡ï¼ˆé»˜è®¤16000Hzï¼‰
            vad_config: VADé…ç½®ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨Sileroï¼‰

        Returns:
            List[Dict]: åˆ†æ®µå…ƒæ•°æ®åˆ—è¡¨
            [
                {"index": 0, "start": 0.0, "end": 30.5, "mode": "memory"},
                {"index": 1, "start": 30.5, "end": 58.2, "mode": "memory"},
                ...
            ]
        """
        # ä½¿ç”¨é»˜è®¤é…ç½®
        if vad_config is None:
            vad_config = VADConfig()

        self.logger.info(f"å¼€å§‹å†…å­˜VADåˆ†æ®µ (æ¨¡åž‹: {vad_config.method.value})...")

        try:
            # æ ¹æ®é…ç½®é€‰æ‹©VADæ¨¡åž‹
            if vad_config.method == VADMethod.SILERO:
                segments = self._vad_silero(audio_array, sr, vad_config)
            else:
                segments = self._vad_pyannote(audio_array, sr, vad_config)

            self.logger.info(f"VADåˆ†æ®µå®Œæˆ: {len(segments)}æ®µ (æ¨¡åž‹: {vad_config.method.value})")
            return segments

        except Exception as e:
            self.logger.error(f"VADåˆ†æ®µå¤±è´¥: {e}")
            # é™çº§åˆ°ç®€æ˜“èƒ½é‡æ£€æµ‹
            self.logger.warning("å°è¯•é™çº§åˆ°èƒ½é‡æ£€æµ‹åˆ†æ®µ...")
            return self._energy_based_split(audio_array, sr, vad_config.chunk_size)

    def _vad_silero(
        self,
        audio_array: np.ndarray,
        sr: int,
        vad_config: VADConfig
    ) -> List[Dict]:
        """
        Silero VADåˆ†æ®µï¼ˆä½¿ç”¨å†…ç½®ONNXæ¨¡åž‹ï¼Œæ— éœ€ä¸‹è½½ï¼‰

        ä¼˜ç‚¹ï¼š
        - ä½¿ç”¨é¡¹ç›®å†…ç½®ONNXæ¨¡åž‹ï¼Œæ— éœ€ç½‘ç»œä¸‹è½½
        - ä½¿ç”¨ onnxruntime æŽ¨ç†ï¼Œè·¨å¹³å°å…¼å®¹æ€§å¥½
        - é€Ÿåº¦å¿«ï¼Œå†…å­˜å ç”¨ä½Žï¼ˆ~2MBï¼‰

        Args:
            audio_array: éŸ³é¢‘æ•°ç»„
            sr: é‡‡æ ·çŽ‡
            vad_config: VADé…ç½®

        Returns:
            List[Dict]: åˆ†æ®µå…ƒæ•°æ®åˆ—è¡¨
        """
        self.logger.info("åŠ è½½Silero VADæ¨¡åž‹ï¼ˆå†…ç½®ONNXï¼‰...")

        # ä½¿ç”¨ silero-vad åº“ï¼ˆåŸºäºŽ onnxruntimeï¼‰
        from silero_vad import get_speech_timestamps
        from silero_vad.utils_vad import OnnxWrapper
        from pathlib import Path as PathlibPath

        # ä½¿ç”¨é¡¹ç›®å†…ç½®çš„ ONNX æ¨¡åž‹
        builtin_model_path = PathlibPath(__file__).parent.parent / "assets" / "silero" / "silero_vad.onnx"

        if not builtin_model_path.exists():
            raise FileNotFoundError(
                f"å†…ç½®Silero VADæ¨¡åž‹ä¸å­˜åœ¨: {builtin_model_path}\n"
                "è¯·ç¡®ä¿é¡¹ç›®å®Œæ•´ï¼Œæˆ–é‡æ–°ä»Žæºç ä»“åº“èŽ·å–"
            )

        self.logger.info(f"ä½¿ç”¨å†…ç½®æ¨¡åž‹: {builtin_model_path}")

        # åŠ è½½ONNXæ¨¡åž‹ï¼ˆç›´æŽ¥ä»Žæœ¬åœ°è·¯å¾„ï¼‰
        model = OnnxWrapper(str(builtin_model_path), force_onnx_cpu=False)

        # è½¬æ¢ä¸ºtorch tensorï¼ˆsilero-vad éœ€è¦ï¼‰
        audio_tensor = torch.from_numpy(audio_array)

        # èŽ·å–è¯­éŸ³æ—¶é—´æˆ³
        speech_timestamps = get_speech_timestamps(
            audio_tensor,
            model,
            sampling_rate=sr,
            threshold=vad_config.onset,      # æ£€æµ‹é˜ˆå€¼
            min_speech_duration_ms=250,       # æœ€å°è¯­éŸ³æ®µé•¿åº¦
            min_silence_duration_ms=100,      # æœ€å°é™éŸ³é•¿åº¦
            return_seconds=False  # è¿”å›žé‡‡æ ·ç‚¹è€Œéžç§’æ•°
        )

        # VAD detection complete

        # åˆå¹¶åˆ†æ®µï¼ˆç¡®ä¿æ¯æ®µä¸è¶…è¿‡chunk_sizeç§’ï¼‰
        segments_metadata = []
        current_start = None
        current_end = None

        for ts in speech_timestamps:
            start_sec = ts['start'] / sr
            end_sec = ts['end'] / sr

            if current_start is None:
                current_start = start_sec
                current_end = end_sec
            elif (end_sec - current_start) <= vad_config.chunk_size:
                # å¯ä»¥åˆå¹¶
                current_end = end_sec
            else:
                # ä¿å­˜å½“å‰æ®µï¼Œå¼€å§‹æ–°æ®µ
                segments_metadata.append({
                    "index": len(segments_metadata),
                    "start": current_start,
                    "end": current_end,
                    "mode": "memory"
                })
                current_start = start_sec
                current_end = end_sec

        # ä¿å­˜æœ€åŽä¸€æ®µ
        if current_start is not None:
            segments_metadata.append({
                "index": len(segments_metadata),
                "start": current_start,
                "end": current_end,
                "mode": "memory"
            })

        # å¦‚æžœæ²¡æœ‰æ£€æµ‹åˆ°ä»»ä½•è¯­éŸ³æ®µï¼ŒæŒ‰å›ºå®šæ—¶é•¿åˆ†æ®µ
        if len(segments_metadata) == 0:
            self.logger.warning("VADæœªæ£€æµ‹åˆ°è¯­éŸ³ï¼Œä½¿ç”¨å›ºå®šæ—¶é•¿åˆ†æ®µ")
            return self._energy_based_split(audio_array, sr, vad_config.chunk_size)

        return segments_metadata

    def _vad_pyannote(
        self,
        audio_array: np.ndarray,
        sr: int,
        vad_config: VADConfig
    ) -> List[Dict]:
        """
        Pyannote VADåˆ†æ®µï¼ˆé«˜ç²¾åº¦æ–¹æ¡ˆï¼Œéœ€è¦HF Tokenï¼‰

        ä¼˜ç‚¹ï¼š
        - ç²¾åº¦æ›´é«˜
        - æ”¯æŒæ›´å¤æ‚çš„è¯­éŸ³æ´»åŠ¨æ£€æµ‹

        æ³¨æ„ï¼š
        - éœ€è¦HuggingFace Token
        - é¦–æ¬¡ä½¿ç”¨éœ€è¦æŽ¥å—æ¨¡åž‹ä½¿ç”¨åè®®

        Args:
            audio_array: éŸ³é¢‘æ•°ç»„
            sr: é‡‡æ ·çŽ‡
            vad_config: VADé…ç½®

        Returns:
            List[Dict]: åˆ†æ®µå…ƒæ•°æ®åˆ—è¡¨

        Raises:
            ValueError: æœªé…ç½®HF Tokenæ—¶æŠ›å‡º
        """
        if not vad_config.hf_token:
            raise ValueError("Pyannote VADéœ€è¦HuggingFace Tokenï¼Œè¯·åœ¨è®¾ç½®ä¸­é…ç½®")

        self.logger.info("åŠ è½½Pyannote VADæ¨¡åž‹ï¼ˆéœ€è¦HF Tokenï¼‰...")

        try:
            from pyannote.audio import Pipeline
        except ImportError:
            raise RuntimeError("Pyannoteæœªå®‰è£…ï¼Œè¯·ä½¿ç”¨Silero VADæˆ–å®‰è£…pyannote-audio")

        # åˆå§‹åŒ–Pyannote VAD Pipeline
        pipeline = Pipeline.from_pretrained(
            "pyannote/voice-activity-detection",
            use_auth_token=vad_config.hf_token
        )

        # å‡†å¤‡è¾“å…¥ï¼ˆPyannoteéœ€è¦ç‰¹å®šæ ¼å¼ï¼‰
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶ç”¨äºŽPyannoteå¤„ç†
        import tempfile
        import soundfile as sf

        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as f:
            temp_path = f.name
            sf.write(temp_path, audio_array, sr)

        try:
            # æ‰§è¡ŒVAD
            vad_result = pipeline(temp_path)

            # åˆå¹¶åˆ†æ®µ
            segments_metadata = []
            current_start = None
            current_end = None

            for speech in vad_result.get_timeline().support():
                start_sec = speech.start
                end_sec = speech.end

                if current_start is None:
                    current_start = start_sec
                    current_end = end_sec
                elif (end_sec - current_start) <= vad_config.chunk_size:
                    current_end = end_sec
                else:
                    segments_metadata.append({
                        "index": len(segments_metadata),
                        "start": current_start,
                        "end": current_end,
                        "mode": "memory"
                    })
                    current_start = start_sec
                    current_end = end_sec

            # ä¿å­˜æœ€åŽä¸€æ®µ
            if current_start is not None:
                segments_metadata.append({
                    "index": len(segments_metadata),
                    "start": current_start,
                    "end": current_end,
                    "mode": "memory"
                })

            return segments_metadata

        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(temp_path):
                os.unlink(temp_path)

    def _energy_based_split(
        self,
        audio_array: np.ndarray,
        sr: int,
        chunk_size: int = 30
    ) -> List[Dict]:
        """
        åŸºäºŽèƒ½é‡çš„ç®€æ˜“åˆ†æ®µï¼ˆé™çº§æ–¹æ¡ˆï¼‰

        å½“VADæ¨¡åž‹åŠ è½½å¤±è´¥æ—¶ä½¿ç”¨ï¼ŒæŒ‰å›ºå®šæ—¶é•¿åˆ†æ®µã€‚
        ä¼šå°è¯•åœ¨é™éŸ³å¤„åˆ†å‰²ä»¥é¿å…åˆ‡æ–­è¯­éŸ³ã€‚

        Args:
            audio_array: éŸ³é¢‘æ•°ç»„
            sr: é‡‡æ ·çŽ‡
            chunk_size: æ¯æ®µæœ€å¤§é•¿åº¦ï¼ˆç§’ï¼‰

        Returns:
            List[Dict]: åˆ†æ®µå…ƒæ•°æ®åˆ—è¡¨
        """
        self.logger.warning("ä½¿ç”¨èƒ½é‡æ£€æµ‹é™çº§åˆ†æ®µï¼ˆå›ºå®šæ—¶é•¿ï¼‰")

        total_duration = len(audio_array) / sr
        segments_metadata = []
        pos = 0.0

        while pos < total_duration:
            # è®¡ç®—ç†æƒ³ç»“æŸä½ç½®
            ideal_end = min(pos + chunk_size, total_duration)

            # å°è¯•åœ¨é™éŸ³å¤„åˆ†å‰²ï¼ˆåœ¨ç†æƒ³ç»“æŸç‚¹å‰åŽ1ç§’èŒƒå›´å†…å¯»æ‰¾ï¼‰
            if ideal_end < total_duration:
                search_start = max(pos, ideal_end - 1.0)
                search_end = min(total_duration, ideal_end + 1.0)

                # è®¡ç®—æœç´¢èŒƒå›´å†…çš„èƒ½é‡
                start_sample = int(search_start * sr)
                end_sample = int(search_end * sr)
                search_audio = audio_array[start_sample:end_sample]

                if len(search_audio) > 0:
                    # è®¡ç®—çŸ­æ—¶èƒ½é‡ï¼ˆæ¯100msä¸€ä¸ªçª—å£ï¼‰
                    window_size = int(0.1 * sr)
                    energies = []
                    for i in range(0, len(search_audio) - window_size, window_size):
                        window = search_audio[i:i + window_size]
                        energy = np.sum(window ** 2)
                        energies.append((i, energy))

                    if energies:
                        # æ‰¾åˆ°èƒ½é‡æœ€ä½Žçš„ç‚¹
                        min_energy_idx = min(energies, key=lambda x: x[1])[0]
                        actual_end = search_start + (min_energy_idx / sr)
                        # ç¡®ä¿åˆ†æ®µè‡³å°‘æœ‰1ç§’
                        if actual_end - pos >= 1.0:
                            ideal_end = actual_end

            segments_metadata.append({
                "index": len(segments_metadata),
                "start": pos,
                "end": ideal_end,
                "mode": "memory"
            })
            pos = ideal_end

        self.logger.info(f"èƒ½é‡æ£€æµ‹åˆ†æ®µå®Œæˆ: {len(segments_metadata)}æ®µ")
        return segments_metadata

    def _extract_audio(self, input_file: str, audio_out: str) -> bool:
        """
        ä½¿ç”¨FFmpegæå–éŸ³é¢‘

        Args:
            input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„
            audio_out: è¾“å‡ºéŸ³é¢‘è·¯å¾„

        Returns:
            bool: æ˜¯å¦æå–æˆåŠŸ
        """
        if os.path.exists(audio_out):
            self.logger.debug(f"éŸ³é¢‘æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡æå–: {audio_out}")
            return True

        # ä½¿ç”¨é…ç½®ä¸­çš„FFmpegå‘½ä»¤ï¼ˆæ”¯æŒç‹¬ç«‹æ‰“åŒ…ï¼‰
        ffmpeg_cmd = config.get_ffmpeg_command()
        self.logger.debug(f"ä½¿ç”¨FFmpeg: {ffmpeg_cmd}")

        cmd = [
            ffmpeg_cmd, '-y', '-i', input_file,
            '-vn',                    # ä»…éŸ³é¢‘
            '-ac', '1',               # å•å£°é“
            '-ar', '16000',           # 16kHz é‡‡æ ·çŽ‡
            '-acodec', 'pcm_s16le',   # PCM ç¼–ç 
            audio_out
        ]

        try:
            proc = subprocess.run(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                timeout=600  # 10åˆ†é’Ÿè¶…æ—¶
            )

            if proc.returncode == 0 and os.path.exists(audio_out):
                self.logger.debug(f"éŸ³é¢‘æå–æˆåŠŸ: {audio_out}")
                return True
            else:
                error_msg = proc.stderr.decode('utf-8', errors='ignore')
                self.logger.error(f"FFmpegæ‰§è¡Œå¤±è´¥: {error_msg}")
                return False

        except subprocess.TimeoutExpired:
            self.logger.error("FFmpegè¶…æ—¶")
            return False
        except Exception as e:
            self.logger.error(f"éŸ³é¢‘æå–å¤±è´¥: {e}")
            return False

    def _split_audio_to_disk(self, audio_path: str) -> List[Dict]:
        """
        ç¡¬ç›˜åˆ†æ®µæ¨¡å¼ï¼ˆä¿ç•™åŽŸæœ‰é€»è¾‘ï¼‰

        ä½¿ç”¨pydubè¿›è¡Œé™éŸ³æ£€æµ‹ï¼Œç”Ÿæˆsegment_N.wavæ–‡ä»¶ã€‚
        é€‚ç”¨äºŽå†…å­˜ä¸è¶³çš„åœºæ™¯ã€‚

        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„

        Returns:
            List[Dict]: åˆ†æ®µä¿¡æ¯åˆ—è¡¨ï¼Œä¸Žå†…å­˜æ¨¡å¼æ ¼å¼ç»Ÿä¸€
            [
                {"index": 0, "file": "segment_0.wav", "start": 0.0, "end": 30.0, "start_ms": 0, "duration_ms": 30000, "mode": "disk"},
                ...
            ]
        """
        self.logger.info("å¼€å§‹ç¡¬ç›˜åˆ†æ®µï¼ˆpydubé™éŸ³æ£€æµ‹ï¼‰...")

        # ä½¿ç”¨é…ç½®ä¸­çš„éŸ³é¢‘å¤„ç†å‚æ•°
        audio_config = config.get_audio_config()
        SEGMENT_LEN_MS = audio_config['segment_length_ms']
        SILENCE_SEARCH_MS = audio_config['silence_search_ms']
        MIN_SILENCE_LEN_MS = audio_config['min_silence_len_ms']
        SILENCE_THRESH_DBFS = audio_config['silence_threshold_dbfs']

        audio = AudioSegment.from_wav(audio_path)
        length = len(audio)
        segments = []
        pos = 0
        idx = 0

        while pos < length:
            end = min(pos + SEGMENT_LEN_MS, length)

            # æ™ºèƒ½å¯»æ‰¾é™éŸ³ç‚¹ï¼ˆé¿å…åœ¨å¥å­ä¸­é—´åˆ†å‰²ï¼‰
            if end < length and (end - pos) > SILENCE_SEARCH_MS:
                search_start = max(pos, endSILENCE_SEARCH_MS)
                search_chunk = audio[search_start:end]

                try:
                    silences = silence.detect_silence(
                        search_chunk,
                        min_silence_len=MIN_SILENCE_LEN_MS,
                        silence_thresh=SILENCE_THRESH_DBFS
                    )

                    if silences:
                        # ä½¿ç”¨ç¬¬ä¸€ä¸ªé™éŸ³ç‚¹
                        silence_start = silences[0][0]
                        new_end = search_start + silence_start
                        if new_end - pos > MIN_SILENCE_LEN_MS:
                            end = new_end
                except Exception as e:
                    self.logger.warning(f"silence detection failed: {e}")

            # å¯¼å‡ºåˆ†æ®µæ–‡ä»¶
            chunk = audio[pos:end]
            seg_file = os.path.join(os.path.dirname(audio_path), f'segment_{idx}.wav')
            chunk.export(seg_file, format='wav')

            # ç»Ÿä¸€è¿”å›žæ ¼å¼ï¼ˆä¸Žå†…å­˜æ¨¡å¼ä¸€è‡´ï¼‰
            segments.append({
                'index': idx,                    # æ–°å¢žï¼šåˆ†æ®µç´¢å¼•
                'file': seg_file,
                'start': pos / 1000.0,           # æ–°å¢žï¼šèµ·å§‹æ—¶é—´ï¼ˆç§’ï¼‰
                'end': end / 1000.0,             # æ–°å¢žï¼šç»“æŸæ—¶é—´ï¼ˆç§’ï¼‰
                'start_ms': pos,                 # ä¿ç•™ï¼šå…¼å®¹æ—§ä»£ç 
                'duration_ms': end - pos,        # ä¿ç•™ï¼šå…¼å®¹æ—§ä»£ç 
                'mode': 'disk'                   # æ–°å¢žï¼šæ¨¡å¼æ ‡è®°
            })

            pos = end
            idx += 1

        self.logger.info(f"disk segmentation complete: {len(segments)} segments (with segment files)")
        return segments

    # å…¼å®¹æ€§åˆ«åï¼šä¿ç•™æ—§æ–¹æ³•åï¼ˆæŒ‡å‘æ–°æ–¹æ³•ï¼‰
    def _split_audio(self, audio_path: str) -> List[Dict]:
        """å…¼å®¹æ€§åˆ«åï¼ŒæŒ‡å‘ _split_audio_to_disk()"""
        return self._split_audio_to_disk(audio_path)

    def _get_model(self, settings: JobSettings, job: Optional[JobState] = None):
        """
        èŽ·å–WhisperXæ¨¡åž‹ï¼ˆå¸¦ç¼“å­˜ï¼‰

        ä¼˜å…ˆä½¿ç”¨æ¨¡åž‹ç®¡ç†æœåŠ¡æ£€æŸ¥å¹¶ä¸‹è½½æ¨¡åž‹ï¼Œå¦åˆ™ä½¿ç”¨ç®€å•ç¼“å­˜

        Args:
            settings: ä»»åŠ¡è®¾ç½®
            job: ä»»åŠ¡çŠ¶æ€å¯¹è±¡(å¯é€‰,ç”¨äºŽæ›´æ–°ä¸‹è½½è¿›åº¦)

        Returns:
            æ¨¡åž‹å¯¹è±¡
        """
        # å°è¯•ä½¿ç”¨æ¨¡åž‹ç®¡ç†æœåŠ¡æ£€æŸ¥å¹¶ä¸‹è½½æ¨¡åž‹
        try:
            from services.model_manager_service import get_model_manager
            model_mgr = get_model_manager()
            whisper_model_info = model_mgr.whisper_models.get(settings.model)

            if whisper_model_info:
                # æ£€æŸ¥æ¨¡åž‹çŠ¶æ€
                if whisper_model_info.status == "not_downloaded" or whisper_model_info.status == "incomplete":
                    self.logger.warning(f"Whisperæ¨¡åž‹æœªä¸‹è½½æˆ–ä¸å®Œæ•´: {settings.model}")

                    # èŽ·å–æ¨¡åž‹å¤§å°ä¿¡æ¯
                    model_size_mb = whisper_model_info.size_mb

                    # å¦‚æžœæ¨¡åž‹å¤§å°>=1GB,ç»™å‡ºç‰¹æ®Šæç¤º
                    download_msg = ""
                    if model_size_mb >= 1024:
                        size_gb = model_size_mb / 1024
                        download_msg = f"å½“å‰ä¸‹è½½æ¨¡åž‹å¤§äºŽ1GB ({size_gb:.1f}GB),è¯·è€å¿ƒç­‰å¾…"
                        self.logger.info(f"{download_msg}")
                    else:
                        download_msg = f"å¼€å§‹ä¸‹è½½æ¨¡åž‹ {settings.model} ({model_size_mb}MB)"

                    # æ›´æ–°ä»»åŠ¡çŠ¶æ€
                    if job:
                        job.message = download_msg

                    self.logger.info(f"è‡ªåŠ¨è§¦å‘ä¸‹è½½Whisperæ¨¡åž‹: {settings.model} ({model_size_mb}MB)")

                    # è§¦å‘ä¸‹è½½
                    success = model_mgr.download_whisper_model(settings.model)
                    if not success:
                        self.logger.warning(f"æ¨¡åž‹ç®¡ç†å™¨ä¸‹è½½å¤±è´¥æˆ–å·²åœ¨ä¸‹è½½ä¸­,å›žé€€åˆ°whisperx")
                        raise RuntimeError("æ¨¡åž‹ç®¡ç†å™¨ä¸‹è½½å¤±è´¥")

                    # ç­‰å¾…ä¸‹è½½å®Œæˆï¼ˆæœ€å¤šç­‰å¾…10åˆ†é’Ÿï¼‰
                    import time
                    max_wait_time = 600  # 10åˆ†é’Ÿ
                    wait_interval = 5  # æ¯5ç§’æ£€æŸ¥ä¸€æ¬¡
                    elapsed = 0

                    while elapsed < max_wait_time:
                        time.sleep(wait_interval)
                        elapsed += wait_interval

                        current_status = model_mgr.whisper_models[settings.model].status
                        progress = model_mgr.whisper_models[settings.model].download_progress

                        if current_status == "ready":
                            self.logger.info(f"Whisperæ¨¡åž‹ä¸‹è½½å®Œæˆ: {settings.model}")
                            if job:
                                job.message = f"æ¨¡åž‹ä¸‹è½½å®Œæˆ,å‡†å¤‡åŠ è½½"
                            break
                        elif current_status == "error":
                            self.logger.error(f"æ¨¡åž‹ç®¡ç†å™¨ä¸‹è½½å¤±è´¥,å›žé€€åˆ°whisperx")
                            raise RuntimeError(f"Whisperæ¨¡åž‹ä¸‹è½½å¤±è´¥: {settings.model}")
                        else:
                            # å¦‚æžœæ¨¡åž‹å¤§å°>=1GB,å®šæœŸæé†’ç”¨æˆ·è€å¿ƒç­‰å¾…
                            if model_size_mb >= 1024 and elapsed % 30 == 0:  # æ¯30ç§’æé†’ä¸€æ¬¡
                                wait_msg = f"å½“å‰ä¸‹è½½æ¨¡åž‹å¤§äºŽ1GB,è¯·è€å¿ƒç­‰å¾…... {progress:.1f}% ({elapsed}s/{max_wait_time}s)"
                                self.logger.info(f"{wait_msg}")
                                if job:
                                    job.message = wait_msg
                            else:
                                wait_msg = f"ç­‰å¾…æ¨¡åž‹ä¸‹è½½... {progress:.1f}%"
                                self.logger.info(f"{wait_msg} ({elapsed}s/{max_wait_time}s)")
                                # æ›´æ–°ä»»åŠ¡çŠ¶æ€(æ¯æ¬¡éƒ½æ›´æ–°,è¿™æ ·ç”¨æˆ·å¯ä»¥çœ‹åˆ°è¿›åº¦å˜åŒ–)
                                if job:
                                    job.message = wait_msg

                    if elapsed >= max_wait_time:
                        self.logger.error(f"æ¨¡åž‹ä¸‹è½½è¶…æ—¶,å›žé€€åˆ°whisperx")
                        raise TimeoutError(f"Whisperæ¨¡åž‹ä¸‹è½½è¶…æ—¶: {settings.model}")

        except Exception as e:
            self.logger.warning(f"æ¨¡åž‹ç®¡ç†æœåŠ¡æ£€æŸ¥å¤±è´¥,å›žé€€åˆ°whisperx: {e}")

        # å°è¯•ä½¿ç”¨æ¨¡åž‹é¢„åŠ è½½ç®¡ç†å™¨
        try:
            from services.model_preload_manager import get_model_manager as get_preload_manager
            model_manager = get_preload_manager()
            if model_manager:
                self.logger.debug("ä½¿ç”¨æ¨¡åž‹é¢„åŠ è½½ç®¡ç†å™¨èŽ·å–æ¨¡åž‹")
                if job:
                    job.message = "åŠ è½½æ¨¡åž‹ä¸­"
                return model_manager.get_model(settings)
        except Exception as e:
            self.logger.debug(f"æ— æ³•ä½¿ç”¨æ¨¡åž‹é¢„åŠ è½½ç®¡ç†å™¨ï¼Œå›žé€€åˆ°æœ¬åœ°ç¼“å­˜: {e}")
            pass

        # å›žé€€åˆ°ç®€å•ç¼“å­˜æœºåˆ¶
        key = (settings.model, settings.compute_type, settings.device)
        with _model_lock:
            if key in _model_cache:
                self.logger.debug(f"å‘½ä¸­æ¨¡åž‹ç¼“å­˜: {key}")
                if job:
                    job.message = "ä½¿ç”¨ç¼“å­˜çš„æ¨¡åž‹"
                return _model_cache[key]

            self.logger.info(f"åŠ è½½æ¨¡åž‹: {key}")
            if job:
                job.message = f"åŠ è½½æ¨¡åž‹ {settings.model}"

            # é¦–å…ˆå°è¯•ä»…ä½¿ç”¨æœ¬åœ°æ–‡ä»¶
            try:
                from core.config import config
                m = whisperx.load_model(
                    settings.model,
                    settings.device,
                    compute_type=settings.compute_type,
                    download_root=str(config.HF_CACHE_DIR),  # æŒ‡å®šç¼“å­˜è·¯å¾„
                    local_files_only=True  # ç¦æ­¢è‡ªåŠ¨ä¸‹è½½ï¼Œåªä½¿ç”¨æœ¬åœ°æ–‡ä»¶
                )
                _model_cache[key] = m
                if job:
                    job.message = "æ¨¡åž‹åŠ è½½å®Œæˆ"
                return m
            except Exception as e:
                self.logger.warning(f"æœ¬åœ°åŠ è½½å¤±è´¥,å…è®¸whisperxä¸‹è½½: {e}")
                if job:
                    job.message = "æœ¬åœ°æ¨¡åž‹ä¸å­˜åœ¨,ä½¿ç”¨whisperxä¸‹è½½"
                # å¦‚æžœæœ¬åœ°åŠ è½½å¤±è´¥,å…è®¸whisperxä¸‹è½½
                m = whisperx.load_model(
                    settings.model,
                    settings.device,
                    compute_type=settings.compute_type,
                    download_root=str(config.HF_CACHE_DIR),  # æŒ‡å®šç¼“å­˜è·¯å¾„
                    local_files_only=False  # å…è®¸ä¸‹è½½
                )
                _model_cache[key] = m
                if job:
                    job.message = "æ¨¡åž‹ä¸‹è½½å¹¶åŠ è½½å®Œæˆ"
                return m

    def _get_align_model(self, lang: str, device: str, job: Optional[JobState] = None):
        """
        èŽ·å–å¯¹é½æ¨¡åž‹ï¼ˆå¸¦LRUç¼“å­˜ï¼‰

        ç­–ç•¥:
        - ç¼“å­˜å‘½ä¸­ï¼šç§»åˆ°æœ«å°¾ï¼ˆæ ‡è®°ä¸ºæœ€è¿‘ä½¿ç”¨ï¼‰
        - ç¼“å­˜å·²æ»¡ï¼šåˆ é™¤æœ€ä¹…æœªä½¿ç”¨çš„æ¨¡åž‹
        - æœ€å¤šç¼“å­˜3ç§è¯­è¨€

        Args:
            lang: è¯­è¨€ä»£ç 
            device: è®¾å¤‡ (cuda/cpu)
            job: ä»»åŠ¡çŠ¶æ€å¯¹è±¡(å¯é€‰,ç”¨äºŽæ›´æ–°ä¸‹è½½è¿›åº¦)

        Returns:
            Tuple[model, metadata]: å¯¹é½æ¨¡åž‹å’Œå…ƒæ•°æ®
        """
        global _align_model_cache, _MAX_ALIGN_MODELS

        with _align_lock:
            # 1. æ£€æŸ¥ç¼“å­˜å‘½ä¸­
            if lang in _align_model_cache:
                # å‘½ä¸­ï¼šç§»åˆ°æœ«å°¾ï¼ˆæœ€è¿‘ä½¿ç”¨ï¼‰
                _align_model_cache.move_to_end(lang)
                self.logger.debug(f"å‘½ä¸­å¯¹é½æ¨¡åž‹ç¼“å­˜: {lang} (ç¼“å­˜: {list(_align_model_cache.keys())})")
                if job:
                    job.message = "ä½¿ç”¨ç¼“å­˜çš„å¯¹é½æ¨¡åž‹"
                return _align_model_cache[lang]

            # 2. ç¼“å­˜æœªå‘½ä¸­ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦æ·˜æ±°
            if len(_align_model_cache) >= _MAX_ALIGN_MODELS:
                # ç¼“å­˜å·²æ»¡ï¼Œåˆ é™¤æœ€ä¹…æœªä½¿ç”¨çš„ï¼ˆé˜Ÿé¦–ï¼‰
                oldest_lang, (oldest_model, _) = _align_model_cache.popitem(last=False)
                self.logger.info(f"æ·˜æ±°æœ€ä¹…æœªç”¨çš„å¯¹é½æ¨¡åž‹: {oldest_lang} (ä¸º {lang} è…¾å‡ºç©ºé—´)")

                # æ˜¾å¼åˆ é™¤æ¨¡åž‹å¯¹è±¡
                try:
                    del oldest_model
                except:
                    pass

        # 3. åŠ è½½æ–°æ¨¡åž‹ï¼ˆä¿ç•™åŽŸæœ‰çš„ä¸‹è½½å’ŒåŠ è½½é€»è¾‘ï¼‰
        self.logger.debug(f"Loading alignment model: {lang}")
        if job:
            job.message = f"åŠ è½½å¯¹é½æ¨¡åž‹ {lang}"

        # å°è¯•ä½¿ç”¨æ¨¡åž‹é¢„åŠ è½½ç®¡ç†å™¨ï¼ˆä¼˜å…ˆä»ŽLRUç¼“å­˜èŽ·å–ï¼‰
        try:
            from services.model_preload_manager import get_model_manager as get_preload_manager
            preload_mgr = get_preload_manager()
            if preload_mgr:
                self.logger.debug("å°è¯•ä»Žé¢„åŠ è½½ç®¡ç†å™¨èŽ·å–å¯¹é½æ¨¡åž‹")
                if job:
                    job.message = "åŠ è½½å¯¹é½æ¨¡åž‹"
                am, meta = preload_mgr.get_align_model(lang, device)
                # 4. åŠ å…¥ç¼“å­˜ï¼ˆè‡ªåŠ¨æ”¾åœ¨æœ«å°¾ï¼Œæ ‡è®°ä¸ºæœ€è¿‘ä½¿ç”¨ï¼‰
                with _align_lock:
                    _align_model_cache[lang] = (am, meta)
                    self.logger.info(f"å¯¹é½æ¨¡åž‹å·²ç¼“å­˜: {lang} (å½“å‰ç¼“å­˜: {list(_align_model_cache.keys())})")
                return am, meta
        except Exception as e:
            self.logger.debug(f"é¢„åŠ è½½ç®¡ç†å™¨èŽ·å–å¤±è´¥ï¼Œä½¿ç”¨ç›´æŽ¥åŠ è½½: {e}")

            # æ£€æŸ¥æ¨¡åž‹æ˜¯å¦éœ€è¦ä¸‹è½½ï¼ˆä½¿ç”¨æ¨¡åž‹ç®¡ç†æœåŠ¡ï¼‰
            try:
                from services.model_manager_service import get_model_manager
                model_mgr = get_model_manager()
                align_model_info = model_mgr.align_models.get(lang)

                if align_model_info and (align_model_info.status == "not_downloaded" or align_model_info.status == "incomplete"):
                    # æ£€æŸ¥æ¨¡åž‹çŠ¶æ€,å¦‚æžœæœªä¸‹è½½æˆ–ä¸å®Œæ•´åˆ™è§¦å‘ä¸‹è½½
                    if align_model_info.status == "incomplete":
                        self.logger.warning(f"å¯¹é½æ¨¡åž‹ä¸å®Œæ•´: {lang}")
                    else:
                        self.logger.warning(f"å¯¹é½æ¨¡åž‹æœªä¸‹è½½: {lang}")

                    # å¯¹é½æ¨¡åž‹é€šå¸¸ä¸º1.2GBå·¦å³,ç»™å‡ºå¤§æ¨¡åž‹æç¤º
                    download_msg = "å½“å‰ä¸‹è½½æ¨¡åž‹å¤§äºŽ1GB (çº¦1.2GB),è¯·è€å¿ƒç­‰å¾…"
                    self.logger.info(f"{download_msg}")
                    self.logger.info(f"è‡ªåŠ¨è§¦å‘ä¸‹è½½å¯¹é½æ¨¡åž‹: {lang}")

                    # æ›´æ–°ä»»åŠ¡çŠ¶æ€
                    if job:
                        job.message = download_msg

                    # è§¦å‘ä¸‹è½½
                    success = model_mgr.download_align_model(lang)
                    if not success:
                        self.logger.warning(f"æ¨¡åž‹ç®¡ç†å™¨ä¸‹è½½å¤±è´¥æˆ–å·²åœ¨ä¸‹è½½ä¸­,å›žé€€åˆ°whisperx")
                        raise RuntimeError("æ¨¡åž‹ç®¡ç†å™¨ä¸‹è½½å¤±è´¥")

                    # ç­‰å¾…ä¸‹è½½å®Œæˆï¼ˆæœ€å¤šç­‰å¾…10åˆ†é’Ÿ,å¯¹é½æ¨¡åž‹è¾ƒå¤§ï¼‰
                    import time
                    max_wait_time = 600  # 10åˆ†é’Ÿ
                    wait_interval = 5  # æ¯5ç§’æ£€æŸ¥ä¸€æ¬¡
                    elapsed = 0

                    while elapsed < max_wait_time:
                        time.sleep(wait_interval)
                        elapsed += wait_interval

                        current_status = model_mgr.align_models[lang].status
                        progress = model_mgr.align_models[lang].download_progress

                        if current_status == "ready":
                            self.logger.info(f"å¯¹é½æ¨¡åž‹ä¸‹è½½å®Œæˆ: {lang}")
                            if job:
                                job.message = "å¯¹é½æ¨¡åž‹ä¸‹è½½å®Œæˆ,å‡†å¤‡åŠ è½½"
                            break
                        elif current_status == "error":
                            self.logger.error(f"æ¨¡åž‹ç®¡ç†å™¨ä¸‹è½½å¤±è´¥,å›žé€€åˆ°whisperx")
                            raise RuntimeError(f"å¯¹é½æ¨¡åž‹ä¸‹è½½å¤±è´¥: {lang}")
                        else:
                            # å®šæœŸæé†’ç”¨æˆ·è€å¿ƒç­‰å¾…(æ¯30ç§’)
                            if elapsed % 30 == 0:
                                wait_msg = f"å½“å‰ä¸‹è½½æ¨¡åž‹å¤§äºŽ1GB,è¯·è€å¿ƒç­‰å¾…... {progress:.1f}% ({elapsed}s/{max_wait_time}s)"
                                self.logger.info(f"{wait_msg}")
                                if job:
                                    job.message = wait_msg
                            else:
                                wait_msg = f"ç­‰å¾…å¯¹é½æ¨¡åž‹ä¸‹è½½... {progress:.1f}%"
                                self.logger.info(f"{wait_msg} ({elapsed}s/{max_wait_time}s)")
                                # æ›´æ–°ä»»åŠ¡çŠ¶æ€(æ¯æ¬¡éƒ½æ›´æ–°,è¿™æ ·ç”¨æˆ·å¯ä»¥çœ‹åˆ°è¿›åº¦å˜åŒ–)
                                if job:
                                    job.message = wait_msg

                    if elapsed >= max_wait_time:
                        self.logger.error(f"æ¨¡åž‹ä¸‹è½½è¶…æ—¶,å›žé€€åˆ°whisperx")
                        raise TimeoutError(f"å¯¹é½æ¨¡åž‹ä¸‹è½½è¶…æ—¶: {lang}")

            except Exception as e:
                self.logger.warning(f"æ¨¡åž‹ç®¡ç†æœåŠ¡æ£€æŸ¥å¤±è´¥,å›žé€€åˆ°whisperx: {e}")

            # ç›´æŽ¥åŠ è½½æ¨¡åž‹ï¼ˆå¦‚æžœå·²ä¸‹è½½æˆ–ä¸‹è½½å®Œæˆï¼‰
            self.logger.debug(f"Loading alignment model: {lang}")
            if job:
                job.message = f"åŠ è½½å¯¹é½æ¨¡åž‹ {lang}"

            # é¦–å…ˆå°è¯•ä»…ä½¿ç”¨æœ¬åœ°æ–‡ä»¶
            try:
                from core.config import config
                am, meta = whisperx.load_align_model(
                    language_code=lang,
                    device=device,
                    model_dir=str(config.HF_CACHE_DIR)  # æŒ‡å®šç¼“å­˜è·¯å¾„
                )
                # åŠ å…¥ç¼“å­˜ï¼ˆè‡ªåŠ¨æ”¾åœ¨æœ«å°¾ï¼Œæ ‡è®°ä¸ºæœ€è¿‘ä½¿ç”¨ï¼‰
                with _align_lock:
                    _align_model_cache[lang] = (am, meta)
                    self.logger.info(f"å¯¹é½æ¨¡åž‹å·²ç¼“å­˜: {lang} (å½“å‰ç¼“å­˜: {list(_align_model_cache.keys())})")
                if job:
                    job.message = "å¯¹é½æ¨¡åž‹åŠ è½½å®Œæˆ"
                return am, meta
            except Exception as e:
                self.logger.warning(f"æœ¬åœ°åŠ è½½å¯¹é½æ¨¡åž‹å¤±è´¥,å…è®¸whisperxä¸‹è½½: {e}")
                if job:
                    job.message = "æœ¬åœ°å¯¹é½æ¨¡åž‹ä¸å­˜åœ¨,ä½¿ç”¨whisperxä¸‹è½½"
                # å¦‚æžœæœ¬åœ°åŠ è½½å¤±è´¥,å…è®¸whisperxä¸‹è½½
                am, meta = whisperx.load_align_model(
                    language_code=lang,
                    device=device
                )
                # åŠ å…¥ç¼“å­˜ï¼ˆè‡ªåŠ¨æ”¾åœ¨æœ«å°¾ï¼Œæ ‡è®°ä¸ºæœ€è¿‘ä½¿ç”¨ï¼‰
                with _align_lock:
                    _align_model_cache[lang] = (am, meta)
                    self.logger.info(f"å¯¹é½æ¨¡åž‹å·²ä¸‹è½½å¹¶ç¼“å­˜: {lang} (å½“å‰ç¼“å­˜: {list(_align_model_cache.keys())})")
                if job:
                    job.message = "å¯¹é½æ¨¡åž‹ä¸‹è½½å¹¶åŠ è½½å®Œæˆ"
                return am, meta

    def _transcribe_segment_unaligned(
        self,
        seg: Dict,
        model,
        job: JobState
    ) -> Optional[Dict]:
        """
        è½¬å½•å•ä¸ªéŸ³é¢‘æ®µï¼ˆä»…è½¬å½•ï¼Œä¸å¯¹é½ï¼‰

        Args:
            seg: æ®µä¿¡æ¯ {file, start_ms, duration_ms, index}
            model: Whisperæ¨¡åž‹
            job: ä»»åŠ¡çŠ¶æ€

        Returns:
            Dict: æœªå¯¹é½çš„è½¬å½•ç»“æžœ
            {
                "segment_index": 0,
                "language": "zh",
                "segments": [{"id": 0, "start": 10.5, "end": 15.2, "text": "..."}]
            }
        """
        audio = whisperx.load_audio(seg['file'])

        try:
            # ä»…è¿›è¡ŒTranscriptionï¼Œä¸è¿›è¡ŒAlignment
            rs = model.transcribe(
                audio,
                batch_size=job.settings.batch_size,
                verbose=False,
                language=job.language
            )

            if not rs or 'segments' not in rs:
                return None

            # æ£€æµ‹è¯­è¨€ï¼ˆé¦–æ¬¡ï¼‰
            if not job.language and 'language' in rs:
                job.language = rs['language']
                self.logger.info(f"ðŸŒ æ£€æµ‹åˆ°è¯­è¨€: {job.language}")

            # æ—¶é—´åç§»æ ¡æ­£ï¼ˆé’ˆå¯¹ç²—ç•¥æ—¶é—´æˆ³ï¼‰
            start_offset = seg['start_ms'] / 1000.0
            adjusted_segments = []

            for idx, s in enumerate(rs['segments']):
                adjusted_segments.append({
                    'id': idx,
                    'start': s.get('start', 0) + start_offset,
                    'end': s.get('end', 0) + start_offset,
                    'text': s.get('text', '').strip()
                })

            return {
                'segment_index': seg.get('index', 0),  # éœ€è¦åœ¨è°ƒç”¨æ—¶ä¼ å…¥
                'language': rs.get('language', job.language),
                'segments': adjusted_segments
            }

        finally:
            del audio
            gc.collect()

    def _transcribe_segment_in_memory(
        self,
        audio_array: np.ndarray,
        seg_meta: Dict,
        model,
        job: JobState
    ) -> Optional[Dict]:
        """
        ä»Žå†…å­˜åˆ‡ç‰‡è½¬å½•ï¼ˆZero-copyï¼Œé«˜æ€§èƒ½ï¼‰

        å†…å­˜æ¨¡å¼ä¸‹ä½¿ç”¨ï¼Œç›´æŽ¥ä»Žå®Œæ•´éŸ³é¢‘æ•°ç»„ä¸­åˆ‡ç‰‡ï¼Œæ— éœ€ç£ç›˜IOã€‚

        Args:
            audio_array: å®Œæ•´éŸ³é¢‘æ•°ç»„
            seg_meta: åˆ†æ®µå…ƒæ•°æ® {"index": 0, "start": 0.0, "end": 30.5, "mode": "memory"}
            model: Whisperæ¨¡åž‹
            job: ä»»åŠ¡çŠ¶æ€

        Returns:
            Dict: æœªå¯¹é½çš„è½¬å½•ç»“æžœ
        """
        sr = 16000
        start_sample = int(seg_meta['start'] * sr)
        end_sample = int(seg_meta['end'] * sr)

        # Zero-copyåˆ‡ç‰‡ï¼ˆnumpy viewï¼Œä¸å¤åˆ¶æ•°æ®ï¼‰
        audio_slice = audio_array[start_sample:end_sample]

        try:
            # Whisperè½¬å½•
            rs = model.transcribe(
                audio_slice,
                batch_size=job.settings.batch_size,
                verbose=False,
                language=job.language
            )

            if not rs or 'segments' not in rs:
                return None

            # æ£€æµ‹è¯­è¨€ï¼ˆé¦–æ¬¡ï¼‰
            if not job.language and 'language' in rs:
                job.language = rs['language']
                self.logger.info(f"detected language: {job.language}")

            # æ—¶é—´åç§»æ ¡æ­£
            start_offset = seg_meta['start']
            adjusted_segments = []

            for idx, s in enumerate(rs['segments']):
                adjusted_segments.append({
                    'id': idx,
                    'start': s.get('start', 0) + start_offset,
                    'end': s.get('end', 0) + start_offset,
                    'text': s.get('text', '').strip()
                })

            return {
                'segment_index': seg_meta['index'],
                'language': rs.get('language', job.language),
                'segments': adjusted_segments
            }

        finally:
            # æ³¨æ„ï¼šaudio_sliceæ˜¯viewï¼Œä¸éœ€è¦å•ç‹¬é‡Šæ”¾
            gc.collect()

    def _transcribe_segment_from_disk(
        self,
        seg: Dict,
        model,
        job: JobState
    ) -> Optional[Dict]:
        """
        ä»Žæ–‡ä»¶åŠ è½½è½¬å½•ï¼ˆç¡¬ç›˜æ¨¡å¼ï¼‰

        ç¡¬ç›˜æ¨¡å¼ä¸‹ä½¿ç”¨ï¼Œä»Žsegmentæ–‡ä»¶åŠ è½½éŸ³é¢‘è¿›è¡Œè½¬å½•ã€‚

        Args:
            seg: åˆ†æ®µä¿¡æ¯ {"index": 0, "file": "segment_0.wav", "start": 0.0, "end": 30.0, "mode": "disk"}
            model: Whisperæ¨¡åž‹
            job: ä»»åŠ¡çŠ¶æ€

        Returns:
            Dict: æœªå¯¹é½çš„è½¬å½•ç»“æžœ
        """
        audio = whisperx.load_audio(seg['file'])

        try:
            rs = model.transcribe(
                audio,
                batch_size=job.settings.batch_size,
                verbose=False,
                language=job.language
            )

            if not rs or 'segments' not in rs:
                return None

            # æ£€æµ‹è¯­è¨€ï¼ˆé¦–æ¬¡ï¼‰
            if not job.language and 'language' in rs:
                job.language = rs['language']
                self.logger.info(f"detected language: {job.language}")

            # æ—¶é—´åç§»æ ¡æ­£ï¼ˆä½¿ç”¨startå­—æ®µï¼Œç§’ä¸ºå•ä½ï¼‰
            start_offset = seg.get('start', seg.get('start_ms', 0) / 1000.0)
            adjusted_segments = []

            for idx, s in enumerate(rs['segments']):
                adjusted_segments.append({
                    'id': idx,
                    'start': s.get('start', 0) + start_offset,
                    'end': s.get('end', 0) + start_offset,
                    'text': s.get('text', '').strip()
                })

            return {
                'segment_index': seg['index'],
                'language': rs.get('language', job.language),
                'segments': adjusted_segments
            }

        finally:
            del audio
            gc.collect()

    def _transcribe_segment(
        self,
        seg_meta: Dict,
        model,
        job: JobState,
        audio_array: Optional[np.ndarray] = None
    ) -> Optional[Dict]:
        """
        ç»Ÿä¸€è½¬å½•å…¥å£ï¼ˆæ ¹æ®æ¨¡å¼è‡ªåŠ¨é€‰æ‹©ï¼‰

        Args:
            seg_meta: åˆ†æ®µå…ƒæ•°æ®
            model: Whisperæ¨¡åž‹
            job: ä»»åŠ¡çŠ¶æ€
            audio_array: éŸ³é¢‘æ•°ç»„ï¼ˆå†…å­˜æ¨¡å¼æ—¶å¿…é¡»æä¾›ï¼‰

        Returns:
            Dict: æœªå¯¹é½çš„è½¬å½•ç»“æžœ
        """
        mode = seg_meta.get('mode', 'disk')

        if mode == 'memory':
            if audio_array is None:
                raise ValueError("memory mode requires audio_array parameter")
            return self._transcribe_segment_in_memory(audio_array, seg_meta, model, job)
        else:
            return self._transcribe_segment_from_disk(seg_meta, model, job)

    def _check_memory_during_transcription(self, job: JobState) -> bool:
        """
        è½¬å½•è¿‡ç¨‹ä¸­æ£€æŸ¥å†…å­˜çŠ¶æ€

        å¦‚æžœå†…å­˜ä¸¥é‡ä¸è¶³ï¼Œæš‚åœä»»åŠ¡å¹¶è­¦å‘Šç”¨æˆ·ã€‚

        Args:
            job: ä»»åŠ¡çŠ¶æ€å¯¹è±¡

        Returns:
            bool: True=ç»§ç»­å¤„ç†ï¼ŒFalse=éœ€è¦æš‚åœ
        """
        mem_info = psutil.virtual_memory()
        available_mb = mem_info.available / (1024 * 1024)
        percent_used = mem_info.percent

        # å±é™©é˜ˆå€¼ï¼šå¯ç”¨å†…å­˜<500MB æˆ– ä½¿ç”¨çŽ‡>95%
        if available_mb < 500 or percent_used > 95:
            self.logger.error(f"memory critically low! available: {available_mb:.0f}MB, usage: {percent_used}%")
            job.status = 'paused'
            job.message = f"memory insufficient (available {available_mb:.0f}MB), please close other programs"
            job.paused = True

            # æŽ¨é€è­¦å‘ŠSSE
            self._push_sse_signal(job, "memory_warning",
                f"memory critically low (available {available_mb:.0f}MB), task paused")

            return False

        # è­¦å‘Šé˜ˆå€¼ï¼šå¯ç”¨å†…å­˜<1GB æˆ– ä½¿ç”¨çŽ‡>90%
        if available_mb < 1024 or percent_used > 90:
            self.logger.warning(f"memory tight: available {available_mb:.0f}MB, usage {percent_used}%")
            # ä¸æš‚åœï¼Œä½†è®°å½•è­¦å‘Š

        return True

    def _align_all_results(
        self,
        unaligned_results: List[Dict],
        job: JobState,
        audio_path: str
    ) -> List[Dict]:
        """
        å¯¹æ‰€æœ‰æœªå¯¹é½çš„è½¬å½•ç»“æžœè¿›è¡Œç»Ÿä¸€å¯¹é½

        Args:
            unaligned_results: æ‰€æœ‰æœªå¯¹é½çš„è½¬å½•ç»“æžœ
            job: ä»»åŠ¡çŠ¶æ€
            audio_path: å®Œæ•´éŸ³é¢‘æ–‡ä»¶è·¯å¾„

        Returns:
            List[Dict]: å¯¹é½åŽçš„ç»“æžœ
        """
        self.logger.info(f"å¼€å§‹ç»Ÿä¸€å¯¹é½ {len(unaligned_results)} ä¸ªåˆ†æ®µçš„è½¬å½•ç»“æžœ")

        # 1. åˆå¹¶æ‰€æœ‰segments
        all_segments = []
        for result in unaligned_results:
            all_segments.extend(result['segments'])

        if not all_segments:
            self.logger.warning("æ²¡æœ‰å¯å¯¹é½çš„å†…å®¹")
            return []

        # 2. åŠ è½½å®Œæ•´éŸ³é¢‘
        audio = whisperx.load_audio(audio_path)

        try:
            # 3. èŽ·å–å¯¹é½æ¨¡åž‹
            lang = job.language or unaligned_results[0].get('language', 'zh')
            align_model, metadata = self._get_align_model(lang, job.settings.device, job)

            # 4. æ‰§è¡Œå¯¹é½ï¼ˆä¸€æ¬¡æ€§å¤„ç†æ‰€æœ‰segmentsï¼‰
            self._update_progress(job, 'align', 0, 'æ­£åœ¨å¯¹é½æ—¶é—´è½´...')

            aligned = whisperx.align(
                all_segments,
                align_model,
                metadata,
                audio,
                job.settings.device
            )

            self._update_progress(job, 'align', 1, 'å¯¹é½å®Œæˆ')

            # 5. è¿”å›žå¯¹é½åŽçš„ç»“æžœ
            return [{
                'segments': aligned.get('segments', []),
                'word_segments': aligned.get('word_segments', [])
            }]

        finally:
            del audio
            gc.collect()

    def _push_sse_align_progress(
        self,
        job: JobState,
        current_batch: int,
        total_batches: int,
        aligned_count: int,
        total_count: int
    ):
        """
        æŽ¨é€å¯¹é½è¿›åº¦SSEäº‹ä»¶ï¼ˆå‰ç«¯è¿›åº¦æ¡å®žæ—¶æ›´æ–°ï¼‰

        äº‹ä»¶ç±»åž‹: "align_progress"

        Args:
            job: ä»»åŠ¡çŠ¶æ€å¯¹è±¡
            current_batch: å½“å‰æ‰¹æ¬¡å·ï¼ˆ1-basedï¼‰
            total_batches: æ€»æ‰¹æ¬¡æ•°
            aligned_count: å·²å¯¹é½çš„segmentæ•°é‡
            total_count: æ€»segmentæ•°é‡
        """
        try:
            from services.sse_service import get_sse_manager
            sse_manager = get_sse_manager()

            channel_id = f"job:{job.job_id}"

            # è®¡ç®—ç™¾åˆ†æ¯”
            batch_progress = (current_batch / total_batches) * 100 if total_batches > 0 else 0
            segment_progress = (aligned_count / total_count) * 100 if total_count > 0 else 0

            sse_manager.broadcast_sync(
                channel_id,
                "align_progress",  # ä¸“ç”¨äº‹ä»¶ç±»åž‹
                {
                    "job_id": job.job_id,
                    "phase": "align",
                    "batch": {
                        "current": current_batch,
                        "total": total_batches,
                        "progress": round(batch_progress, 2)
                    },
                    "segments": {
                        "aligned": aligned_count,
                        "total": total_count,
                        "progress": round(segment_progress, 2)
                    },
                    "message": f"aligning batch {current_batch}/{total_batches} ({aligned_count}/{total_count} segments)"
                }
            )

        except Exception as e:
            self.logger.debug(f"SSE align progress push failed (non-fatal): {e}")

    def _align_all_results_batched(
        self,
        unaligned_results: List[Dict],
        job: JobState,
        audio_source,  # Union[np.ndarray, str]
        processing_mode: ProcessingMode
    ) -> List[Dict]:
        """
        åˆ†æ‰¹å¯¹é½ï¼ˆæ”¯æŒå®žæ—¶SSEè¿›åº¦æŽ¨é€ï¼‰

        æ‰¹æ¬¡å¯¹é½çš„ä¼˜åŠ¿ï¼š
        1. é¿å…ä¸€æ¬¡æ€§å¯¹é½æ‰€æœ‰å†…å®¹å¯¼è‡´çš„é•¿æ—¶é—´å¡é¡¿
        2. æ”¯æŒå‰ç«¯è¿›åº¦æ¡å®žæ—¶æ›´æ–°
        3. å†…å­˜ä½¿ç”¨æ›´å¯æŽ§

        Args:
            unaligned_results: æ‰€æœ‰æœªå¯¹é½çš„è½¬å½•ç»“æžœ
            job: ä»»åŠ¡çŠ¶æ€å¯¹è±¡
            audio_source: éŸ³é¢‘æ¥æºï¼ˆå†…å­˜æ¨¡å¼ä¼ æ•°ç»„ï¼Œç¡¬ç›˜æ¨¡å¼ä¼ è·¯å¾„ï¼‰
            processing_mode: å½“å‰å¤„ç†æ¨¡å¼

        Returns:
            List[Dict]: å¯¹é½åŽçš„ç»“æžœ
        """
        self.logger.info(f"starting batched alignment: {len(unaligned_results)} segments")

        # 1. åˆå¹¶æ‰€æœ‰segments
        all_segments = []
        for result in unaligned_results:
            all_segments.extend(result['segments'])

        if not all_segments:
            self.logger.warning("no segments to align")
            return []

        # 2. åŠ è½½éŸ³é¢‘ï¼ˆæ ¹æ®æ¨¡å¼ï¼‰
        if processing_mode == ProcessingMode.MEMORY:
            audio_array = audio_source  # ç›´æŽ¥ä½¿ç”¨å†…å­˜æ•°ç»„
            self.logger.info("align phase: reusing audio array from memory")
        else:
            # ç¡¬ç›˜æ¨¡å¼ï¼šéœ€è¦åŠ è½½å®Œæ•´éŸ³é¢‘
            self.logger.info("align phase: loading complete audio from disk...")
            audio_array = whisperx.load_audio(audio_source)

        try:
            # 3. èŽ·å–å¯¹é½æ¨¡åž‹
            lang = job.language or unaligned_results[0].get('language', 'zh')
            align_model, metadata = self._get_align_model(lang, job.settings.device, job)

            # 4. åˆ†æ‰¹å¯¹é½
            BATCH_SIZE = 50  # æ¯æ‰¹50æ¡segment
            total_segments = len(all_segments)
            total_batches = math.ceil(total_segments / BATCH_SIZE)
            aligned_segments = []

            self.logger.info(f"alignment config: total {total_segments} segments, {BATCH_SIZE} per batch, {total_batches} batches")

            for batch_idx in range(total_batches):
                start_idx = batch_idx * BATCH_SIZE
                end_idx = min(start_idx + BATCH_SIZE, total_segments)
                batch = all_segments[start_idx:end_idx]

                # è®¡ç®—è¿›åº¦
                progress = batch_idx / total_batches

                # æ›´æ–°ä»»åŠ¡è¿›åº¦
                self._update_progress(
                    job,
                    'align',
                    progress,
                    f'aligning batch {batch_idx + 1}/{total_batches}'
                )

                # æŽ¨é€å¯¹é½è¿›åº¦SSEï¼ˆä¸“ç”¨äº‹ä»¶ï¼‰
                self._push_sse_align_progress(
                    job,
                    batch_idx + 1,
                    total_batches,
                    len(aligned_segments),
                    total_segments
                )

                # æ‰§è¡Œå¯¹é½
                try:
                    aligned_batch = whisperx.align(
                        batch,
                        align_model,
                        metadata,
                        audio_array,
                        job.settings.device
                    )
                    aligned_segments.extend(aligned_batch.get('segments', []))
                    self.logger.debug(f"batch {batch_idx + 1}/{total_batches} completed")

                except Exception as e:
                    self.logger.error(f"batch {batch_idx + 1} alignment failed: {e}")
                    # ç»§ç»­å¤„ç†å…¶ä»–æ‰¹æ¬¡ï¼Œä¸ä¸­æ–­æ•´ä½“æµç¨‹
                    continue

            # 5. å®Œæˆ
            self._update_progress(job, 'align', 1, 'alignment complete')
            self._push_sse_align_progress(job, total_batches, total_batches, total_segments, total_segments)

            self.logger.info(f"batched alignment complete: {len(aligned_segments)} segments")

            return [{
                'segments': aligned_segments,
                'word_segments': []
            }]

        finally:
            # å¦‚æžœæ˜¯ç¡¬ç›˜æ¨¡å¼ï¼Œé‡Šæ”¾åŠ è½½çš„éŸ³é¢‘
            if processing_mode == ProcessingMode.DISK:
                del audio_array
                gc.collect()

    def _format_ts(self, sec: float) -> str:
        """
        æ ¼å¼åŒ–æ—¶é—´æˆ³ä¸ºSRTæ ¼å¼

        Args:
            sec: ç§’æ•°

        Returns:
            str: SRTæ—¶é—´æˆ³ (HH:MM:SS,mmm)
        """
        if sec < 0:
            sec = 0

        ms = int(round(sec * 1000))
        h = ms // 3600000
        ms %= 3600000
        m = ms // 60000
        ms %= 60000
        s = ms // 1000
        ms %= 1000

        return f"{h:02}:{m:02}:{s:02},{ms:03}"

    def _generate_srt(self, results: List[Dict], path: str, word_level: bool):
        """
        ç”ŸæˆSRTå­—å¹•æ–‡ä»¶

        Args:
            results: è½¬å½•ç»“æžœåˆ—è¡¨
            path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            word_level: æ˜¯å¦ä½¿ç”¨è¯çº§æ—¶é—´æˆ³
        """
        lines = []
        n = 1  # å­—å¹•åºå·

        for r in results:
            if not r:
                continue

            entries = []

            # è¯çº§æ—¶é—´æˆ³æ¨¡å¼
            if word_level and r.get('word_segments'):
                for w in r['word_segments']:
                    if w.get('start') is not None and w.get('end') is not None:
                        txt = (w.get('word') or '').strip()
                        if txt:
                            entries.append({
                                'start': w['start'],
                                'end': w['end'],
                                'text': txt
                            })

            # å¥å­çº§æ—¶é—´æˆ³æ¨¡å¼ï¼ˆé»˜è®¤ï¼‰
            elif r.get('segments'):
                for s in r['segments']:
                    if s.get('start') is not None and s.get('end') is not None:
                        txt = (s.get('text') or '').strip()
                        if txt:
                            entries.append({
                                'start': s['start'],
                                'end': s['end'],
                                'text': txt
                            })

            # å†™å…¥SRTæ ¼å¼
            for e in entries:
                if e['end'] <= e['start']:
                    continue  # è·³è¿‡æ— æ•ˆæ—¶é—´æˆ³

                lines.append(str(n))  # åºå·
                lines.append(
                    f"{self._format_ts(e['start'])} --> {self._format_ts(e['end'])}"
                )  # æ—¶é—´æˆ³
                lines.append(e['text'])  # å­—å¹•æ–‡æœ¬
                lines.append("")  # ç©ºè¡Œ
                n += 1

        # å†™å…¥æ–‡ä»¶
        with open(path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(lines))

        self.logger.info(f"SRTæ–‡ä»¶å·²ç”Ÿæˆ: {path}, å…±{n-1}æ¡å­—å¹•")

    def clear_model_cache(self):
        """
        æ¸…ç©ºæ¨¡åž‹ç¼“å­˜ï¼ˆä¾›é˜Ÿåˆ—æœåŠ¡è°ƒç”¨ï¼‰

        ç­–ç•¥:
        - æ€»æ˜¯æ¸…ç† Whisper æ¨¡åž‹ï¼ˆæ˜¾å­˜å ç”¨å¤§ï¼Œ1-3GBï¼‰
        - ä¿ç•™å¯¹é½æ¨¡åž‹çš„ LRU ç¼“å­˜ï¼ˆå ç”¨å°ï¼Œæ¯ä¸ª~200MBï¼‰
        """
        global _model_cache, _align_model_cache

        # 1. æ€»æ˜¯æ¸…ç† Whisper æ¨¡åž‹
        with _model_lock:
            for key in list(_model_cache.keys()):
                try:
                    del _model_cache[key]
                except:
                    pass
            _model_cache.clear()
            self.logger.info("Whisperæ¨¡åž‹ç¼“å­˜å·²æ¸…ç©º")

        # 2. ä¿ç•™å¯¹é½æ¨¡åž‹ï¼ˆè®°å½•å½“å‰ç¼“å­˜çŠ¶æ€ï¼‰
        with _align_lock:
            cached_langs = list(_align_model_cache.keys())
            if cached_langs:
                self.logger.debug(f"ä¿ç•™å¯¹é½æ¨¡åž‹ç¼“å­˜ (LRU): {cached_langs}")
            else:
                self.logger.debug("å¯¹é½æ¨¡åž‹ç¼“å­˜ä¸ºç©º")


# å•ä¾‹å¤„ç†å™¨
_service_instance: Optional[TranscriptionService] = None


def get_transcription_service(root: str) -> TranscriptionService:
    """èŽ·å–è½¬å½•æœåŠ¡å®žä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰"""
    global _service_instance
    if _service_instance is None:
        _service_instance = TranscriptionService(root)
    return _service_instance