"""
ç»Ÿä¸€æ¨¡å‹ä¸æ•°æ®é›†ç®¡ç†æœåŠ¡ - æ”¹è¿›ç‰ˆ
- ä¸‹è½½ç®¡ç†ï¼ˆæ”¯æŒè¿›åº¦è¿½è¸ªï¼‰
- å®Œæ•´æ€§éªŒè¯
- ä¸‹è½½é˜Ÿåˆ—ç®¡ç†ï¼ˆä¸€æ¬¡åªä¸‹è½½ä¸€ä¸ªï¼‰
- ç¼“å­˜ç®¡ç†
- è‡ªåŠ¨æ£€æµ‹è¯­è¨€å¹¶ä¸‹è½½
"""

from dataclasses import dataclass
from typing import List, Optional, Dict, Callable
from pathlib import Path
import threading
import logging
import os
import shutil
import time

from models.model_models import ModelInfo, AlignModelInfo
from core.config import config
from services.model_validator import ModelValidator


class ModelManagerService:
    """
    æ¨¡å‹ç®¡ç†æœåŠ¡
    ç»Ÿä¸€ç®¡ç†Whisperæ¨¡å‹å’Œå¯¹é½æ¨¡å‹çš„ä¸‹è½½ã€ç¼“å­˜ã€åˆ é™¤
    """

    # æ”¯æŒçš„Whisperæ¨¡å‹
    WHISPER_MODELS = {
        "tiny": {"size_mb": 75, "desc": "æœ€å¿«ï¼Œç²¾åº¦è¾ƒä½"},
        "base": {"size_mb": 145, "desc": "å¿«é€Ÿï¼Œç²¾åº¦ä¸€èˆ¬"},
        "small": {"size_mb": 490, "desc": "å¹³è¡¡é€Ÿåº¦ä¸ç²¾åº¦"},
        "medium": {"size_mb": 1500, "desc": "è¾ƒæ…¢ï¼Œç²¾åº¦è¾ƒé«˜"},
        "large-v2": {"size_mb": 3100, "desc": "æœ€æ…¢ï¼Œç²¾åº¦æœ€é«˜"},
        "large-v3": {"size_mb": 3100, "desc": "æœ€æ–°ç‰ˆæœ¬ï¼Œç²¾åº¦æœ€é«˜"},
    }

    # æ”¯æŒçš„è¯­è¨€ï¼ˆå¯¹é½æ¨¡å‹ï¼‰
    SUPPORTED_LANGUAGES = {
        "zh": "ä¸­æ–‡ (Chinese)",
        "en": "è‹±è¯­ (English)",
        "ja": "æ—¥è¯­ (Japanese)",
        "ko": "éŸ©è¯­ (Korean)",
        "es": "è¥¿ç­ç‰™è¯­ (Spanish)",
        "fr": "æ³•è¯­ (French)",
        "de": "å¾·è¯­ (German)",
        "ru": "ä¿„è¯­ (Russian)",
        "pt": "è‘¡è„ç‰™è¯­ (Portuguese)",
        "it": "æ„å¤§åˆ©è¯­ (Italian)",
        "ar": "é˜¿æ‹‰ä¼¯è¯­ (Arabic)",
        "hi": "å°åœ°è¯­ (Hindi)",
    }

    # å¯¹é½æ¨¡å‹çš„å®é™…è·¯å¾„åç§°æ˜ å°„ï¼ˆHuggingFaceä»“åº“ä¸­çš„å®Œæ•´åç§°ï¼‰
    ALIGN_MODEL_PATHS = {
        "zh": [
            "models--jonatasgrosman--wav2vec2-large-xlsr-53-chinese-zh-cn",
            "models--facebook--wav2vec2-large-xlsr-53-chinese-zh-cn",
        ],
        "en": [
            "models--jonatasgrosman--wav2vec2-large-xlsr-53-english",
            "models--facebook--wav2vec2-large-xlsr-53-english",
        ],
        "ja": [
            "models--jonatasgrosman--wav2vec2-large-xlsr-53-japanese",
            "models--facebook--wav2vec2-large-xlsr-53-japanese",
        ],
        "ko": [
            "models--jonatasgrosman--wav2vec2-large-xlsr-53-korean",
            "models--facebook--wav2vec2-large-xlsr-53-korean",
        ],
        "es": [
            "models--jonatasgrosman--wav2vec2-large-xlsr-53-spanish",
            "models--facebook--wav2vec2-large-xlsr-53-spanish",
        ],
        "fr": [
            "models--jonatasgrosman--wav2vec2-large-xlsr-53-french",
            "models--facebook--wav2vec2-large-xlsr-53-french",
        ],
        "de": [
            "models--jonatasgrosman--wav2vec2-large-xlsr-53-german",
            "models--facebook--wav2vec2-large-xlsr-53-german",
        ],
        "ru": [
            "models--jonatasgrosman--wav2vec2-large-xlsr-53-russian",
            "models--facebook--wav2vec2-large-xlsr-53-russian",
        ],
        "pt": [
            "models--jonatasgrosman--wav2vec2-large-xlsr-53-portuguese",
            "models--facebook--wav2vec2-large-xlsr-53-portuguese",
        ],
        "it": [
            "models--jonatasgrosman--wav2vec2-large-xlsr-53-italian",
            "models--facebook--wav2vec2-large-xlsr-53-italian",
        ],
        "ar": [
            "models--jonatasgrosman--wav2vec2-large-xlsr-53-arabic",
            "models--facebook--wav2vec2-large-xlsr-53-arabic",
        ],
        "hi": [
            "models--jonatasgrosman--wav2vec2-large-xlsr-53-hindi",
            "models--facebook--wav2vec2-large-xlsr-53-hindi",
        ],
    }

    # Whisperæ¨¡å‹æ¨èçš„å¯¹é½æ¨¡å‹ï¼ˆé»˜è®¤ä¸ºä¸­æ–‡ï¼‰
    WHISPER_RECOMMENDED_ALIGN_MODELS = {
        "tiny": "zh",
        "base": "zh",
        "small": "zh",
        "medium": "zh",
        "large-v2": "zh",
        "large-v3": "zh",
    }

    def __init__(self, models_dir: Path = None):
        """
        åˆå§‹åŒ–æ¨¡å‹ç®¡ç†æœåŠ¡

        Args:
            models_dir: æ¨¡å‹ç›®å½•è·¯å¾„ï¼Œé»˜è®¤ä½¿ç”¨configä¸­çš„é…ç½®
        """
        self.models_dir = models_dir or config.MODELS_DIR
        self.logger = logging.getLogger(__name__)

        print("="*80)
        print("ğŸš€ ModelManagerService åˆå§‹åŒ–å¼€å§‹")
        print(f"ğŸ“ æ¨¡å‹ç›®å½•: {self.models_dir}")
        print("="*80)

        # æ¨¡å‹çŠ¶æ€è·Ÿè¸ª
        self.whisper_models: Dict[str, ModelInfo] = {}
        self.align_models: Dict[str, AlignModelInfo] = {}

        # ä¸‹è½½é˜Ÿåˆ—å’Œé” - ç¡®ä¿ä¸€æ¬¡åªä¸‹è½½ä¸€ä¸ªæ¨¡å‹ï¼ˆæ”¹è¿›ç‰ˆï¼‰
        self.download_lock = threading.Lock()
        # è·Ÿè¸ªæ­£åœ¨ä¸‹è½½çš„æ¨¡å‹ï¼ˆä½¿ç”¨å­—å…¸è€Œä¸æ˜¯ç®€å•å¸ƒå°”å€¼ï¼‰
        self.downloading_models: Dict[str, bool] = {}  # key: "whisper/model_id" æˆ– "align/language"

        # è¿›åº¦å›è°ƒå‡½æ•°åˆ—è¡¨ï¼ˆç”¨äº SSE æ¨é€ï¼‰
        self.progress_callbacks: List[Callable] = []

        # åˆå§‹åŒ–æ¨¡å‹ä¿¡æ¯
        print("ğŸ” å¼€å§‹å¿«é€Ÿæ‰«ææœ¬åœ°æ¨¡å‹...")
        self._init_model_info()
        print(f"âœ… æ¨¡å‹æ‰«æå®Œæˆ: Whisper={len([m for m in self.whisper_models.values() if m.status == 'ready'])}/{len(self.whisper_models)}, Align={len([m for m in self.align_models.values() if m.status == 'ready'])}/{len(self.align_models)}")

        # å¯åŠ¨åå°éªŒè¯ä»»åŠ¡
        print("ğŸ”§ å¯åŠ¨åå°éªŒè¯çº¿ç¨‹...")
        threading.Thread(target=self._background_validate_models, daemon=True).start()
        print("="*80)

    def _init_model_info(self):
        """å¿«é€Ÿæ‰«ææœ¬åœ°å·²æœ‰æ¨¡å‹ï¼ˆä¸è¿›è¡Œå®Œæ•´æ€§éªŒè¯ï¼Œç•™ç»™åå°ä»»åŠ¡ï¼‰"""
        self.logger.info("ğŸ” å¿«é€Ÿæ‰«ææœ¬åœ°æ¨¡å‹...")
        print("ğŸ” å¿«é€Ÿæ‰«ææœ¬åœ°æ¨¡å‹...")

        # åˆå§‹åŒ–Whisperæ¨¡å‹ä¿¡æ¯ï¼ˆä»…æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨ï¼‰
        for model_id, info in self.WHISPER_MODELS.items():
            # å¿«é€Ÿæ£€æµ‹ï¼šåªæ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
            exists, local_path = self._quick_check_whisper_model(model_id)

            if exists:
                # ç›®å½•å­˜åœ¨ï¼Œå…ˆæ ‡è®°ä¸ºreadyï¼Œåå°ä¼šéªŒè¯å®Œæ•´æ€§
                self.whisper_models[model_id] = ModelInfo(
                    model_id=model_id,
                    size_mb=info["size_mb"],
                    status="ready",
                    download_progress=100.0,
                    local_path=str(local_path) if local_path else None,
                    description=info["desc"]
                )
                print(f"   âœ… Whisperæ¨¡å‹ {model_id}: å·²ä¸‹è½½ (è·¯å¾„: {local_path})")
                self.logger.info(f"âœ… å‘ç°Whisperæ¨¡å‹ç›®å½•: {model_id}ï¼ˆå¾…åå°éªŒè¯ï¼‰")
            else:
                # ç›®å½•ä¸å­˜åœ¨ï¼Œæ ‡è®°ä¸ºæœªä¸‹è½½
                self.whisper_models[model_id] = ModelInfo(
                    model_id=model_id,
                    size_mb=info["size_mb"],
                    status="not_downloaded",
                    download_progress=0.0,
                    local_path=None,
                    description=info["desc"]
                )
                print(f"   âšª Whisperæ¨¡å‹ {model_id}: æœªä¸‹è½½")

        # åˆå§‹åŒ–å¯¹é½æ¨¡å‹ä¿¡æ¯ï¼ˆä»…æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨ï¼‰
        for lang, name in self.SUPPORTED_LANGUAGES.items():
            # å¿«é€Ÿæ£€æµ‹ï¼šåªæ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
            exists, local_path = self._quick_check_align_model(lang)

            if exists:
                # ç›®å½•å­˜åœ¨ï¼Œå…ˆæ ‡è®°ä¸ºreadyï¼Œåå°ä¼šéªŒè¯å®Œæ•´æ€§
                self.align_models[lang] = AlignModelInfo(
                    language=lang,
                    language_name=name,
                    status="ready",
                    download_progress=100.0,
                    local_path=str(local_path) if local_path else None
                )
                print(f"   âœ… å¯¹é½æ¨¡å‹ {lang} ({name}): å·²ä¸‹è½½ (è·¯å¾„: {local_path})")
                self.logger.info(f"âœ… å‘ç°å¯¹é½æ¨¡å‹ç›®å½•: {lang} ({name})ï¼ˆå¾…åå°éªŒè¯ï¼‰")
            else:
                # ç›®å½•ä¸å­˜åœ¨ï¼Œæ ‡è®°ä¸ºæœªä¸‹è½½
                self.align_models[lang] = AlignModelInfo(
                    language=lang,
                    language_name=name,
                    status="not_downloaded",
                    download_progress=0.0,
                    local_path=None
                )
                print(f"   âšª å¯¹é½æ¨¡å‹ {lang} ({name}): æœªä¸‹è½½")

    def _get_latest_snapshot(self, model_dir: Path) -> Optional[Path]:
        """
        è·å–æ¨¡å‹çš„æœ€æ–°å¿«ç…§ï¼ˆä¼˜å…ˆä½¿ç”¨refs/mainæŒ‡å‘çš„å¿«ç…§ï¼‰

        Args:
            model_dir: æ¨¡å‹ç›®å½•

        Returns:
            æœ€æ–°å¿«ç…§è·¯å¾„ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›None
        """
        # ä¼˜å…ˆä½¿ç”¨refs/mainæŒ‡å‘çš„å¿«ç…§
        main_ref = model_dir / "refs" / "main"
        if main_ref.exists():
            try:
                snapshot_id = main_ref.read_text().strip()
                snapshot_path = model_dir / "snapshots" / snapshot_id
                if snapshot_path.exists() and snapshot_path.is_dir():
                    self.logger.debug(f"   ä½¿ç”¨mainå¼•ç”¨çš„å¿«ç…§: {snapshot_id}")
                    return snapshot_path
            except Exception as e:
                self.logger.warning(f"   è¯»å–mainå¼•ç”¨å¤±è´¥: {e}")

        # å›é€€åˆ°æœ€æ–°ä¿®æ”¹æ—¶é—´çš„å¿«ç…§
        snapshots_dir = model_dir / "snapshots"
        if not snapshots_dir.exists():
            return None

        snapshots = [d for d in snapshots_dir.iterdir() if d.is_dir()]
        if not snapshots:
            return None

        latest = max(snapshots, key=lambda p: p.stat().st_mtime)
        self.logger.debug(f"   ä½¿ç”¨æœ€æ–°å¿«ç…§ï¼ˆæŒ‰æ—¶é—´ï¼‰: {latest.name}")
        return latest

    def _quick_check_whisper_model(self, model_id: str) -> tuple[bool, Optional[Path]]:
        """
        å¿«é€Ÿæ£€æŸ¥Whisperæ¨¡å‹ç›®å½•æ˜¯å¦å­˜åœ¨ï¼ˆä¸éªŒè¯å®Œæ•´æ€§ï¼‰

        Args:
            model_id: æ¨¡å‹ID

        Returns:
            tuple: (æ˜¯å¦å­˜åœ¨, æœ¬åœ°è·¯å¾„)
        """
        # æ¨¡å‹å®é™…å­˜å‚¨åœ¨ HF_CACHE_DIR ç›´æ¥ç›®å½•ä¸‹ï¼ˆä¸æ˜¯hubå­ç›®å½•ï¼‰
        hf_cache = config.HF_CACHE_DIR

        print(f"      ğŸ” æ£€æŸ¥ {model_id}")
        print(f"         HFç¼“å­˜: {hf_cache}")
        print(f"         æ˜¯å¦å­˜åœ¨: {hf_cache.exists()}")

        # æ£€æŸ¥å¯èƒ½çš„æ¨¡å‹ç¼“å­˜è·¯å¾„
        possible_paths = [
            hf_cache / f"models--Systran--faster-whisper-{model_id}",
            hf_cache / f"models--guillaumekln--faster-whisper-{model_id}",
        ]

        for model_dir in possible_paths:
            print(f"         æ£€æŸ¥è·¯å¾„: {model_dir}")
            print(f"         è·¯å¾„å­˜åœ¨: {model_dir.exists()}")
            if not model_dir.exists():
                continue

            # ä½¿ç”¨ç»Ÿä¸€çš„å¿«ç…§é€‰æ‹©é€»è¾‘
            latest_snapshot = self._get_latest_snapshot(model_dir)
            if latest_snapshot:
                print(f"         âœ… æ‰¾åˆ°å¿«ç…§: {latest_snapshot}")
                self.logger.info(f"   âœ“ æ£€æµ‹åˆ°Whisperæ¨¡å‹: {model_id} (è·¯å¾„: {latest_snapshot.name})")
                return (True, latest_snapshot)

        self.logger.debug(f"   âœ— æœªæ£€æµ‹åˆ°Whisperæ¨¡å‹: {model_id}")
        return (False, None)

    def _quick_check_align_model(self, language: str) -> tuple[bool, Optional[Path]]:
        """
        å¿«é€Ÿæ£€æŸ¥å¯¹é½æ¨¡å‹ç›®å½•æ˜¯å¦å­˜åœ¨ï¼ˆä¸éªŒè¯å®Œæ•´æ€§ï¼‰

        Args:
            language: è¯­è¨€ä»£ç 

        Returns:
            tuple: (æ˜¯å¦å­˜åœ¨, æœ¬åœ°è·¯å¾„)
        """
        # æ¨¡å‹å®é™…å­˜å‚¨åœ¨ HF_CACHE_DIR ç›´æ¥ç›®å½•ä¸‹ï¼ˆä¸æ˜¯hubå­ç›®å½•ï¼‰
        hf_cache = config.HF_CACHE_DIR

        # ä½¿ç”¨é¢„å®šä¹‰çš„è·¯å¾„æ˜ å°„
        model_patterns = self.ALIGN_MODEL_PATHS.get(language, [])

        if not model_patterns:
            self.logger.warning(f"âš ï¸ è¯­è¨€ {language} æ²¡æœ‰å¯¹åº”çš„æ¨¡å‹è·¯å¾„æ˜ å°„")
            return (False, None)

        print(f"      ğŸ” æ£€æŸ¥å¯¹é½æ¨¡å‹ {language}")
        print(f"         å€™é€‰è·¯å¾„: {model_patterns}")

        for pattern in model_patterns:
            model_dir = hf_cache / pattern
            print(f"         æ£€æŸ¥: {model_dir}")
            print(f"         å­˜åœ¨: {model_dir.exists()}")

            if not model_dir.exists():
                continue

            # ä½¿ç”¨ç»Ÿä¸€çš„å¿«ç…§é€‰æ‹©é€»è¾‘
            latest_snapshot = self._get_latest_snapshot(model_dir)
            if latest_snapshot:
                print(f"         âœ… æ‰¾åˆ°å¿«ç…§: {latest_snapshot}")
                self.logger.info(f"   âœ“ æ£€æµ‹åˆ°å¯¹é½æ¨¡å‹: {language} (è·¯å¾„: {latest_snapshot.name})")
                return (True, latest_snapshot)

        self.logger.debug(f"   âœ— æœªæ£€æµ‹åˆ°å¯¹é½æ¨¡å‹: {language}")
        return (False, None)

    def _check_whisper_model_exists(self, model_id: str) -> tuple[str, Optional[Path], str]:
        """
        æ£€æŸ¥Whisperæ¨¡å‹æ˜¯å¦å­˜åœ¨å¹¶éªŒè¯å®Œæ•´æ€§

        Args:
            model_id: æ¨¡å‹ID

        Returns:
            tuple: (çŠ¶æ€, æœ¬åœ°è·¯å¾„, éªŒè¯ä¿¡æ¯)
            çŠ¶æ€å¯ä»¥æ˜¯: "ready"(å®Œæ•´), "incomplete"(ä¸å®Œæ•´), "not_downloaded"(ä¸å­˜åœ¨)
        """
        # WhisperXæ¨¡å‹ç¼“å­˜åœ¨HuggingFaceç¼“å­˜ç›®å½•ä¸­
        hf_cache = config.HF_CACHE_DIR  # ä¿®å¤ï¼šç›´æ¥ä½¿ç”¨ HF_CACHE_DIRï¼Œä¸åŠ  hub

        # æ£€æŸ¥å¯èƒ½çš„æ¨¡å‹ç¼“å­˜è·¯å¾„
        possible_paths = [
            hf_cache / f"models--Systran--faster-whisper-{model_id}",
            hf_cache / f"models--guillaumekln--faster-whisper-{model_id}",
        ]

        self.logger.debug(f"ğŸ” æŸ¥æ‰¾æ¨¡å‹ {model_id}ï¼Œå€™é€‰è·¯å¾„: {[str(p) for p in possible_paths]}")

        for model_dir in possible_paths:
            self.logger.debug(f"  æ£€æŸ¥è·¯å¾„: {model_dir}")
            if not model_dir.exists():
                self.logger.debug(f"    âœ— è·¯å¾„ä¸å­˜åœ¨")
                continue

            # ä½¿ç”¨ç»Ÿä¸€çš„å¿«ç…§é€‰æ‹©é€»è¾‘
            latest_snapshot = self._get_latest_snapshot(model_dir)
            if not latest_snapshot:
                self.logger.debug(f"    âœ— æœªæ‰¾åˆ°æœ‰æ•ˆå¿«ç…§")
                continue

            self.logger.debug(f"    æœ€æ–°å¿«ç…§: {latest_snapshot}")

            # éªŒè¯å®Œæ•´æ€§
            is_complete, missing_files, detail = ModelValidator.validate_whisper_model(latest_snapshot)

            if is_complete:
                self.logger.debug(f"    âœ“ éªŒè¯æˆåŠŸ")
                return ("ready", latest_snapshot, detail)
            else:
                self.logger.debug(f"    âœ— éªŒè¯å¤±è´¥: {missing_files}")
                return ("incomplete", latest_snapshot, f"ç¼ºå¤±æ–‡ä»¶: {', '.join(missing_files)}\n{detail}")

        self.logger.debug(f"  æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„æ¨¡å‹è·¯å¾„")
        return ("not_downloaded", None, "æ¨¡å‹æœªä¸‹è½½")

    def _check_align_model_exists(self, language: str) -> tuple[str, Optional[Path], str]:
        """
        æ£€æŸ¥å¯¹é½æ¨¡å‹æ˜¯å¦å­˜åœ¨å¹¶éªŒè¯å®Œæ•´æ€§

        Args:
            language: è¯­è¨€ä»£ç 

        Returns:
            tuple: (çŠ¶æ€, æœ¬åœ°è·¯å¾„, éªŒè¯ä¿¡æ¯)
        """
        # å¯¹é½æ¨¡å‹ä¹Ÿç¼“å­˜åœ¨HuggingFaceç›®å½•ä¸­
        hf_cache = config.HF_CACHE_DIR  # ä¿®å¤ï¼šç›´æ¥ä½¿ç”¨ HF_CACHE_DIRï¼Œä¸åŠ  hub

        # ä½¿ç”¨é¢„å®šä¹‰çš„è·¯å¾„æ˜ å°„
        model_patterns = self.ALIGN_MODEL_PATHS.get(language, [])

        if not model_patterns:
            return ("not_downloaded", None, f"è¯­è¨€ {language} æ²¡æœ‰å¯¹åº”çš„æ¨¡å‹è·¯å¾„æ˜ å°„")

        for pattern in model_patterns:
            model_dir = hf_cache / pattern
            if not model_dir.exists():
                continue

            # ä½¿ç”¨ç»Ÿä¸€çš„å¿«ç…§é€‰æ‹©é€»è¾‘
            latest_snapshot = self._get_latest_snapshot(model_dir)
            if not latest_snapshot:
                continue

            # éªŒè¯å®Œæ•´æ€§
            is_complete, missing_files, detail = ModelValidator.validate_align_model(latest_snapshot)

            if is_complete:
                return ("ready", latest_snapshot, detail)
            else:
                return ("incomplete", latest_snapshot, f"ç¼ºå¤±æ–‡ä»¶: {', '.join(missing_files)}\n{detail}")

        return ("not_downloaded", None, "æ¨¡å‹æœªä¸‹è½½")

    def list_whisper_models(self) -> List[ModelInfo]:
        """åˆ—å‡ºæ‰€æœ‰Whisperæ¨¡å‹çŠ¶æ€"""
        return list(self.whisper_models.values())

    def list_align_models(self) -> List[AlignModelInfo]:
        """åˆ—å‡ºæ‰€æœ‰å¯¹é½æ¨¡å‹çŠ¶æ€"""
        return list(self.align_models.values())

    def get_largest_ready_model(self) -> Optional[str]:
        """
        è·å–ä½“ç§¯æœ€å¤§çš„å·²å°±ç»ªï¼ˆreadyï¼‰çš„Whisperæ¨¡å‹

        Returns:
            Optional[str]: æ¨¡å‹IDï¼Œå¦‚æœæ²¡æœ‰readyçš„æ¨¡å‹åˆ™è¿”å›None
        """
        ready_models = [
            (model_id, model.size_mb)
            for model_id, model in self.whisper_models.items()
            if model.status == "ready"
        ]

        if not ready_models:
            return None

        # æŒ‰ä½“ç§¯æ’åºï¼Œè¿”å›æœ€å¤§çš„
        largest_model = max(ready_models, key=lambda x: x[1])
        self.logger.debug(f"ğŸ“Š æœ€å¤§çš„readyæ¨¡å‹: {largest_model[0]} ({largest_model[1]}MB)")
        return largest_model[0]

    def get_ready_whisper_models(self) -> List[str]:
        """
        è·å–æ‰€æœ‰å·²å°±ç»ªï¼ˆreadyï¼‰çš„Whisperæ¨¡å‹IDåˆ—è¡¨

        Returns:
            List[str]: æ¨¡å‹IDåˆ—è¡¨
        """
        ready_models = [
            model_id
            for model_id, model in self.whisper_models.items()
            if model.status == "ready"
        ]
        return ready_models
    
    def register_progress_callback(self, callback: Callable):
        """æ³¨å†Œè¿›åº¦å›è°ƒå‡½æ•°ï¼ˆç”¨äºSSEæ¨é€ï¼‰"""
        if callback not in self.progress_callbacks:
            self.progress_callbacks.append(callback)
    
    def unregister_progress_callback(self, callback: Callable):
        """å–æ¶ˆæ³¨å†Œè¿›åº¦å›è°ƒå‡½æ•°"""
        if callback in self.progress_callbacks:
            self.progress_callbacks.remove(callback)
    
    def _notify_progress(self, model_type: str, model_id: str, progress: float, status: str, message: str = ""):
        """é€šçŸ¥æ‰€æœ‰æ³¨å†Œçš„å›è°ƒå‡½æ•°"""
        for callback in self.progress_callbacks:
            try:
                callback(model_type, model_id, progress, status, message)
            except Exception as e:
                self.logger.error(f"è¿›åº¦å›è°ƒå¤±è´¥: {e}")
    
    def _background_validate_models(self):
        """åå°å¼‚æ­¥éªŒè¯æ‰€æœ‰æ¨¡å‹å®Œæ•´æ€§ï¼ˆç«‹å³å¯åŠ¨ï¼Œæ— å»¶è¿Ÿï¼‰"""
        self.logger.info("ğŸ” å¼€å§‹åå°éªŒè¯æ¨¡å‹å®Œæ•´æ€§...")

        # éªŒè¯ Whisper æ¨¡å‹
        for model_id, model in self.whisper_models.items():
            if model.status == "ready":
                self.logger.debug(f"ğŸ” éªŒè¯Whisperæ¨¡å‹: {model_id}")
                status, local_path, detail = self._check_whisper_model_exists(model_id)

                if status != "ready":
                    # éªŒè¯å¤±è´¥ï¼Œç«‹å³æ›´æ–°çŠ¶æ€å¹¶é€šçŸ¥å‰ç«¯
                    self.logger.warning(f"âš ï¸ åå°éªŒè¯å‘ç°æ¨¡å‹ä¸å®Œæ•´: {model_id}\n{detail}")
                    model.status = "incomplete"
                    model.download_progress = 0.0

                    # é€šè¿‡SSEé€šçŸ¥å‰ç«¯
                    self._notify_progress(
                        "whisper",
                        model_id,
                        0,
                        "incomplete",
                        f"æ¨¡å‹æ–‡ä»¶ä¸å®Œæ•´ï¼š{detail}"
                    )
                else:
                    self.logger.info(f"âœ… Whisperæ¨¡å‹éªŒè¯é€šè¿‡: {model_id}")

        # éªŒè¯å¯¹é½æ¨¡å‹
        for lang, model in self.align_models.items():
            if model.status == "ready":
                self.logger.debug(f"ğŸ” éªŒè¯å¯¹é½æ¨¡å‹: {lang}")
                status, local_path, detail = self._check_align_model_exists(lang)

                if status != "ready":
                    # éªŒè¯å¤±è´¥ï¼Œç«‹å³æ›´æ–°çŠ¶æ€å¹¶é€šçŸ¥å‰ç«¯
                    self.logger.warning(f"âš ï¸ åå°éªŒè¯å‘ç°å¯¹é½æ¨¡å‹ä¸å®Œæ•´: {lang}\n{detail}")
                    model.status = "incomplete"
                    model.download_progress = 0.0

                    # é€šè¿‡SSEé€šçŸ¥å‰ç«¯
                    self._notify_progress(
                        "align",
                        lang,
                        0,
                        "incomplete",
                        f"æ¨¡å‹æ–‡ä»¶ä¸å®Œæ•´ï¼š{detail}"
                    )
                else:
                    self.logger.info(f"âœ… å¯¹é½æ¨¡å‹éªŒè¯é€šè¿‡: {lang}")

        self.logger.info("âœ… åå°æ¨¡å‹éªŒè¯å®Œæˆ")

    def download_whisper_model(self, model_id: str) -> bool:
        """
        ä¸‹è½½Whisperæ¨¡å‹ï¼ˆæ”¯æŒé˜Ÿåˆ—ç®¡ç† + åŒé‡æ£€æŸ¥é”å®šï¼‰

        Args:
            model_id: æ¨¡å‹ID

        Returns:
            bool: æ˜¯å¦æˆåŠŸåŠ å…¥ä¸‹è½½é˜Ÿåˆ—
        """
        if model_id not in self.whisper_models:
            self.logger.warning(f"âŒ ä¸æ”¯æŒçš„æ¨¡å‹: {model_id}")
            return False

        model = self.whisper_models[model_id]
        model_key = f"whisper/{model_id}"

        # ç¬¬ä¸€æ¬¡æ£€æŸ¥ï¼ˆå¿«é€Ÿå¤±è´¥ï¼Œæ— é”ï¼‰
        if model_key in self.downloading_models and self.downloading_models[model_key]:
            self.logger.warning(f"â³ æ¨¡å‹æ­£åœ¨ä¸‹è½½ä¸­: {model_id}")
            self._notify_progress("whisper", model_id, 0, "waiting", f"æ¨¡å‹æ­£åœ¨ä¸‹è½½ä¸­ï¼Œè¯·ç­‰å¾…")
            return False

        # æ£€æŸ¥å½“å‰æ¨¡å‹çŠ¶æ€
        if model.status == "downloading":
            self.logger.info(f"â³ æ¨¡å‹æ­£åœ¨ä¸‹è½½ä¸­: {model_id}")
            return False

        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨ä¸”å®Œæ•´
        status, local_path, detail = self._check_whisper_model_exists(model_id)
        if status == "ready":
            self.logger.info(f"âœ… æ¨¡å‹å·²å­˜åœ¨ä¸”å®Œæ•´: {model_id}")
            model.status = "ready"
            model.download_progress = 100.0
            if local_path:
                model.local_path = str(local_path)
            self._notify_progress("whisper", model_id, 100, "ready", "æ¨¡å‹å·²å°±ç»ª")
            return True  # ä¸éœ€è¦ä¸‹è½½

        # åŒé‡æ£€æŸ¥é”å®šï¼ˆç¡®ä¿åŸå­æ€§ï¼‰
        with self.download_lock:
            # ç¬¬äºŒæ¬¡æ£€æŸ¥ï¼ˆé”å†…ï¼Œç¡®ä¿åŸå­æ€§ï¼‰
            if model_key in self.downloading_models and self.downloading_models[model_key]:
                self.logger.warning(f"â³ æ¨¡å‹æ­£åœ¨ä¸‹è½½ä¸­ï¼ˆé”å†…æ£€æŸ¥ï¼‰: {model_id}")
                return False

            # æ ‡è®°ä¸ºä¸‹è½½ä¸­
            self.downloading_models[model_key] = True

        # å¦‚æœæ¨¡å‹ä¸å®Œæ•´ï¼Œæ¸…ç†æ—§æ–‡ä»¶ï¼ˆåªæ¸…ç†è¯¥æ¨¡å‹ï¼Œä¸å½±å“å…¶ä»–æ¨¡å‹ï¼‰
        if status == "incomplete" and local_path:
            self.logger.warning(f"ğŸ—‘ï¸ æ¸…ç†ä¸å®Œæ•´çš„æ¨¡å‹æ–‡ä»¶: {model_id}")
            try:
                # è·å–è¯¥æ¨¡å‹çš„æ ¹ç›®å½•ï¼šsnapshotsçš„ä¸Šä¸¤çº§
                # ç»“æ„: models--Systran--faster-whisper-xxx/snapshots/hash/
                # éœ€è¦åˆ é™¤: models--Systran--faster-whisper-xxx/
                model_root = local_path.parent.parent
                if model_root.exists() and model_root.name.startswith("models--"):
                    self.logger.info(f"ğŸ—‘ï¸ åˆ é™¤ä¸å®Œæ•´æ¨¡å‹ç›®å½•: {model_root}")
                    shutil.rmtree(model_root)
                    self.logger.info(f"âœ… å·²æ¸…ç†ä¸å®Œæ•´æ¨¡å‹: {model_root.name}")
                else:
                    self.logger.warning(f"âš ï¸ æ¨¡å‹è·¯å¾„å¼‚å¸¸ï¼Œè·³è¿‡æ¸…ç†: {model_root}")
            except Exception as e:
                self.logger.error(f"æ¸…ç†å¤±è´¥: {e}")

        model.status = "downloading"
        model.download_progress = 0.0

        self._notify_progress("whisper", model_id, 0, "downloading", "å¼€å§‹ä¸‹è½½...")

        # å¯åŠ¨ä¸‹è½½çº¿ç¨‹
        threading.Thread(
            target=self._download_whisper_model_task,
            args=(model_id,),
            daemon=True,
            name=f"DownloadWhisper-{model_id}"
        ).start()

        self.logger.info(f"ğŸš€ å¼€å§‹ä¸‹è½½Whisperæ¨¡å‹: {model_id}")
        return True

    def download_align_model(self, language: str) -> bool:
        """
        ä¸‹è½½å¯¹é½æ¨¡å‹ï¼ˆæ”¯æŒå¹¶å‘æ§åˆ¶ + åŒé‡æ£€æŸ¥é”å®šï¼‰

        Args:
            language: è¯­è¨€ä»£ç 

        Returns:
            bool: æ˜¯å¦æˆåŠŸåŠ å…¥ä¸‹è½½é˜Ÿåˆ—
        """
        if language not in self.align_models:
            self.logger.warning(f"âŒ ä¸æ”¯æŒçš„è¯­è¨€: {language}")
            return False

        model = self.align_models[language]
        model_key = f"align/{language}"

        # ç¬¬ä¸€æ¬¡æ£€æŸ¥ï¼ˆå¿«é€Ÿå¤±è´¥ï¼Œæ— é”ï¼‰
        if model_key in self.downloading_models and self.downloading_models[model_key]:
            self.logger.warning(f"â³ å¯¹é½æ¨¡å‹æ­£åœ¨ä¸‹è½½ä¸­: {language}")
            return False

        if model.status == "downloading":
            self.logger.info(f"â³ å¯¹é½æ¨¡å‹æ­£åœ¨ä¸‹è½½ä¸­: {language}")
            return False

        # åŒé‡æ£€æŸ¥é”å®šï¼ˆç¡®ä¿åŸå­æ€§ï¼‰
        with self.download_lock:
            # ç¬¬äºŒæ¬¡æ£€æŸ¥ï¼ˆé”å†…ï¼Œç¡®ä¿åŸå­æ€§ï¼‰
            if model_key in self.downloading_models and self.downloading_models[model_key]:
                self.logger.warning(f"â³ å¯¹é½æ¨¡å‹æ­£åœ¨ä¸‹è½½ä¸­ï¼ˆé”å†…æ£€æŸ¥ï¼‰: {language}")
                return False

            # æ ‡è®°ä¸ºä¸‹è½½ä¸­
            self.downloading_models[model_key] = True

        # æ ‡è®°ä¸ºä¸‹è½½ä¸­
        model.status = "downloading"
        model.download_progress = 0.0

        self._notify_progress("align", language, 0, "downloading", "å¼€å§‹ä¸‹è½½...")

        # å¯åŠ¨ä¸‹è½½çº¿ç¨‹
        threading.Thread(
            target=self._download_align_model_task,
            args=(language,),
            daemon=True,
            name=f"DownloadAlign-{language}"
        ).start()

        self.logger.info(f"ğŸš€ å¼€å§‹ä¸‹è½½å¯¹é½æ¨¡å‹: {language}")
        return True

    def auto_download_for_language(self, language: str) -> bool:
        """
        è‡ªåŠ¨ä¸‹è½½æŒ‡å®šè¯­è¨€æ‰€éœ€çš„å¯¹é½æ¨¡å‹
        ç”¨äºæ–­ç‚¹ç»­ä¼ æ¢å¤æ—¶è‡ªåŠ¨è¡¥é½æ¨¡å‹

        Args:
            language: è¯­è¨€ä»£ç 

        Returns:
            bool: æ˜¯å¦éœ€è¦ä¸‹è½½ï¼ˆTrueï¼‰æˆ–å·²å­˜åœ¨ï¼ˆFalseï¼‰
        """
        if language not in self.align_models:
            self.logger.warning(f"âš ï¸ ä¸æ”¯æŒçš„è¯­è¨€: {language}")
            return False

        model = self.align_models[language]

        if model.status == "ready":
            self.logger.info(f"âœ… å¯¹é½æ¨¡å‹å·²å­˜åœ¨: {language}")
            return False

        self.logger.info(f"ğŸ” æ£€æµ‹åˆ°æ–°è¯­è¨€ {language}ï¼Œå¼€å§‹è‡ªåŠ¨ä¸‹è½½å¯¹é½æ¨¡å‹")
        return self.download_align_model(language)

    def delete_whisper_model(self, model_id: str) -> bool:
        """
        åˆ é™¤Whisperæ¨¡å‹ï¼ˆåªåˆ é™¤æŒ‡å®šæ¨¡å‹ï¼Œä¸å½±å“å…¶ä»–æ¨¡å‹ï¼‰

        Args:
            model_id: æ¨¡å‹ID

        Returns:
            bool: æ˜¯å¦åˆ é™¤æˆåŠŸ
        """
        if model_id not in self.whisper_models:
            return False

        model = self.whisper_models[model_id]

        if model.status != "ready" or not model.local_path:
            self.logger.warning(f"âš ï¸ æ¨¡å‹æœªä¸‹è½½æˆ–è·¯å¾„ä¸å­˜åœ¨: {model_id}")
            return False

        try:
            # è·å–æ¨¡å‹çš„æ ¹ç›®å½•ï¼ˆåˆ é™¤æ•´ä¸ªæ¨¡å‹ç¼“å­˜ï¼Œè€Œéä»…å¿«ç…§ï¼‰
            local_path = Path(model.local_path)
            # ç»“æ„: models--Systran--faster-whisper-xxx/snapshots/hash/
            # éœ€è¦åˆ é™¤: models--Systran--faster-whisper-xxx/
            model_root = local_path.parent.parent

            if model_root.exists() and model_root.name.startswith("models--"):
                self.logger.info(f"ğŸ—‘ï¸ åˆ é™¤Whisperæ¨¡å‹ç›®å½•: {model_root}")
                shutil.rmtree(model_root)
                self.logger.info(f"âœ… å·²åˆ é™¤Whisperæ¨¡å‹: {model_id} ({model_root.name})")
            else:
                self.logger.warning(f"âš ï¸ æ¨¡å‹è·¯å¾„å¼‚å¸¸: {model_root}")
                return False

            # æ›´æ–°çŠ¶æ€
            model.status = "not_downloaded"
            model.download_progress = 0.0
            model.local_path = None

            return True

        except Exception as e:
            self.logger.error(f"âŒ åˆ é™¤æ¨¡å‹å¤±è´¥: {model_id} - {e}")
            return False

    def delete_align_model(self, language: str) -> bool:
        """
        åˆ é™¤å¯¹é½æ¨¡å‹ï¼ˆåªåˆ é™¤æŒ‡å®šæ¨¡å‹ï¼Œä¸å½±å“å…¶ä»–æ¨¡å‹ï¼‰

        Args:
            language: è¯­è¨€ä»£ç 

        Returns:
            bool: æ˜¯å¦åˆ é™¤æˆåŠŸ
        """
        if language not in self.align_models:
            return False

        model = self.align_models[language]

        if model.status != "ready" or not model.local_path:
            self.logger.warning(f"âš ï¸ å¯¹é½æ¨¡å‹æœªä¸‹è½½æˆ–è·¯å¾„ä¸å­˜åœ¨: {language}")
            return False

        try:
            # è·å–æ¨¡å‹çš„æ ¹ç›®å½•ï¼ˆåˆ é™¤æ•´ä¸ªæ¨¡å‹ç¼“å­˜ï¼Œè€Œéä»…å¿«ç…§ï¼‰
            local_path = Path(model.local_path)
            # ç»“æ„: models--jonatasgrosman--wav2vec2-large-xlsr-53-chinese-zh-cn/snapshots/hash/
            # éœ€è¦åˆ é™¤: models--jonatasgrosman--wav2vec2-large-xlsr-53-chinese-zh-cn/
            model_root = local_path.parent.parent

            if model_root.exists() and model_root.name.startswith("models--"):
                self.logger.info(f"ğŸ—‘ï¸ åˆ é™¤å¯¹é½æ¨¡å‹ç›®å½•: {model_root}")
                shutil.rmtree(model_root)
                self.logger.info(f"âœ… å·²åˆ é™¤å¯¹é½æ¨¡å‹: {language} ({model_root.name})")
            else:
                self.logger.warning(f"âš ï¸ æ¨¡å‹è·¯å¾„å¼‚å¸¸: {model_root}")
                return False

            # æ›´æ–°çŠ¶æ€
            model.status = "not_downloaded"
            model.download_progress = 0.0
            model.local_path = None

            return True

        except Exception as e:
            self.logger.error(f"âŒ åˆ é™¤å¯¹é½æ¨¡å‹å¤±è´¥: {language} - {e}")
            return False

    def get_download_progress(self) -> Dict:
        """è·å–æ‰€æœ‰ä¸‹è½½è¿›åº¦"""
        return {
            "whisper": {
                mid: {
                    "status": m.status,
                    "progress": m.download_progress
                }
                for mid, m in self.whisper_models.items()
            },
            "align": {
                lang: {
                    "status": m.status,
                    "progress": m.download_progress
                }
                for lang, m in self.align_models.items()
            }
        }

    def is_model_downloading(self, model_type: str, model_id: str) -> bool:
        """
        æ£€æŸ¥æŒ‡å®šæ¨¡å‹æ˜¯å¦æ­£åœ¨ä¸‹è½½

        Args:
            model_type: "whisper" æˆ– "align"
            model_id: æ¨¡å‹IDæˆ–è¯­è¨€ä»£ç 

        Returns:
            bool: æ˜¯å¦æ­£åœ¨ä¸‹è½½
        """
        model_key = f"{model_type}/{model_id}"
        with self.download_lock:
            return self.downloading_models.get(model_key, False)

    def wait_for_download_complete(
        self,
        model_type: str,
        model_id: str,
        timeout: int = 600,
        check_interval: float = 2.0
    ) -> bool:
        """
        ç­‰å¾…æ¨¡å‹ä¸‹è½½å®Œæˆï¼ˆå¸¦è¶…æ—¶ï¼‰

        Args:
            model_type: æ¨¡å‹ç±»å‹ ("whisper" æˆ– "align")
            model_id: æ¨¡å‹IDæˆ–è¯­è¨€ä»£ç 
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            check_interval: æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰

        Returns:
            bool: æ˜¯å¦æˆåŠŸå®Œæˆï¼ˆTrueï¼‰æˆ–è¶…æ—¶/å¤±è´¥ï¼ˆFalseï¼‰
        """
        start_time = time.time()
        model_key = f"{model_type}/{model_id}"

        self.logger.info(f"â³ ç­‰å¾…æ¨¡å‹ä¸‹è½½å®Œæˆ: {model_key} (è¶…æ—¶: {timeout}ç§’)")

        while time.time() - start_time < timeout:
            # æ£€æŸ¥ä¸‹è½½çŠ¶æ€
            with self.download_lock:
                if model_key not in self.downloading_models or \
                   not self.downloading_models[model_key]:
                    # ä¸‹è½½å·²ç»“æŸï¼Œæ£€æŸ¥ç»“æœ
                    if model_type == "whisper":
                        model = self.whisper_models.get(model_id)
                    else:
                        model = self.align_models.get(model_id)

                    if model and model.status == "ready":
                        self.logger.info(f"âœ… æ¨¡å‹ä¸‹è½½å®Œæˆ: {model_key}")
                        return True
                    elif model and model.status == "error":
                        self.logger.error(f"âŒ æ¨¡å‹ä¸‹è½½å¤±è´¥: {model_key}")
                        return False

            # ç­‰å¾…ä¸€æ®µæ—¶é—´åé‡è¯•
            time.sleep(check_interval)

        self.logger.warning(f"â° ç­‰å¾…æ¨¡å‹ä¸‹è½½è¶…æ—¶: {model_key}")
        return False

    def _download_whisper_model_task(self, model_id: str):
        """ä¸‹è½½Whisperæ¨¡å‹ä»»åŠ¡ï¼ˆåå°çº¿ç¨‹ï¼‰- æ”¹è¿›ç‰ˆ"""
        model = None
        try:
            model = self.whisper_models[model_id]
            self.logger.info(f"ğŸ“¥ æ­£åœ¨ä¸‹è½½Whisperæ¨¡å‹: {model_id}")
            self.logger.info(f"ğŸ“ ä¸‹è½½ç›®å½•: {config.HF_CACHE_DIR}")
            
            # æ›´æ–°è¿›åº¦: å‡†å¤‡ä¸‹è½½
            self._notify_progress("whisper", model_id, 5, "downloading", "å‡†å¤‡ä¸‹è½½...")
            model.download_progress = 5.0
            
            # ç­–ç•¥: ä¼˜å…ˆé•œåƒç«™ï¼Œå¤±è´¥åå°è¯•å®˜æ–¹æº
            use_mirror = os.getenv('USE_HF_MIRROR', 'false').lower() == 'true'
            download_success = False
            last_error = None
            local_dir = None  # åˆå§‹åŒ–ä¸‹è½½è·¯å¾„å˜é‡
            
            # æ–¹å¼1: ä½¿ç”¨ requests æ‰‹åŠ¨ä¸‹è½½ï¼ˆå®Œå…¨æ§åˆ¶ï¼Œå¸¦å®æ—¶è¿›åº¦è¿½è¸ªï¼‰
            if not download_success:
                try:
                    self.logger.info(f"ğŸ”„ æ–¹å¼1: ä½¿ç”¨æ‰‹åŠ¨ä¸‹è½½æ–¹å¼...")
                    self._notify_progress("whisper", model_id, 0, "downloading", "å‡†å¤‡ä¸‹è½½...")

                    import requests
                    from huggingface_hub import hf_hub_url, list_repo_files
                    from pathlib import Path as PathlibPath

                    repo_id = f"Systran/faster-whisper-{model_id}"
                    cache_dir = str(config.HF_CACHE_DIR)

                    if use_mirror:
                        self.logger.info(f"ğŸ“¦ ä»é•œåƒç«™ä¸‹è½½: {config.HF_ENDPOINT}")
                    else:
                        self.logger.info(f"ğŸ“¦ ä»å®˜æ–¹æºä¸‹è½½: {repo_id}")

                    # è·å–æ–‡ä»¶åˆ—è¡¨
                    self.logger.info("ğŸ“‹ è·å–æ¨¡å‹æ–‡ä»¶åˆ—è¡¨...")
                    files = list_repo_files(repo_id, repo_type="model")

                    # åˆ†ç±»æ–‡ä»¶ï¼šå°æ–‡ä»¶å’Œå¤§æ–‡ä»¶ï¼ˆmodel.binï¼‰
                    small_files = [f for f in files if not f.endswith('.bin')]
                    large_files = [f for f in files if f.endswith('.bin')]

                    self.logger.info(f"ğŸ“¦ éœ€è¦ä¸‹è½½ {len(small_files)} ä¸ªé…ç½®æ–‡ä»¶å’Œ {len(large_files)} ä¸ªæ¨¡å‹æ–‡ä»¶")

                    # ç¡®å®šä¿å­˜è·¯å¾„ï¼ˆä½¿ç”¨HuggingFaceçš„æ ‡å‡†è·¯å¾„ç»“æ„ï¼‰
                    # æ ¼å¼ï¼šmodels--Systran--faster-whisper-{model_id}
                    repo_path = repo_id.replace("/", "--")
                    storage_folder = PathlibPath(cache_dir) / f"models--{repo_path}"

                    # åˆ›å»ºsnapshotsç›®å½•
                    snapshots_dir = storage_folder / "snapshots"
                    # ä½¿ç”¨æ—¶é—´æˆ³ä½œä¸ºsnapshot ID
                    import hashlib
                    snapshot_id = hashlib.sha256(str(time.time()).encode()).hexdigest()[:12]
                    snapshot_dir = snapshots_dir / snapshot_id
                    snapshot_dir.mkdir(parents=True, exist_ok=True)

                    # é˜¶æ®µ1ï¼šä¸‹è½½å°æ–‡ä»¶ï¼ˆ0% -> 10%ï¼‰
                    for idx, filename in enumerate(small_files):
                        try:
                            progress = (idx / len(small_files)) * 10
                            self._notify_progress("whisper", model_id, progress, "downloading", f"ä¸‹è½½é…ç½®æ–‡ä»¶ ({idx+1}/{len(small_files)})")
                            model.download_progress = progress

                            url = hf_hub_url(repo_id, filename, repo_type="model")
                            response = requests.get(url, timeout=(30, 300))  # è¿æ¥30ç§’ï¼Œè¯»å–5åˆ†é’Ÿ
                            response.raise_for_status()

                            file_path = snapshot_dir / filename
                            file_path.parent.mkdir(parents=True, exist_ok=True)
                            file_path.write_bytes(response.content)

                            self.logger.info(f"  âœ“ {filename}")
                        except Exception as e:
                            self.logger.warning(f"  âœ— {filename}: {e}")
                            raise  # å°æ–‡ä»¶ä¸‹è½½å¤±è´¥å°±ç»ˆæ­¢

                    self._notify_progress("whisper", model_id, 10, "downloading", "é…ç½®æ–‡ä»¶ä¸‹è½½å®Œæˆï¼Œå¼€å§‹ä¸‹è½½æ¨¡å‹æ–‡ä»¶...")
                    model.download_progress = 10.0

                    # é˜¶æ®µ2ï¼šä¸‹è½½å¤§æ–‡ä»¶ï¼ˆ10% -> 100%ï¼‰
                    for filename in large_files:
                        self.logger.info(f"ğŸ“¥ å¼€å§‹ä¸‹è½½å¤§æ–‡ä»¶: {filename}")

                        url = hf_hub_url(repo_id, filename, repo_type="model")

                        # è·å–æ–‡ä»¶å¤§å°
                        head_response = requests.head(url, allow_redirects=True, timeout=30)
                        total_size = int(head_response.headers.get('content-length', 0))

                        self.logger.info(f"ğŸ“Š æ–‡ä»¶å¤§å°: {total_size / 1024 / 1024:.1f} MB")

                        # æµå¼ä¸‹è½½å¹¶è¿½è¸ªè¿›åº¦
                        response = requests.get(url, stream=True, timeout=(30, 600))  # è¿æ¥30ç§’ï¼Œè¯»å–10åˆ†é’Ÿ
                        response.raise_for_status()

                        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
                        temp_file = snapshot_dir / f"{filename}.download"
                        final_file = snapshot_dir / filename
                        temp_file.parent.mkdir(parents=True, exist_ok=True)

                        downloaded = 0
                        chunk_size = 1024 * 1024  # 1MB chunks
                        last_reported_progress = 0  # è®°å½•ä¸Šæ¬¡æŠ¥å‘Šçš„è¿›åº¦

                        with open(temp_file, 'wb') as f:
                            for chunk in response.iter_content(chunk_size=chunk_size):
                                if chunk:
                                    f.write(chunk)
                                    downloaded += len(chunk)

                                    # è®¡ç®—è¿›åº¦ï¼š10% + (å½“å‰ä¸‹è½½/æ€»å¤§å°) * 90%
                                    if total_size > 0:
                                        file_progress = (downloaded / total_size) * 90
                                        total_progress = 10 + file_progress

                                        # ä¼˜åŒ–ï¼šåªåœ¨è¿›åº¦å˜åŒ–è¶…è¿‡0.5%æ—¶æ‰æ›´æ–°ï¼ˆé¿å…é¢‘ç¹æ›´æ–°ï¼‰
                                        if total_progress - last_reported_progress >= 0.5 or downloaded == total_size:
                                            self._notify_progress("whisper", model_id, total_progress, "downloading",
                                                                f"ä¸‹è½½æ¨¡å‹æ–‡ä»¶ {downloaded/1024/1024:.1f}/{total_size/1024/1024:.1f} MB ({total_progress:.1f}%)")
                                            model.download_progress = total_progress
                                            last_reported_progress = total_progress

                        # ä¸‹è½½å®Œæˆï¼Œé‡å‘½åæ–‡ä»¶
                        temp_file.rename(final_file)
                        self.logger.info(f"  âœ“ {filename} ä¸‹è½½å®Œæˆ")

                    # åˆ›å»º refs/main æŒ‡å‘å½“å‰snapshot
                    refs_dir = storage_folder / "refs"
                    refs_dir.mkdir(parents=True, exist_ok=True)
                    (refs_dir / "main").write_text(snapshot_id)

                    local_dir = snapshot_dir
                    self.logger.info(f"âœ… æ–¹å¼1æˆåŠŸä¸‹è½½åˆ°: {local_dir}")
                    self._notify_progress("whisper", model_id, 100, "downloading", "ä¸‹è½½å®Œæˆï¼ŒéªŒè¯æ–‡ä»¶...")
                    model.download_progress = 100.0
                    download_success = True

                except Exception as e1:
                    last_error = e1
                    self.logger.warning(f"âš ï¸ æ–¹å¼1å¤±è´¥: {e1}")
                    self._notify_progress("whisper", model_id, 0, "downloading", f"æ–¹å¼1å¤±è´¥ï¼Œå°è¯•å…¶ä»–æ–¹å¼...")
            
            # æ–¹å¼2: å¦‚æœæ–¹å¼1å¤±è´¥ä¸”ä½¿ç”¨äº†é•œåƒï¼Œå°è¯•åˆ‡æ¢åˆ°å®˜æ–¹æº
            if not download_success and use_mirror:
                try:
                    self.logger.info(f"ğŸ”„ æ–¹å¼2: åˆ‡æ¢åˆ°å®˜æ–¹æºé‡è¯•...")
                    self._notify_progress("whisper", model_id, 0, "downloading", "åˆ‡æ¢åˆ°å®˜æ–¹æº...")

                    # ä¸´æ—¶åˆ‡æ¢åˆ°å®˜æ–¹æº
                    old_endpoint = os.environ.get('HF_ENDPOINT')
                    if 'HF_ENDPOINT' in os.environ:
                        del os.environ['HF_ENDPOINT']

                    try:
                        import requests
                        from huggingface_hub import hf_hub_url, list_repo_files
                        from pathlib import Path as PathlibPath

                        repo_id = f"Systran/faster-whisper-{model_id}"
                        cache_dir = str(config.HF_CACHE_DIR)

                        self.logger.info(f"ğŸ“¦ ä»å®˜æ–¹æºä¸‹è½½: https://huggingface.co")

                        # è·å–æ–‡ä»¶åˆ—è¡¨
                        files = list_repo_files(repo_id, repo_type="model")
                        small_files = [f for f in files if not f.endswith('.bin')]
                        large_files = [f for f in files if f.endswith('.bin')]

                        # ç¡®å®šä¿å­˜è·¯å¾„
                        repo_path = repo_id.replace("/", "--")
                        storage_folder = PathlibPath(cache_dir) / f"models--{repo_path}"
                        snapshots_dir = storage_folder / "snapshots"

                        import hashlib
                        snapshot_id = hashlib.sha256(str(time.time()).encode()).hexdigest()[:12]
                        snapshot_dir = snapshots_dir / snapshot_id
                        snapshot_dir.mkdir(parents=True, exist_ok=True)

                        # ä¸‹è½½å°æ–‡ä»¶ï¼ˆ0% -> 10%ï¼‰
                        for idx, filename in enumerate(small_files):
                            progress = (idx / len(small_files)) * 10
                            self._notify_progress("whisper", model_id, progress, "downloading", f"ä¸‹è½½é…ç½®æ–‡ä»¶ ({idx+1}/{len(small_files)})")
                            model.download_progress = progress

                            url = hf_hub_url(repo_id, filename, repo_type="model")
                            response = requests.get(url, timeout=(30, 300))
                            response.raise_for_status()

                            file_path = snapshot_dir / filename
                            file_path.parent.mkdir(parents=True, exist_ok=True)
                            file_path.write_bytes(response.content)

                            self.logger.info(f"  âœ“ {filename}")

                        self._notify_progress("whisper", model_id, 10, "downloading", "é…ç½®æ–‡ä»¶ä¸‹è½½å®Œæˆï¼Œå¼€å§‹ä¸‹è½½æ¨¡å‹æ–‡ä»¶...")
                        model.download_progress = 10.0

                        # ä¸‹è½½å¤§æ–‡ä»¶ï¼ˆ10% -> 100%ï¼‰
                        for filename in large_files:
                            self.logger.info(f"ğŸ“¥ å¼€å§‹ä¸‹è½½å¤§æ–‡ä»¶: {filename}")

                            url = hf_hub_url(repo_id, filename, repo_type="model")

                            # è·å–æ–‡ä»¶å¤§å°
                            head_response = requests.head(url, allow_redirects=True, timeout=30)
                            total_size = int(head_response.headers.get('content-length', 0))
                            self.logger.info(f"ğŸ“Š æ–‡ä»¶å¤§å°: {total_size / 1024 / 1024:.1f} MB")

                            # æµå¼ä¸‹è½½
                            response = requests.get(url, stream=True, timeout=(30, 600))
                            response.raise_for_status()

                            temp_file = snapshot_dir / f"{filename}.download"
                            final_file = snapshot_dir / filename
                            temp_file.parent.mkdir(parents=True, exist_ok=True)

                            downloaded = 0
                            chunk_size = 1024 * 1024
                            last_reported_progress = 0  # è®°å½•ä¸Šæ¬¡æŠ¥å‘Šçš„è¿›åº¦

                            with open(temp_file, 'wb') as f:
                                for chunk in response.iter_content(chunk_size=chunk_size):
                                    if chunk:
                                        f.write(chunk)
                                        downloaded += len(chunk)

                                        if total_size > 0:
                                            file_progress = (downloaded / total_size) * 90
                                            total_progress = 10 + file_progress

                                            # ä¼˜åŒ–ï¼šåªåœ¨è¿›åº¦å˜åŒ–è¶…è¿‡0.5%æ—¶æ‰æ›´æ–°ï¼ˆé¿å…é¢‘ç¹æ›´æ–°ï¼‰
                                            if total_progress - last_reported_progress >= 0.5 or downloaded == total_size:
                                                self._notify_progress("whisper", model_id, total_progress, "downloading",
                                                                    f"ä¸‹è½½æ¨¡å‹æ–‡ä»¶ {downloaded/1024/1024:.1f}/{total_size/1024/1024:.1f} MB ({total_progress:.1f}%)")
                                                model.download_progress = total_progress
                                                last_reported_progress = total_progress

                            temp_file.rename(final_file)
                            self.logger.info(f"  âœ“ {filename} ä¸‹è½½å®Œæˆ")

                        # åˆ›å»º refs/main
                        refs_dir = storage_folder / "refs"
                        refs_dir.mkdir(parents=True, exist_ok=True)
                        (refs_dir / "main").write_text(snapshot_id)

                        local_dir = snapshot_dir
                        self.logger.info(f"âœ… æ–¹å¼2æˆåŠŸ")
                        self._notify_progress("whisper", model_id, 100, "downloading", "ä¸‹è½½å®Œæˆï¼ŒéªŒè¯æ–‡ä»¶...")
                        model.download_progress = 100.0
                        download_success = True

                    finally:
                        # æ¢å¤é•œåƒæºè®¾ç½®
                        if old_endpoint:
                            os.environ['HF_ENDPOINT'] = old_endpoint

                except Exception as e2:
                    last_error = e2
                    self.logger.error(f"âŒ æ–¹å¼2ä¹Ÿå¤±è´¥: {e2}")
                    self._notify_progress("whisper", model_id, 0, "downloading", "æ–¹å¼2å¤±è´¥ï¼Œå°è¯•æœ€åæ–¹å¼...")
            
            # æ–¹å¼3: ä½¿ç”¨ whisperx åŠ è½½ï¼ˆä¼šè§¦å‘ä¸‹è½½ï¼‰
            if not download_success:
                try:
                    self.logger.info(f"ğŸ”„ æ–¹å¼3: ä½¿ç”¨ whisperx åŠ è½½æ¨¡å‹...")
                    self._notify_progress("whisper", model_id, 30, "downloading", "ä½¿ç”¨å¤‡ç”¨æ–¹å¼ä¸‹è½½...")
                    model.download_progress = 30.0
                    
                    import whisperx
                    _ = whisperx.load_model(
                        model_id,
                        device="cpu",
                        compute_type="int8",
                        download_root=str(config.HF_CACHE_DIR)
                    )
                    
                    self.logger.info(f"âœ… æ–¹å¼3æˆåŠŸ")
                    self._notify_progress("whisper", model_id, 85, "downloading", "éªŒè¯æ¨¡å‹æ–‡ä»¶...")
                    model.download_progress = 85.0
                    download_success = True
                    
                except Exception as e3:
                    last_error = e3
                    self.logger.error(f"âŒ æ–¹å¼3ä¹Ÿå¤±è´¥: {e3}")
            
            # æ£€æŸ¥ä¸‹è½½æ˜¯å¦æˆåŠŸ
            if not download_success:
                raise Exception(f"æ‰€æœ‰ä¸‹è½½æ–¹å¼å‡å¤±è´¥ã€‚æœ€åé”™è¯¯: {str(last_error)[:200]}")

            # éªŒè¯æ¨¡å‹å®Œæ•´æ€§ï¼ˆä½¿ç”¨ä¸‹è½½è¿”å›çš„è·¯å¾„ï¼‰
            self._notify_progress("whisper", model_id, 90, "downloading", "éªŒè¯æ¨¡å‹å®Œæ•´æ€§...")
            model.download_progress = 90.0

            # ä½¿ç”¨ snapshot_download è¿”å›çš„è·¯å¾„ç›´æ¥éªŒè¯
            if local_dir:
                download_path = Path(local_dir)
                self.logger.info(f"ğŸ“‚ éªŒè¯ä¸‹è½½è·¯å¾„: {download_path}")

                # ç›´æ¥éªŒè¯è¿”å›çš„è·¯å¾„
                is_complete, missing_files, detail = ModelValidator.validate_whisper_model(download_path)

                if is_complete:
                    self.logger.info(f"âœ… ä¸‹è½½è·¯å¾„éªŒè¯æˆåŠŸ")
                else:
                    self.logger.warning(f"âš ï¸ ä¸‹è½½è·¯å¾„éªŒè¯å¤±è´¥ï¼Œå°è¯•æ ‡å‡†æŸ¥æ‰¾...")
                    # å›é€€åˆ°æ ‡å‡†æŸ¥æ‰¾
                    status, local_path, detail = self._check_whisper_model_exists(model_id)
                    if status != "ready":
                        raise Exception(f"æ¨¡å‹ä¸‹è½½åéªŒè¯å¤±è´¥: {detail}")
                    download_path = local_path
            else:
                # æ²¡æœ‰è¿”å›è·¯å¾„ï¼Œä½¿ç”¨æ ‡å‡†æŸ¥æ‰¾
                status, download_path, detail = self._check_whisper_model_exists(model_id)
                if status != "ready":
                    raise Exception(f"æ¨¡å‹ä¸‹è½½åéªŒè¯å¤±è´¥: {detail}")
            
            # ä¸‹è½½å®Œæˆï¼Œæ›´æ–°çŠ¶æ€
            model.status = "ready"
            model.download_progress = 100.0
            if download_path:
                model.local_path = str(download_path)

            self._notify_progress("whisper", model_id, 100, "ready", "ä¸‹è½½å®Œæˆï¼")
            self.logger.info(f"âœ… Whisperæ¨¡å‹ä¸‹è½½å®Œæˆ: {model_id}")
            self.logger.info(f"ğŸ“‚ æ¨¡å‹ä½ç½®: {download_path}")
            self.logger.info(f"ğŸ“‹ æ–‡ä»¶éªŒè¯:\n{detail}")

            # è‡ªåŠ¨ä¸‹è½½å¯¹åº”çš„å¯¹é½æ¨¡å‹ï¼ˆä¸²è¡Œç­–ç•¥ï¼‰
            self._auto_download_align_model_for_whisper(model_id)

        except Exception as e:
            if model:
                model.status = "error"
                model.download_progress = 0.0
            error_msg = f"ä¸‹è½½å¤±è´¥: {str(e)[:200]}"
            self._notify_progress("whisper", model_id, 0, "error", error_msg)
            self.logger.error(f"âŒ Whisperæ¨¡å‹ä¸‹è½½å¤±è´¥: {model_id} - {e}", exc_info=True)

        finally:
            # é‡Šæ”¾ä¸‹è½½é”
            model_key = f"whisper/{model_id}"
            with self.download_lock:
                if model_key in self.downloading_models:
                    del self.downloading_models[model_key]
            self.logger.info(f"ğŸ”“ ä¸‹è½½é”å·²é‡Šæ”¾: {model_key}")

    def _auto_download_align_model_for_whisper(self, model_id: str):
        """
        è‡ªåŠ¨ä¸‹è½½Whisperæ¨¡å‹å¯¹åº”çš„å¯¹é½æ¨¡å‹ï¼ˆä¸²è¡Œæ‰§è¡Œï¼‰

        Args:
            model_id: Whisperæ¨¡å‹ID
        """
        # è·å–æ¨èçš„å¯¹é½æ¨¡å‹è¯­è¨€
        align_language = self.WHISPER_RECOMMENDED_ALIGN_MODELS.get(model_id)
        if not align_language:
            self.logger.warning(f"âš ï¸ æœªæ‰¾åˆ°æ¨¡å‹ {model_id} çš„æ¨èå¯¹é½æ¨¡å‹")
            return

        # æ£€æŸ¥å¯¹é½æ¨¡å‹æ˜¯å¦å·²å­˜åœ¨
        status, local_path, detail = self._check_align_model_exists(align_language)
        if status == "ready":
            self.logger.info(f"âœ… å¯¹é½æ¨¡å‹ {align_language} å·²å­˜åœ¨ï¼Œæ— éœ€ä¸‹è½½")
            return

        self.logger.info(f"ğŸ”„ å¼€å§‹è‡ªåŠ¨ä¸‹è½½å¯¹é½æ¨¡å‹: {align_language}")
        self._notify_progress("align", align_language, 0, "downloading", f"è‡ªåŠ¨ä¸‹è½½å¯¹é½æ¨¡å‹ï¼ˆå…³è”æ¨¡å‹: {model_id}ï¼‰")

        # ç›´æ¥è°ƒç”¨ä¸‹è½½å¯¹é½æ¨¡å‹å‡½æ•°ï¼ˆä¼šè‡ªåŠ¨å¤„ç†å¹¶å‘æ§åˆ¶ï¼‰
        success = self.download_align_model(align_language)
        if success:
            self.logger.info(f"âœ… å¯¹é½æ¨¡å‹ {align_language} å·²åŠ å…¥ä¸‹è½½é˜Ÿåˆ—")
        else:
            self.logger.warning(f"âš ï¸ å¯¹é½æ¨¡å‹ {align_language} ä¸‹è½½å¤±è´¥æˆ–å·²åœ¨ä¸‹è½½ä¸­")

    def _download_align_model_task(self, language: str):
        """ä¸‹è½½å¯¹é½æ¨¡å‹ä»»åŠ¡ï¼ˆåå°çº¿ç¨‹ï¼‰"""
        model = None
        try:
            model = self.align_models[language]

            import whisperx

            self.logger.info(f"ğŸ“¥ æ­£åœ¨ä¸‹è½½å¯¹é½æ¨¡å‹: {language}")
            self._notify_progress("align", language, 10, "downloading", "å¼€å§‹ä¸‹è½½...")

            # åŠ è½½å¯¹é½æ¨¡å‹ä¼šè‡ªåŠ¨è§¦å‘ä¸‹è½½
            _, _ = whisperx.load_align_model(
                language_code=language,
                device="cpu",
                model_dir=str(config.HF_CACHE_DIR)
            )

            # ä¸‹è½½å®Œæˆï¼Œæ›´æ–°çŠ¶æ€
            model.status = "ready"
            model.download_progress = 100.0

            # é‡æ–°æ£€æŸ¥è·¯å¾„
            status, local_path, validation_msg = self._check_align_model_exists(language)
            if local_path:
                model.local_path = str(local_path)

            self._notify_progress("align", language, 100, "ready", "ä¸‹è½½å®Œæˆï¼")
            self.logger.info(f"âœ… å¯¹é½æ¨¡å‹ä¸‹è½½å®Œæˆ: {language}")

        except Exception as e:
            if model:
                model.status = "error"
                model.download_progress = 0.0
            error_msg = f"ä¸‹è½½å¤±è´¥: {str(e)[:200]}"
            self._notify_progress("align", language, 0, "error", error_msg)
            self.logger.error(f"âŒ å¯¹é½æ¨¡å‹ä¸‹è½½å¤±è´¥: {language} - {e}", exc_info=True)

        finally:
            # é‡Šæ”¾ä¸‹è½½é”
            model_key = f"align/{language}"
            with self.download_lock:
                if model_key in self.downloading_models:
                    del self.downloading_models[model_key]
            self.logger.info(f"ğŸ”“ ä¸‹è½½é”å·²é‡Šæ”¾: {model_key}")


# ========== å•ä¾‹æ¨¡å¼ ==========

_model_manager_instance: Optional[ModelManagerService] = None


def get_model_manager() -> ModelManagerService:
    """
    è·å–æ¨¡å‹ç®¡ç†å™¨å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰

    Returns:
        ModelManagerService: æ¨¡å‹ç®¡ç†å™¨å®ä¾‹
    """
    global _model_manager_instance
    if _model_manager_instance is None:
        _model_manager_instance = ModelManagerService()
    return _model_manager_instance
