"""
ç»Ÿä¸€æ¨¡å‹ä¸æ•°æ®é›†ç®¡ç†æœåŠ¡
- ä¸‹è½½ç®¡ç†
- ç¼“å­˜ç®¡ç†
- è‡ªåŠ¨æ£€æµ‹è¯­è¨€å¹¶ä¸‹è½½
- ç‰ˆæœ¬ç®¡ç†
"""

from dataclasses import dataclass
from typing import List, Optional, Dict
from pathlib import Path
import threading
import logging
import os
import shutil

from models.model_models import ModelInfo, AlignModelInfo
from core.config import config


class ModelManagerService:
    """
    æ¨¡å‹ç®¡ç†æœåŠ¡
    ç»Ÿä¸€ç®¡ç†Whisperæ¨¡å‹å’Œå¯¹é½æ¨¡å‹çš„ä¸‹è½½ã€ç¼“å­˜ã€åˆ é™¤
    """

    # æ”¯æŒçš„Whisperæ¨¡å‹
    WHISPER_MODELS = {
        "tiny": {"size_mb": 75, "desc": "æœ€å¿«ï¼Œç²¾åº¦è¾ƒä½"},
        "base": {"size_mb": 145, "desc": "å¿«é€Ÿï¼Œç²¾åº¦ä¸€èˆ¬"},
        "small": {"size_mb": 490, "desc": "å¹³è¡¡é€Ÿåº¦ä¸ç²¾åº¦"},
        "medium": {"size_mb": 1500, "desc": "è¾ƒæ…¢ï¼Œç²¾åº¦è¾ƒé«˜"},
        "large-v2": {"size_mb": 3100, "desc": "æœ€æ…¢ï¼Œç²¾åº¦æœ€é«˜"},
        "large-v3": {"size_mb": 3100, "desc": "æœ€æ–°ç‰ˆæœ¬ï¼Œç²¾åº¦æœ€é«˜"},
    }

    # æ”¯æŒçš„è¯­è¨€ï¼ˆå¯¹é½æ¨¡å‹ï¼‰
    SUPPORTED_LANGUAGES = {
        "zh": "ä¸­æ–‡ (Chinese)",
        "en": "è‹±è¯­ (English)",
        "ja": "æ—¥è¯­ (Japanese)",
        "ko": "éŸ©è¯­ (Korean)",
        "es": "è¥¿ç­ç‰™è¯­ (Spanish)",
        "fr": "æ³•è¯­ (French)",
        "de": "å¾·è¯­ (German)",
        "ru": "ä¿„è¯­ (Russian)",
        "pt": "è‘¡è„ç‰™è¯­ (Portuguese)",
        "it": "æ„å¤§åˆ©è¯­ (Italian)",
        "ar": "é˜¿æ‹‰ä¼¯è¯­ (Arabic)",
        "hi": "å°åœ°è¯­ (Hindi)",
    }

    def __init__(self, models_dir: Path = None):
        """
        åˆå§‹åŒ–æ¨¡å‹ç®¡ç†æœåŠ¡

        Args:
            models_dir: æ¨¡å‹ç›®å½•è·¯å¾„ï¼Œé»˜è®¤ä½¿ç”¨configä¸­çš„é…ç½®
        """
        self.models_dir = models_dir or config.MODELS_DIR
        self.logger = logging.getLogger(__name__)

        # æ¨¡å‹çŠ¶æ€è·Ÿè¸ª
        self.whisper_models: Dict[str, ModelInfo] = {}
        self.align_models: Dict[str, AlignModelInfo] = {}

        # ä¸‹è½½é˜Ÿåˆ—å’Œé”
        self.download_queue = []
        self.download_lock = threading.Lock()

        # åˆå§‹åŒ–æ¨¡å‹ä¿¡æ¯
        self._init_model_info()

    def _init_model_info(self):
        """æ‰«ææœ¬åœ°å·²æœ‰æ¨¡å‹"""
        self.logger.info("ğŸ” æ‰«ææœ¬åœ°å·²æœ‰æ¨¡å‹...")

        # åˆå§‹åŒ–Whisperæ¨¡å‹ä¿¡æ¯
        for model_id, info in self.WHISPER_MODELS.items():
            status, local_path = self._check_whisper_model_exists(model_id)
            self.whisper_models[model_id] = ModelInfo(
                model_id=model_id,
                size_mb=info["size_mb"],
                status=status,
                download_progress=100.0 if status == "ready" else 0.0,
                local_path=str(local_path) if local_path else None,
                description=info["desc"]
            )
            if status == "ready":
                self.logger.info(f"âœ… å‘ç°Whisperæ¨¡å‹: {model_id}")

        # åˆå§‹åŒ–å¯¹é½æ¨¡å‹ä¿¡æ¯
        for lang, name in self.SUPPORTED_LANGUAGES.items():
            status, local_path = self._check_align_model_exists(lang)
            self.align_models[lang] = AlignModelInfo(
                language=lang,
                language_name=name,
                status=status,
                download_progress=100.0 if status == "ready" else 0.0,
                local_path=str(local_path) if local_path else None
            )
            if status == "ready":
                self.logger.info(f"âœ… å‘ç°å¯¹é½æ¨¡å‹: {lang} ({name})")

    def _check_whisper_model_exists(self, model_id: str) -> tuple[str, Optional[Path]]:
        """
        æ£€æŸ¥Whisperæ¨¡å‹æ˜¯å¦å­˜åœ¨

        Args:
            model_id: æ¨¡å‹ID

        Returns:
            tuple: (çŠ¶æ€, æœ¬åœ°è·¯å¾„)
        """
        # WhisperXæ¨¡å‹ç¼“å­˜åœ¨HuggingFaceç¼“å­˜ç›®å½•ä¸­
        # è·¯å¾„æ ¼å¼: models/huggingface/hub/models--guillaumekln--faster-whisper-{model}
        hf_cache = config.HF_CACHE_DIR / "hub"

        # æ£€æŸ¥å¯èƒ½çš„æ¨¡å‹ç¼“å­˜è·¯å¾„
        possible_paths = [
            hf_cache / f"models--guillaumekln--faster-whisper-{model_id}",
            hf_cache / f"models--Systran--faster-whisper-{model_id}",
        ]

        for path in possible_paths:
            if path.exists():
                return ("ready", path)

        return ("not_downloaded", None)

    def _check_align_model_exists(self, language: str) -> tuple[str, Optional[Path]]:
        """
        æ£€æŸ¥å¯¹é½æ¨¡å‹æ˜¯å¦å­˜åœ¨

        Args:
            language: è¯­è¨€ä»£ç 

        Returns:
            tuple: (çŠ¶æ€, æœ¬åœ°è·¯å¾„)
        """
        # å¯¹é½æ¨¡å‹ä¹Ÿç¼“å­˜åœ¨HuggingFaceç›®å½•ä¸­
        hf_cache = config.HF_CACHE_DIR / "hub"

        # ä¸åŒè¯­è¨€çš„æ¨¡å‹åç§°å¯èƒ½ä¸åŒï¼Œè¿™é‡Œåˆ—ä¸¾å¸¸è§çš„
        # å®é™…è·¯å¾„éœ€è¦æ ¹æ®whisperxå®ç°æ¥ç¡®å®š
        model_patterns = [
            f"models--jonatasgrosman--wav2vec2-large-xlsr-53-{language}",
            f"models--facebook--wav2vec2-large-xlsr-53-{language}",
        ]

        for pattern in model_patterns:
            path = hf_cache / pattern
            if path.exists():
                return ("ready", path)

        return ("not_downloaded", None)

    def list_whisper_models(self) -> List[ModelInfo]:
        """åˆ—å‡ºæ‰€æœ‰Whisperæ¨¡å‹çŠ¶æ€"""
        return list(self.whisper_models.values())

    def list_align_models(self) -> List[AlignModelInfo]:
        """åˆ—å‡ºæ‰€æœ‰å¯¹é½æ¨¡å‹çŠ¶æ€"""
        return list(self.align_models.values())

    def download_whisper_model(self, model_id: str) -> bool:
        """
        ä¸‹è½½Whisperæ¨¡å‹

        Args:
            model_id: æ¨¡å‹ID

        Returns:
            bool: æ˜¯å¦æˆåŠŸåŠ å…¥ä¸‹è½½é˜Ÿåˆ—
        """
        if model_id not in self.whisper_models:
            self.logger.warning(f"âŒ ä¸æ”¯æŒçš„æ¨¡å‹: {model_id}")
            return False

        model = self.whisper_models[model_id]
        if model.status == "downloading":
            self.logger.info(f"â³ æ¨¡å‹æ­£åœ¨ä¸‹è½½ä¸­: {model_id}")
            return False  # å·²åœ¨ä¸‹è½½ä¸­

        # æ ‡è®°ä¸ºä¸‹è½½ä¸­
        model.status = "downloading"
        model.download_progress = 0.0

        # å¯åŠ¨ä¸‹è½½çº¿ç¨‹
        threading.Thread(
            target=self._download_whisper_model_task,
            args=(model_id,),
            daemon=True,
            name=f"DownloadWhisper-{model_id}"
        ).start()

        self.logger.info(f"ğŸš€ å¼€å§‹ä¸‹è½½Whisperæ¨¡å‹: {model_id}")
        return True

    def download_align_model(self, language: str) -> bool:
        """
        ä¸‹è½½å¯¹é½æ¨¡å‹

        Args:
            language: è¯­è¨€ä»£ç 

        Returns:
            bool: æ˜¯å¦æˆåŠŸåŠ å…¥ä¸‹è½½é˜Ÿåˆ—
        """
        if language not in self.align_models:
            self.logger.warning(f"âŒ ä¸æ”¯æŒçš„è¯­è¨€: {language}")
            return False

        model = self.align_models[language]
        if model.status == "downloading":
            self.logger.info(f"â³ å¯¹é½æ¨¡å‹æ­£åœ¨ä¸‹è½½ä¸­: {language}")
            return False

        # æ ‡è®°ä¸ºä¸‹è½½ä¸­
        model.status = "downloading"
        model.download_progress = 0.0

        # å¯åŠ¨ä¸‹è½½çº¿ç¨‹
        threading.Thread(
            target=self._download_align_model_task,
            args=(language,),
            daemon=True,
            name=f"DownloadAlign-{language}"
        ).start()

        self.logger.info(f"ğŸš€ å¼€å§‹ä¸‹è½½å¯¹é½æ¨¡å‹: {language}")
        return True

    def auto_download_for_language(self, language: str) -> bool:
        """
        è‡ªåŠ¨ä¸‹è½½æŒ‡å®šè¯­è¨€æ‰€éœ€çš„å¯¹é½æ¨¡å‹
        ç”¨äºæ–­ç‚¹ç»­ä¼ æ¢å¤æ—¶è‡ªåŠ¨è¡¥é½æ¨¡å‹

        Args:
            language: è¯­è¨€ä»£ç 

        Returns:
            bool: æ˜¯å¦éœ€è¦ä¸‹è½½ï¼ˆTrueï¼‰æˆ–å·²å­˜åœ¨ï¼ˆFalseï¼‰
        """
        if language not in self.align_models:
            self.logger.warning(f"âš ï¸ ä¸æ”¯æŒçš„è¯­è¨€: {language}")
            return False

        model = self.align_models[language]

        if model.status == "ready":
            self.logger.info(f"âœ… å¯¹é½æ¨¡å‹å·²å­˜åœ¨: {language}")
            return False

        self.logger.info(f"ğŸ” æ£€æµ‹åˆ°æ–°è¯­è¨€ {language}ï¼Œå¼€å§‹è‡ªåŠ¨ä¸‹è½½å¯¹é½æ¨¡å‹")
        return self.download_align_model(language)

    def delete_whisper_model(self, model_id: str) -> bool:
        """
        åˆ é™¤Whisperæ¨¡å‹

        Args:
            model_id: æ¨¡å‹ID

        Returns:
            bool: æ˜¯å¦åˆ é™¤æˆåŠŸ
        """
        if model_id not in self.whisper_models:
            return False

        model = self.whisper_models[model_id]

        if model.status != "ready" or not model.local_path:
            self.logger.warning(f"âš ï¸ æ¨¡å‹æœªä¸‹è½½æˆ–è·¯å¾„ä¸å­˜åœ¨: {model_id}")
            return False

        try:
            # åˆ é™¤æ¨¡å‹ç›®å½•
            local_path = Path(model.local_path)
            if local_path.exists():
                shutil.rmtree(local_path)
                self.logger.info(f"ğŸ—‘ï¸ å·²åˆ é™¤Whisperæ¨¡å‹: {model_id}")

            # æ›´æ–°çŠ¶æ€
            model.status = "not_downloaded"
            model.download_progress = 0.0
            model.local_path = None

            return True

        except Exception as e:
            self.logger.error(f"âŒ åˆ é™¤æ¨¡å‹å¤±è´¥: {model_id} - {e}")
            return False

    def delete_align_model(self, language: str) -> bool:
        """
        åˆ é™¤å¯¹é½æ¨¡å‹

        Args:
            language: è¯­è¨€ä»£ç 

        Returns:
            bool: æ˜¯å¦åˆ é™¤æˆåŠŸ
        """
        if language not in self.align_models:
            return False

        model = self.align_models[language]

        if model.status != "ready" or not model.local_path:
            self.logger.warning(f"âš ï¸ å¯¹é½æ¨¡å‹æœªä¸‹è½½æˆ–è·¯å¾„ä¸å­˜åœ¨: {language}")
            return False

        try:
            # åˆ é™¤æ¨¡å‹ç›®å½•
            local_path = Path(model.local_path)
            if local_path.exists():
                shutil.rmtree(local_path)
                self.logger.info(f"ğŸ—‘ï¸ å·²åˆ é™¤å¯¹é½æ¨¡å‹: {language}")

            # æ›´æ–°çŠ¶æ€
            model.status = "not_downloaded"
            model.download_progress = 0.0
            model.local_path = None

            return True

        except Exception as e:
            self.logger.error(f"âŒ åˆ é™¤å¯¹é½æ¨¡å‹å¤±è´¥: {language} - {e}")
            return False

    def get_download_progress(self) -> Dict:
        """è·å–æ‰€æœ‰ä¸‹è½½è¿›åº¦"""
        return {
            "whisper": {
                mid: {
                    "status": m.status,
                    "progress": m.download_progress
                }
                for mid, m in self.whisper_models.items()
            },
            "align": {
                lang: {
                    "status": m.status,
                    "progress": m.download_progress
                }
                for lang, m in self.align_models.items()
            }
        }

    def _download_whisper_model_task(self, model_id: str):
        """ä¸‹è½½Whisperæ¨¡å‹ä»»åŠ¡ï¼ˆåå°çº¿ç¨‹ï¼‰"""
        try:
            model = self.whisper_models[model_id]

            # ä½¿ç”¨whisperxçš„ä¸‹è½½æ¥å£
            import whisperx

            self.logger.info(f"ğŸ“¥ æ­£åœ¨ä¸‹è½½Whisperæ¨¡å‹: {model_id}")

            # åŠ è½½æ¨¡å‹ä¼šè‡ªåŠ¨è§¦å‘ä¸‹è½½
            # device="cpu"è¡¨ç¤ºä»…ä¸‹è½½ï¼Œä¸åŠ è½½åˆ°GPU
            _ = whisperx.load_model(
                model_id,
                device="cpu",
                compute_type="int8",  # ä½¿ç”¨è¾ƒå°çš„ç²¾åº¦ä»¥èŠ‚çœå†…å­˜
                download_root=str(config.HF_CACHE_DIR)
            )

            # ä¸‹è½½å®Œæˆï¼Œæ›´æ–°çŠ¶æ€
            model.status = "ready"
            model.download_progress = 100.0

            # é‡æ–°æ£€æŸ¥è·¯å¾„
            status, local_path = self._check_whisper_model_exists(model_id)
            if local_path:
                model.local_path = str(local_path)

            self.logger.info(f"âœ… Whisperæ¨¡å‹ä¸‹è½½å®Œæˆ: {model_id}")

        except Exception as e:
            model = self.whisper_models[model_id]
            model.status = "error"
            model.download_progress = 0.0
            self.logger.error(f"âŒ Whisperæ¨¡å‹ä¸‹è½½å¤±è´¥: {model_id} - {e}", exc_info=True)

    def _download_align_model_task(self, language: str):
        """ä¸‹è½½å¯¹é½æ¨¡å‹ä»»åŠ¡ï¼ˆåå°çº¿ç¨‹ï¼‰"""
        try:
            model = self.align_models[language]

            import whisperx

            self.logger.info(f"ğŸ“¥ æ­£åœ¨ä¸‹è½½å¯¹é½æ¨¡å‹: {language}")

            # åŠ è½½å¯¹é½æ¨¡å‹ä¼šè‡ªåŠ¨è§¦å‘ä¸‹è½½
            _, _ = whisperx.load_align_model(
                language_code=language,
                device="cpu",
                model_dir=str(config.HF_CACHE_DIR)
            )

            # ä¸‹è½½å®Œæˆï¼Œæ›´æ–°çŠ¶æ€
            model.status = "ready"
            model.download_progress = 100.0

            # é‡æ–°æ£€æŸ¥è·¯å¾„
            status, local_path = self._check_align_model_exists(language)
            if local_path:
                model.local_path = str(local_path)

            self.logger.info(f"âœ… å¯¹é½æ¨¡å‹ä¸‹è½½å®Œæˆ: {language}")

        except Exception as e:
            model = self.align_models[language]
            model.status = "error"
            model.download_progress = 0.0
            self.logger.error(f"âŒ å¯¹é½æ¨¡å‹ä¸‹è½½å¤±è´¥: {language} - {e}", exc_info=True)


# ========== å•ä¾‹æ¨¡å¼ ==========

_model_manager_instance: Optional[ModelManagerService] = None


def get_model_manager() -> ModelManagerService:
    """
    è·å–æ¨¡å‹ç®¡ç†å™¨å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰

    Returns:
        ModelManagerService: æ¨¡å‹ç®¡ç†å™¨å®ä¾‹
    """
    global _model_manager_instance
    if _model_manager_instance is None:
        _model_manager_instance = ModelManagerService()
    return _model_manager_instance
