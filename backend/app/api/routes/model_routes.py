"""
æ¨¡å‹ç®¡ç†APIè·¯ç”±
"""

from fastapi import APIRouter, HTTPException, Request
from fastapi.responses import StreamingResponse
from typing import List, AsyncGenerator
import asyncio
import json
import time
import logging

from models.model_models import ModelInfo, AlignModelInfo
from services.model_manager_service import get_model_manager

router = APIRouter(prefix="/api/models", tags=["models"])
logger = logging.getLogger(__name__)

# è·å–æ¨¡å‹ç®¡ç†å™¨å®ä¾‹
model_manager = get_model_manager()


@router.get("/whisper", response_model=List[dict])
async def list_whisper_models():
    """
    åˆ—å‡ºæ‰€æœ‰Whisperæ¨¡å‹

    Returns:
        List[dict]: æ¨¡å‹ä¿¡æ¯åˆ—è¡¨
    """
    try:
        models = model_manager.list_whisper_models()
        return [model.to_dict() for model in models]
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {str(e)}")


@router.get("/align", response_model=List[dict])
async def list_align_models():
    """
    åˆ—å‡ºæ‰€æœ‰å¯¹é½æ¨¡å‹

    Returns:
        List[dict]: å¯¹é½æ¨¡å‹ä¿¡æ¯åˆ—è¡¨
    """
    try:
        models = model_manager.list_align_models()
        return [model.to_dict() for model in models]
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–å¯¹é½æ¨¡å‹åˆ—è¡¨å¤±è´¥: {str(e)}")


@router.post("/whisper/{model_id}/download")
async def download_whisper_model(model_id: str):
    """
    ä¸‹è½½æŒ‡å®šçš„Whisperæ¨¡å‹

    Args:
        model_id: æ¨¡å‹ID (tiny, base, small, medium, large-v2, large-v3)

    Returns:
        dict: æ“ä½œç»“æœ
    """
    try:
        success = model_manager.download_whisper_model(model_id)
        if not success:
            raise HTTPException(status_code=400, detail="æ¨¡å‹ä¸å­˜åœ¨æˆ–æ­£åœ¨ä¸‹è½½ä¸­")
        return {"success": True, "message": f"å¼€å§‹ä¸‹è½½æ¨¡å‹ {model_id}"}
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ä¸‹è½½å¤±è´¥: {str(e)}")


@router.post("/align/{language}/download")
async def download_align_model(language: str):
    """
    ä¸‹è½½æŒ‡å®šè¯­è¨€çš„å¯¹é½æ¨¡å‹

    Args:
        language: è¯­è¨€ä»£ç  (zh, en, ja, ko, etc.)

    Returns:
        dict: æ“ä½œç»“æœ
    """
    try:
        success = model_manager.download_align_model(language)
        if not success:
            raise HTTPException(status_code=400, detail="è¯­è¨€ä¸æ”¯æŒæˆ–æ­£åœ¨ä¸‹è½½ä¸­")
        return {"success": True, "message": f"å¼€å§‹ä¸‹è½½ {language} å¯¹é½æ¨¡å‹"}
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ä¸‹è½½å¤±è´¥: {str(e)}")


@router.delete("/whisper/{model_id}")
async def delete_whisper_model(model_id: str):
    """
    åˆ é™¤æŒ‡å®šçš„Whisperæ¨¡å‹

    Args:
        model_id: æ¨¡å‹ID

    Returns:
        dict: æ“ä½œç»“æœ
    """
    try:
        success = model_manager.delete_whisper_model(model_id)
        if not success:
            raise HTTPException(status_code=400, detail="åˆ é™¤å¤±è´¥ï¼šæ¨¡å‹ä¸å­˜åœ¨æˆ–æœªä¸‹è½½")
        return {"success": True, "message": f"å·²åˆ é™¤æ¨¡å‹ {model_id}"}
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"åˆ é™¤å¤±è´¥: {str(e)}")


@router.delete("/align/{language}")
async def delete_align_model(language: str):
    """
    åˆ é™¤æŒ‡å®šçš„å¯¹é½æ¨¡å‹

    Args:
        language: è¯­è¨€ä»£ç 

    Returns:
        dict: æ“ä½œç»“æœ
    """
    try:
        success = model_manager.delete_align_model(language)
        if not success:
            raise HTTPException(status_code=400, detail="åˆ é™¤å¤±è´¥ï¼šæ¨¡å‹ä¸å­˜åœ¨æˆ–æœªä¸‹è½½")
        return {"success": True, "message": f"å·²åˆ é™¤å¯¹é½æ¨¡å‹ {language}"}
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"åˆ é™¤å¤±è´¥: {str(e)}")


@router.get("/progress")
async def get_download_progress():
    """
    è·å–æ‰€æœ‰ä¸‹è½½è¿›åº¦ï¼ˆè½®è¯¢æ¨¡å¼ï¼Œå»ºè®®ä½¿ç”¨SSEç«¯ç‚¹ï¼‰

    Returns:
        dict: ä¸‹è½½è¿›åº¦ä¿¡æ¯
    """
    try:
        return model_manager.get_download_progress()
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–è¿›åº¦å¤±è´¥: {str(e)}")


# ========== SSE å®æ—¶è¿›åº¦æ¨é€ç«¯ç‚¹ ==========

# å­˜å‚¨æ´»åŠ¨çš„ SSE è¿æ¥é˜Ÿåˆ—ï¼ˆæ”¹ç”¨ asyncio.Queueï¼‰
# å¢å¤§é˜Ÿåˆ—å®¹é‡ï¼Œé¿å…é¢‘ç¹æ›´æ–°æ—¶é˜Ÿåˆ—æº¢å‡º
sse_queues: List[asyncio.Queue] = []

# è·å–å½“å‰äº‹ä»¶å¾ªç¯çš„å¼•ç”¨ï¼ˆåœ¨åº”ç”¨å¯åŠ¨æ—¶è®¾ç½®ï¼‰
_event_loop = None

def set_event_loop():
    """è®¾ç½®äº‹ä»¶å¾ªç¯å¼•ç”¨ï¼ˆåœ¨åº”ç”¨å¯åŠ¨æ—¶è°ƒç”¨ï¼‰"""
    global _event_loop
    try:
        _event_loop = asyncio.get_running_loop()
        logger.info("âœ… SSEäº‹ä»¶å¾ªç¯å·²è®¾ç½®")
        return True
    except RuntimeError as e:
        logger.warning(f"âš ï¸ æ— æ³•è·å–äº‹ä»¶å¾ªç¯: {e}")
        return False

def get_event_loop():
    """è·å–äº‹ä»¶å¾ªç¯å¼•ç”¨ï¼ˆçº¿ç¨‹å®‰å…¨ï¼Œæ”¯æŒå»¶è¿Ÿè·å–ï¼‰"""
    global _event_loop
    if _event_loop is None or _event_loop.is_closed():
        try:
            _event_loop = asyncio.get_running_loop()
            logger.debug("ğŸ”„ å»¶è¿Ÿè·å–äº‹ä»¶å¾ªç¯æˆåŠŸ")
        except RuntimeError:
            logger.debug("âš ï¸ å½“å‰çº¿ç¨‹æ²¡æœ‰è¿è¡Œä¸­çš„äº‹ä»¶å¾ªç¯")
            return None
    return _event_loop

def progress_callback(model_type: str, model_id: str, progress: float, status: str, message: str = ""):
    """
    è¿›åº¦å›è°ƒå‡½æ•°ï¼Œç”¨äºæ¨é€åˆ°æ‰€æœ‰ SSE è¿æ¥ï¼ˆçº¿ç¨‹å®‰å…¨ï¼Œä¼˜åŒ–é˜Ÿåˆ—æº¢å‡ºå¤„ç†ï¼‰

    å…³é”®ä¼˜åŒ–ï¼š
    1. æ£€æŸ¥é˜Ÿåˆ—å®¹é‡ï¼Œé¿å… QueueFull å¼‚å¸¸
    2. é˜Ÿåˆ—æ»¡æ—¶è·³è¿‡æ›´æ–°ï¼Œè€Œä¸æ˜¯æŠ›å‡ºå¼‚å¸¸
    3. é™ä½æ—¥å¿—çº§åˆ«ï¼Œé¿å…æ—¥å¿—æ´ªæ°´
    """
    event_data = {
        "type": model_type,
        "model_id": model_id,
        "progress": progress,
        "status": status,
        "message": message,
        "timestamp": time.time()
    }

    # è·å–äº‹ä»¶å¾ªç¯
    loop = get_event_loop()
    if loop is None:
        # åªåœ¨ç¬¬ä¸€æ¬¡å¤±è´¥æ—¶è­¦å‘Šï¼Œé¿å…æ—¥å¿—æ´ªæ°´
        if not hasattr(progress_callback, '_warned'):
            logger.warning(f"âš ï¸ äº‹ä»¶å¾ªç¯æœªè®¾ç½®ï¼Œæ— æ³•æ¨é€SSEæ¶ˆæ¯")
            progress_callback._warned = True
        return

    # ä½¿ç”¨ call_soon_threadsafe ä»ä¸‹è½½çº¿ç¨‹å‘ä¸»äº‹ä»¶å¾ªç¯æ³¨å…¥æ¶ˆæ¯
    success_count = 0
    skipped_count = 0

    for q in sse_queues[:]:  # ä½¿ç”¨åˆ‡ç‰‡å¤åˆ¶åˆ—è¡¨
        try:
            # å…³é”®ä¼˜åŒ–ï¼šæ£€æŸ¥é˜Ÿåˆ—å®¹é‡ï¼Œé¿å… QueueFull å¼‚å¸¸
            current_size = q.qsize()
            max_size = q.maxsize

            # å¦‚æœé˜Ÿåˆ—ä½¿ç”¨ç‡è¶…è¿‡90%ï¼Œè·³è¿‡æ­¤æ¬¡æ›´æ–°ï¼ˆä¿ç•™ç´§æ€¥å®¹é‡ï¼‰
            if current_size >= max_size * 0.9:
                skipped_count += 1
                # åªè®°å½• debug çº§åˆ«ï¼Œé¿å…æ—¥å¿—æ´ªæ°´
                if skipped_count == 1:  # åªè®°å½•ç¬¬ä¸€æ¬¡è·³è¿‡
                    logger.debug(f"é˜Ÿåˆ—æ¥è¿‘æ»¡({current_size}/{max_size})ï¼Œè·³è¿‡æ›´æ–°: {model_type}/{model_id}")
                continue

            # çº¿ç¨‹å®‰å…¨åœ°å°†æ¶ˆæ¯æ”¾å…¥é˜Ÿåˆ—
            loop.call_soon_threadsafe(q.put_nowait, event_data)
            success_count += 1

        except Exception as e:
            # é™ä½æ—¥å¿—çº§åˆ«ï¼Œé¿å…æ—¥å¿—æ´ªæ°´
            logger.debug(f"æ¨é€SSEæ¶ˆæ¯å¤±è´¥: {e}")

    # åªåœ¨æˆåŠŸæ¨é€æˆ–æœ‰è·³è¿‡æ—¶è®°å½• debug æ—¥å¿—
    if success_count > 0:
        logger.debug(f"SSEæ¶ˆæ¯å·²æ¨é€åˆ° {success_count} ä¸ªè¿æ¥: {model_type}/{model_id} - {status} ({progress:.1f}%)")
    if skipped_count > 0 and skipped_count % 10 == 0:  # æ¯10æ¬¡è·³è¿‡æ‰è®°å½•ä¸€æ¬¡
        logger.debug(f"å·²è·³è¿‡ {skipped_count} æ¬¡æ›´æ–°ï¼ˆé˜Ÿåˆ—ç¹å¿™ï¼‰")

# æ³¨å†Œè¿›åº¦å›è°ƒ
model_manager.register_progress_callback(progress_callback)

@router.get("/events/progress")
async def stream_all_progress(request: Request):
    """
    SSEç«¯ç‚¹ï¼šå®æ—¶æ¨é€æ‰€æœ‰æ¨¡å‹ä¸‹è½½è¿›åº¦ï¼ˆæ”¹è¿›ç‰ˆ - éé˜»å¡ asyncio.Queueï¼‰

    äº‹ä»¶ç±»å‹ï¼š
    - model_progress: ä¸‹è½½è¿›åº¦æ›´æ–°
    - model_complete: ä¸‹è½½å®Œæˆ
    - model_error: ä¸‹è½½å¤±è´¥
    - model_incomplete: æ¨¡å‹ä¸å®Œæ•´
    - heartbeat: å¿ƒè·³ï¼ˆæ¯15ç§’ï¼‰

    Returns:
        StreamingResponse: SSEäº‹ä»¶æµ
    """

    async def event_generator() -> AsyncGenerator[str, None]:
        """SSEäº‹ä»¶ç”Ÿæˆå™¨ï¼ˆéé˜»å¡å®ç°ï¼Œä¼˜åŒ–é˜Ÿåˆ—å¤§å°ï¼‰"""
        # åˆ›å»ºæ­¤è¿æ¥çš„ä¸“ç”¨ asyncio.Queueï¼ˆå¢å¤§å®¹é‡åˆ°1000ï¼Œé¿å…é¢‘ç¹æº¢å‡ºï¼‰
        event_queue = asyncio.Queue(maxsize=1000)
        sse_queues.append(event_queue)

        heartbeat_counter = 0

        try:
            logger.info(f"âœ… SSEè¿æ¥å·²å»ºç«‹ï¼ˆå½“å‰è¿æ¥æ•°: {len(sse_queues)}ï¼‰")

            # é¦–æ¬¡å‘é€æ‰€æœ‰æ¨¡å‹çŠ¶æ€
            initial_state = {
                "whisper": {
                    m.model_id: {
                        "status": m.status,
                        "progress": m.download_progress
                    }
                    for m in model_manager.list_whisper_models()
                },
                "align": {
                    m.language: {
                        "status": m.status,
                        "progress": m.download_progress
                    }
                    for m in model_manager.list_align_models()
                }
            }

            yield f"event: initial_state\ndata: {json.dumps(initial_state)}\n\n"

            while True:
                # æ£€æŸ¥å®¢æˆ·ç«¯æ˜¯å¦æ–­å¼€
                if await request.is_disconnected():
                    logger.info("âš ï¸ å®¢æˆ·ç«¯å·²æ–­å¼€è¿æ¥")
                    break

                try:
                    # éé˜»å¡ç­‰å¾…æ¶ˆæ¯ï¼Œè¶…æ—¶åå‘é€å¿ƒè·³
                    event_data = await asyncio.wait_for(event_queue.get(), timeout=15)

                    # æ ¹æ®çŠ¶æ€å‘é€ä¸åŒç±»å‹çš„äº‹ä»¶
                    if event_data['status'] == 'ready':
                        event_type = 'model_complete'
                    elif event_data['status'] == 'error':
                        event_type = 'model_error'
                    elif event_data['status'] == 'incomplete':
                        event_type = 'model_incomplete'
                    else:
                        event_type = 'model_progress'

                    yield f"event: {event_type}\ndata: {json.dumps(event_data)}\n\n"

                except asyncio.TimeoutError:
                    # è¶…æ—¶ï¼Œå‘é€å¿ƒè·³
                    heartbeat_counter += 1
                    yield f"event: heartbeat\ndata: {json.dumps({'count': heartbeat_counter})}\n\n"

        except asyncio.CancelledError:
            logger.info("âš ï¸ SSEè¿æ¥è¢«å®¢æˆ·ç«¯å–æ¶ˆ")
        except Exception as e:
            logger.error(f"âŒ SSEé”™è¯¯: {e}")
        finally:
            # æ¸…ç†ï¼šç§»é™¤æ­¤è¿æ¥çš„é˜Ÿåˆ—
            try:
                sse_queues.remove(event_queue)
                logger.info(f"ğŸ”Œ SSEè¿æ¥å·²æ–­å¼€ï¼ˆå‰©ä½™è¿æ¥æ•°: {len(sse_queues)}ï¼‰")
            except ValueError:
                pass

    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"
        }
    )


@router.get("/events/{model_type}/{model_id}")
async def stream_single_progress(model_type: str, model_id: str):
    """
    SSEç«¯ç‚¹ï¼šæ¨é€å•ä¸ªæ¨¡å‹çš„ä¸‹è½½è¿›åº¦

    Args:
        model_type: æ¨¡å‹ç±»å‹ (whisper æˆ– align)
        model_id: æ¨¡å‹IDæˆ–è¯­è¨€ä»£ç 

    Returns:
        StreamingResponse: SSEäº‹ä»¶æµ
    """
    # éªŒè¯å‚æ•°
    if model_type not in ["whisper", "align"]:
        raise HTTPException(status_code=400, detail="model_type å¿…é¡»æ˜¯ 'whisper' æˆ– 'align'")

    # éªŒè¯æ¨¡å‹å­˜åœ¨
    if model_type == "whisper":
        models = {m.model_id: m for m in model_manager.list_whisper_models()}
    else:
        models = {m.language: m for m in model_manager.list_align_models()}

    if model_id not in models:
        raise HTTPException(status_code=404, detail=f"æ¨¡å‹ä¸å­˜åœ¨: {model_type}/{model_id}")

    async def event_generator() -> AsyncGenerator[str, None]:
        """å•æ¨¡å‹SSEäº‹ä»¶ç”Ÿæˆå™¨"""
        last_state = {}
        heartbeat_counter = 0

        try:
            logger.info(f"âœ… å•æ¨¡å‹SSEè¿æ¥å·²å»ºç«‹: {model_type}/{model_id}")

            while True:
                # è·å–å½“å‰æ¨¡å‹çŠ¶æ€
                if model_type == "whisper":
                    current_models = {m.model_id: m for m in model_manager.list_whisper_models()}
                else:
                    current_models = {m.language: m for m in model_manager.list_align_models()}

                if model_id not in current_models:
                    break

                model = current_models[model_id]
                current_state = {
                    "status": model.status,
                    "progress": model.download_progress
                }

                # æ£€æµ‹å˜åŒ–
                if current_state != last_state:
                    event_data = {
                        "type": model_type,
                        "model_id": model_id,
                        "status": current_state["status"],
                        "progress": current_state["progress"]
                    }

                    # ç¡®å®šäº‹ä»¶ç±»å‹
                    if current_state["status"] == "ready" and last_state.get("status") != "ready":
                        event_name = "model_complete"
                    elif current_state["status"] == "error":
                        event_name = "model_error"
                        event_data["error"] = "ä¸‹è½½å¤±è´¥"
                    else:
                        event_name = "model_progress"

                    # æ¨é€äº‹ä»¶
                    yield f"event: {event_name}\n"
                    yield f"data: {json.dumps(event_data, ensure_ascii=False)}\n\n"

                last_state = current_state

                # æ¯30ç§’å‘é€å¿ƒè·³
                heartbeat_counter += 1
                if heartbeat_counter >= 30:
                    yield f"event: heartbeat\n"
                    yield f"data: {json.dumps({'timestamp': int(time.time())})}\n\n"
                    heartbeat_counter = 0

                # æ¯ç§’æ£€æŸ¥ä¸€æ¬¡
                await asyncio.sleep(1)

        except asyncio.CancelledError:
            logger.info(f"ğŸ”Œ å•æ¨¡å‹SSEè¿æ¥å·²å…³é—­: {model_type}/{model_id}")
            raise

    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"
        }
    )
