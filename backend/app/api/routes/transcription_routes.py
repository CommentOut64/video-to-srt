"""
è½¬å½•ä»»åŠ¡ç›¸å…³APIè·¯ç”±
"""
import os
import uuid
import shutil
import time
from typing import Optional
from fastapi import APIRouter, HTTPException, UploadFile, File, Form, Request, Body
from fastapi.responses import FileResponse, StreamingResponse
from pydantic import BaseModel
import json

from models.job_models import JobSettings, JobState
from services.transcription_service import TranscriptionService
from services.file_service import FileManagementService
from services.sse_service import get_sse_manager
from services.job_queue_service import get_queue_service  # æ–°å¢å¯¼å…¥


class TranscribeSettings(BaseModel):
    """è½¬å½•è®¾ç½®è¯·æ±‚æ¨¡å‹"""
    model: str = "medium"
    compute_type: str = "float16"
    device: str = "cuda"
    batch_size: int = 16
    word_timestamps: bool = False


class UploadResponse(BaseModel):
    """ä¸Šä¼ å“åº”æ¨¡å‹"""
    job_id: str
    filename: str
    original_name: str
    message: str


def create_transcription_router(
    transcription_service: TranscriptionService,
    file_service: FileManagementService,
    output_dir: str
):
    """åˆ›å»ºè½¬å½•ä»»åŠ¡è·¯ç”±"""

    # åˆ›å»ºè·¯ç”±å™¨å®ä¾‹
    router = APIRouter(prefix="/api", tags=["transcription"])

    # è·å–SSEç®¡ç†å™¨
    sse_manager = get_sse_manager()

    @router.get("/stream/{job_id}")
    async def stream_job_progress(job_id: str, request: Request):
        """
        SSEæµå¼ç«¯ç‚¹ - å®æ—¶æ¨é€è½¬å½•ä»»åŠ¡è¿›åº¦

        é¢‘é“IDæ ¼å¼: job:{job_id}
        äº‹ä»¶ç±»å‹:
        - progress: è¿›åº¦æ›´æ–° (åŒ…å« percent, phase, message, statusç­‰)
        - signal: å…³é”®èŠ‚ç‚¹ä¿¡å· (job_complete, job_failed, job_canceled, job_paused)
        - ping: å¿ƒè·³
        """
        # éªŒè¯ä»»åŠ¡æ˜¯å¦å­˜åœ¨
        job = transcription_service.get_job(job_id)
        if not job:
            raise HTTPException(status_code=404, detail="ä»»åŠ¡æœªæ‰¾åˆ°")

        channel_id = f"job:{job_id}"

        # å®šä¹‰åˆå§‹çŠ¶æ€å›è°ƒ - è¿æ¥æ—¶ç«‹å³å‘é€å½“å‰çŠ¶æ€
        def get_initial_state():
            current_job = transcription_service.get_job(job_id)
            if current_job:
                return {
                    "job_id": current_job.job_id,
                    "phase": current_job.phase,
                    "percent": current_job.progress,
                    "message": current_job.message,
                    "status": current_job.status,
                    "processed": current_job.processed,
                    "total": current_job.total,
                    "language": current_job.language or ""
                }
            return None

        # è®¢é˜…SSEæµ
        return StreamingResponse(
            sse_manager.subscribe(channel_id, request, initial_state_callback=get_initial_state),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no"
            }
        )

    @router.post("/upload")
    async def upload_file(file: UploadFile = File(...)):
        """ä¸Šä¼ æ–‡ä»¶å¹¶è‡ªåŠ¨åˆ›å»ºè½¬å½•ä»»åŠ¡ï¼ˆV2.2: åŠ å…¥é˜Ÿåˆ—ï¼‰"""
        try:
            # éªŒè¯æ–‡ä»¶ç±»å‹
            if not file_service.is_supported_file(file.filename):
                raise HTTPException(status_code=400, detail="ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼")

            # ä¿å­˜ç”¨æˆ·åŸå§‹æ–‡ä»¶è·¯å¾„ä¿¡æ¯
            original_filename = file.filename

            # å°†æ–‡ä»¶ä¿å­˜åˆ°inputç›®å½•
            input_path = file_service.get_input_file_path(original_filename)

            # å¦‚æœåŒåæ–‡ä»¶å·²å­˜åœ¨ï¼Œæ·»åŠ æ—¶é—´æˆ³
            counter = 1
            base_name, ext = os.path.splitext(original_filename)
            while os.path.exists(input_path):
                new_filename = f"{base_name}_{counter}{ext}"
                input_path = file_service.get_input_file_path(new_filename)
                original_filename = new_filename
                counter += 1

            # ä¿å­˜æ–‡ä»¶
            with open(input_path, "wb") as buffer:
                content = await file.read()
                buffer.write(content)

            # åˆ›å»ºä»»åŠ¡
            job_id = uuid.uuid4().hex
            settings = JobSettings()
            job = transcription_service.create_job(original_filename, input_path, settings, job_id=job_id)

            # ğŸ”¥ æ–°å¢: åŠ å…¥é˜Ÿåˆ—ï¼ˆè€Œéç›´æ¥å¯åŠ¨ï¼‰
            queue_service = get_queue_service()
            queue_service.add_job(job)

            return {
                "job_id": job_id,
                "filename": original_filename,
                "original_name": file.filename,
                "message": "æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼Œå·²åŠ å…¥è½¬å½•é˜Ÿåˆ—",
                "queue_position": len(queue_service.queue)  # æ–°å¢: é˜Ÿåˆ—ä½ç½®
            }
        except HTTPException:
            raise
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"ä¸Šä¼ æ–‡ä»¶å¤±è´¥: {str(e)}")

    @router.post("/create-job")
    async def create_job(filename: str = Form(...)):
        """ä¸ºæŒ‡å®šæ–‡ä»¶åˆ›å»ºè½¬å½•ä»»åŠ¡ï¼ˆæœ¬åœ°inputæ¨¡å¼ï¼‰"""
        try:
            input_path = file_service.get_input_file_path(filename)
            if not os.path.exists(input_path):
                raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")

            if not file_service.is_supported_file(filename):
                raise HTTPException(status_code=400, detail="ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼")

            job_id = uuid.uuid4().hex
            settings = JobSettings()
            transcription_service.create_job(filename, input_path, settings, job_id=job_id)

            return {"job_id": job_id, "filename": filename}
        except HTTPException:
            raise
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"åˆ›å»ºä»»åŠ¡å¤±è´¥: {str(e)}")

    @router.post("/create-jobs-batch")
    async def create_jobs_batch(filenames: list = Body(..., embed=True)):
        """
        æ‰¹é‡åˆ›å»ºè½¬å½•ä»»åŠ¡ï¼ˆä» input ç›®å½•é€‰æ‹©å¤šä¸ªæ–‡ä»¶ï¼‰

        Args:
            filenames: æ–‡ä»¶ååˆ—è¡¨

        Returns:
            {
                "success": true,
                "jobs": [{job_id, filename, queue_position}, ...],
                "failed": [{filename, error}, ...],
                "total": int,
                "succeeded": int,
                "failed_count": int
            }
        """
        try:
            queue_service = get_queue_service()
            jobs = []
            failed = []

            for filename in filenames:
                try:
                    # éªŒè¯æ–‡ä»¶å­˜åœ¨
                    input_path = file_service.get_input_file_path(filename)
                    if not os.path.exists(input_path):
                        failed.append({"filename": filename, "error": "æ–‡ä»¶ä¸å­˜åœ¨"})
                        continue

                    # éªŒè¯æ–‡ä»¶æ ¼å¼
                    if not file_service.is_supported_file(filename):
                        failed.append({"filename": filename, "error": "ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼"})
                        continue

                    # åˆ›å»ºä»»åŠ¡
                    job_id = uuid.uuid4().hex
                    settings = JobSettings()
                    job = transcription_service.create_job(filename, input_path, settings, job_id=job_id)

                    # åŠ å…¥é˜Ÿåˆ—
                    queue_service.add_job(job)

                    jobs.append({
                        "job_id": job_id,
                        "filename": filename,
                        "queue_position": len(queue_service.queue)
                    })

                except Exception as e:
                    failed.append({"filename": filename, "error": str(e)})

            return {
                "success": True,
                "jobs": jobs,
                "failed": failed,
                "total": len(filenames),
                "succeeded": len(jobs),
                "failed_count": len(failed)
            }

        except Exception as e:
            raise HTTPException(status_code=500, detail=f"æ‰¹é‡åˆ›å»ºä»»åŠ¡å¤±è´¥: {str(e)}")

    @router.post("/start")
    async def start_job(job_id: str = Form(...), settings: str = Form(...)):
        """å¯åŠ¨è½¬å½•ä»»åŠ¡ï¼ˆV2.2: åŠ å…¥é˜Ÿåˆ—è€Œéç›´æ¥å¯åŠ¨ï¼‰"""
        try:
            from pathlib import Path

            settings_obj = TranscribeSettings(**json.loads(settings))

            # è·å–é˜Ÿåˆ—æœåŠ¡
            queue_service = get_queue_service()
            job = queue_service.get_job(job_id)

            if not job:
                # å¦‚æœé˜Ÿåˆ—æœåŠ¡ä¸­æ²¡æœ‰ï¼Œå°è¯•ä»transcription_serviceè·å–
                job = transcription_service.get_job(job_id)

            if not job:
                raise HTTPException(status_code=404, detail="æ— æ•ˆ job_id")

            # æ£€æŸ¥æ˜¯å¦æœ‰checkpointï¼ˆæ–­ç‚¹ç»­ä¼ åœºæ™¯ï¼‰
            job_dir = Path(job.dir) if job.dir else None
            checkpoint_path = job_dir / "checkpoint.json" if job_dir else None

            if checkpoint_path and checkpoint_path.exists():
                # æœ‰checkpointï¼Œéœ€è¦æ ¡éªŒå‚æ•°å¹¶å¼ºåˆ¶è¦†ç›–ç¦æ­¢ä¿®æ”¹çš„å‚æ•°
                try:
                    with open(checkpoint_path, 'r', encoding='utf-8') as f:
                        checkpoint_data = json.load(f)

                    original_settings = checkpoint_data.get("original_settings", {})

                    if original_settings:
                        # å¼ºåˆ¶è¦†ç›–ç¦æ­¢ä¿®æ”¹çš„å‚æ•°
                        # 1. word_timestamps - ç¦æ­¢ä¿®æ”¹
                        if "word_timestamps" in original_settings:
                            settings_obj.word_timestamps = original_settings["word_timestamps"]

                        # æ³¨æ„ï¼šdeviceå’Œmodelè™½ç„¶ä¼šè­¦å‘Šï¼Œä½†ä»å…è®¸ç”¨æˆ·ä¿®æ”¹
                        # å‰ç«¯åº”è¯¥åœ¨è°ƒç”¨æ­¤æ¥å£å‰æ˜¾ç¤ºè­¦å‘Šå¹¶è·å¾—ç”¨æˆ·ç¡®è®¤
                except Exception as e:
                    # å¦‚æœè¯»å–checkpointå¤±è´¥ï¼Œè®°å½•æ—¥å¿—ä½†ç»§ç»­
                    print(f"è¯»å–checkpointè®¾ç½®å¤±è´¥: {e}")

            # åº”ç”¨è®¾ç½®
            job.settings = JobSettings(**settings_obj.dict())

            # ğŸ”¥ å…³é”®æ”¹åŠ¨: å¦‚æœä»»åŠ¡ä¸åœ¨é˜Ÿåˆ—ä¸­ï¼ŒåŠ å…¥é˜Ÿåˆ—
            with queue_service.lock:
                if job.status == "paused" or job.status == "failed":
                    # æ¢å¤ä»»åŠ¡ï¼šé‡æ–°åŠ å…¥é˜Ÿåˆ—
                    job.canceled = False
                    job.paused = False
                    job.error = None
                    queue_service.queue.append(job_id)
                    job.status = "queued"
                    job.message = f"å·²åŠ å…¥é˜Ÿåˆ— (ä½ç½®: {len(queue_service.queue)})"
                    # ç¡®ä¿ä»»åŠ¡åœ¨jobså­—å…¸ä¸­
                    queue_service.jobs[job_id] = job
                elif job.status == "uploaded" or job.status == "created":
                    # æ–°ä»»åŠ¡ï¼šåŠ å…¥é˜Ÿåˆ—
                    queue_service.queue.append(job_id)
                    job.status = "queued"
                    job.message = f"å·²åŠ å…¥é˜Ÿåˆ— (ä½ç½®: {len(queue_service.queue)})"
                    # ç¡®ä¿ä»»åŠ¡åœ¨jobså­—å…¸ä¸­
                    queue_service.jobs[job_id] = job
                elif job.status == "queued":
                    # ä»»åŠ¡å·²åœ¨é˜Ÿåˆ—ä¸­
                    queue_position = list(queue_service.queue).index(job_id) + 1 if job_id in queue_service.queue else -1
                    job.message = f"å·²åœ¨é˜Ÿåˆ—ä¸­ (ä½ç½®: {queue_position})"

            # ä¿å­˜é˜Ÿåˆ—çŠ¶æ€å¹¶æ¨é€ SSE é€šçŸ¥ï¼ˆä¿®å¤ï¼šä¹‹å‰ç¼ºå°‘è¿™ä¸€æ­¥å¯¼è‡´å‰ç«¯æ”¶ä¸åˆ°çŠ¶æ€æ›´æ–°ï¼‰
            queue_service._save_state()
            queue_service._notify_queue_change()
            queue_service._notify_job_status(job_id, job.status)

            return {
                "job_id": job_id,
                "started": True,
                "queue_position": len(queue_service.queue)
            }
        except HTTPException:
            raise
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"å¯åŠ¨ä»»åŠ¡å¤±è´¥: {str(e)}")

    @router.post("/cancel/{job_id}")
    async def cancel_job(job_id: str, delete_data: bool = False):
        """å–æ¶ˆè½¬å½•ä»»åŠ¡ï¼ˆV2.2: ä½¿ç”¨é˜Ÿåˆ—æœåŠ¡ï¼‰"""
        queue_service = get_queue_service()
        ok = queue_service.cancel_job(job_id, delete_data=delete_data)
        if not ok:
            raise HTTPException(status_code=404, detail="ä»»åŠ¡æœªæ‰¾åˆ°")
        return {"job_id": job_id, "canceled": ok, "data_deleted": delete_data}

    @router.post("/pause/{job_id}")
    async def pause_job(job_id: str):
        """æš‚åœè½¬å½•ä»»åŠ¡ï¼ˆV2.2: ä½¿ç”¨é˜Ÿåˆ—æœåŠ¡ï¼‰"""
        queue_service = get_queue_service()
        ok = queue_service.pause_job(job_id)
        if not ok:
            raise HTTPException(status_code=404, detail="ä»»åŠ¡æœªæ‰¾åˆ°")
        return {"job_id": job_id, "paused": ok}

    @router.post("/resume/{job_id}")
    async def resume_job(job_id: str):
        """
        æ¢å¤æš‚åœçš„ä»»åŠ¡ï¼ˆé‡æ–°åŠ å…¥é˜Ÿåˆ—ï¼‰

        ä¸ /restore-job ä¸åŒï¼š
        - /resume: æ¢å¤æš‚åœçš„ä»»åŠ¡ï¼Œé‡æ–°åŠ å…¥é˜Ÿåˆ—å°¾éƒ¨ï¼ŒçŠ¶æ€å˜ä¸º queued
        - /restore-job: ä» checkpoint æ–­ç‚¹ç»­ä¼ 
        """
        queue_service = get_queue_service()
        ok = queue_service.resume_job(job_id)
        if not ok:
            raise HTTPException(status_code=400, detail="æ— æ³•æ¢å¤ä»»åŠ¡ï¼ˆä»»åŠ¡æœªæš‚åœæˆ–ä¸å­˜åœ¨ï¼‰")

        job = queue_service.get_job(job_id)
        queue_position = 0
        if job_id in queue_service.queue:
            queue_position = list(queue_service.queue).index(job_id) + 1

        return {
            "job_id": job_id,
            "resumed": True,
            "status": job.status if job else "queued",
            "queue_position": queue_position
        }

    @router.post("/prioritize/{job_id}")
    async def prioritize_job(job_id: str, mode: Optional[str] = None):
        """
        å°†ä»»åŠ¡ç§»åˆ°é˜Ÿåˆ—å¤´éƒ¨ï¼ˆæ’é˜Ÿï¼‰

        Args:
            job_id: ä»»åŠ¡ID
            mode: æ’é˜Ÿæ¨¡å¼
                - "gentle": æ¸©å’Œæ’é˜Ÿï¼Œæ”¾åˆ°é˜Ÿåˆ—å¤´éƒ¨ï¼Œç­‰å½“å‰ä»»åŠ¡å®Œæˆåæ‰§è¡Œ
                - "force": å¼ºåˆ¶æ’é˜Ÿï¼Œæš‚åœå½“å‰ä»»åŠ¡A -> æ‰§è¡ŒB -> Bå®Œæˆåè‡ªåŠ¨æ¢å¤A
                - None: ä½¿ç”¨é»˜è®¤æ¨¡å¼ï¼ˆå¯é€šè¿‡ /api/queue-settings é…ç½®ï¼‰
        """
        queue_service = get_queue_service()
        result = queue_service.prioritize_job(job_id, mode=mode)

        if not result.get("success"):
            raise HTTPException(
                status_code=400,
                detail=result.get("error", "æ— æ³•ä¼˜å…ˆæ­¤ä»»åŠ¡")
            )

        return {
            "job_id": job_id,
            "prioritized": True,
            "mode": result.get("mode"),
            "interrupted_job_id": result.get("interrupted_job_id"),
            "queue_position": 1
        }

    @router.get("/queue-settings")
    async def get_queue_settings():
        """
        è·å–é˜Ÿåˆ—è®¾ç½®

        è¿”å›:
            - default_prioritize_mode: é»˜è®¤æ’é˜Ÿæ¨¡å¼ ("gentle" æˆ– "force")
        """
        queue_service = get_queue_service()
        return queue_service.get_settings()

    @router.post("/queue-settings")
    async def update_queue_settings(
        default_prioritize_mode: Optional[str] = Body(None, embed=True)
    ):
        """
        æ›´æ–°é˜Ÿåˆ—è®¾ç½®

        Args:
            default_prioritize_mode: é»˜è®¤æ’é˜Ÿæ¨¡å¼
                - "gentle": æ¸©å’Œæ’é˜Ÿï¼ˆé»˜è®¤ï¼‰
                - "force": å¼ºåˆ¶æ’é˜Ÿ
        """
        queue_service = get_queue_service()
        try:
            settings = queue_service.update_settings(
                default_prioritize_mode=default_prioritize_mode
            )
            return {
                "success": True,
                "settings": settings
            }
        except ValueError as e:
            raise HTTPException(status_code=400, detail=str(e))

    @router.post("/reorder-queue")
    async def reorder_queue(job_ids: list = Body(..., embed=True)):
        """
        é‡æ–°æ’åºé˜Ÿåˆ—

        Args:
            job_ids: æŒ‰æ–°é¡ºåºæ’åˆ—çš„ä»»åŠ¡IDåˆ—è¡¨
        """
        queue_service = get_queue_service()
        ok = queue_service.reorder_queue(job_ids)

        if not ok:
            raise HTTPException(status_code=400, detail="é‡æ’é˜Ÿåˆ—å¤±è´¥ï¼ˆä»»åŠ¡IDä¸åŒ¹é…ï¼‰")

        return {
            "reordered": True,
            "queue": job_ids
        }

    @router.get("/queue-status")
    async def get_queue_status():
        """è·å–é˜Ÿåˆ—çŠ¶æ€æ‘˜è¦"""
        queue_service = get_queue_service()
        return queue_service.get_queue_status()

    @router.get("/events/global")
    async def stream_global_events(request: Request):
        """
        å…¨å±€SSEæµ - æ¨é€æ‰€æœ‰ä»»åŠ¡çš„çŠ¶æ€å˜åŒ– (V3.0)

        äº‹ä»¶ç±»å‹:
        - initial_state: è¿æ¥æ—¶çš„åˆå§‹çŠ¶æ€
        - queue_update: é˜Ÿåˆ—é¡ºåºå˜åŒ–
        - job_status: ä»»åŠ¡çŠ¶æ€å˜åŒ–
        - job_progress: ä»»åŠ¡è¿›åº¦æ›´æ–°

        æ³¨æ„:
        - initial_stateè¿”å›æ‰€æœ‰ä»»åŠ¡ï¼ˆå¤„ç†ä¸­ + å·²å®Œæˆï¼‰
        - é¿å…å®¢æˆ·ç«¯è¿æ¥æ—¶æ¼æ‰å®Œæˆä»»åŠ¡çš„å®æ—¶æ›´æ–°
        """
        queue_service = get_queue_service()

        def get_initial_state():
            """
            è¿”å›æ‰€æœ‰ä»»åŠ¡åˆ—è¡¨ï¼ˆç¬¬äºŒé˜¶æ®µä¿®å¤ï¼šå®æ—¶æ›´æ–°ï¼‰
            åŒ…å«æ´»è·ƒä»»åŠ¡ + å†å²å®Œæˆä»»åŠ¡
            """
            from services.job_index_service import get_job_index_service
            from core.config import config
            from pathlib import Path
            import json as json_module

            jobs_summary = []

            # 1. æ·»åŠ æ´»è·ƒä»»åŠ¡ï¼ˆä»é˜Ÿåˆ—ä¸­ï¼‰
            with queue_service.lock:
                for jid, job in queue_service.jobs.items():
                    jobs_summary.append({
                        "id": jid,
                        "status": job.status,
                        "progress": job.progress,
                        "filename": job.filename,
                        "title": job.title if hasattr(job, 'title') else "",  # ç”¨æˆ·è‡ªå®šä¹‰åç§°
                        "message": job.message,
                        "created_time": job.createdAt if hasattr(job, 'createdAt') else None,
                        "phase": job.phase if hasattr(job, 'phase') else 'unknown'
                    })

                queue_list = list(queue_service.queue)
                running_id = queue_service.running_job_id
                interrupted_id = queue_service.interrupted_job_id

            # 2. æ·»åŠ å†å²å®Œæˆä»»åŠ¡ï¼ˆä» jobs ç›®å½•ï¼‰
            try:
                jobs_root = Path(config.JOBS_DIR)
                job_index = get_job_index_service(config.JOBS_DIR)
                active_job_ids = set(jid for jid, _ in queue_service.jobs.items())

                for job_dir in jobs_root.iterdir():
                    if not job_dir.is_dir():
                        continue

                    job_id = job_dir.name
                    if job_id in active_job_ids:
                        # å·²åœ¨æ´»è·ƒä»»åŠ¡ä¸­ï¼Œè·³è¿‡
                        continue

                    # å°è¯•æ‰¾åˆ°æ–‡ä»¶å
                    filename = "æœªçŸ¥æ–‡ä»¶"
                    file_path = job_index.get_file_path(job_id)
                    if file_path:
                        filename = os.path.basename(file_path)
                    else:
                        # ä»ç›®å½•ä¸­æ‰¾è§†é¢‘æ–‡ä»¶
                        for ext in ['.mp4', '.avi', '.mkv', '.mov', '.flv', '.wmv', '.mp3', '.wav', '.m4a']:
                            matches = list(job_dir.glob(f"*{ext}"))
                            if matches:
                                filename = matches[0].name
                                break

                    # æ£€æŸ¥æ˜¯å¦å®Œæˆ
                    srt_files = list(job_dir.glob("*.srt"))
                    is_finished = len(srt_files) > 0

                    # è·å–åˆ›å»ºæ—¶é—´
                    try:
                        stat = job_dir.stat()
                        created_time = int(stat.st_ctime * 1000)
                    except:
                        created_time = None

                    # å°è¯•ä» checkpoint è·å–è¿›åº¦
                    progress = 100 if is_finished else 0
                    phase = 'editing' if is_finished else 'transcribing'
                    status = 'finished' if is_finished else 'processing'

                    checkpoint_path = job_dir / "checkpoint.json"
                    if checkpoint_path.exists():
                        try:
                            with open(checkpoint_path, 'r', encoding='utf-8') as f:
                                checkpoint_data = json_module.load(f)
                                total_segments = checkpoint_data.get('total_segments', 0)
                                processed_indices = checkpoint_data.get('processed_indices', [])
                                if total_segments > 0:
                                    progress = (len(processed_indices) / total_segments) * 100
                                phase = checkpoint_data.get('phase', 'transcribing')
                        except:
                            pass

                    # å°è¯•ä» state.json è¯»å– title
                    title = ""
                    state_file = job_dir / "state.json"
                    if state_file.exists():
                        try:
                            with open(state_file, 'r', encoding='utf-8') as f:
                                state_data = json_module.load(f)
                                title = state_data.get('title', '')
                        except:
                            pass

                    jobs_summary.append({
                        "id": job_id,
                        "status": status,
                        "progress": min(progress, 100),
                        "filename": filename,
                        "title": title,  # ç”¨æˆ·è‡ªå®šä¹‰åç§°
                        "message": "å·²å®Œæˆ" if is_finished else "å¤„ç†ä¸­",
                        "created_time": created_time,
                        "phase": phase
                    })

            except Exception as e:
                logger = logging.getLogger(__name__)
                logger.warning(f"åŠ è½½å†å²ä»»åŠ¡å¤±è´¥: {e}")

            return {
                "queue": queue_list,
                "running": running_id,
                "interrupted": interrupted_id,
                "jobs": jobs_summary
            }

        # è®¢é˜…SSEæµï¼Œé¢‘é“åä¸º "global"
        return StreamingResponse(
            sse_manager.subscribe("global", request, initial_state_callback=get_initial_state),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no"
            }
        )

    @router.get("/sync-tasks")
    async def sync_tasks():
        """
        åŒæ­¥æ‰€æœ‰ä»»åŠ¡ï¼ˆç¬¬ä¸€é˜¶æ®µä¿®å¤ï¼šæ•°æ®åŒæ­¥ï¼‰

        è¿”å›æ‰€æœ‰ä»»åŠ¡åˆ—è¡¨ï¼ˆå¤„ç†ä¸­ + å·²å®Œæˆï¼‰ï¼Œå‰ç«¯ç”¨æ­¤æ¥å£åŒæ­¥åç«¯å®é™…å­˜åœ¨çš„ä»»åŠ¡
        æ­¤æ¥å£ä¸ºçœŸå®æºï¼Œç”¨äºä¿®å¤å¹½çµä»»åŠ¡é—®é¢˜
        """
        from services.job_index_service import get_job_index_service
        from core.config import config
        from pathlib import Path
        import json as json_module

        queue_service = get_queue_service()
        job_index = get_job_index_service(config.JOBS_DIR)
        jobs_root = Path(config.JOBS_DIR)

        # æ¸…ç†æ— æ•ˆæ˜ å°„ï¼ˆä»»åŠ¡æˆ–æ–‡ä»¶ä¸å­˜åœ¨çš„æ˜ å°„ï¼‰
        job_index.cleanup_invalid_mappings()

        # æ”¶é›†æ‰€æœ‰ä»»åŠ¡
        all_tasks = {}  # ä½¿ç”¨ dict é¿å…é‡å¤ï¼Œkey ä¸º job_id

        # 1. é˜Ÿåˆ—ä¸­çš„ä»»åŠ¡ï¼ˆå¤„ç†ä¸­æˆ–ç­‰å¾…ä¸­ï¼‰- ä¼˜å…ˆçº§æœ€é«˜
        with queue_service.lock:
            for job_id, job in queue_service.jobs.items():
                all_tasks[job_id] = {
                    "id": job.job_id,
                    "filename": job.filename,
                    "title": job.title if hasattr(job, 'title') else "",  # ç”¨æˆ·è‡ªå®šä¹‰åç§°
                    "status": job.status,
                    "progress": job.progress,
                    "message": job.message,
                    "created_time": job.createdAt if hasattr(job, 'createdAt') else None,
                    "phase": job.phase if hasattr(job, 'phase') else 'unknown'
                }

        # 2. æ‰«æ jobs ç›®å½•ä¸­çš„æ‰€æœ‰ä»»åŠ¡ï¼ˆåŒ…æ‹¬å·²å®Œæˆçš„ï¼‰
        try:
            for job_dir in jobs_root.iterdir():
                if not job_dir.is_dir():
                    continue

                job_id = job_dir.name
                if job_id in all_tasks:
                    # å·²åœ¨é˜Ÿåˆ—ä¸­ï¼Œè·³è¿‡
                    continue

                # å°è¯•æ‰¾åˆ°æ–‡ä»¶å
                filename = "æœªçŸ¥æ–‡ä»¶"

                # 1. ä» job_index æŸ¥æ‰¾
                file_path = job_index.get_file_path(job_id)
                if file_path:
                    filename = os.path.basename(file_path)
                else:
                    # 2. ä»ç›®å½•ä¸­æ‰¾è§†é¢‘æ–‡ä»¶
                    for ext in ['.mp4', '.avi', '.mkv', '.mov', '.flv', '.wmv', '.mp3', '.wav', '.m4a']:
                        matches = list(job_dir.glob(f"*{ext}"))
                        if matches:
                            filename = matches[0].name
                            break

                # åˆ¤æ–­ä»»åŠ¡æ˜¯å¦å®Œæˆ
                srt_files = list(job_dir.glob("*.srt"))
                is_finished = len(srt_files) > 0

                # è·å–åˆ›å»ºæ—¶é—´
                try:
                    stat = job_dir.stat()
                    created_time = int(stat.st_ctime * 1000)
                except:
                    created_time = None

                # å°è¯•ä» checkpoint è·å–è¿›åº¦ä¿¡æ¯
                checkpoint_path = job_dir / "checkpoint.json"
                progress = 100 if is_finished else 0
                phase = 'editing' if is_finished else 'transcribing'
                status = 'finished' if is_finished else 'processing'

                if checkpoint_path.exists():
                    try:
                        with open(checkpoint_path, 'r', encoding='utf-8') as f:
                            checkpoint_data = json_module.load(f)
                            total_segments = checkpoint_data.get('total_segments', 0)
                            processed_indices = checkpoint_data.get('processed_indices', [])
                            if total_segments > 0:
                                progress = (len(processed_indices) / total_segments) * 100
                            phase = checkpoint_data.get('phase', 'transcribing')
                    except:
                        pass

                # å°è¯•ä» state.json è¯»å– title
                title = ""
                state_file = job_dir / "state.json"
                if state_file.exists():
                    try:
                        with open(state_file, 'r', encoding='utf-8') as f:
                            state_data = json_module.load(f)
                            title = state_data.get('title', '')
                    except:
                        pass

                all_tasks[job_id] = {
                    "id": job_id,
                    "filename": filename,
                    "title": title,  # ç”¨æˆ·è‡ªå®šä¹‰åç§°
                    "status": status,
                    "progress": min(progress, 100),  # ç¡®ä¿ä¸è¶…è¿‡100
                    "message": "å·²å®Œæˆ" if is_finished else "å¤„ç†ä¸­",
                    "created_time": created_time,
                    "phase": phase
                }

        except Exception as e:
            logger = logging.getLogger(__name__)
            logger.error(f"æ‰«æ jobs ç›®å½•å¤±è´¥: {e}")

        return {
            "success": True,
            "tasks": list(all_tasks.values()),
            "count": len(all_tasks),
            "timestamp": int(time.time() * 1000)
        }

    @router.get("/incomplete-jobs")
    async def get_incomplete_jobs():
        """è·å–æ‰€æœ‰æœªå®Œæˆçš„ä»»åŠ¡"""
        jobs = transcription_service.scan_incomplete_jobs()
        return {"jobs": jobs, "count": len(jobs)}

    @router.post("/restore-job/{job_id}")
    async def restore_job(job_id: str):
        """ä»æ£€æŸ¥ç‚¹æ¢å¤ä»»åŠ¡"""
        job = transcription_service.restore_job_from_checkpoint(job_id)
        if not job:
            raise HTTPException(status_code=404, detail="æ— æ³•æ¢å¤ä»»åŠ¡ï¼Œæ£€æŸ¥ç‚¹ä¸å­˜åœ¨æˆ–å·²æŸå")

        return job.to_dict()

    @router.get("/status/{job_id}")
    async def get_job_status(job_id: str, include_media: bool = True):
        """
        è·å–ä»»åŠ¡çŠ¶æ€ï¼ˆV2.3: åŒ…å«é˜Ÿåˆ—ä½ç½®å’Œåª’ä½“çŠ¶æ€ï¼‰

        Args:
            job_id: ä»»åŠ¡ID
            include_media: æ˜¯å¦åŒ…å«åª’ä½“çŠ¶æ€ä¿¡æ¯ï¼ˆé»˜è®¤Trueï¼‰
        """
        queue_service = get_queue_service()
        job = queue_service.get_job(job_id)
        if not job:
            # å¦‚æœé˜Ÿåˆ—æœåŠ¡ä¸­æ²¡æœ‰ï¼Œå°è¯•ä»transcription_serviceè·å–
            job = transcription_service.get_job(job_id)
            if not job:
                raise HTTPException(status_code=404, detail="ä»»åŠ¡æœªæ‰¾åˆ°")

        # è¿”å›çŠ¶æ€ï¼ˆæ–°å¢queue_positionå­—æ®µï¼‰
        result = job.to_dict()

        # è®¡ç®—é˜Ÿåˆ—ä½ç½®
        with queue_service.lock:
            if job_id in queue_service.queue:
                result["queue_position"] = list(queue_service.queue).index(job_id) + 1
            elif job_id == queue_service.running_job_id:
                result["queue_position"] = 0  # 0è¡¨ç¤ºæ­£åœ¨æ‰§è¡Œ
            else:
                result["queue_position"] = -1  # -1è¡¨ç¤ºä¸åœ¨é˜Ÿåˆ—ä¸­

        # æ·»åŠ åª’ä½“çŠ¶æ€ä¿¡æ¯ï¼ˆç”¨äºç¼–è¾‘å™¨ï¼‰
        if include_media and job.status == "finished" and job.dir:
            job.update_media_status(job.dir)
            if job.media_status:
                result["media_status"] = {
                    "video_exists": job.media_status.video_exists,
                    "video_format": job.media_status.video_format,
                    "needs_proxy": job.media_status.needs_proxy,
                    "proxy_exists": job.media_status.proxy_exists,
                    "audio_exists": job.media_status.audio_exists,
                    "peaks_ready": job.media_status.peaks_ready,
                    "thumbnails_ready": job.media_status.thumbnails_ready,
                    "srt_exists": job.media_status.srt_exists,
                    # ä¾¿æ·çš„URLå­—æ®µ
                    "video_url": f"/api/media/{job_id}/video" if job.media_status.video_exists or job.media_status.proxy_exists else None,
                    "audio_url": f"/api/media/{job_id}/audio" if job.media_status.audio_exists else None,
                    "peaks_url": f"/api/media/{job_id}/peaks" if job.media_status.audio_exists else None,
                    "thumbnails_url": f"/api/media/{job_id}/thumbnails" if job.media_status.video_exists else None,
                    "srt_url": f"/api/media/{job_id}/srt" if job.media_status.srt_exists else None
                }

        return result

    @router.get("/download/{job_id}")
    async def download_result(job_id: str, copy_to_source: bool = False):
        """ä¸‹è½½è½¬å½•ç»“æœ"""
        job = transcription_service.get_job(job_id)
        if not job:
            raise HTTPException(status_code=404, detail="ä»»åŠ¡æœªæ‰¾åˆ°")
        
        if not job.srt_path or not os.path.exists(job.srt_path):
            raise HTTPException(status_code=404, detail="å­—å¹•æ–‡ä»¶æœªç”Ÿæˆ")
        
        filename = os.path.basename(job.srt_path)
        
        # å¦‚æœéœ€è¦å¤åˆ¶åˆ°æºæ–‡ä»¶ç›®å½•
        if copy_to_source and job.input_path:
            source_dir = os.path.dirname(job.input_path)
            source_srt_path = os.path.join(source_dir, filename)
            
            try:
                shutil.copy2(job.srt_path, source_srt_path)
                print(f"SRTæ–‡ä»¶å·²å¤åˆ¶åˆ°æºç›®å½•: {source_srt_path}")
            except Exception as e:
                print(f"å¤åˆ¶åˆ°æºç›®å½•å¤±è´¥: {e}")
        
        # åŒæ—¶å¤åˆ¶åˆ°è¾“å‡ºç›®å½•
        output_path = os.path.join(output_dir, filename)
        try:
            if not os.path.exists(output_path):
                shutil.copy2(job.srt_path, output_path)
            
            return FileResponse(
                path=output_path, 
                filename=filename, 
                media_type='text/plain; charset=utf-8'
            )
        except Exception as e:
            # å¦‚æœå¤åˆ¶å¤±è´¥ï¼Œç›´æ¥è¿”å›åŸæ–‡ä»¶
            return FileResponse(
                path=job.srt_path, 
                filename=filename, 
                media_type='text/plain; charset=utf-8'
            )

    @router.post("/copy-result/{job_id}")
    async def copy_result_to_source(job_id: str):
        """å°†è½¬å½•ç»“æœå¤åˆ¶åˆ°æºæ–‡ä»¶ç›®å½•"""
        job = transcription_service.get_job(job_id)
        if not job:
            raise HTTPException(status_code=404, detail="ä»»åŠ¡æœªæ‰¾åˆ°")

        if not job.srt_path or not os.path.exists(job.srt_path):
            raise HTTPException(status_code=404, detail="å­—å¹•æ–‡ä»¶æœªç”Ÿæˆ")

        try:
            # è·å–åŸå§‹æ–‡ä»¶ç›®å½•
            if job.input_path:
                source_dir = os.path.dirname(job.input_path)
            else:
                # å¦‚æœæ²¡æœ‰input_pathï¼Œä½¿ç”¨inputç›®å½•
                source_dir = file_service.input_dir

            # ç”Ÿæˆç›®æ ‡è·¯å¾„
            srt_filename = os.path.basename(job.srt_path)
            target_path = os.path.join(source_dir, srt_filename)

            # å¤åˆ¶æ–‡ä»¶
            shutil.copy2(job.srt_path, target_path)

            return {
                "success": True,
                "message": f"å­—å¹•æ–‡ä»¶å·²å¤åˆ¶åˆ°: {target_path}",
                "target_path": target_path
            }
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"å¤åˆ¶æ–‡ä»¶å¤±è´¥: {str(e)}")

    @router.get("/check-resume/{job_id}")
    async def check_resume(job_id: str):
        """æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å¯ä»¥æ–­ç‚¹ç»­ä¼ """
        from pathlib import Path

        job = transcription_service.get_job(job_id)
        if not job:
            raise HTTPException(status_code=404, detail="ä»»åŠ¡æœªæ‰¾åˆ°")

        job_dir = Path(job.dir)
        checkpoint_path = job_dir / "checkpoint.json"

        if not checkpoint_path.exists():
            return {
                "can_resume": False,
                "message": "æ— æ£€æŸ¥ç‚¹"
            }

        try:
            with open(checkpoint_path, 'r', encoding='utf-8') as f:
                data = json.load(f)

            total_segments = data.get('total_segments', 0)
            processed_indices = data.get('processed_indices', [])
            processed_count = len(processed_indices)

            if total_segments > 0:
                progress = (processed_count / total_segments) * 100
            else:
                progress = 0

            return {
                "can_resume": True,
                "progress": round(progress, 2),
                "processed_segments": processed_count,
                "total_segments": total_segments,
                "phase": data.get('phase', 'unknown'),
                "message": f"æ£€æµ‹åˆ°ä¸Šæ¬¡è¿›åº¦ ({progress:.1f}%)ï¼Œå¯ä»æ–­ç‚¹ç»§ç»­"
            }
        except Exception as e:
            return {
                "can_resume": False,
                "message": f"æ£€æŸ¥ç‚¹æ–‡ä»¶æŸå: {str(e)}"
            }

    @router.get("/checkpoint-settings/{job_id}")
    async def get_checkpoint_settings(job_id: str):
        """è·å–checkpointä¸­ä¿å­˜çš„åŸå§‹è®¾ç½®ï¼ˆç”¨äºå‚æ•°æ ¡éªŒï¼‰"""
        from pathlib import Path

        job = transcription_service.get_job(job_id)
        if not job:
            raise HTTPException(status_code=404, detail="ä»»åŠ¡æœªæ‰¾åˆ°")

        job_dir = Path(job.dir)
        checkpoint_path = job_dir / "checkpoint.json"

        if not checkpoint_path.exists():
            return {"has_checkpoint": False}

        try:
            with open(checkpoint_path, 'r', encoding='utf-8') as f:
                data = json.load(f)

            return {
                "has_checkpoint": True,
                "original_settings": data.get("original_settings", {}),
                "progress": {
                    "phase": data.get("phase"),
                    "processed": len(data.get("processed_indices", [])),
                    "total": data.get("total_segments", 0)
                }
            }
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"è¯»å–æ£€æŸ¥ç‚¹å¤±è´¥: {str(e)}")

    @router.get("/transcription-text/{job_id}")
    async def get_transcription_text(job_id: str):
        """
        ä»checkpointä¸­æå–å·²å®Œæˆçš„è½¬å½•æ–‡å­—ï¼ˆæœªå¯¹é½ç‰ˆæœ¬ï¼‰

        ç”¨äºSSEæ–­çº¿é‡è¿åï¼Œå‰ç«¯å¯ä»¥è°ƒç”¨æ­¤APIè·å–å½“å‰å·²è½¬å½•çš„æ‰€æœ‰æ–‡å­—

        è¿”å›æ ¼å¼ï¼š
        {
            "job_id": "...",
            "has_checkpoint": true,
            "language": "zh",
            "segments": [
                {"id": 0, "start": 10.5, "end": 15.2, "text": "ç¬¬ä¸€å¥è¯"},
                {"id": 1, "start": 15.2, "end": 20.0, "text": "ç¬¬äºŒå¥è¯"}
            ],
            "progress": {
                "processed": 50,
                "total": 100,
                "percentage": 50.0
            }
        }
        """
        from pathlib import Path

        job = transcription_service.get_job(job_id)
        if not job:
            raise HTTPException(status_code=404, detail="ä»»åŠ¡æœªæ‰¾åˆ°")

        job_dir = Path(job.dir)
        checkpoint_path = job_dir / "checkpoint.json"

        if not checkpoint_path.exists():
            return {
                "job_id": job_id,
                "has_checkpoint": False,
                "message": "æ²¡æœ‰æ£€æŸ¥ç‚¹æ•°æ®"
            }

        try:
            with open(checkpoint_path, 'r', encoding='utf-8') as f:
                data = json.load(f)

            # æå–æœªå¯¹é½ç»“æœ
            unaligned_results = data.get("unaligned_results", [])

            # åˆå¹¶æ‰€æœ‰segments
            all_segments = []
            detected_language = None
            for result in unaligned_results:
                if not detected_language and 'language' in result:
                    detected_language = result['language']
                all_segments.extend(result.get('segments', []))

            # æŒ‰æ—¶é—´æ’åº
            all_segments.sort(key=lambda x: x.get('start', 0))

            # é‡æ–°ç¼–å·
            for idx, seg in enumerate(all_segments):
                seg['id'] = idx

            return {
                "job_id": job_id,
                "has_checkpoint": True,
                "language": detected_language or job.language or "unknown",
                "segments": all_segments,
                "progress": {
                    "processed": len(data.get("processed_indices", [])),
                    "total": data.get("total_segments", 0),
                    "percentage": round(
                        len(data.get("processed_indices", [])) / max(1, data.get("total_segments", 1)) * 100,
                        2
                    )
                }
            }

        except Exception as e:
            raise HTTPException(status_code=500, detail=f"è¯»å–è½¬å½•æ–‡å­—å¤±è´¥: {str(e)}")

    @router.post("/validate-resume-settings")
    async def validate_resume_settings(
        job_id: str = Form(...),
        new_settings: str = Form(...)
    ):
        """
        æ ¡éªŒæ¢å¤ä»»åŠ¡æ—¶çš„å‚æ•°ä¿®æ”¹

        è¿”å›ï¼š
        - valid: bool - æ˜¯å¦å¯ä»¥ä½¿ç”¨æ–°å‚æ•°
        - warnings: list - è­¦å‘Šä¿¡æ¯
        - errors: list - é”™è¯¯ä¿¡æ¯ï¼ˆç¦æ­¢ä¿®æ”¹çš„å‚æ•°ï¼‰
        - force_original: dict - å¿…é¡»å¼ºåˆ¶ä½¿ç”¨çš„åŸå§‹å‚æ•°
        """
        from pathlib import Path

        job = transcription_service.get_job(job_id)
        if not job:
            raise HTTPException(status_code=404, detail="ä»»åŠ¡æœªæ‰¾åˆ°")

        job_dir = Path(job.dir)
        checkpoint_path = job_dir / "checkpoint.json"

        if not checkpoint_path.exists():
            return {
                "valid": True,
                "warnings": [],
                "errors": [],
                "force_original": {},
                "message": "æ— æ£€æŸ¥ç‚¹ï¼Œå¯ä»¥ä½¿ç”¨ä»»æ„å‚æ•°"
            }

        try:
            # åŠ è½½checkpoint
            with open(checkpoint_path, 'r', encoding='utf-8') as f:
                checkpoint_data = json.load(f)

            original_settings = checkpoint_data.get("original_settings", {})
            if not original_settings:
                return {
                    "valid": True,
                    "warnings": [],
                    "errors": [],
                    "force_original": {},
                    "message": "æ—§ç‰ˆcheckpointæ ¼å¼ï¼Œå»ºè®®ä½¿ç”¨é»˜è®¤å‚æ•°"
                }

            # è§£ææ–°è®¾ç½®
            new_settings_obj = json.loads(new_settings)

            warnings = []
            errors = []
            force_original = {}

            # æ£€æŸ¥ç¦æ­¢ä¿®æ”¹çš„å‚æ•°
            # 1. word_timestamps - ç¦æ­¢ä¿®æ”¹
            if "word_timestamps" in original_settings:
                if new_settings_obj.get("word_timestamps") != original_settings["word_timestamps"]:
                    errors.append({
                        "param": "word_timestamps",
                        "reason": "ä¿®æ”¹æ­¤å‚æ•°ä¼šå¯¼è‡´å‰åSRTæ ¼å¼ä¸ä¸€è‡´",
                        "impact": "ä¸¥é‡",
                        "original": original_settings["word_timestamps"],
                        "new": new_settings_obj.get("word_timestamps")
                    })
                    force_original["word_timestamps"] = original_settings["word_timestamps"]

            # 2. device - å»ºè®®ä¸ä¿®æ”¹ï¼ˆä¸­ç­‰å½±å“ï¼‰
            if "device" in original_settings:
                if new_settings_obj.get("device") != original_settings["device"]:
                    warnings.append({
                        "param": "device",
                        "level": "medium",
                        "reason": "ä¸åŒè®¾å¤‡çš„ç²¾åº¦å¯èƒ½æœ‰ç»†å¾®å·®å¼‚",
                        "impact": "ä¸­ç­‰",
                        "original": original_settings["device"],
                        "new": new_settings_obj.get("device"),
                        "suggestion": "å»ºè®®ä¿æŒåŸè®¾å¤‡è®¾ç½®"
                    })

            # 3. model - å…è®¸ä½†éœ€ä¸¥é‡è­¦å‘Š
            if "model" in original_settings:
                if new_settings_obj.get("model") != original_settings["model"]:
                    warnings.append({
                        "param": "model",
                        "level": "high",
                        "reason": "ä¸åŒæ¨¡å‹çš„è¾“å‡ºæ ¼å¼å’Œè´¨é‡å¯èƒ½ä¸åŒï¼Œæ··ç”¨ä¼šå¯¼è‡´å‰åå­—å¹•è´¨é‡ä¸ä¸€è‡´",
                        "impact": "é«˜",
                        "original": original_settings["model"],
                        "new": new_settings_obj.get("model"),
                        "suggestion": "ä»…åœ¨ç¡®è®¤ç”¨é”™æ¨¡å‹æ—¶æ‰ä¿®æ”¹"
                    })

            # compute_type å’Œ batch_size å¯ä»¥è‡ªç”±ä¿®æ”¹ï¼Œä¸éœ€è¦è­¦å‘Š

            return {
                "valid": len(errors) == 0,
                "warnings": warnings,
                "errors": errors,
                "force_original": force_original,
                "message": "å‚æ•°æ ¡éªŒå®Œæˆ" if len(errors) == 0 else "æ£€æµ‹åˆ°ä¸å…¼å®¹çš„å‚æ•°ä¿®æ”¹"
            }

        except Exception as e:
            raise HTTPException(status_code=500, detail=f"å‚æ•°æ ¡éªŒå¤±è´¥: {str(e)}")

    @router.post("/rename-job/{job_id}")
    async def rename_job(job_id: str, title: str = Body(..., embed=True)):
        """
        é‡å‘½åä»»åŠ¡

        Args:
            job_id: ä»»åŠ¡ID
            title: æ–°çš„ä»»åŠ¡åç§°ï¼ˆä¸ºç©ºæ—¶æ¢å¤ä½¿ç”¨ filenameï¼‰

        Returns:
            {
                "success": bool,
                "job_id": str,
                "title": str,
                "message": str
            }
        """
        try:
            # ä»é˜Ÿåˆ—æœåŠ¡æˆ–è½¬å½•æœåŠ¡è·å–ä»»åŠ¡
            queue_service = get_queue_service()
            job = queue_service.get_job(job_id)

            if not job:
                # å¦‚æœé˜Ÿåˆ—æœåŠ¡ä¸­æ²¡æœ‰ï¼Œå°è¯•ä» jobs ç›®å½•æ¢å¤
                job = transcription_service.get_job(job_id)

            if not job:
                raise HTTPException(status_code=404, detail="ä»»åŠ¡æœªæ‰¾åˆ°")

            # æ›´æ–° title å­—æ®µ
            job.title = title.strip() if title else ""

            # ä¿å­˜ä»»åŠ¡çŠ¶æ€åˆ°æ–‡ä»¶
            if job.dir:
                from pathlib import Path
                job_dir = Path(job.dir)
                state_file = job_dir / "state.json"

                try:
                    state_data = job.to_dict()
                    with open(state_file, 'w', encoding='utf-8') as f:
                        json.dump(state_data, f, ensure_ascii=False, indent=2)
                except Exception as e:
                    print(f"ä¿å­˜ä»»åŠ¡çŠ¶æ€å¤±è´¥: {e}")

            # é€šçŸ¥ SSE è®¢é˜…è€…ä»»åŠ¡ä¿¡æ¯å·²æ›´æ–°
            sse_manager.broadcast_sync("global", "job_renamed", {
                "job_id": job_id,
                "title": job.title,
                "filename": job.filename
            })

            return {
                "success": True,
                "job_id": job_id,
                "title": job.title,
                "message": "ä»»åŠ¡é‡å‘½åæˆåŠŸ"
            }

        except HTTPException:
            raise
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"é‡å‘½åä»»åŠ¡å¤±è´¥: {str(e)}")

    return router