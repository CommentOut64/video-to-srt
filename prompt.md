请为video_to_srt_gpu项目实现CPU核心绑定优化功能。

项目背景：
- 这是一个基于WhisperX的视频转字幕工具
- 后端使用FastAPI + Python
- 核心处理文件：backend/app/processor.py 和 backend/app/main.py

具体需求：
1. 在processor.py中添加CPU亲和性设置功能
2. 根据系统CPU核心数智能分配：为转录进程绑定前50%的CPU核心
3. 在TranscriptionProcessor类初始化时应用CPU绑定
4. 添加配置选项允许用户自定义绑定策略
5. 包含错误处理，绑定失败时不影响正常功能

技术要求：
- 使用psutil库进行CPU亲和性设置
- 保持现有API接口不变
- 添加日志记录绑定状态
- 跨平台兼容（Windows/Linux）

代码风格：
- 遵循现有代码风格和命名规范
- 添加必要的中文注释
- 使用类型提示

实现后请确保：
- 不影响现有功能
- 性能有所提升
- 代码可读性良好

---



请为video_to_srt_gpu项目实现模型预加载机制，优化模型加载性能。

具体需求：
1. 在服务启动时预加载默认模型配置（默认为medium）
3. 添加预加载进度显示
4. 实现模型预热功能（空跑一次确保完全加载）
5. 添加内存监控，避免预加载过多模型导致内存不足

技术实现：
- 扩展现有的_get_model和_get_align_model方法
- 在main.py中添加服务启动时的预加载逻辑
- 实现LRU缓存策略管理模型

注意事项：
- 保持现有模型缓存机制不变
- 预加载失败不应影响服务启动
- 支持配置化的预加载策略
- 添加GPU内存使用监控

代码要求：
- 保持向后兼容
- 详细的错误处理和日志
- 清晰的进度反馈

---
请为video_to_srt_gpu项目实现核心硬件检测，专注于影响转录性能的关键硬件信息。

检测重点（仅影响转录性能的核心部分）：
1. GPU核心信息
   - CUDA GPU数量
   - 每个GPU显存容量（用于批处理大小决策）
   - 是否支持CUDA（决定device参数）

2. CPU基础信息
   - CPU核心数（用于并发控制和CPU绑定）
   - 是否支持多线程（影响并行策略）

3. 内存关键信息
   - 系统总内存（决定是否使用内存映射）
   - 当前可用内存（防止内存不足）

4. 存储基础信息
   - 临时目录可用空间（确保有足够空间处理大文件）

技术实现：
1. 简化的硬件信息结构
   ```python
   @dataclass
   class HardwareInfo:
       # GPU关键信息
       gpu_count: int
       gpu_memory_mb: List[int]  # 每个GPU显存容量
       cuda_available: bool
       
       # CPU关键信息  
       cpu_cores: int
       cpu_threads: int
       
       # 内存关键信息
       memory_total_mb: int
       memory_available_mb: int
       
       # 存储关键信息
       temp_space_available_gb: int
```
2. 核心优化决策器
```
class CoreOptimizer:
    def get_optimal_batch_size(self, gpu_memory_mb: int) -> int:
        """根据GPU显存计算最优批处理大小"""
        return min(32, gpu_memory_mb // 500)  # 每500MB支持batch_size=1
    
    def get_optimal_concurrency(self, cpu_cores: int, gpu_memory_mb: int) -> int:
        """计算最优并发数"""
        return min(cpu_cores // 2, gpu_memory_mb // 2000)
    
    def should_use_memory_mapping(self, memory_total_mb: int) -> bool:
        """决定是否使用内存映射"""
        return memory_total_mb < 8000  # 小于8GB强制使用
    
    def get_cpu_affinity_cores(self, total_cores: int) -> List[int]:
        """获取CPU绑定核心列表"""
        return list(range(min(4, total_cores // 2)))
```
3. 检测实现（只检测核心信息）
```
class CoreHardwareDetector:
    def detect(self) -> HardwareInfo:
        # GPU检测
        gpu_info = self._detect_gpu()
        
        # CPU检测  
        cpu_info = self._detect_cpu()
        
        # 内存检测
        memory_info = self._detect_memory()
        
        # 存储检测
        storage_info = self._detect_storage()
        
        return HardwareInfo(**gpu_info, **cpu_info, **memory_info, **storage_info)
        ```
        
使用的库：
torch: GPU信息检测
psutil: CPU、内存信息
shutil: 磁盘空间检测
集成方式：

在TranscriptionProcessor初始化时检测一次
将结果用于JobSettings的默认值优化
在API中提供简单的硬件状态端点
输出示例：
检测到硬件配置：
- GPU: RTX 4090 (24GB显存)
- CPU: 16核心/32线程
- 内存: 32GB总量，28GB可用
- 存储: 500GB可用空间

自动优化配置：
- 批处理大小: 48
- 并发数: 8
- 启用内存映射: 否
- CPU绑定: 核心0-7

预期效果：

5秒内完成所有关键硬件检测
自动生成针对当前硬件的最优配置
为后续优化阶段提供必要的硬件基础信息
检测失败时使用保守默认值，不影响功能
API接口（简化）：

GET /api/hardware/basic - 获取核心硬件信息
GET /api/hardware/optimize - 获取基于硬件的优化配置



重新查看一键启动的预加载所有逻辑关系，目前的情况是ModelStatusButton能显示加载中却显示“模型预加载失败: 预加载正在进行中”并无法加载模型，能成功加载模型却ModelStatusButton的状态没有更新到“加载中”，必要时完全重写这部分的所有逻辑，包括一键启动，App.vue等。注意，这部分修改了多次都没有成功，我希望最终的状态是一键启动后等待前后端完全加载完成后再开始预加载模型，并给前端发出加载中信息，前端接收到后立即修改为加载中状态，并实时监测后端是否已完成加载，此时建立任务等其他流程正常运行，如果前端切换模型，如果当前正在加载模型提示正在加载，如果已完成加载则重新执行新的一轮加载。你需要理清相关逻辑并给所有可能性建立可靠的处理机制



---

请为video_to_srt_gpu项目实现断点续传功能，提升大文件处理的用户体验。

现状分析：
- JobState类已有basic进度跟踪（processed字段）
- 处理过程中断后需要重新开始
- 缺少中间结果保存机制

具体需求：
1. 实现检查点(checkpoint)保存机制
   - 保存已完成的音频段转录结果
   - 记录当前处理进度和状态
   - 包含任务元数据和配置信息

2. 恢复机制
   - 服务重启或任务中断后自动检测未完成任务
   - 从上次中断点继续处理
   - 验证检查点数据完整性

3. 失败重试策略
   - 单个音频段失败时自动重试（最多3次）
   - 区分临时错误和永久错误
   - 记录失败原因和重试历史

4. 清理机制
   - 完成的任务自动清理临时检查点
   - 过期任务的清理策略
   - 磁盘空间管理

技术实现要点：
- 在JobState中添加checkpoint相关字段
- 修改_run_pipeline方法支持断点续传
- 实现CheckpointManager类管理检查点
- 在processor.py中添加恢复逻辑

文件结构：
- 每个任务目录下保存checkpoint.json
- 包含segments_results/目录存储单段结果
- 保持现有目录结构不变

代码要求：
- 向后兼容，不影响现有任务
- 原子性操作，避免数据损坏
- 详细的状态跟踪和日志

---

请为video_to_srt_gpu项目实现内存映射优化，减少大文件内存占用。

问题分析：
- 当前使用AudioSegment.from_wav()加载整个音频文件到内存
- 大文件（几GB）会占用大量内存
- 处理多个任务时容易内存不足

优化目标：
1. 实现内存映射音频文件访问
2. 按需读取音频段，而非加载整个文件
3. 支持多进程共享同一文件的内存映射
4. 保持现有API接口兼容性

具体实现：
1. 创建MemoryMappedAudioHandler类
   - 使用mmap映射音频文件
   - 实现按时间范围读取音频段
   - 支持WAV格式的header解析

2. 修改_split_audio方法
   - 使用内存映射替代AudioSegment.from_wav
   - 实现延迟加载策略
   - 保持分段逻辑不变

3. 修改_transcribe_segment方法
   - 适配内存映射的音频读取
   - 保持与whisperx.load_audio的兼容性

4. 添加内存监控
   - 跟踪实际内存使用量
   - 对比优化前后的内存效率

技术要求：
- 使用标准库mmap模块
- 处理不同音频格式的兼容性
- 异常处理和资源清理
- 线程安全的内存映射管理

注意事项：
- 保持现有功能完全不变
- 添加fallback机制（内存映射失败时使用原方法）
- 详细的性能对比日志
- 跨平台兼容性测试

---

请为video_to_srt_gpu项目实现音频段并行转录，大幅提升处理速度。

当前分析：
- processor.py中的转录循环是串行处理
- 每个音频段独立转录，天然支持并行
- GPU和CPU资源未充分利用

并行策略：
1. 实现智能并发控制
   - 根据GPU内存动态调整并发数
   - 监控GPU利用率，避免过载
   - CPU和GPU资源的合理分配

2. 批处理优化
   - 将多个小段合并为一个批次
   - 动态调整batch_size
   - 内存安全的批次管理

3. 结果管理
   - 保持转录结果的顺序
   - 处理并发过程中的错误
   - 进度跟踪的线程安全更新

技术实现：
1. 创建ParallelTranscriptionManager类
   - 管理工作线程池
   - 实现任务分发和结果收集
   - GPU资源锁管理

2. 修改_run_pipeline方法
   - 替换串行循环为并行处理
   - 保持现有进度更新机制
   - 错误处理和取消机制

3. GPU内存管理
   - 实时监控GPU内存使用
   - 动态调整并发数和批次大小
   - 实现GPU内存池化

4. 线程安全保证
   - 保护共享状态的访问
   - 安全的进度更新
   - 模型缓存的线程安全

关键要求：
- 保持API接口不变
- 结果与串行处理完全一致
- 优雅的错误处理和恢复
- 详细的性能监控和日志
- 支持动态调整并行参数

风险控制：
- 实现降级机制（并行失败时回退到串行）
- 内存和GPU使用的上限控制
- 全面的单元测试覆盖

---

请为video_to_srt_gpu项目实现异步I/O优化，提升文件操作并发性能。

现状分析：
- 当前所有文件操作都是同步阻塞的
- processor.py中的文件复制、音频导出、SRT写入都会阻塞主线程
- 大文件操作时影响整体响应性能

问题定位：
1. shutil.copyfile() - 大视频文件复制阻塞
2. chunk.export() - 音频段导出串行执行
3. SRT文件写入 - 阻塞任务完成
4. FFmpeg音频提取 - 长时间同步等待

优化目标：
1. 所有文件I/O操作异步化
2. 支持多个任务并发文件操作
3. 保持现有API接口兼容
4. 实现I/O操作的优先级管理

技术实现：
1. 异步文件操作管理器
   - 使用aiofiles处理文件I/O
   - 实现异步的文件复制和写入
   - 管理I/O操作队列和优先级

2. 重构核心方法为异步
   - _extract_audio -> async _extract_audio_async
   - _split_audio -> 保持同步，但导出操作异步化
   - _generate_srt -> async _generate_srt_async
   - create_job -> 异步文件复制

3. 事件循环管理
   - 在TranscriptionProcessor中集成asyncio
   - 实现混合同步/异步的工作模式
   - 保持现有同步API的兼容性

4. 并发控制
   - 限制同时进行的I/O操作数量
   - 实现I/O资源池管理
   - 磁盘I/O的优先级调度

具体修改点：
1. 在processor.py中添加AsyncIOManager类
2. 修改create_job方法支持异步文件复制
3. 重构_run_pipeline使用异步I/O
4. 添加async/await支持到核心处理流程

代码要求：
- 使用aiofiles, asyncio标准库
- 保持同步API向后兼容
- 实现优雅的异步/同步桥接
- 详细的I/O性能监控
- 异常处理覆盖所有异步操作

注意事项：
- 异步化不能影响处理结果准确性
- 实现I/O失败的重试机制
- 保持文件操作的原子性
- 添加I/O操作的取消支持

---

请为video_to_srt_gpu项目实现流水线并行处理，让各阶段重叠执行提升整体效率。

当前处理流程分析：
- 串行执行：音频提取 → 分段 → 转录 → SRT生成
- 每个阶段都等待前一阶段完全完成
- 存在大量等待时间和资源空闲

流水线设计：
1. 阶段重叠执行
   - 音频提取完成后立即开始分段
   - 分段产生的段立即进入转录队列
   - 转录完成的段立即可用于SRT生成

2. 资源隔离
   - 音频提取：主要消耗CPU和磁盘I/O
   - 分段处理：主要消耗CPU和内存
   - 转录处理：主要消耗GPU和内存
   - SRT生成：主要消耗CPU和磁盘I/O

3. 队列管理
   - 分段队列：存储待转录的音频段
   - 结果队列：存储已转录等待写入的结果
   - 优先级调度：紧急任务优先处理

技术实现：
1. 流水线管理器(PipelineManager)
   - 管理各阶段的异步执行
   - 实现阶段间的数据流转
   - 监控各阶段的执行状态

2. 异步队列系统
   - asyncio.Queue管理阶段间数据传递
   - 实现背压控制避免内存溢出
   - 支持优先级和批处理

3. 重构_run_pipeline方法
   - 分解为独立的异步阶段函数
   - 实现阶段间的数据流和控制流
   - 保持进度跟踪的准确性

4. 错误处理和恢复
   - 任意阶段失败不影响其他阶段
   - 实现优雅的降级和恢复
   - 支持部分结果的保存

具体阶段设计：
1. ExtractorStage: 音频提取阶段
2. SegmenterStage: 音频分段阶段  
3. TranscriberStage: 转录处理阶段
4. SRTGeneratorStage: 字幕生成阶段

关键技术点：
- 使用asyncio.Queue实现生产者-消费者模式
- 每个阶段独立的asyncio.Task
- 实现阶段间的依赖管理
- 支持动态调整各阶段的并发度

代码要求：
- 基于阶段6的异步I/O基础
- 保持现有API接口不变
- 实现详细的阶段性能监控
- 支持流水线的暂停和恢复
- 完整的单元测试覆盖

优化预期：
- 整体处理时间减少30-50%
- GPU和CPU利用率提升
- 支持更高的并发任务数

---

请为video_to_srt_gpu项目实现基于VAD(语音活动检测)的智能分段策略，提升转录准确性和效率。

现状问题分析：
- 当前固定60秒分段策略过于简单
- 静音检测分段容易切断单词或句子
- 长静音段浪费GPU计算资源
- 分段边界不自然影响转录连贯性

VAD智能分段目标：
1. 基于语音活动智能确定分段点
2. 避免在语音活跃期切断
3. 跳过长时间静音段提升效率
4. 自适应调整段长度

技术方案：
1. VAD模型集成
   - 集成lightweight VAD模型（如silero-vad）
   - 实现音频的语音活动检测
   - 生成时间戳级别的语音活动标注

2. 智能分段算法
   - 基于VAD结果识别语音边界
   - 在语音停顿处进行分段
   - 控制分段长度在合理范围(30-90秒)
   - 实现自适应的分段策略

3. 性能优化
   - VAD处理与音频分段并行
   - 缓存VAD结果避免重复计算
   - 支持不同精度的VAD模型选择

具体实现：
1. 创建VADSegmenter类
   - 集成VAD模型的加载和推理
   - 实现基于VAD的分段算法
   - 提供配置化的分段参数

2. 扩展音频分段配置
   - 添加VAD使能开关
   - 支持传统分段作为fallback
   - 可配置的分段策略参数

3. 修改_split_audio方法
   - 集成VAD分段逻辑
   - 保持与现有接口的兼容性
   - 实现分段质量评估

4. 静音段处理
   - 识别并跳过长静音段
   - 保留必要的静音边界
   - 优化转录效率

算法流程：
1. 对整段音频进行VAD分析
2. 识别语音活动区间
3. 在语音停顿处确定分段点
4. 生成优化的音频分段列表
5. 跳过纯静音段

代码要求：
- 使用silero-vad或类似轻量级VAD模型
- 实现配置化的VAD参数
- 保持现有分段接口兼容
- 添加分段质量评估指标
- 支持VAD功能的开关控制

性能考虑：
- VAD推理速度要足够快
- 内存使用要控制在合理范围
- 支持GPU加速VAD推理
- 实现VAD结果的缓存机制

风险控制：
- VAD失败时自动降级到传统分段
- 异常分段时的修复机制
- 分段结果的质量验证
- 详细的分段效果日志

预期效果：
- 减少无效的静音段转录
- 提升转录边界的自然性
- 整体转录速度提升15-25%
- 转录准确性有所改善

---

请为video_to_srt_gpu项目实现负载均衡系统，支持多实例部署和智能任务调度。

系统架构分析：
- 当前为单实例处理架构
- 缺少多任务间的资源协调
- 无法实现水平扩展
- 资源利用不够充分

负载均衡设计目标：
1. 支持多Worker实例并行处理
2. 智能任务分发和调度
3. 实时资源监控和负载评估  
4. 故障自动恢复和任务重分配
5. 弹性扩缩容支持

系统架构设计：
1. Master-Worker架构
   - LoadBalancerMaster: 任务调度和负载管理
   - TranscriptionWorker: 实际转录处理节点
   - 支持多进程和多机器部署

2. 任务队列系统
   - 使用Redis作为分布式任务队列
   - 支持任务优先级和批处理
   - 实现任务的持久化和恢复

3. 资源监控系统
   - 实时监控CPU、GPU、内存使用率
   - 网络带宽和磁盘I/O监控
   - Worker节点的健康状态检查

技术实现：
1. 负载均衡器(LoadBalancer)
   - 实现任务分发算法
   - 监控Worker负载状态
   - 处理Worker的注册和注销

2. 任务调度器(TaskScheduler)  
   - 基于资源使用率的调度算法
   - 支持不同类型任务的优先级
   - 实现任务的预估和规划

3. Worker管理器(WorkerManager)
   - Worker节点的生命周期管理
   - 健康检查和故障恢复
   - 动态扩缩容控制

4. 分布式状态管理
   - 使用Redis管理全局状态
   - 实现分布式锁和同步
   - 任务状态的一致性保证

关键算法：
1. 负载评估算法
   - 综合CPU、GPU、内存、任务队列长度
   - 计算Worker的负载评分
   - 动态调整权重系数

2. 任务分发策略
   - 最少连接数分发
   - 加权轮询调度
   - 基于响应时间的自适应调度

3. 故障检测和恢复
   - 心跳检测Worker状态
   - 任务执行超时检测
   - 自动重分配失败任务

具体实现组件：
1. 修改main.py支持Master/Worker模式
2. 创建DistributedTranscriptionService
3. 实现RedisTaskQueue任务队列
4. 添加WorkerHeartbeat心跳机制
5. 创建LoadBalancingPolicy调度策略

配置和部署：
1. 支持配置化的部署模式
   - 单机模式(现有功能)
   - 多进程模式
   - 分布式集群模式

2. 服务发现机制
   - Worker自动注册到Master
   - 支持动态添加/移除Worker
   - 配置中心统一管理

3. 监控和告警
   - 实时性能Dashboard
   - 关键指标的告警机制
   - 系统健康状态报告

代码架构要求：
- 保持现有单实例模式完全兼容
- 实现模块化的负载均衡组件
- 支持渐进式的分布式部署
- 详细的监控和日志系统

部署策略：
1. 向后兼容：默认单实例模式
2. 配置驱动：通过配置启用分布式
3. 渐进部署：支持混合部署模式
4. 零停机：支持在线扩缩容

风险控制：
- Master单点故障的高可用方案
- 网络分区时的数据一致性
- 任务重复执行的幂等性保证
- 详细的异常处理和恢复机制

预期效果：
- 支持水平扩展到多台机器
- 整体处理能力线性提升
- 系统可用性和容错性大幅改善
- 资源利用率提升到85%以上

实施建议：
- 先实现多进程版本验证架构
- 再扩展到分布式集群部署
- 重点测试故障恢复机制
- 逐步优化调度算法性能

---

