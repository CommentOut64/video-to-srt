# Video-to-SRT GPU é¡¹ç›®é‡æ„è®¡åˆ’ (å®æˆ˜ç‰ˆ)

> **æ ¸å¿ƒåŸåˆ™**: å…ˆç¨³åå¿«ï¼Œé»‘ç›’æµ‹è¯•æŠ¤èˆªï¼Œèšç„¦æ–­ç‚¹ç»­ä¼ 
> **é¢„è®¡è€—æ—¶**: 3-5å¤©
> **å½“å‰é¡¹ç›®ç‰ˆæœ¬**: v2.0
> **å½“å‰åˆ†æ”¯**: feature/breakpoint-resume
> **é‡æ„ç›®æ ‡**: ç»Ÿä¸€é€»è¾‘ã€å®ç°æ–­ç‚¹ç»­ä¼ ã€æ”¯æŒç‹¬ç«‹æ‰“åŒ…

---

## ğŸ“‹ ç›®å½•

- [ä¸€ã€ä¸ºä»€ä¹ˆé‡æ„ï¼Ÿ](#ä¸€ä¸ºä»€ä¹ˆé‡æ„)
- [äºŒã€é‡æ„å‰çš„"æ•‘å‘½ç´¢"](#äºŒé‡æ„å‰çš„æ•‘å‘½ç´¢)
- [ä¸‰ã€åˆ†æ­¥æ‰§è¡Œè®¡åˆ’](#ä¸‰åˆ†æ­¥æ‰§è¡Œè®¡åˆ’)
- [å››ã€é£é™©æ§åˆ¶](#å››é£é™©æ§åˆ¶)
- [äº”ã€éªŒæ”¶æ ‡å‡†](#äº”éªŒæ”¶æ ‡å‡†)

---

## ä¸€ã€ä¸ºä»€ä¹ˆé‡æ„ï¼Ÿ

### 1.1 å½“å‰ç—›ç‚¹

#### é—®é¢˜1: å…¥å£æ–‡ä»¶æ··ä¹± âš ï¸âš ï¸âš ï¸
**ç°çŠ¶**:
```
backend/app/
â”œâ”€â”€ main.py                # å½“å‰ä¸»å…¥å£ï¼Ÿ
â”œâ”€â”€ main_refactored.py     # é‡æ„ç‰ˆæœ¬ï¼Ÿ
â”œâ”€â”€ main_simple.py         # ç®€åŒ–ç‰ˆæœ¬ï¼Ÿ
â””â”€â”€ debug_main.py          # è°ƒè¯•ç‰ˆæœ¬ï¼Ÿ
```

**é—®é¢˜**: 4ä¸ªå…¥å£æ–‡ä»¶ï¼Œä¸æ¸…æ¥šè¯¥è¿è¡Œå“ªä¸ªï¼Œè¿‡æ®µæ—¶é—´è‡ªå·±éƒ½å¿˜äº†ã€‚

---

#### é—®é¢˜2: è½¬å½•é€»è¾‘é‡å¤ âš ï¸âš ï¸âš ï¸
**ç°çŠ¶**:
- `processor.py` (534è¡Œ) - åŒ…å«å®Œæ•´è½¬å½•æµç¨‹
- `services/transcription_service.py` (405è¡Œ) - å‡ ä¹ç›¸åŒçš„å®ç°

**ä»£ç é‡å¤ç‡**: >90%

**é—®é¢˜**: æ”¹ä¸€å¤„è¿˜å¾—æ”¹å¦ä¸€å¤„ï¼Œå®¹æ˜“æ¼æ”¹å¯¼è‡´Bugï¼Œä¸”éš¾ä»¥å®ç°æ–­ç‚¹ç»­ä¼ ã€‚

---

#### é—®é¢˜3: è·¯å¾„ç¡¬ç¼–ç  âš ï¸âš ï¸
**ç°çŠ¶**: ä»£ç ä¸­å­˜åœ¨ç¡¬ç¼–ç è·¯å¾„ï¼Œä¸åˆ©äºç‹¬ç«‹æ‰“åŒ…

**é—®é¢˜**:
- æ— æ³•ä¸€é”®åˆ‡æ¢åˆ°åµŒå…¥å¼ç¯å¢ƒ
- ä¾èµ–ç³»ç»Ÿç¯å¢ƒå˜é‡
- æ¨¡å‹ä¸‹è½½è·¯å¾„ä¸å¯æ§

---

### 1.2 é‡æ„ç›®æ ‡

1. **ç»Ÿä¸€é€»è¾‘** - åªä¿ç•™ä¸€å¥—è½¬å½•ä»£ç 
2. **ç›®å½•æ•´æ´** - æ¸…æ™°çš„åˆ†å±‚ç»“æ„
3. **åŠŸèƒ½è½åœ°** - å®ç°æ–­ç‚¹ç»­ä¼ 
4. **ç‹¬ç«‹æ‰“åŒ…** - æ”¯æŒä¾¿æºå¼éƒ¨ç½²

---

## äºŒã€é‡æ„å‰çš„"æ•‘å‘½ç´¢"

### 2.1 é»„é‡‘æ ‡å‡†æµ‹è¯• (Golden Master Test)

**ç›®çš„**: ç¡®ä¿é‡æ„ä¸æ”¹ååŠŸèƒ½

**å‡†å¤‡å·¥ä½œ** (30åˆ†é’Ÿ):

1. **å‡†å¤‡æµ‹è¯•æ–‡ä»¶**
```bash
# æ‰¾ä¸€ä¸ª30ç§’-1åˆ†é’Ÿçš„æµ‹è¯•è§†é¢‘
# æ”¾åˆ°: tests/fixtures/test_video.mp4
```

2. **ç”Ÿæˆé»„é‡‘æ ‡å‡†**
```bash
# ç”¨å½“å‰æœªä¿®æ”¹çš„ç‰ˆæœ¬è¿è¡Œ
python backend/app/main.py

# ä¸Šä¼  test_video.mp4ï¼Œç”Ÿæˆå­—å¹•
# ä¿å­˜ç»“æœä¸º: tests/fixtures/golden_standard.srt
```

3. **åˆ›å»ºé‡æ„åˆ†æ”¯**
```bash
# åŸºäºå½“å‰åˆ†æ”¯åˆ›å»ºé‡æ„åˆ†æ”¯
git checkout -b refactor/clean-architecture

# åˆ›å»ºå¤‡ä»½æ ‡ç­¾
git tag backup-before-refactor-$(date +%Y%m%d)
git push origin backup-before-refactor-$(date +%Y%m%d)
```

**éªŒè¯è„šæœ¬**:
```python
# tests/test_golden_master.py
"""
é»„é‡‘æ ‡å‡†æµ‹è¯•
ç¡®ä¿é‡æ„åç”Ÿæˆçš„å­—å¹•ä¸é‡æ„å‰ä¸€è‡´
"""
import os
import difflib
from pathlib import Path

def load_srt(path):
    """åŠ è½½SRTæ–‡ä»¶"""
    with open(path, 'r', encoding='utf-8') as f:
        return f.read()

def compare_srt(golden_path, new_path, tolerance_ms=100):
    """
    æ¯”è¾ƒä¸¤ä¸ªSRTæ–‡ä»¶

    Args:
        golden_path: é»„é‡‘æ ‡å‡†æ–‡ä»¶è·¯å¾„
        new_path: æ–°ç”Ÿæˆçš„æ–‡ä»¶è·¯å¾„
        tolerance_ms: æ—¶é—´æˆ³å®¹å·®(æ¯«ç§’)

    Returns:
        bool: æ˜¯å¦ä¸€è‡´
    """
    golden = load_srt(golden_path)
    new = load_srt(new_path)

    # ç®€å•å¯¹æ¯”ï¼šå†…å®¹å®Œå…¨ä¸€è‡´
    if golden == new:
        print("âœ… å®Œå…¨ä¸€è‡´")
        return True

    # è¯¦ç»†å¯¹æ¯”ï¼šæ˜¾ç¤ºå·®å¼‚
    diff = difflib.unified_diff(
        golden.splitlines(keepends=True),
        new.splitlines(keepends=True),
        fromfile='golden',
        tofile='new'
    )

    diff_text = ''.join(diff)
    if diff_text:
        print("âš ï¸ å­˜åœ¨å·®å¼‚:")
        print(diff_text)
        return False

    return True

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    golden = Path("tests/fixtures/golden_standard.srt")
    new = Path("output/test_video.srt")

    if compare_srt(golden, new):
        print("âœ… é»„é‡‘æ ‡å‡†æµ‹è¯•é€šè¿‡")
    else:
        print("âŒ é»„é‡‘æ ‡å‡†æµ‹è¯•å¤±è´¥")
        exit(1)
```

---

## ä¸‰ã€åˆ†æ­¥æ‰§è¡Œè®¡åˆ’

### é˜¶æ®µ1: å¤§æ‰«é™¤ä¸åˆå¹¶ (Day 1)

#### æ­¥éª¤1.1: æ¸…ç†å…¥å£æ–‡ä»¶ (1å°æ—¶)

**ç›®æ ‡**: åªä¿ç•™ä¸€ä¸ªmain.py

**æ“ä½œæ­¥éª¤**:

1. **ç¡®å®šä¸»å…¥å£**
```bash
# æ£€æŸ¥å„ä¸ªmainæ–‡ä»¶çš„å·®å¼‚
diff backend/app/main.py backend/app/main_simple.py
diff backend/app/main.py backend/app/main_refactored.py
```

2. **ç¡®è®¤main.pyæ˜¯æœ€å®Œæ•´çš„ç‰ˆæœ¬**
```python
# backend/app/main.py åº”è¯¥åŒ…å«:
# - FastAPIåº”ç”¨å®šä¹‰
# - æ‰€æœ‰APIè·¯ç”±
# - æ¨¡å‹é¢„åŠ è½½ç®¡ç†
# - CORSé…ç½®
# - å¯åŠ¨/å…³é—­äº‹ä»¶å¤„ç†
```

3. **å½’æ¡£å…¶ä»–mainæ–‡ä»¶**
```bash
# åˆ›å»ºå½’æ¡£ç›®å½•
mkdir -p _deprecated

# ç§»åŠ¨åºŸå¼ƒæ–‡ä»¶
mv backend/app/main_refactored.py _deprecated/
mv backend/app/main_simple.py _deprecated/
mv backend/app/debug_main.py _deprecated/

# æ·»åŠ è¯´æ˜æ–‡ä»¶
cat > _deprecated/README.md << 'EOF'
# åºŸå¼ƒæ–‡ä»¶å½’æ¡£

è¿™äº›æ–‡ä»¶å·²è¢«åºŸå¼ƒï¼Œä»…ä¿ç•™ä½œä¸ºå†å²å‚è€ƒã€‚

- main_refactored.py - æ—©æœŸé‡æ„å°è¯•
- main_simple.py - ç®€åŒ–ç‰ˆæœ¬
- debug_main.py - è°ƒè¯•ç‰ˆæœ¬

**å½“å‰å”¯ä¸€å…¥å£**: backend/app/main.py
EOF
```

4. **æ›´æ–°å¯åŠ¨è„šæœ¬**
```python
# simple_launcher.py
# ç¡®ä¿æŒ‡å‘å”¯ä¸€çš„main.py

# ä¿®æ”¹å‰
backend_cmd = [sys.executable, "-m", "uvicorn", "backend.app.main_simple:app", ...]

# ä¿®æ”¹å
backend_cmd = [sys.executable, "-m", "uvicorn", "backend.app.main:app", ...]
```

5. **æäº¤å˜æ›´**
```bash
git add .
git commit -m "refactor: ç»Ÿä¸€å…¥å£æ–‡ä»¶ï¼Œåªä¿ç•™main.py"
```

---

#### æ­¥éª¤1.2: åˆå¹¶æ ¸å¿ƒé€»è¾‘ (4å°æ—¶) ğŸ”¥

**ç›®æ ‡**: æ¶ˆé™¤processor.pyå’Œtranscription_service.pyçš„é‡å¤

**ç­–ç•¥**: ä»¥ `services/transcription_service.py` ä¸ºä¸»ï¼Œæ•´åˆæ‰€æœ‰åŠŸèƒ½

**è¯¦ç»†æ“ä½œ**:

**1. åˆ†æå·®å¼‚**
```python
# processor.py ç‹¬æœ‰åŠŸèƒ½:
# - CPUAffinityManager (CPUäº²å’Œæ€§ç®¡ç†)
# - æ¨¡å‹ç®¡ç†å™¨é›†æˆ (get_model_manager)
# - å…¨å±€å•ä¾‹æ¨¡å¼ (get_processor)

# transcription_service.py ç‹¬æœ‰åŠŸèƒ½:
# - ç¡¬ä»¶æ£€æµ‹é›†æˆ
# - æ›´æ¸…æ™°çš„æœåŠ¡å±‚è®¾è®¡
```

**2. åˆ›å»ºCPUäº²å’Œæ€§æœåŠ¡**
```python
# backend/app/services/cpu_affinity_service.py
"""
CPUäº²å’Œæ€§ç®¡ç†æœåŠ¡
ä»processor.pyæå–
"""

import os
import logging
import platform
from dataclasses import dataclass, field
from typing import List, Optional

try:
    import psutil
except ImportError:
    psutil = None

@dataclass
class CPUAffinityConfig:
    """CPUäº²å’Œæ€§é…ç½®"""
    enabled: bool = True
    strategy: str = "auto"  # "auto", "half", "custom"
    custom_cores: Optional[List[int]] = None
    exclude_cores: Optional[List[int]] = None

class CPUAffinityManager:
    """
    CPUäº²å’Œæ€§ç®¡ç†å™¨
    é€šè¿‡ç»‘å®šç‰¹å®šCPUæ ¸å¿ƒæ¥ä¼˜åŒ–æ€§èƒ½
    """

    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.original_affinity = None
        self.is_supported = psutil is not None and hasattr(psutil.Process(), 'cpu_affinity')

        if not self.is_supported:
            self.logger.warning("âš ï¸ CPUäº²å’Œæ€§åŠŸèƒ½ä¸å¯ç”¨ï¼špsutilæœªå®‰è£…æˆ–ç³»ç»Ÿä¸æ”¯æŒ")

    def get_system_info(self) -> dict:
        """
        è·å–ç³»ç»ŸCPUä¿¡æ¯

        Returns:
            dict: CPUä¿¡æ¯
                - supported: bool, æ˜¯å¦æ”¯æŒCPUäº²å’Œæ€§
                - logical_cores: int, é€»è¾‘æ ¸å¿ƒæ•°
                - physical_cores: int, ç‰©ç†æ ¸å¿ƒæ•°
                - current_affinity: List[int], å½“å‰äº²å’Œæ€§è®¾ç½®
                - platform: str, æ“ä½œç³»ç»Ÿå¹³å°
        """
        if not self.is_supported:
            return {"supported": False, "reason": "psutil not available"}

        try:
            cpu_count = psutil.cpu_count(logical=True)
            physical_count = psutil.cpu_count(logical=False)
            current_affinity = psutil.Process().cpu_affinity()

            return {
                "supported": True,
                "logical_cores": cpu_count,
                "physical_cores": physical_count,
                "current_affinity": current_affinity,
                "platform": platform.system()
            }
        except Exception as e:
            return {"supported": False, "error": str(e)}

    def calculate_optimal_cores(
        self,
        strategy: str = "auto",
        custom_cores: Optional[List[int]] = None,
        exclude_cores: Optional[List[int]] = None
    ) -> List[int]:
        """
        è®¡ç®—æœ€ä½³CPUæ ¸å¿ƒåˆ†é…

        Args:
            strategy: åˆ†é…ç­–ç•¥
                - "auto": è‡ªåŠ¨æ ¹æ®æ ¸å¿ƒæ•°æ™ºèƒ½åˆ†é…
                - "half": ä½¿ç”¨å‰50%æ ¸å¿ƒ
                - "custom": ä½¿ç”¨è‡ªå®šä¹‰æ ¸å¿ƒåˆ—è¡¨
            custom_cores: è‡ªå®šä¹‰æ ¸å¿ƒåˆ—è¡¨ (strategy="custom"æ—¶ä½¿ç”¨)
            exclude_cores: æ’é™¤çš„æ ¸å¿ƒåˆ—è¡¨

        Returns:
            List[int]: æ¨èä½¿ç”¨çš„æ ¸å¿ƒåˆ—è¡¨
        """
        if not self.is_supported:
            return []

        try:
            cpu_count = psutil.cpu_count(logical=True)
            available_cores = list(range(cpu_count))

            # æ’é™¤æŒ‡å®šæ ¸å¿ƒ
            if exclude_cores:
                available_cores = [c for c in available_cores if c not in exclude_cores]

            if strategy == "custom" and custom_cores:
                # ä½¿ç”¨è‡ªå®šä¹‰æ ¸å¿ƒåˆ—è¡¨ï¼Œä½†è¦ç¡®ä¿åœ¨å¯ç”¨èŒƒå›´å†…
                return [c for c in custom_cores if c in available_cores]

            elif strategy == "half":
                # ä½¿ç”¨å‰50%çš„æ ¸å¿ƒ
                half_count = max(1, len(available_cores) // 2)
                return available_cores[:half_count]

            else:  # "auto" é»˜è®¤ç­–ç•¥
                # æ™ºèƒ½åˆ†é…ï¼šæ ¹æ®CPUæ ¸å¿ƒæ•°é‡‡ç”¨ä¸åŒç­–ç•¥
                if cpu_count <= 4:
                    # ä½ç«¯ç³»ç»Ÿï¼Œä½¿ç”¨æ‰€æœ‰æ ¸å¿ƒ
                    return available_cores
                elif cpu_count <= 8:
                    # ä¸­ç«¯CPUï¼Œç•™ä¸€ä¸ªæ ¸å¿ƒç»™ç³»ç»Ÿ
                    return available_cores[:-1]
                else:
                    # é«˜ç«¯å¤šæ ¸CPUï¼Œä½¿ç”¨å‰75%çš„æ ¸å¿ƒ
                    use_count = max(1, int(cpu_count * 0.75))
                    return available_cores[:use_count]

        except Exception as e:
            self.logger.error(f"è®¡ç®—æœ€ä½³æ ¸å¿ƒå¤±è´¥: {e}")
            return []

    def apply_cpu_affinity(self, config: CPUAffinityConfig) -> bool:
        """
        åº”ç”¨CPUäº²å’Œæ€§è®¾ç½®

        Args:
            config: CPUäº²å’Œæ€§é…ç½®

        Returns:
            bool: æ˜¯å¦åº”ç”¨æˆåŠŸ
        """
        if not config.enabled or not self.is_supported:
            return False

        try:
            # ä¿å­˜åŸå§‹äº²å’Œæ€§è®¾ç½®ï¼ˆç”¨äºæ¢å¤ï¼‰
            if self.original_affinity is None:
                self.original_affinity = psutil.Process().cpu_affinity()

            # è®¡ç®—ç›®æ ‡æ ¸å¿ƒ
            target_cores = self.calculate_optimal_cores(
                strategy=config.strategy,
                custom_cores=config.custom_cores,
                exclude_cores=config.exclude_cores
            )

            if not target_cores:
                self.logger.warning("æœªæ‰¾åˆ°å¯ç”¨çš„CPUæ ¸å¿ƒè¿›è¡Œç»‘å®š")
                return False

            # åº”ç”¨äº²å’Œæ€§è®¾ç½®
            psutil.Process().cpu_affinity(target_cores)

            # è®°å½•æˆåŠŸä¿¡æ¯
            sys_info = self.get_system_info()
            self.logger.info(
                f"âœ… CPUäº²å’Œæ€§è®¾ç½®æˆåŠŸ: "
                f"ç­–ç•¥={config.strategy}, "
                f"ç»‘å®šæ ¸å¿ƒ={target_cores}, "
                f"ç³»ç»Ÿæ ¸å¿ƒæ•°={sys_info.get('logical_cores', '?')}"
            )
            return True

        except Exception as e:
            self.logger.error(f"âŒ CPUäº²å’Œæ€§è®¾ç½®å¤±è´¥: {e}")
            return False

    def restore_cpu_affinity(self) -> bool:
        """
        æ¢å¤åŸå§‹CPUäº²å’Œæ€§è®¾ç½®

        Returns:
            bool: æ˜¯å¦æ¢å¤æˆåŠŸ
        """
        if not self.is_supported or self.original_affinity is None:
            return False

        try:
            psutil.Process().cpu_affinity(self.original_affinity)
            self.logger.info(f"ğŸ”„ å·²æ¢å¤CPUäº²å’Œæ€§è®¾ç½®: {self.original_affinity}")
            return True
        except Exception as e:
            self.logger.error(f"âŒ æ¢å¤CPUäº²å’Œæ€§å¤±è´¥: {e}")
            return False
```

**3. å¢å¼ºtranscription_service.py**
```python
# backend/app/services/transcription_service.py
"""
è½¬å½•å¤„ç†æœåŠ¡ - æ•´åˆç‰ˆæœ¬
æ•´åˆäº†processor.pyå’ŒåŸtranscription_service.pyçš„æ‰€æœ‰åŠŸèƒ½
"""

import os
import subprocess
import uuid
import threading
import gc
import logging
import shutil
from pathlib import Path
from typing import List, Dict, Optional, Tuple
from pydub import AudioSegment, silence
import whisperx
import torch

from models.job_models import JobSettings, JobState
from services.cpu_affinity_service import CPUAffinityManager, CPUAffinityConfig
from services.hardware_service import get_hardware_detector

# å…¨å±€å˜é‡ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
_model_cache: Dict[Tuple[str, str, str], object] = {}
_align_model_cache: Dict[str, Tuple[object, object]] = {}
_model_lock = threading.Lock()
_align_lock = threading.Lock()

# éŸ³é¢‘å¤„ç†é…ç½®ï¼ˆåç»­ä¼šç§»åˆ°config.pyï¼‰
SEGMENT_LEN_MS = 60_000
SILENCE_SEARCH_MS = 2_000
MIN_SILENCE_LEN_MS = 300
SILENCE_THRESH_DBFS = -40

# è¿›åº¦æƒé‡é…ç½®
PHASE_WEIGHTS = {
    "extract": 5,      # éŸ³é¢‘æå–å 5%
    "split": 10,       # éŸ³é¢‘åˆ†æ®µå 10%
    "transcribe": 80,  # è½¬å½•å¤„ç†å 80%ï¼ˆä¸»è¦è€—æ—¶ï¼‰
    "srt": 5           # SRTç”Ÿæˆå 5%
}
TOTAL_WEIGHT = sum(PHASE_WEIGHTS.values())


class TranscriptionService:
    """
    è½¬å½•å¤„ç†æœåŠ¡
    æ•´åˆäº†æ‰€æœ‰è½¬å½•ç›¸å…³åŠŸèƒ½
    """

    def __init__(self, jobs_root: str):
        """
        åˆå§‹åŒ–è½¬å½•æœåŠ¡

        Args:
            jobs_root: ä»»åŠ¡å·¥ä½œç›®å½•æ ¹è·¯å¾„
        """
        self.jobs_root = Path(jobs_root)
        self.jobs_root.mkdir(parents=True, exist_ok=True)

        self.jobs: Dict[str, JobState] = {}
        self.lock = threading.Lock()
        self.logger = logging.getLogger(__name__)

        # é›†æˆCPUäº²å’Œæ€§ç®¡ç†å™¨
        self.cpu_manager = CPUAffinityManager()

        # é›†æˆç¡¬ä»¶æ£€æµ‹
        self.hardware_detector = get_hardware_detector()
        self._hardware_info = None

        # è®°å½•CPUä¿¡æ¯
        sys_info = self.cpu_manager.get_system_info()
        if sys_info.get('supported', False):
            self.logger.info(
                f"ğŸ’» CPUä¿¡æ¯: {sys_info['logical_cores']}ä¸ªé€»è¾‘æ ¸å¿ƒ, "
                f"{sys_info.get('physical_cores', '?')}ä¸ªç‰©ç†æ ¸å¿ƒ, "
                f"å¹³å°: {sys_info.get('platform', '?')}"
            )
        else:
            self.logger.warning("âš ï¸ CPUäº²å’Œæ€§åŠŸèƒ½ä¸å¯ç”¨")

    def create_job(
        self,
        filename: str,
        src_path: str,
        settings: JobSettings,
        job_id: Optional[str] = None
    ) -> JobState:
        """
        åˆ›å»ºè½¬å½•ä»»åŠ¡

        Args:
            filename: æ–‡ä»¶å
            src_path: æºæ–‡ä»¶è·¯å¾„
            settings: ä»»åŠ¡è®¾ç½®
            job_id: ä»»åŠ¡IDï¼ˆå¯é€‰ï¼Œä¸æä¾›åˆ™è‡ªåŠ¨ç”Ÿæˆï¼‰

        Returns:
            JobState: åˆ›å»ºçš„ä»»åŠ¡çŠ¶æ€å¯¹è±¡
        """
        job_id = job_id or uuid.uuid4().hex
        job_dir = self.jobs_root / job_id
        job_dir.mkdir(parents=True, exist_ok=True)

        dest_path = job_dir / filename

        # å¤åˆ¶æ–‡ä»¶åˆ°ä»»åŠ¡ç›®å½•
        if os.path.abspath(src_path) != os.path.abspath(dest_path):
            try:
                shutil.copyfile(src_path, dest_path)
                self.logger.debug(f"æ–‡ä»¶å·²å¤åˆ¶: {src_path} -> {dest_path}")
            except Exception as e:
                self.logger.warning(f"æ–‡ä»¶å¤åˆ¶å¤±è´¥: {e}")

        # åˆ›å»ºä»»åŠ¡çŠ¶æ€å¯¹è±¡
        job = JobState(
            job_id=job_id,
            filename=filename,
            dir=str(job_dir),
            input_path=src_path,
            settings=settings,
            status="uploaded",
            phase="pending",
            message="æ–‡ä»¶å·²ä¸Šä¼ "
        )

        with self.lock:
            self.jobs[job_id] = job

        self.logger.info(f"âœ… ä»»åŠ¡å·²åˆ›å»º: {job_id} - {filename}")
        return job

    def get_job(self, job_id: str) -> Optional[JobState]:
        """
        è·å–ä»»åŠ¡çŠ¶æ€

        Args:
            job_id: ä»»åŠ¡ID

        Returns:
            Optional[JobState]: ä»»åŠ¡çŠ¶æ€å¯¹è±¡ï¼Œä¸å­˜åœ¨åˆ™è¿”å›None
        """
        with self.lock:
            return self.jobs.get(job_id)

    def start_job(self, job_id: str):
        """
        å¯åŠ¨è½¬å½•ä»»åŠ¡

        Args:
            job_id: ä»»åŠ¡ID
        """
        job = self.get_job(job_id)
        if not job or job.status not in ("uploaded", "failed"):
            self.logger.warning(f"ä»»åŠ¡æ— æ³•å¯åŠ¨: {job_id}, çŠ¶æ€: {job.status if job else 'not found'}")
            return

        job.canceled = False
        job.error = None
        job.status = "processing"
        job.message = "å¼€å§‹å¤„ç†"

        # åœ¨ç‹¬ç«‹çº¿ç¨‹ä¸­æ‰§è¡Œè½¬å½•
        threading.Thread(
            target=self._run_pipeline,
            args=(job,),
            daemon=True,
            name=f"Transcription-{job_id[:8]}"
        ).start()

        self.logger.info(f"ğŸš€ ä»»åŠ¡å·²å¯åŠ¨: {job_id}")

    def cancel_job(self, job_id: str) -> bool:
        """
        å–æ¶ˆè½¬å½•ä»»åŠ¡

        Args:
            job_id: ä»»åŠ¡ID

        Returns:
            bool: æ˜¯å¦æˆåŠŸè®¾ç½®å–æ¶ˆæ ‡å¿—
        """
        job = self.get_job(job_id)
        if not job:
            return False

        job.canceled = True
        job.message = "å–æ¶ˆä¸­..."
        self.logger.info(f"ğŸ›‘ ä»»åŠ¡å–æ¶ˆè¯·æ±‚: {job_id}")
        return True

    def _update_progress(
        self,
        job: JobState,
        phase: str,
        phase_ratio: float,
        message: str = ""
    ):
        """
        æ›´æ–°ä»»åŠ¡è¿›åº¦

        Args:
            job: ä»»åŠ¡çŠ¶æ€å¯¹è±¡
            phase: å½“å‰é˜¶æ®µ (extract/split/transcribe/srt)
            phase_ratio: å½“å‰é˜¶æ®µå®Œæˆæ¯”ä¾‹ (0.0-1.0)
            message: è¿›åº¦æ¶ˆæ¯
        """
        job.phase = phase

        # è®¡ç®—ç´¯è®¡è¿›åº¦
        done_weight = 0
        for p, w in PHASE_WEIGHTS.items():
            if p == phase:
                break
            done_weight += w

        current_weight = PHASE_WEIGHTS.get(phase, 0) * max(0.0, min(1.0, phase_ratio))
        job.progress = round((done_weight + current_weight) / TOTAL_WEIGHT * 100, 2)

        if message:
            job.message = message

    def _run_pipeline(self, job: JobState):
        """
        æ‰§è¡Œè½¬å½•å¤„ç†ç®¡é“

        Args:
            job: ä»»åŠ¡çŠ¶æ€å¯¹è±¡
        """
        # åº”ç”¨CPUäº²å’Œæ€§è®¾ç½®
        cpu_applied = False
        if job.settings.cpu_affinity.enabled:
            cpu_applied = self.cpu_manager.apply_cpu_affinity(
                job.settings.cpu_affinity
            )
            if cpu_applied:
                self.logger.info(f"ğŸ“Œ ä»»åŠ¡ {job.job_id} å·²åº”ç”¨CPUäº²å’Œæ€§è®¾ç½®")

        try:
            # æ£€æŸ¥å–æ¶ˆæ ‡å¿—
            if job.canceled:
                job.status = 'canceled'
                job.message = 'å·²å–æ¶ˆ'
                return

            job_dir = Path(job.dir)
            input_path = job_dir / job.filename
            audio_path = job_dir / 'audio.wav'

            # ========== é˜¶æ®µ1: æå–éŸ³é¢‘ ==========
            self._update_progress(job, 'extract', 0, 'æå–éŸ³é¢‘ä¸­')
            if job.canceled:
                raise RuntimeError('ä»»åŠ¡å·²å–æ¶ˆ')

            if not self._extract_audio(str(input_path), str(audio_path)):
                raise RuntimeError('FFmpeg æå–éŸ³é¢‘å¤±è´¥')

            self._update_progress(job, 'extract', 1, 'éŸ³é¢‘æå–å®Œæˆ')
            if job.canceled:
                raise RuntimeError('ä»»åŠ¡å·²å–æ¶ˆ')

            # ========== é˜¶æ®µ2: æ™ºèƒ½åˆ†æ®µ ==========
            self._update_progress(job, 'split', 0, 'éŸ³é¢‘åˆ†æ®µä¸­')
            segments = self._split_audio(str(audio_path))
            if job.canceled:
                raise RuntimeError('ä»»åŠ¡å·²å–æ¶ˆ')

            job.segments = segments
            job.total = len(segments)
            self._update_progress(job, 'split', 1, f'åˆ†æ®µå®Œæˆ å…±{job.total}æ®µ')

            # ========== é˜¶æ®µ3: è½¬å½•å¤„ç† ==========
            self._update_progress(job, 'transcribe', 0, 'åŠ è½½æ¨¡å‹ä¸­')
            if job.canceled:
                raise RuntimeError('ä»»åŠ¡å·²å–æ¶ˆ')

            model = self._get_model(job.settings)
            align_cache = {}
            processed_results = []

            for idx, seg in enumerate(segments):
                if job.canceled:
                    raise RuntimeError('ä»»åŠ¡å·²å–æ¶ˆ')

                ratio = idx / max(1, len(segments))
                self._update_progress(
                    job,
                    'transcribe',
                    ratio,
                    f'è½¬å½• {idx+1}/{len(segments)}'
                )

                seg_result = self._transcribe_segment(seg, model, job, align_cache)
                if seg_result:
                    processed_results.append(seg_result)

                job.processed = idx + 1

            self._update_progress(job, 'transcribe', 1, 'è½¬å½•å®Œæˆ ç”Ÿæˆå­—å¹•ä¸­')
            if job.canceled:
                raise RuntimeError('ä»»åŠ¡å·²å–æ¶ˆ')

            # ========== é˜¶æ®µ4: ç”ŸæˆSRT ==========
            base_name = os.path.splitext(job.filename)[0]
            srt_path = job_dir / f'{base_name}.srt'
            self._update_progress(job, 'srt', 0, 'å†™å…¥ SRT...')
            self._generate_srt(
                processed_results,
                str(srt_path),
                job.settings.word_timestamps
            )
            self._update_progress(job, 'srt', 1, 'å¤„ç†å®Œæˆ')

            job.srt_path = str(srt_path)

            if job.canceled:
                job.status = 'canceled'
                job.message = 'å·²å–æ¶ˆ'
            else:
                job.status = 'finished'
                job.message = 'å®Œæˆ'
                self.logger.info(f"âœ… ä»»åŠ¡å®Œæˆ: {job.job_id}")

        except Exception as e:
            if job.canceled and 'å–æ¶ˆ' in str(e):
                job.status = 'canceled'
                job.message = 'å·²å–æ¶ˆ'
                self.logger.info(f"ğŸ›‘ ä»»åŠ¡å·²å–æ¶ˆ: {job.job_id}")
            else:
                job.status = 'failed'
                job.message = f'å¤±è´¥: {e}'
                job.error = str(e)
                self.logger.error(f"âŒ ä»»åŠ¡å¤±è´¥: {job.job_id} - {e}", exc_info=True)

        finally:
            # æ¢å¤CPUäº²å’Œæ€§è®¾ç½®
            if cpu_applied:
                restored = self.cpu_manager.restore_cpu_affinity()
                if restored:
                    self.logger.info(f"ğŸ”„ ä»»åŠ¡ {job.job_id} å·²æ¢å¤CPUäº²å’Œæ€§è®¾ç½®")

            # é‡Šæ”¾å†…å­˜
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()

    # ========== æ ¸å¿ƒå¤„ç†æ–¹æ³• ==========

    def _extract_audio(self, input_file: str, audio_out: str) -> bool:
        """
        ä½¿ç”¨FFmpegæå–éŸ³é¢‘

        Args:
            input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„
            audio_out: è¾“å‡ºéŸ³é¢‘è·¯å¾„

        Returns:
            bool: æ˜¯å¦æå–æˆåŠŸ
        """
        if os.path.exists(audio_out):
            self.logger.debug(f"éŸ³é¢‘æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡æå–: {audio_out}")
            return True

        # ä¼˜å…ˆä½¿ç”¨é¡¹ç›®å†…çš„FFmpegï¼ˆæ”¯æŒç‹¬ç«‹æ‰“åŒ…ï¼‰
        project_root = Path(__file__).parent.parent.parent
        local_ffmpeg = project_root / "ffmpeg" / "bin" / "ffmpeg.exe"

        if local_ffmpeg.exists():
            ffmpeg_cmd = str(local_ffmpeg)
            self.logger.debug(f"ä½¿ç”¨é¡¹ç›®å†…FFmpeg: {ffmpeg_cmd}")
        else:
            ffmpeg_cmd = 'ffmpeg'
            self.logger.debug("ä½¿ç”¨ç³»ç»ŸFFmpeg")

        cmd = [
            ffmpeg_cmd, '-y', '-i', input_file,
            '-vn',                    # ä»…éŸ³é¢‘
            '-ac', '1',               # å•å£°é“
            '-ar', '16000',           # 16kHz é‡‡æ ·ç‡
            '-acodec', 'pcm_s16le',   # PCM ç¼–ç 
            audio_out
        ]

        try:
            proc = subprocess.run(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                timeout=600  # 10åˆ†é’Ÿè¶…æ—¶
            )

            if proc.returncode == 0 and os.path.exists(audio_out):
                self.logger.debug(f"âœ… éŸ³é¢‘æå–æˆåŠŸ: {audio_out}")
                return True
            else:
                error_msg = proc.stderr.decode('utf-8', errors='ignore')
                self.logger.error(f"âŒ FFmpegæ‰§è¡Œå¤±è´¥: {error_msg}")
                return False

        except subprocess.TimeoutExpired:
            self.logger.error("âŒ FFmpegè¶…æ—¶")
            return False
        except Exception as e:
            self.logger.error(f"âŒ éŸ³é¢‘æå–å¤±è´¥: {e}")
            return False

    def _split_audio(self, audio_path: str) -> List[Dict]:
        """
        æ™ºèƒ½åˆ†æ®µéŸ³é¢‘ï¼ˆåŸºäºé™éŸ³æ£€æµ‹ï¼‰

        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„

        Returns:
            List[Dict]: æ®µä¿¡æ¯åˆ—è¡¨ï¼Œæ¯é¡¹åŒ…å« file å’Œ start_ms
        """
        self.logger.debug(f"å¼€å§‹éŸ³é¢‘åˆ†æ®µ: {audio_path}")

        audio = AudioSegment.from_wav(audio_path)
        length = len(audio)
        segments = []
        pos = 0
        idx = 0

        while pos < length:
            end = min(pos + SEGMENT_LEN_MS, length)

            # æ™ºèƒ½å¯»æ‰¾é™éŸ³ç‚¹ï¼ˆé¿å…åœ¨å¥å­ä¸­é—´åˆ†å‰²ï¼‰
            if end < length and (end - pos) > SILENCE_SEARCH_MS:
                search_start = max(pos, end - SILENCE_SEARCH_MS)
                search_chunk = audio[search_start:end]

                try:
                    silences = silence.detect_silence(
                        search_chunk,
                        min_silence_len=MIN_SILENCE_LEN_MS,
                        silence_thresh=SILENCE_THRESH_DBFS
                    )

                    if silences:
                        # ä½¿ç”¨ç¬¬ä¸€ä¸ªé™éŸ³ç‚¹
                        silence_start = silences[0][0]
                        new_end = search_start + silence_start
                        if new_end - pos > MIN_SILENCE_LEN_MS:
                            end = new_end
                except Exception as e:
                    self.logger.warning(f"é™éŸ³æ£€æµ‹å¤±è´¥: {e}")

            # å¯¼å‡ºåˆ†æ®µ
            chunk = audio[pos:end]
            seg_file = os.path.join(os.path.dirname(audio_path), f'segment_{idx}.wav')
            chunk.export(seg_file, format='wav')

            segments.append({
                'file': seg_file,
                'start_ms': pos,
                'duration_ms': end - pos
            })

            pos = end
            idx += 1

        self.logger.debug(f"âœ… éŸ³é¢‘åˆ†æ®µå®Œæˆ: å…±{len(segments)}æ®µ")
        return segments

    def _get_model(self, settings: JobSettings):
        """
        è·å–WhisperXæ¨¡å‹ï¼ˆå¸¦ç¼“å­˜ï¼‰

        ä¼˜å…ˆä½¿ç”¨æ¨¡å‹ç®¡ç†å™¨ï¼Œå¦åˆ™ä½¿ç”¨ç®€å•ç¼“å­˜

        Args:
            settings: ä»»åŠ¡è®¾ç½®

        Returns:
            æ¨¡å‹å¯¹è±¡
        """
        # å°è¯•ä½¿ç”¨æ¨¡å‹ç®¡ç†å™¨
        try:
            from services.model_preload_manager import get_model_manager
            model_manager = get_model_manager()
            if model_manager:
                return model_manager.get_model(settings)
        except ImportError:
            pass

        # å›é€€åˆ°ç®€å•ç¼“å­˜æœºåˆ¶
        key = (settings.model, settings.compute_type, settings.device)
        with _model_lock:
            if key in _model_cache:
                self.logger.debug(f"âœ… å‘½ä¸­æ¨¡å‹ç¼“å­˜: {key}")
                return _model_cache[key]

            self.logger.info(f"ğŸ” åŠ è½½æ¨¡å‹: {key}")
            m = whisperx.load_model(
                settings.model,
                settings.device,
                compute_type=settings.compute_type
            )
            _model_cache[key] = m
            return m

    def _get_align_model(self, lang: str, device: str):
        """
        è·å–å¯¹é½æ¨¡å‹ï¼ˆå¸¦ç¼“å­˜ï¼‰

        Args:
            lang: è¯­è¨€ä»£ç 
            device: è®¾å¤‡ (cuda/cpu)

        Returns:
            Tuple[model, metadata]: å¯¹é½æ¨¡å‹å’Œå…ƒæ•°æ®
        """
        with _align_lock:
            if lang in _align_model_cache:
                self.logger.debug(f"âœ… å‘½ä¸­å¯¹é½æ¨¡å‹ç¼“å­˜: {lang}")
                return _align_model_cache[lang]

            self.logger.info(f"ğŸ” åŠ è½½å¯¹é½æ¨¡å‹: {lang}")
            am, meta = whisperx.load_align_model(language_code=lang, device=device)
            _align_model_cache[lang] = (am, meta)
            return am, meta

    def _transcribe_segment(
        self,
        seg: Dict,
        model,
        job: JobState,
        align_cache: Dict
    ):
        """
        è½¬å½•å•ä¸ªéŸ³é¢‘æ®µ

        Args:
            seg: æ®µä¿¡æ¯ {file, start_ms, duration_ms}
            model: Whisperæ¨¡å‹
            job: ä»»åŠ¡çŠ¶æ€
            align_cache: å¯¹é½æ¨¡å‹ç¼“å­˜

        Returns:
            Dict: è½¬å½•ç»“æœï¼ˆåŒ…å«segmentså’Œword_segmentsï¼‰
        """
        audio = whisperx.load_audio(seg['file'])

        try:
            # Whisperè½¬å½•
            rs = model.transcribe(
                audio,
                batch_size=job.settings.batch_size,
                verbose=False,
                language=job.language
            )

            if not rs or 'segments' not in rs:
                return None

            # æ£€æµ‹è¯­è¨€
            if not job.language and 'language' in rs:
                job.language = rs['language']
                self.logger.info(f"ğŸŒ æ£€æµ‹åˆ°è¯­è¨€: {job.language}")

            lang = job.language or rs.get('language')

            # åŠ è½½å¯¹é½æ¨¡å‹
            if lang not in align_cache:
                am, meta = self._get_align_model(lang, job.settings.device)
                align_cache[lang] = (am, meta)

            am, meta = align_cache[lang]

            # è¯çº§å¯¹é½
            aligned = whisperx.align(
                rs['segments'],
                am,
                meta,
                audio,
                job.settings.device
            )

            # æ—¶é—´åç§»æ ¡æ­£ï¼ˆé‡è¦ï¼ï¼‰
            start_offset = seg['start_ms'] / 1000.0
            final = {'segments': []}

            if 'segments' in aligned:
                for s in aligned['segments']:
                    if 'start' in s:
                        s['start'] += start_offset
                    if 'end' in s:
                        s['end'] += start_offset
                    final['segments'].append(s)

            if 'word_segments' in aligned:
                final['word_segments'] = []
                for w in aligned['word_segments']:
                    if 'start' in w:
                        w['start'] += start_offset
                    if 'end' in w:
                        w['end'] += start_offset
                    final['word_segments'].append(w)

            return final

        finally:
            del audio
            gc.collect()

    def _format_ts(self, sec: float) -> str:
        """
        æ ¼å¼åŒ–æ—¶é—´æˆ³ä¸ºSRTæ ¼å¼

        Args:
            sec: ç§’æ•°

        Returns:
            str: SRTæ—¶é—´æˆ³ (HH:MM:SS,mmm)
        """
        if sec < 0:
            sec = 0

        ms = int(round(sec * 1000))
        h = ms // 3600000
        ms %= 3600000
        m = ms // 60000
        ms %= 60000
        s = ms // 1000
        ms %= 1000

        return f"{h:02}:{m:02}:{s:02},{ms:03}"

    def _generate_srt(self, results: List[Dict], path: str, word_level: bool):
        """
        ç”ŸæˆSRTå­—å¹•æ–‡ä»¶

        Args:
            results: è½¬å½•ç»“æœåˆ—è¡¨
            path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            word_level: æ˜¯å¦ä½¿ç”¨è¯çº§æ—¶é—´æˆ³
        """
        lines = []
        n = 1  # å­—å¹•åºå·

        for r in results:
            if not r:
                continue

            entries = []

            # è¯çº§æ—¶é—´æˆ³æ¨¡å¼
            if word_level and r.get('word_segments'):
                for w in r['word_segments']:
                    if w.get('start') is not None and w.get('end') is not None:
                        txt = (w.get('word') or '').strip()
                        if txt:
                            entries.append({
                                'start': w['start'],
                                'end': w['end'],
                                'text': txt
                            })

            # å¥å­çº§æ—¶é—´æˆ³æ¨¡å¼ï¼ˆé»˜è®¤ï¼‰
            elif r.get('segments'):
                for s in r['segments']:
                    if s.get('start') is not None and s.get('end') is not None:
                        txt = (s.get('text') or '').strip()
                        if txt:
                            entries.append({
                                'start': s['start'],
                                'end': s['end'],
                                'text': txt
                            })

            # å†™å…¥SRTæ ¼å¼
            for e in entries:
                if e['end'] <= e['start']:
                    continue  # è·³è¿‡æ— æ•ˆæ—¶é—´æˆ³

                lines.append(str(n))  # åºå·
                lines.append(
                    f"{self._format_ts(e['start'])} --> {self._format_ts(e['end'])}"
                )  # æ—¶é—´æˆ³
                lines.append(e['text'])  # å­—å¹•æ–‡æœ¬
                lines.append("")  # ç©ºè¡Œ
                n += 1

        # å†™å…¥æ–‡ä»¶
        with open(path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(lines))

        self.logger.info(f"âœ… SRTæ–‡ä»¶å·²ç”Ÿæˆ: {path}, å…±{n-1}æ¡å­—å¹•")


# ========== å•ä¾‹æ¨¡å¼ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰ ==========

_service_instance: Optional[TranscriptionService] = None

def get_transcription_service(root: str) -> TranscriptionService:
    """
    è·å–è½¬å½•æœåŠ¡å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰

    Args:
        root: ä»»åŠ¡å·¥ä½œç›®å½•æ ¹è·¯å¾„

    Returns:
        TranscriptionService: è½¬å½•æœåŠ¡å®ä¾‹
    """
    global _service_instance
    if _service_instance is None:
        _service_instance = TranscriptionService(root)
    return _service_instance
```

**4. æ›´æ–°main.py**
```python
# backend/app/main.py

# ä¿®æ”¹å¯¼å…¥
# from processor import get_processor  # æ—§
from services.transcription_service import get_transcription_service  # æ–°

# æ›¿æ¢å…¨å±€å˜é‡
# proc = get_processor(JOBS_DIR)  # æ—§
transcription_service = get_transcription_service(JOBS_DIR)  # æ–°

# æ›´æ–°æ‰€æœ‰APIç«¯ç‚¹
@app.post("/api/create-job")
async def create_job(filename: str = Form(...)):
    try:
        # ... éªŒè¯é€»è¾‘ ...
        job = transcription_service.create_job(  # ä½¿ç”¨æ–°æœåŠ¡
            filename, input_path, JobSettings(), job_id=job_id
        )
        return {"job_id": job_id, "filename": filename}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/start")
async def start(job_id: str = Form(...), settings: str = Form(...)):
    settings_obj = TranscribeSettings(**json.loads(settings))
    job = transcription_service.get_job(job_id)  # ä½¿ç”¨æ–°æœåŠ¡
    # ... å…¶ä½™é€»è¾‘ ...
    transcription_service.start_job(job_id)  # ä½¿ç”¨æ–°æœåŠ¡
    return {"job_id": job_id, "started": True}

# æ›´æ–°æ‰€æœ‰å…¶ä»–APIç«¯ç‚¹...
```

**5. åˆ é™¤processor.py**
```bash
# å½’æ¡£processor.py
mv backend/app/processor.py _deprecated/

# æ›´æ–°è¯´æ˜
cat >> _deprecated/README.md << 'EOF'

- processor.py - å·²è¢«services/transcription_service.pyæ›¿ä»£
  - CPUAffinityManager -> services/cpu_affinity_service.py
  - TranscriptionProcessor -> services/transcription_service.py
EOF
```

**6. è¿è¡Œé»„é‡‘æ ‡å‡†æµ‹è¯•**
```bash
# å¯åŠ¨æœåŠ¡
python backend/app/main.py

# è¿è¡Œæµ‹è¯•è§†é¢‘
# ä¸Šä¼  tests/fixtures/test_video.mp4
# ä¸‹è½½ç”Ÿæˆçš„å­—å¹•åˆ° output/new.srt

# å¯¹æ¯”ç»“æœ
python tests/test_golden_master.py
```

**7. æäº¤å˜æ›´**
```bash
git add .
git commit -m "refactor: åˆå¹¶è½¬å½•é€»è¾‘ï¼Œç»Ÿä¸€åˆ°transcription_service"
```

**å®Œæˆæ ‡å‡†**:
- âœ… åªæœ‰ä¸€ä¸ªè½¬å½•æœåŠ¡å®ç°
- âœ… CPUäº²å’Œæ€§åŠŸèƒ½æ­£å¸¸
- âœ… æ‰€æœ‰APIæ­£å¸¸å·¥ä½œ
- âœ… é»„é‡‘æ ‡å‡†æµ‹è¯•é€šè¿‡
- âœ… processor.pyå·²åˆ é™¤

---

### é˜¶æ®µ2: ç»“æ„æ•´ç† (Day 2)

#### æ­¥éª¤2.1: æå–é…ç½®ç®¡ç† (2å°æ—¶)

**ç›®æ ‡**: æ¶ˆé™¤ç¡¬ç¼–ç ï¼Œæ”¯æŒç‹¬ç«‹æ‰“åŒ…

**åˆ›å»ºç»Ÿä¸€é…ç½®**:

```python
# backend/app/core/config.py
"""
ç»Ÿä¸€é…ç½®ç®¡ç†
ä¸¥æ ¼éµå®ˆç‹¬ç«‹æ‰“åŒ…åŸåˆ™ï¼š
1. æœç»ç¡¬ç¼–ç ç»å¯¹è·¯å¾„
2. æœç»ä¾èµ–ç³»ç»Ÿç¯å¢ƒå˜é‡
3. å¼ºåˆ¶æ¥ç®¡æ¨¡å‹ä¸‹è½½è·¯å¾„
"""

import os
from pathlib import Path
from typing import Optional

class ProjectConfig:
    """é¡¹ç›®é…ç½®ç±»"""

    def __init__(self):
        # ========== è·¯å¾„é…ç½®ï¼ˆåŸºäºé¡¹ç›®æ ¹ç›®å½•ï¼‰ ==========
        # è·å–é¡¹ç›®æ ¹ç›®å½•ï¼ˆä»å½“å‰æ–‡ä»¶ä½ç½®å‘ä¸Šä¸‰çº§ï¼‰
        self.BASE_DIR = Path(__file__).parent.parent.parent.parent.resolve()

        # è¾“å…¥è¾“å‡ºç›®å½•
        self.INPUT_DIR = self.BASE_DIR / "input"
        self.OUTPUT_DIR = self.BASE_DIR / "output"
        self.JOBS_DIR = self.BASE_DIR / "jobs"
        self.TEMP_DIR = self.BASE_DIR / "temp"

        # FFmpegè·¯å¾„ï¼ˆä¼˜å…ˆä½¿ç”¨é¡¹ç›®å†…çš„ï¼Œæ”¯æŒç‹¬ç«‹æ‰“åŒ…ï¼‰
        self.FFMPEG_DIR = self.BASE_DIR / "ffmpeg" / "bin"
        self.FFMPEG_EXE = self.FFMPEG_DIR / "ffmpeg.exe"

        # æ¨¡å‹ç¼“å­˜ç›®å½•ï¼ˆå¼ºåˆ¶æ¥ç®¡ï¼Œä¸ä½¿ç”¨é»˜è®¤çš„ç”¨æˆ·ç›®å½•ï¼‰
        self.MODELS_DIR = self.BASE_DIR / "models"
        self.HF_CACHE_DIR = self.MODELS_DIR / "huggingface"
        self.TORCH_CACHE_DIR = self.MODELS_DIR / "torch"

        # è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œå¼ºåˆ¶æ¨¡å‹ä¸‹è½½åˆ°é¡¹ç›®ç›®å½•
        os.environ['HF_HOME'] = str(self.HF_CACHE_DIR)
        os.environ['TORCH_HOME'] = str(self.TORCH_CACHE_DIR)
        os.environ['TRANSFORMERS_CACHE'] = str(self.HF_CACHE_DIR / "transformers")

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        for dir_path in [
            self.INPUT_DIR,
            self.OUTPUT_DIR,
            self.JOBS_DIR,
            self.TEMP_DIR,
            self.MODELS_DIR,
            self.HF_CACHE_DIR,
            self.TORCH_CACHE_DIR,
            self.FFMPEG_DIR
        ]:
            dir_path.mkdir(parents=True, exist_ok=True)

        # ========== éŸ³é¢‘å¤„ç†é…ç½® ==========
        self.SEGMENT_LENGTH_MS = 60_000      # 60ç§’
        self.SILENCE_SEARCH_MS = 2_000       # 2ç§’
        self.MIN_SILENCE_LEN_MS = 300        # 300æ¯«ç§’
        self.SILENCE_THRESHOLD_DBFS = -40    # -40dB

        # ========== æ¨¡å‹é…ç½® ==========
        self.DEFAULT_MODEL = "medium"
        self.DEFAULT_DEVICE = "cuda"  # è‡ªåŠ¨æ£€æµ‹ä¼šè¦†ç›–
        self.DEFAULT_COMPUTE_TYPE = "float16"
        self.DEFAULT_BATCH_SIZE = 16
        self.MAX_CACHE_SIZE = 3              # æœ€å¤šç¼“å­˜3ä¸ªæ¨¡å‹
        self.MEMORY_THRESHOLD = 0.8          # å†…å­˜ä½¿ç”¨é˜ˆå€¼

        # ========== æœåŠ¡å™¨é…ç½® ==========
        self.API_HOST = "127.0.0.1"
        self.API_PORT = 8000
        self.API_RELOAD = False

        # ========== CPUäº²å’Œæ€§é…ç½® ==========
        self.CPU_AFFINITY_ENABLED = True
        self.CPU_AFFINITY_STRATEGY = "auto"  # auto/half/custom

        # ========== æ—¥å¿—é…ç½® ==========
        self.LOG_LEVEL = os.getenv("LOG_LEVEL", "INFO")
        self.LOG_FILE = self.BASE_DIR / "logs" / "app.log"
        self.LOG_FILE.parent.mkdir(parents=True, exist_ok=True)

    def get_ffmpeg_command(self) -> str:
        """
        è·å–FFmpegå‘½ä»¤
        ä¼˜å…ˆä½¿ç”¨é¡¹ç›®å†…çš„FFmpegï¼Œæ”¯æŒç‹¬ç«‹æ‰“åŒ…

        Returns:
            str: FFmpegå¯æ‰§è¡Œæ–‡ä»¶è·¯å¾„
        """
        if self.FFMPEG_EXE.exists():
            # ä½¿ç”¨é¡¹ç›®å†…çš„FFmpeg
            return str(self.FFMPEG_EXE)
        else:
            # å›é€€åˆ°ç³»ç»Ÿå‘½ä»¤
            return "ffmpeg"

    def get_audio_config(self) -> dict:
        """è·å–éŸ³é¢‘å¤„ç†é…ç½®"""
        return {
            "segment_length_ms": self.SEGMENT_LENGTH_MS,
            "silence_search_ms": self.SILENCE_SEARCH_MS,
            "min_silence_len_ms": self.MIN_SILENCE_LEN_MS,
            "silence_threshold_dbfs": self.SILENCE_THRESHOLD_DBFS
        }

    def get_model_config(self) -> dict:
        """è·å–æ¨¡å‹é…ç½®"""
        return {
            "default_model": self.DEFAULT_MODEL,
            "default_device": self.DEFAULT_DEVICE,
            "default_compute_type": self.DEFAULT_COMPUTE_TYPE,
            "default_batch_size": self.DEFAULT_BATCH_SIZE,
            "max_cache_size": self.MAX_CACHE_SIZE,
            "memory_threshold": self.MEMORY_THRESHOLD
        }

# å…¨å±€é…ç½®å®ä¾‹
config = ProjectConfig()

# æ‰“å°é…ç½®ä¿¡æ¯ï¼ˆå¯åŠ¨æ—¶æ˜¾ç¤ºï¼‰
print(f"""
ğŸ”§ é¡¹ç›®é…ç½®å·²åŠ è½½
ğŸ“ é¡¹ç›®æ ¹ç›®å½•: {config.BASE_DIR}
ğŸ“¥ è¾“å…¥ç›®å½•: {config.INPUT_DIR}
ğŸ“¤ è¾“å‡ºç›®å½•: {config.OUTPUT_DIR}
ğŸ¬ FFmpeg: {config.get_ffmpeg_command()}
ğŸ¤– æ¨¡å‹ç¼“å­˜: {config.MODELS_DIR}
""")
```

**æ›´æ–°transcription_service.pyä½¿ç”¨é…ç½®**:

```python
# backend/app/services/transcription_service.py

from core.config import config

class TranscriptionService:
    def _extract_audio(self, input_file: str, audio_out: str) -> bool:
        """ä½¿ç”¨é…ç½®ä¸­çš„FFmpeg"""
        ffmpeg_cmd = config.get_ffmpeg_command()  # ä½¿ç”¨é…ç½®

        cmd = [
            ffmpeg_cmd, '-y', '-i', input_file,
            # ... å…¶ä½™å‚æ•°
        ]
        # ... å…¶ä½™é€»è¾‘

    def _split_audio(self, audio_path: str) -> List[Dict]:
        """ä½¿ç”¨é…ç½®ä¸­çš„éŸ³é¢‘å‚æ•°"""
        audio_config = config.get_audio_config()

        SEGMENT_LEN_MS = audio_config['segment_length_ms']
        SILENCE_SEARCH_MS = audio_config['silence_search_ms']
        # ... ä½¿ç”¨é…ç½®å‚æ•°
```

**æ›´æ–°main.pyä½¿ç”¨é…ç½®**:

```python
# backend/app/main.py

from core.config import config

# ä½¿ç”¨é…ç½®ä¸­çš„è·¯å¾„
INPUT_DIR = config.INPUT_DIR
OUTPUT_DIR = config.OUTPUT_DIR
JOBS_DIR = config.JOBS_DIR

# ... å…¶ä½™é€»è¾‘
```

**æäº¤å˜æ›´**:
```bash
git add .
git commit -m "refactor: æå–é…ç½®ç®¡ç†ï¼Œæ”¯æŒç‹¬ç«‹æ‰“åŒ…"
```

---

#### æ­¥éª¤2.2: ç®€åŒ–æ—¥å¿—é…ç½® (1å°æ—¶)

**åˆ›å»ºç®€å•æ—¥å¿—é…ç½®**:

```python
# backend/app/core/logging.py
"""
ç®€å•çš„æ—¥å¿—é…ç½®
"""

import logging
import sys
from pathlib import Path
from core.config import config

def setup_logging():
    """é…ç½®æ—¥å¿—ç³»ç»Ÿ"""

    # é…ç½®æ ¼å¼
    log_format = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    date_format = '%Y-%m-%d %H:%M:%S'

    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=getattr(logging, config.LOG_LEVEL),
        format=log_format,
        datefmt=date_format,
        handlers=[
            # æ§åˆ¶å°è¾“å‡º
            logging.StreamHandler(sys.stdout),
            # æ–‡ä»¶è¾“å‡º
            logging.FileHandler(config.LOG_FILE, encoding='utf-8')
        ]
    )

    # è®¾ç½®ç¬¬ä¸‰æ–¹åº“æ—¥å¿—çº§åˆ«
    logging.getLogger('urllib3').setLevel(logging.WARNING)
    logging.getLogger('multipart').setLevel(logging.WARNING)

    logger = logging.getLogger(__name__)
    logger.info(f"ğŸ“ æ—¥å¿—ç³»ç»Ÿå·²åˆå§‹åŒ– - çº§åˆ«: {config.LOG_LEVEL}")
    logger.info(f"ğŸ“„ æ—¥å¿—æ–‡ä»¶: {config.LOG_FILE}")

    return logger
```

**åœ¨main.pyä¸­ä½¿ç”¨**:

```python
# backend/app/main.py

from core.logging import setup_logging

# åœ¨åº”ç”¨å¯åŠ¨æ—¶åˆå§‹åŒ–æ—¥å¿—
logger = setup_logging()

@app.on_event("startup")
async def startup_event():
    logger.info("ğŸš€ åº”ç”¨å¯åŠ¨ä¸­...")
    # ... å…¶ä½™å¯åŠ¨é€»è¾‘
```

---

#### æ­¥éª¤2.3: æ•´ç†ç›®å½•ç»“æ„ (1å°æ—¶)

**ç›®æ ‡ç»“æ„**:
```
backend/app/
â”œâ”€â”€ main.py                  # å”¯ä¸€å…¥å£
â”œâ”€â”€ core/                    # æ ¸å¿ƒå±‚
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py            # é…ç½®ç®¡ç†
â”‚   â””â”€â”€ logging.py           # æ—¥å¿—é…ç½®
â”œâ”€â”€ services/                # æœåŠ¡å±‚
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ transcription_service.py
â”‚   â”œâ”€â”€ cpu_affinity_service.py
â”‚   â”œâ”€â”€ hardware_service.py
â”‚   â”œâ”€â”€ file_service.py
â”‚   â””â”€â”€ model_preload_manager.py
â”œâ”€â”€ api/                     # APIå±‚
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ routes/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ transcription_routes.py
â”‚       â”œâ”€â”€ file_routes.py
â”‚       â””â”€â”€ hardware_routes.py
â””â”€â”€ models/                  # æ•°æ®æ¨¡å‹
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ job_models.py
    â””â”€â”€ hardware_models.py
```

**åˆ›å»º__init__.py**:
```python
# backend/app/core/__init__.py
from .config import config
from .logging import setup_logging

__all__ = ['config', 'setup_logging']
```

**è¿è¡Œé»„é‡‘æ ‡å‡†æµ‹è¯•éªŒè¯**:
```bash
python tests/test_golden_master.py
```

**æäº¤å˜æ›´**:
```bash
git add .
git commit -m "refactor: æ•´ç†ç›®å½•ç»“æ„ï¼Œæ¸…æ™°åˆ†å±‚"
```

**å®Œæˆæ ‡å‡†**:
- âœ… é…ç½®ç»Ÿä¸€ç®¡ç†
- âœ… è·¯å¾„ä½¿ç”¨ç›¸å¯¹è·¯å¾„
- âœ… æ—¥å¿—ç³»ç»Ÿç®€å•æœ‰æ•ˆ
- âœ… ç›®å½•ç»“æ„æ¸…æ™°
- âœ… é»„é‡‘æ ‡å‡†æµ‹è¯•é€šè¿‡

---

### é˜¶æ®µ3: å®ç°æ–­ç‚¹ç»­ä¼  (Day 3)

#### æ­¥éª¤3.1: è®¾è®¡æ£€æŸ¥ç‚¹ç»“æ„ (30åˆ†é’Ÿ)

**æ£€æŸ¥ç‚¹æ•°æ®ç»“æ„**:
```python
# backend/app/models/checkpoint_models.py
"""
æ£€æŸ¥ç‚¹æ•°æ®æ¨¡å‹
"""

from dataclasses import dataclass, asdict
from typing import List, Dict, Optional
from datetime import datetime
import json

@dataclass
class Checkpoint:
    """
    è½¬å½•ä»»åŠ¡æ£€æŸ¥ç‚¹
    ç”¨äºæ–­ç‚¹ç»­ä¼ 
    """
    job_id: str
    phase: str  # extract/split/transcribe/srt
    progress: float

    # éŸ³é¢‘å¤„ç†ä¿¡æ¯
    audio_path: Optional[str] = None
    segments: List[Dict] = None  # æ‰€æœ‰æ®µä¿¡æ¯

    # è½¬å½•è¿›åº¦
    total_segments: int = 0
    processed_segments: List[int] = None  # å·²å¤„ç†çš„æ®µç´¢å¼•
    results: List[Dict] = None  # å·²è½¬å½•çš„ç»“æœ

    # è¯­è¨€æ£€æµ‹
    language: Optional[str] = None

    # æ—¶é—´æˆ³
    created_at: str = None
    updated_at: str = None

    def __post_init__(self):
        """åˆå§‹åŒ–é»˜è®¤å€¼"""
        if self.segments is None:
            self.segments = []
        if self.processed_segments is None:
            self.processed_segments = []
        if self.results is None:
            self.results = []
        if self.created_at is None:
            self.created_at = datetime.now().isoformat()
        if self.updated_at is None:
            self.updated_at = datetime.now().isoformat()

    def to_dict(self) -> dict:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return asdict(self)

    def to_json(self) -> str:
        """è½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²"""
        return json.dumps(self.to_dict(), ensure_ascii=False, indent=2)

    @classmethod
    def from_dict(cls, data: dict) -> 'Checkpoint':
        """ä»å­—å…¸åˆ›å»º"""
        return cls(**data)

    @classmethod
    def from_json(cls, json_str: str) -> 'Checkpoint':
        """ä»JSONå­—ç¬¦ä¸²åˆ›å»º"""
        return cls.from_dict(json.loads(json_str))
```

---

#### æ­¥éª¤3.2: å®ç°æ£€æŸ¥ç‚¹æœåŠ¡ (2å°æ—¶)

```python
# backend/app/services/checkpoint_service.py
"""
æ£€æŸ¥ç‚¹ç®¡ç†æœåŠ¡
å®ç°æ–­ç‚¹ç»­ä¼ åŠŸèƒ½
"""

import logging
from pathlib import Path
from typing import Optional
from models.checkpoint_models import Checkpoint

class CheckpointService:
    """æ£€æŸ¥ç‚¹ç®¡ç†æœåŠ¡"""

    def __init__(self, jobs_root: Path):
        """
        åˆå§‹åŒ–æ£€æŸ¥ç‚¹æœåŠ¡

        Args:
            jobs_root: ä»»åŠ¡æ ¹ç›®å½•
        """
        self.jobs_root = Path(jobs_root)
        self.logger = logging.getLogger(__name__)

    def _get_checkpoint_path(self, job_id: str) -> Path:
        """
        è·å–æ£€æŸ¥ç‚¹æ–‡ä»¶è·¯å¾„

        Args:
            job_id: ä»»åŠ¡ID

        Returns:
            Path: æ£€æŸ¥ç‚¹æ–‡ä»¶è·¯å¾„
        """
        return self.jobs_root / job_id / "checkpoint.json"

    def save(self, checkpoint: Checkpoint):
        """
        ä¿å­˜æ£€æŸ¥ç‚¹

        Args:
            checkpoint: æ£€æŸ¥ç‚¹å¯¹è±¡
        """
        checkpoint_file = self._get_checkpoint_path(checkpoint.job_id)
        checkpoint_file.parent.mkdir(parents=True, exist_ok=True)

        # æ›´æ–°æ—¶é—´æˆ³
        from datetime import datetime
        checkpoint.updated_at = datetime.now().isoformat()

        # å†™å…¥æ–‡ä»¶
        with open(checkpoint_file, 'w', encoding='utf-8') as f:
            f.write(checkpoint.to_json())

        self.logger.debug(
            f"ğŸ’¾ æ£€æŸ¥ç‚¹å·²ä¿å­˜: {checkpoint.job_id} - "
            f"{checkpoint.phase} - {checkpoint.progress:.1f}%"
        )

    def load(self, job_id: str) -> Optional[Checkpoint]:
        """
        åŠ è½½æ£€æŸ¥ç‚¹

        Args:
            job_id: ä»»åŠ¡ID

        Returns:
            Optional[Checkpoint]: æ£€æŸ¥ç‚¹å¯¹è±¡ï¼Œä¸å­˜åœ¨åˆ™è¿”å›None
        """
        checkpoint_file = self._get_checkpoint_path(job_id)

        if not checkpoint_file.exists():
            return None

        try:
            with open(checkpoint_file, 'r', encoding='utf-8') as f:
                json_str = f.read()

            checkpoint = Checkpoint.from_json(json_str)
            self.logger.info(
                f"ğŸ“‚ æ£€æŸ¥ç‚¹å·²åŠ è½½: {job_id} - "
                f"{checkpoint.phase} - {checkpoint.progress:.1f}%"
            )
            return checkpoint

        except Exception as e:
            self.logger.error(f"âŒ æ£€æŸ¥ç‚¹åŠ è½½å¤±è´¥: {job_id} - {e}")
            return None

    def exists(self, job_id: str) -> bool:
        """
        æ£€æŸ¥æ£€æŸ¥ç‚¹æ˜¯å¦å­˜åœ¨

        Args:
            job_id: ä»»åŠ¡ID

        Returns:
            bool: æ˜¯å¦å­˜åœ¨
        """
        return self._get_checkpoint_path(job_id).exists()

    def delete(self, job_id: str):
        """
        åˆ é™¤æ£€æŸ¥ç‚¹

        Args:
            job_id: ä»»åŠ¡ID
        """
        checkpoint_file = self._get_checkpoint_path(job_id)
        if checkpoint_file.exists():
            checkpoint_file.unlink()
            self.logger.debug(f"ğŸ—‘ï¸ æ£€æŸ¥ç‚¹å·²åˆ é™¤: {job_id}")
```

---

#### æ­¥éª¤3.3: é›†æˆæ–­ç‚¹ç»­ä¼ åˆ°è½¬å½•æœåŠ¡ (3å°æ—¶)

```python
# backend/app/services/transcription_service.py

from services.checkpoint_service import CheckpointService
from models.checkpoint_models import Checkpoint

class TranscriptionService:
    """è½¬å½•æœåŠ¡ï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰"""

    def __init__(self, jobs_root: str):
        # ... åŸæœ‰åˆå§‹åŒ– ...

        # æ·»åŠ æ£€æŸ¥ç‚¹æœåŠ¡
        self.checkpoint_service = CheckpointService(self.jobs_root)

    def _run_pipeline(self, job: JobState):
        """è½¬å½•æµç¨‹ï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰"""

        # ... åŸæœ‰CPUäº²å’Œæ€§è®¾ç½® ...

        try:
            # ========== å°è¯•åŠ è½½æ£€æŸ¥ç‚¹ ==========
            checkpoint = self.checkpoint_service.load(job.job_id)

            if checkpoint:
                self.logger.info(f"ğŸ”„ ä»æ£€æŸ¥ç‚¹æ¢å¤ä»»åŠ¡: {job.job_id}")
                self._resume_from_checkpoint(job, checkpoint)
            else:
                self.logger.info(f"ğŸš€ å¼€å§‹æ–°ä»»åŠ¡: {job.job_id}")
                self._start_new_transcription(job)

        except Exception as e:
            # ä¿å­˜å¤±è´¥çŠ¶æ€çš„æ£€æŸ¥ç‚¹
            self.checkpoint_service.save(Checkpoint(
                job_id=job.job_id,
                phase=job.phase,
                progress=job.progress
            ))
            raise

        finally:
            # ... åŸæœ‰æ¸…ç†é€»è¾‘ ...
            pass

    def _start_new_transcription(self, job: JobState):
        """å¼€å§‹æ–°çš„è½¬å½•ä»»åŠ¡"""
        job_dir = Path(job.dir)
        input_path = job_dir / job.filename
        audio_path = job_dir / 'audio.wav'

        # ========== é˜¶æ®µ1: æå–éŸ³é¢‘ ==========
        self._update_progress(job, 'extract', 0, 'æå–éŸ³é¢‘ä¸­')
        if job.canceled:
            raise RuntimeError('ä»»åŠ¡å·²å–æ¶ˆ')

        if not self._extract_audio(str(input_path), str(audio_path)):
            raise RuntimeError('FFmpeg æå–éŸ³é¢‘å¤±è´¥')

        # ä¿å­˜æ£€æŸ¥ç‚¹
        self.checkpoint_service.save(Checkpoint(
            job_id=job.job_id,
            phase='extract',
            progress=5.0,
            audio_path=str(audio_path)
        ))

        self._update_progress(job, 'extract', 1, 'éŸ³é¢‘æå–å®Œæˆ')

        # ========== é˜¶æ®µ2: æ™ºèƒ½åˆ†æ®µ ==========
        self._update_progress(job, 'split', 0, 'éŸ³é¢‘åˆ†æ®µä¸­')
        if job.canceled:
            raise RuntimeError('ä»»åŠ¡å·²å–æ¶ˆ')

        segments = self._split_audio(str(audio_path))
        job.segments = segments
        job.total = len(segments)

        # ä¿å­˜æ£€æŸ¥ç‚¹
        self.checkpoint_service.save(Checkpoint(
            job_id=job.job_id,
            phase='split',
            progress=15.0,
            audio_path=str(audio_path),
            segments=[
                {"file": str(seg['file']), "start_ms": seg['start_ms']}
                for seg in segments
            ],
            total_segments=len(segments)
        ))

        self._update_progress(job, 'split', 1, f'åˆ†æ®µå®Œæˆ å…±{job.total}æ®µ')

        # ========== é˜¶æ®µ3: è½¬å½•å¤„ç† ==========
        self._transcribe_all_segments(job, segments)

    def _resume_from_checkpoint(self, job: JobState, checkpoint: Checkpoint):
        """ä»æ£€æŸ¥ç‚¹æ¢å¤ä»»åŠ¡"""
        phase = checkpoint.phase

        if phase == 'extract':
            # éŸ³é¢‘å·²æå–ï¼Œç»§ç»­åˆ†æ®µ
            self.logger.info("ğŸ“ æ¢å¤ç‚¹: éŸ³é¢‘å·²æå–ï¼Œå¼€å§‹åˆ†æ®µ")
            audio_path = Path(checkpoint.audio_path)

            segments = self._split_audio(str(audio_path))
            job.segments = segments
            job.total = len(segments)

            # æ›´æ–°æ£€æŸ¥ç‚¹
            checkpoint.phase = 'split'
            checkpoint.progress = 15.0
            checkpoint.segments = [
                {"file": str(seg['file']), "start_ms": seg['start_ms']}
                for seg in segments
            ]
            checkpoint.total_segments = len(segments)
            self.checkpoint_service.save(checkpoint)

            self._transcribe_all_segments(job, segments)

        elif phase == 'split':
            # åˆ†æ®µå·²å®Œæˆï¼Œå¼€å§‹è½¬å½•
            self.logger.info("ğŸ“ æ¢å¤ç‚¹: åˆ†æ®µå·²å®Œæˆï¼Œå¼€å§‹è½¬å½•")
            segments = [
                {"file": Path(seg['file']), "start_ms": seg['start_ms']}
                for seg in checkpoint.segments
            ]
            job.segments = segments
            job.total = len(segments)

            self._transcribe_all_segments(job, segments)

        elif phase == 'transcribe':
            # éƒ¨åˆ†è½¬å½•å·²å®Œæˆï¼Œç»§ç»­æœªå®Œæˆçš„éƒ¨åˆ†
            processed_count = len(checkpoint.processed_segments)
            total_count = checkpoint.total_segments
            self.logger.info(
                f"ğŸ“ æ¢å¤ç‚¹: ç»§ç»­è½¬å½• "
                f"(å·²å®Œæˆ {processed_count}/{total_count} æ®µ)"
            )

            segments = [
                {"file": Path(seg['file']), "start_ms": seg['start_ms']}
                for seg in checkpoint.segments
            ]
            job.segments = segments
            job.total = len(segments)
            job.language = checkpoint.language

            # ç»§ç»­æœªå®Œæˆçš„æ®µ
            self._transcribe_all_segments(
                job,
                segments,
                skip_indices=set(checkpoint.processed_segments),
                existing_results=checkpoint.results
            )

        elif phase == 'srt':
            # è½¬å½•å·²å®Œæˆï¼Œé‡æ–°ç”ŸæˆSRT
            self.logger.info("ğŸ“ æ¢å¤ç‚¹: é‡æ–°ç”ŸæˆSRT")
            job.language = checkpoint.language

            base_name = os.path.splitext(job.filename)[0]
            srt_path = Path(job.dir) / f'{base_name}.srt'

            self._generate_srt(
                checkpoint.results,
                str(srt_path),
                job.settings.word_timestamps
            )

            job.srt_path = str(srt_path)
            job.status = 'finished'
            job.message = 'å®Œæˆ'

            # æ¸…é™¤æ£€æŸ¥ç‚¹
            self.checkpoint_service.delete(job.job_id)

    def _transcribe_all_segments(
        self,
        job: JobState,
        segments: List[Dict],
        skip_indices: set = None,
        existing_results: List[Dict] = None
    ):
        """
        è½¬å½•æ‰€æœ‰éŸ³é¢‘æ®µï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰

        Args:
            job: ä»»åŠ¡çŠ¶æ€
            segments: æ‰€æœ‰æ®µä¿¡æ¯
            skip_indices: è¦è·³è¿‡çš„æ®µç´¢å¼•ï¼ˆå·²å¤„ç†ï¼‰
            existing_results: å·²æœ‰çš„è½¬å½•ç»“æœ
        """
        skip_indices = skip_indices or set()
        results = existing_results or []
        processed_indices = list(skip_indices)

        self._update_progress(job, 'transcribe', 0, 'åŠ è½½æ¨¡å‹ä¸­')
        model = self._get_model(job.settings)
        align_cache = {}

        for idx, seg in enumerate(segments):
            # è·³è¿‡å·²å¤„ç†çš„æ®µ
            if idx in skip_indices:
                self.logger.debug(f"â­ï¸ è·³è¿‡å·²å¤„ç†æ®µ: {idx}/{len(segments)}")
                continue

            if job.canceled:
                raise RuntimeError('ä»»åŠ¡å·²å–æ¶ˆ')

            # æ›´æ–°è¿›åº¦
            ratio = (idx + 1) / len(segments)
            self._update_progress(
                job,
                'transcribe',
                ratio,
                f'è½¬å½• {idx+1}/{len(segments)}'
            )

            # è½¬å½•å½“å‰æ®µ
            seg_result = self._transcribe_segment(seg, model, job, align_cache)
            if seg_result:
                results.append(seg_result)
                processed_indices.append(idx)

            job.processed = len(processed_indices)

            # æ¯5æ®µä¿å­˜ä¸€æ¬¡æ£€æŸ¥ç‚¹
            if (idx + 1) % 5 == 0:
                progress = 15 + ratio * 80
                self.checkpoint_service.save(Checkpoint(
                    job_id=job.job_id,
                    phase='transcribe',
                    progress=progress,
                    segments=[
                        {"file": str(s['file']), "start_ms": s['start_ms']}
                        for s in segments
                    ],
                    total_segments=len(segments),
                    processed_segments=processed_indices,
                    results=results,
                    language=job.language
                ))
                self.logger.debug(f"ğŸ’¾ æ£€æŸ¥ç‚¹å·²æ›´æ–°: {idx+1}/{len(segments)} æ®µ")

        # æ‰€æœ‰æ®µè½¬å½•å®Œæˆ
        self._update_progress(job, 'transcribe', 1, 'è½¬å½•å®Œæˆ ç”Ÿæˆå­—å¹•ä¸­')

        # ä¿å­˜å®ŒæˆçŠ¶æ€çš„æ£€æŸ¥ç‚¹
        self.checkpoint_service.save(Checkpoint(
            job_id=job.job_id,
            phase='srt',
            progress=95.0,
            results=results,
            language=job.language
        ))

        # ç”ŸæˆSRT
        base_name = os.path.splitext(job.filename)[0]
        srt_path = Path(job.dir) / f'{base_name}.srt'

        self._generate_srt(results, str(srt_path), job.settings.word_timestamps)

        job.srt_path = str(srt_path)
        job.status = 'finished'
        job.message = 'å®Œæˆ'

        # æ¸…é™¤æ£€æŸ¥ç‚¹
        self.checkpoint_service.delete(job.job_id)
        self.logger.info(f"âœ… ä»»åŠ¡å®Œæˆ: {job.job_id}")
```

---

#### æ­¥éª¤3.4: æ·»åŠ æ¢å¤API (30åˆ†é’Ÿ)

```python
# backend/app/main.py

@app.post("/api/resume/{job_id}")
async def resume_transcription(job_id: str):
    """
    æ¢å¤ä¸­æ–­çš„è½¬å½•ä»»åŠ¡

    Args:
        job_id: ä»»åŠ¡ID

    Returns:
        dict: æ¢å¤ç»“æœ
    """
    try:
        # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å­˜åœ¨
        job = transcription_service.get_job(job_id)
        if not job:
            raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

        # æ£€æŸ¥æ˜¯å¦æœ‰æ£€æŸ¥ç‚¹
        if not transcription_service.checkpoint_service.exists(job_id):
            raise HTTPException(status_code=404, detail="æ²¡æœ‰æ‰¾åˆ°å¯æ¢å¤çš„æ£€æŸ¥ç‚¹")

        # æ£€æŸ¥ä»»åŠ¡çŠ¶æ€
        if job.status == "processing":
            raise HTTPException(status_code=400, detail="ä»»åŠ¡æ­£åœ¨è¿è¡Œä¸­")

        # é‡æ–°å¯åŠ¨ä»»åŠ¡ï¼ˆä¼šè‡ªåŠ¨ä»æ£€æŸ¥ç‚¹æ¢å¤ï¼‰
        transcription_service.start_job(job_id)

        return {
            "success": True,
            "message": "ä»»åŠ¡å·²ä»æ£€æŸ¥ç‚¹æ¢å¤",
            "job_id": job_id
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.exception(f"æ¢å¤ä»»åŠ¡å¤±è´¥: {job_id}")
        raise HTTPException(status_code=500, detail=str(e))
```

---

#### æ­¥éª¤3.5: æµ‹è¯•æ–­ç‚¹ç»­ä¼  (1å°æ—¶)

**æ‰‹åŠ¨æµ‹è¯•æ­¥éª¤**:

1. **å¼€å§‹ä¸€ä¸ªè½¬å½•ä»»åŠ¡**
```bash
# å¯åŠ¨æœåŠ¡
python backend/app/main.py

# ä¸Šä¼ ä¸€ä¸ªè¾ƒé•¿çš„è§†é¢‘ï¼ˆ5-10åˆ†é’Ÿï¼‰
# ç­‰å¾…è½¬å½•å¼€å§‹
```

2. **ä¸­æ–­ä»»åŠ¡**
```bash
# åœ¨è½¬å½•è¿›è¡Œåˆ°ä¸€åŠæ—¶ï¼Œå…³é—­æœåŠ¡ï¼ˆCtrl+Cï¼‰
```

3. **é‡æ–°å¯åŠ¨æœåŠ¡**
```bash
# å†æ¬¡å¯åŠ¨
python backend/app/main.py
```

4. **æ¢å¤ä»»åŠ¡**
```bash
# è°ƒç”¨æ¢å¤API
curl -X POST http://localhost:8000/api/resume/{job_id}

# æˆ–è€…åœ¨å‰ç«¯ç‚¹å‡»"æ¢å¤"æŒ‰é’®
```

5. **éªŒè¯ç»“æœ**
- æ£€æŸ¥æ—¥å¿—ï¼Œç¡®è®¤ä»æ£€æŸ¥ç‚¹æ¢å¤
- ç¡®è®¤ä¸ä¼šé‡æ–°å¤„ç†å·²å®Œæˆçš„æ®µ
- æœ€ç»ˆç”Ÿæˆçš„å­—å¹•æ–‡ä»¶å®Œæ•´

**æäº¤å˜æ›´**:
```bash
git add .
git commit -m "feat: å®ç°æ–­ç‚¹ç»­ä¼ åŠŸèƒ½"
```

**å®Œæˆæ ‡å‡†**:
- âœ… æ£€æŸ¥ç‚¹æœåŠ¡å·²å®ç°
- âœ… è½¬å½•æœåŠ¡æ”¯æŒæ–­ç‚¹ç»­ä¼ 
- âœ… æ¯5æ®µä¿å­˜ä¸€æ¬¡æ£€æŸ¥ç‚¹
- âœ… APIæ”¯æŒæ¢å¤ä»»åŠ¡
- âœ… æ‰‹åŠ¨æµ‹è¯•é€šè¿‡
- âœ… æ¢å¤åç”Ÿæˆçš„å­—å¹•å®Œæ•´

---

### é˜¶æ®µ4: æ”¶å°¾ä¼˜åŒ– (Day 4)

#### æ­¥éª¤4.1: å‰ç«¯è¿›åº¦æ˜¾ç¤ºä¼˜åŒ– (å¯é€‰, 2å°æ—¶)

**å¦‚æœæ—¶é—´å……è¶³ï¼Œå¯ä»¥å®ç°SSEæ›¿ä»£è½®è¯¢**

```python
# backend/app/main.py

from sse_starlette.sse import EventSourceResponse
import asyncio

@app.get("/api/status/{job_id}/stream")
async def stream_job_status(job_id: str):
    """
    ä½¿ç”¨SSEæµå¼ä¼ è¾“ä»»åŠ¡çŠ¶æ€

    Args:
        job_id: ä»»åŠ¡ID

    Returns:
        EventSourceResponse: SSEå“åº”
    """
    async def event_generator():
        """ç”ŸæˆSSEäº‹ä»¶"""
        while True:
            job = transcription_service.get_job(job_id)
            if not job:
                yield {
                    "event": "error",
                    "data": json.dumps({"error": "ä»»åŠ¡ä¸å­˜åœ¨"})
                }
                break

            # å‘é€çŠ¶æ€
            yield {
                "event": "status",
                "data": json.dumps(job.to_dict())
            }

            # ä»»åŠ¡å®Œæˆæˆ–å¤±è´¥ï¼Œåœæ­¢æµ
            if job.status in ["finished", "failed", "canceled"]:
                yield {
                    "event": "complete",
                    "data": json.dumps(job.to_dict())
                }
                break

            # ç­‰å¾…1ç§’åå†æ¬¡æ£€æŸ¥
            await asyncio.sleep(1)

    return EventSourceResponse(event_generator())
```

**å‰ç«¯ä½¿ç”¨SSE**:
```javascript
// frontend/src/App.vue

function watchJobProgress(jobId) {
  const eventSource = new EventSource(`/api/status/${jobId}/stream`)

  eventSource.addEventListener('status', (event) => {
    const data = JSON.parse(event.data)
    // æ›´æ–°è¿›åº¦æ˜¾ç¤º
    updateProgress(data)
  })

  eventSource.addEventListener('complete', (event) => {
    const data = JSON.parse(event.data)
    // ä»»åŠ¡å®Œæˆ
    handleComplete(data)
    eventSource.close()
  })

  eventSource.addEventListener('error', () => {
    eventSource.close()
  })
}
```

---

#### æ­¥éª¤4.2: æ‰“åŒ…é¢„æ£€æŸ¥ (1å°æ—¶)

**æ£€æŸ¥æ¸…å•**:

1. **è·¯å¾„æ£€æŸ¥**
```bash
# æœç´¢ç¡¬ç¼–ç è·¯å¾„
grep -r "C:\\" backend/
grep -r "D:\\" backend/
grep -r "/Users/" backend/
grep -r "/home/" backend/

# åº”è¯¥æ²¡æœ‰ç»“æœ
```

2. **FFmpegæ£€æŸ¥**
```python
# ç¡®è®¤config.pyä¸­çš„FFmpegé€»è¾‘
from core.config import config

ffmpeg_cmd = config.get_ffmpeg_command()
print(f"FFmpegå‘½ä»¤: {ffmpeg_cmd}")

# æµ‹è¯•æ˜¯å¦å¯ç”¨
import subprocess
result = subprocess.run([ffmpeg_cmd, "-version"], capture_output=True)
print(result.returncode == 0)
```

3. **æ¨¡å‹è·¯å¾„æ£€æŸ¥**
```python
# ç¡®è®¤ç¯å¢ƒå˜é‡å·²è®¾ç½®
import os
print(f"HF_HOME: {os.environ.get('HF_HOME')}")
print(f"TORCH_HOME: {os.environ.get('TORCH_HOME')}")

# åº”è¯¥éƒ½æŒ‡å‘é¡¹ç›®ç›®å½•
```

4. **ä¾èµ–å¯¼å‡º**
```bash
# å¯¼å‡ºPythonä¾èµ–
pip freeze > requirements.txt

# æˆ–è€…ä½¿ç”¨conda
conda env export > environment.yml
```

---

#### æ­¥éª¤4.3: æ›´æ–°æ–‡æ¡£ (1å°æ—¶)

**æ›´æ–°README.md**:

```markdown
# Video-to-SRT GPU

è§†é¢‘è½¬å­—å¹•å·¥å…·ï¼Œæ”¯æŒGPUåŠ é€Ÿå’Œæ–­ç‚¹ç»­ä¼ 

## âœ¨ æ–°åŠŸèƒ½

- âœ… **æ–­ç‚¹ç»­ä¼ **: ä»»åŠ¡ä¸­æ–­åå¯ä»¥ç»§ç»­ï¼Œä¸ä¼šä¸¢å¤±è¿›åº¦
- âœ… **ç‹¬ç«‹æ‰“åŒ…**: æ‰€æœ‰è·¯å¾„ä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼Œæ”¯æŒä¾¿æºéƒ¨ç½²
- âœ… **æ™ºèƒ½åˆ†æ®µ**: åŸºäºé™éŸ³æ£€æµ‹ï¼Œé¿å…å¥å­æ–­è£‚

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
# ä½¿ç”¨conda (æ¨è)
conda create -n video_to_srt python=3.10
conda activate video_to_srt
pip install -r requirements.txt
```

### 2. å‡†å¤‡FFmpeg

ä¸‹è½½FFmpegå¹¶è§£å‹åˆ°é¡¹ç›®æ ¹ç›®å½•:
```
é¡¹ç›®æ ¹ç›®å½•/
â””â”€â”€ ffmpeg/
    â””â”€â”€ bin/
        â””â”€â”€ ffmpeg.exe
```

### 3. å¯åŠ¨æœåŠ¡

```bash
# æ–¹å¼1: ä½¿ç”¨å¯åŠ¨å™¨ï¼ˆæ¨èï¼‰
python simple_launcher.py

# æ–¹å¼2: æ‰‹åŠ¨å¯åŠ¨
python backend/app/main.py
```

### 4. è®¿é—®ç•Œé¢

æ‰“å¼€æµè§ˆå™¨è®¿é—®: http://localhost:5174

## ğŸ“– ä½¿ç”¨è¯´æ˜

### åŸºæœ¬æµç¨‹

1. ä¸Šä¼ è§†é¢‘æ–‡ä»¶
2. é…ç½®è½¬å½•å‚æ•°ï¼ˆæ¨¡å‹ã€è®¾å¤‡ç­‰ï¼‰
3. å¼€å§‹è½¬å½•
4. ç­‰å¾…å®Œæˆ
5. ä¸‹è½½å­—å¹•

### æ–­ç‚¹ç»­ä¼ 

å¦‚æœè½¬å½•è¿‡ç¨‹ä¸­æ–­ï¼š

1. é‡æ–°å¯åŠ¨æœåŠ¡
2. åœ¨ä»»åŠ¡åˆ—è¡¨ä¸­æ‰¾åˆ°ä¸­æ–­çš„ä»»åŠ¡
3. ç‚¹å‡»"æ¢å¤"æŒ‰é’®
4. ä»»åŠ¡ä¼šä»ä¸­æ–­å¤„ç»§ç»­

## ğŸ”§ é…ç½®è¯´æ˜

æ‰€æœ‰é…ç½®åœ¨ `backend/app/core/config.py` ä¸­:

- `DEFAULT_MODEL`: é»˜è®¤æ¨¡å‹ (tiny/base/small/medium/large)
- `SEGMENT_LENGTH_MS`: åˆ†æ®µé•¿åº¦ (æ¯«ç§’)
- `MAX_CACHE_SIZE`: æœ€å¤§æ¨¡å‹ç¼“å­˜æ•°é‡

## ğŸ“¦ ç‹¬ç«‹æ‰“åŒ…

é¡¹ç›®å·²æ”¯æŒç‹¬ç«‹æ‰“åŒ…éƒ¨ç½²ï¼š

- âœ… æ‰€æœ‰è·¯å¾„ä½¿ç”¨ç›¸å¯¹è·¯å¾„
- âœ… FFmpegé›†æˆåˆ°é¡¹ç›®å†…
- âœ… æ¨¡å‹ç¼“å­˜åœ¨é¡¹ç›®ç›®å½•

## ğŸ“ è®¸å¯è¯

MIT License
```

---

## å››ã€é£é™©æ§åˆ¶

### 4.1 ç»™ç‹¬ç«‹å¼€å‘è€…çš„å»ºè®®

1. **ä¸è¦è¿‡åº¦æŠ½è±¡**
   - ä¸éœ€è¦å†™ `BaseService` è¿™ç§åŸºç±»
   - Pythoné¸­å­ç±»å‹å°±å¤Ÿäº†
   - åªåœ¨ç¡®å®éœ€è¦æ—¶æ‰æŠ½è±¡

2. **æ—¥å¿—ä¼˜äºDebug**
   - åœ¨å…³é”®æ­¥éª¤åŠ  `logger.info()`
   - å‡ºé—®é¢˜æ—¶çœ‹æ—¥å¿—æ¯”æ–­ç‚¹è°ƒè¯•å¿«
   - æ—¥å¿—è¦æœ‰emojiï¼Œæ–¹ä¾¿æ‰«è§†

3. **Commitç²’åº¦**
   - åˆ æ–‡ä»¶å‰ Commit ä¸€æ¬¡
   - æ¬è¿ä»£ç å Commit ä¸€æ¬¡
   - é»„é‡‘æµ‹è¯•é€šè¿‡å Commit ä¸€æ¬¡
   - **åƒä¸‡ä¸è¦æ”’åˆ°æœ€åä¸€èµ·æäº¤**

4. **åŠæ—¶å¤‡ä»½**
   - æ¯å®Œæˆä¸€ä¸ªé˜¶æ®µåˆ›å»ºtag
   - é‡è¦æ”¹åŠ¨å‰å…ˆåˆ›å»ºåˆ†æ”¯
   - å¯ä»¥éšæ—¶å›æ»š

### 4.2 å›æ»šç­–ç•¥

å¦‚æœé‡æ„å‡ºç°ä¸¥é‡é—®é¢˜:
```bash
# æŸ¥çœ‹æ‰€æœ‰å¤‡ä»½æ ‡ç­¾
git tag -l "backup-*"

# å›æ»šåˆ°é‡æ„å‰
git reset --hard backup-before-refactor-20251117

# æˆ–åˆ‡æ¢å›ä¸»åˆ†æ”¯
git checkout feature/breakpoint-resume
```

---

## äº”ã€éªŒæ”¶æ ‡å‡†

å½“ä½ å®Œæˆä¸Šè¿°æ­¥éª¤ï¼Œä½ åº”è¯¥è¾¾åˆ°ï¼š

### 5.1 åŠŸèƒ½éªŒæ”¶

- âœ… é¡¹ç›®åªæœ‰ä¸€ä¸ª `main.py`ï¼Œç‚¹å¼€å°±èƒ½è·‘
- âœ… å…³æ‰è¿è¡Œçª—å£ï¼Œå†é‡æ–°æ‰“å¼€ï¼Œæœªå®Œæˆçš„ä»»åŠ¡èƒ½æ¥ç€è·‘ï¼ˆæ–­ç‚¹ç»­ä¼ ï¼‰
- âœ… è¿è¡Œ"é»„é‡‘æ ‡å‡†æµ‹è¯•"ï¼Œç”Ÿæˆçš„å­—å¹•å’Œé‡æ„å‰ä¸€è‡´
- âœ… ä»£ç é‡Œæ²¡æœ‰ç¡¬ç¼–ç çš„ç»å¯¹è·¯å¾„

### 5.2 ä»£ç è´¨é‡

- âœ… ä»£ç é‡å¤ç‡ < 5%
- âœ… å•ä¸ªæ–‡ä»¶ä¸è¶…è¿‡500è¡Œ
- âœ… æ‰€æœ‰é…ç½®é›†ä¸­åœ¨config.py
- âœ… æ—¥å¿—ä¿¡æ¯å®Œæ•´æ¸…æ™°

### 5.3 ç‹¬ç«‹æ‰“åŒ…

- âœ… FFmpegä½¿ç”¨é¡¹ç›®å†…çš„ç‰ˆæœ¬
- âœ… æ¨¡å‹ä¸‹è½½åˆ°é¡¹ç›®ç›®å½•
- âœ… æ‰€æœ‰è·¯å¾„ä½¿ç”¨ç›¸å¯¹è·¯å¾„
- âœ… ç¯å¢ƒå˜é‡ä¸å½±å“è¿è¡Œ

---

## é™„å½•

### A. æµ‹è¯•æ£€æŸ¥æ¸…å•

æ¯å®Œæˆä¸€ä¸ªé˜¶æ®µï¼Œéƒ½è¦è¿è¡Œè¿™ä¸ªæ£€æŸ¥æ¸…å•ï¼š

```bash
# 1. å¯åŠ¨æµ‹è¯•
python backend/app/main.py
# âœ… èƒ½æ­£å¸¸å¯åŠ¨

# 2. ä¸Šä¼ æµ‹è¯•
# ä¸Šä¼  tests/fixtures/test_video.mp4
# âœ… ä¸Šä¼ æˆåŠŸ

# 3. è½¬å½•æµ‹è¯•
# å¼€å§‹è½¬å½•
# âœ… è½¬å½•å®Œæˆ

# 4. é»„é‡‘æ ‡å‡†æµ‹è¯•
python tests/test_golden_master.py
# âœ… æµ‹è¯•é€šè¿‡

# 5. æ–­ç‚¹ç»­ä¼ æµ‹è¯•ï¼ˆé˜¶æ®µ3åï¼‰
# å¼€å§‹è½¬å½• -> ä¸­æ–­ -> é‡å¯ -> æ¢å¤
# âœ… èƒ½ä»æ–­ç‚¹ç»§ç»­
```

### B. å¸¸è§é—®é¢˜

**Q1: é»„é‡‘æ ‡å‡†æµ‹è¯•å¤±è´¥æ€ä¹ˆåŠï¼Ÿ**

A: æ£€æŸ¥å·®å¼‚ï¼š
```bash
# å¯¹æ¯”æ–‡ä»¶
diff tests/fixtures/golden_standard.srt output/new.srt

# å¦‚æœåªæ˜¯æ—¶é—´æˆ³å¾®å°å·®å¼‚ï¼ˆ<100msï¼‰ï¼Œå¯ä»¥æ¥å—
# å¦‚æœæ–‡æœ¬å†…å®¹ä¸ä¸€è‡´ï¼Œè¯´æ˜é‡æ„æ”¹åäº†
```

**Q2: æ£€æŸ¥ç‚¹ä¿å­˜å¤±è´¥ï¼Ÿ**

A: æ£€æŸ¥ç›®å½•æƒé™ï¼š
```bash
# ç¡®ä¿jobsç›®å½•å¯å†™
ls -la jobs/

# æ£€æŸ¥æ£€æŸ¥ç‚¹æ–‡ä»¶
cat jobs/{job_id}/checkpoint.json
```

**Q3: FFmpegæ‰¾ä¸åˆ°ï¼Ÿ**

A: æ£€æŸ¥è·¯å¾„é…ç½®ï¼š
```python
from core.config import config
print(config.get_ffmpeg_command())
print(config.FFMPEG_EXE.exists())
```

---

**æ–‡æ¡£ç»“æŸ**

*è¿™ä»½è®¡åˆ’æ˜¯ä¸€ä¸ªå®æˆ˜æŒ‡å—ï¼Œè¾¹åšè¾¹è°ƒæ•´ã€‚ç¥é‡æ„é¡ºåˆ©ï¼* ğŸš€
