1.架构重构
你提到的 Bug（阻塞、无法断点续传）是架构设计问题。不要在 FastAPI 的路由函数或简单的 Thread 中跑 AI 推理。

1. 推荐架构：生产者-消费者模式 (Producer-Consumer)
目前的架构中，Web Server 和 AI Worker 耦合太紧。建议拆分：

数据库 (SQLite): 作为唯一的“事实来源”。记录任务状态（Pending, Processing, Completed, Failed）、进度百分比、文件路径。

Web 进程 (FastAPI):

只负责读写数据库。

用户上传 -> 存文件 -> 往数据库写一条 status='pending' 的记录 -> 返回 JobID。

用户查询进度 -> 读数据库 -> 返回 JSON。

完全不加载 PyTorch，秒启动。

Worker 进程 (独立 Python 进程):

这是唯一的“重型”进程，加载 PyTorch 和 Whisper。

死循环：检查数据库有没有 status='pending' 的任务 -> 取出一个 -> 标记为 processing -> 开始跑 -> 更新进度 -> 标记 completed。

优势: 即使 Web 服务挂了，Worker 还在跑；或者 Worker 崩了（显存溢出），Web 服务还能响应报错，甚至重启 Worker。

2. 解决具体 Bug 的技术手段
预加载阻塞主进程:

现状: backend/app/services/model_preload_manager.py 可能在主线程加载模型。

解决: 只有 Worker 进程才需要加载模型。Web 进程根本不需要加载模型，它只负责 UI 交互。

断点续传:

逻辑: 在 _split_audio (文档 6.2.2) 阶段，每处理完一段音频，就在数据库里记录一下 last_processed_segment_index。

重启时: 读取数据库，跳过已完成的 segments，直接从断点处继续 transcribe。

无法自动下载模型:

逻辑: 在 Worker 启动时，先进行网络检查。如果模型不存在，调用 huggingface_hub.snapshot_download 并捕获异常，如果下载失败，通过 websocket 或数据库状态明确告诉前端“下载失败，请检查网络或配置代理”，而不是直接崩溃。

目标: 解决 Bug，分离前后端，引入数据库。

动作:

引入 SQLModel (SQLite ORM)。

拆分 server.py (API) 和 worker.py (AI 推理)。

实现基于数据库的任务队列。

修复模型路径，全部改为相对路径配置。

实现 Worker 的自动重启机制和错误捕获。

2.将轮询改为sse

#### 后端改造 (FastAPI)

你需要引入 `sse-starlette` 库（FastAPI 推荐方案）或者直接使用 `StreamingResponse`。

**核心逻辑变更：**
目前的 `_update_progress` 只是修改内存中的变量。改为 SSE 后，你需要引入一个 **队列 (Queue)** 或 **生成器 (Generator)**。

```python
# 伪代码示例
import asyncio
from sse_starlette.sse import EventSourceResponse
from fastapi import Request

# 假设这是你的全局任务状态管理器
# 你需要在 transcription_service 里把进度写入一个 asyncio.Queue

async def status_stream(job_id: str, request: Request):
    """SSE 生成器"""
    while True:
        # 1. 检测客户端是否断开连接
        if await request.is_disconnected():
            break
            
        # 2. 获取当前任务状态 (这里最好是从 Redis 或 内存队列 获取)
        # 现在的做法是去 processor 查对象，依然可以沿用，但最好加个 await sleep 释放控制权
        job_status = processor.get_job_status(job_id) 
        
        # 3. 构建消息
        data = {
            "progress": job_status.progress,
            "phase": job_status.phase,
            "message": job_status.message,
            "status": job_status.status
        }
        
        # 4. 推送数据
        yield {
            "event": "update",  # 事件名
            "data": json.dumps(data)
        }
        
        # 5. 如果任务结束，发送最后一条并关闭
        if job_status.status in ["finished", "failed"]:
            yield {"event": "end", "data": "done"}
            break
            
        # 控制推送频率，避免太快，但比轮询的 1.5s 可以快得多，比如 0.1s
        await asyncio.sleep(0.5)

@app.get("/api/stream/{job_id}")
async def stream_status(job_id: str, request: Request):
    return EventSourceResponse(status_stream(job_id, request))
```

#### 前端改造 (Vue 3)

前端代码将从复杂的 `setTimeout` 递归调用 简化为事件监听。

```javascript
// 前端 Vue 组件伪代码
import { onUnmounted, ref } from 'vue'

const eventSource = ref(null)

const startMonitoring = (jobId) => {
    // 关闭旧连接
    if (eventSource.value) eventSource.value.close()
    
    // 建立 SSE 连接
    eventSource.value = new EventSource(`/api/stream/${jobId}`)
    
    // 监听进度更新
    eventSource.value.addEventListener('update', (event) => {
        const data = JSON.parse(event.data)
        progress.value = data.progress
        status.value = data.status
        // 实时日志
        logs.value.push(data.message) 
    })
    
    // 监听结束
    eventSource.value.addEventListener('end', () => {
        eventSource.value.close()
        // 触发下载逻辑
    })
    
    // 错误处理
    eventSource.value.onerror = (err) => {
        console.error("SSE Error", err)
        eventSource.value.close()
        // 可以保留一个低频轮询作为兜底降级策略
    }
}

onUnmounted(() => {
    if (eventSource.value) eventSource.value.close()
})
```

### 3\. 实施中的潜在坑点（如何避坑）

在你的重构规划中，如果你决定上 SSE，要注意以下几点：

1.  **Nginx 代理缓冲 (Buffering)**：

      * 如果你未来使用 Nginx 部署，Nginx 默认会缓存后端响应，导致 SSE 数据积压，最后一次性发给前端（失去了实时性）。
      * **解决**：需要在 Nginx 配置中关闭缓冲：`proxy_buffering off;`，或者在 FastAPI 响应头中添加 `X-Accel-Buffering: no`。

2.  **连接数限制**：

      * 浏览器对同一个域名的 HTTP/1.1 连接数有限制（通常 6 个）。如果用户同时开了 6 个标签页转录，第 7 个就会阻塞。
      * **解决**：这对桌面单用户应用一般不是问题。如果未来做多用户 Web 服务，建议上 HTTP/2，它支持多路复用，没有这个限制。

3.  **线程阻塞**：

      * 目前的 `_run_pipeline` 是在线程中运行的。SSE 接口必须是 `async` 的。在 `async` 函数中读取同步线程更新的变量是安全的，但要注意不要在 SSE 生成器里写阻塞代码（如 `time.sleep`），必须用 `asyncio.sleep`。

。