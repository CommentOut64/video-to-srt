# è§†é¢‘è½¬å½•ç³»ç»Ÿå†…å­˜ä¼˜åŒ–å®æ–½æ–¹æ¡ˆ V2.3

## ğŸ“‹ æ–¹æ¡ˆæ¦‚è¿°

### æ ¸å¿ƒç›®æ ‡

é€šè¿‡"**åŒæ¨¡å¼æ¶æ„**"å®ç°é«˜æ€§èƒ½è½¬å½•ä¸ç¨³å®šæ€§çš„å¹³è¡¡ï¼š
- âœ… **å†…å­˜æ¨¡å¼**ï¼ˆé»˜è®¤ï¼‰ï¼šä¸€æ¬¡åŠ è½½ + å†…å­˜åˆ‡ç‰‡ï¼Œæ¶ˆé™¤ç£ç›˜IOç“¶é¢ˆ
- âœ… **ç¡¬ç›˜æ¨¡å¼**ï¼ˆé™çº§ï¼‰ï¼šä¿ç•™åŸæœ‰åˆ†æ®µé€»è¾‘ï¼Œåº”å¯¹å†…å­˜ä¸è¶³åœºæ™¯
- âœ… **æ™ºèƒ½åˆ‡æ¢**ï¼šåŸºäºå®æ—¶å†…å­˜æ£€æµ‹ï¼Œè‡ªåŠ¨æ— æ„Ÿé™çº§
- âœ… **æ‰¹æ¬¡å¯¹é½**ï¼šå®æ—¶SSEè¿›åº¦æ¨é€ï¼Œå‰ç«¯è¿›åº¦æ¡æµç•…æ›´æ–°

### æ€§èƒ½é¢„æœŸ

| ä¼˜åŒ–é¡¹ | ç¡¬ç›˜æ¨¡å¼ï¼ˆåŸï¼‰ | å†…å­˜æ¨¡å¼ï¼ˆæ–°ï¼‰ | æ”¶ç›Š |
|--------|---------------|---------------|------|
| ç£ç›˜IOæ¬¡æ•°ï¼ˆ1hrè§†é¢‘ï¼‰ | ~120æ¬¡å†™å…¥+è¯»å– | 2æ¬¡å¤§æ–‡ä»¶è¯»å– | **å‡å°‘98%** |
| åˆ†æ®µé˜¶æ®µè€—æ—¶ | 10-30ç§’ | <2ç§’ | **5-15å€åŠ é€Ÿ** |
| å¯¹é½é˜¶æ®µè€—æ—¶ | é‡å¤åŠ è½½audio.wav | å¤ç”¨å†…å­˜æ•°ç»„ | **2-3å€åŠ é€Ÿ** |
| å†…å­˜å ç”¨ï¼ˆ1hrè§†é¢‘ï¼‰ | ~200MB + ä¸´æ—¶æ–‡ä»¶ | ~230MBçº¯å†…å­˜ | ç•¥å¢ä½†å¯æ§ |

### å†…å­˜æ¶ˆè€—ä¼°ç®—å…¬å¼
```
å†…å­˜éœ€æ±‚ (MB) = éŸ³é¢‘æ—¶é•¿(ç§’) Ã— 16000 Ã— 4 / 1024 / 1024
           â‰ˆ éŸ³é¢‘æ—¶é•¿(åˆ†é’Ÿ) Ã— 3.66 MB
```

| è§†é¢‘æ—¶é•¿ | ä¼°ç®—å†…å­˜éœ€æ±‚ | æ¨èæ¨¡å¼ |
|---------|-------------|---------|
| 30åˆ†é’Ÿ  | ~110 MB | å†…å­˜æ¨¡å¼ |
| 1å°æ—¶   | ~220 MB | å†…å­˜æ¨¡å¼ |
| 2å°æ—¶   | ~440 MB | å†…å­˜æ¨¡å¼ |
| 3å°æ—¶   | ~660 MB | å†…å­˜æ¨¡å¼ï¼ˆ8GB+ç³»ç»Ÿï¼‰ |
| 5å°æ—¶+  | >1.1 GB | ç¡¬ç›˜æ¨¡å¼ï¼ˆè‡ªåŠ¨é™çº§ï¼‰ |

---

## ğŸ—ï¸ åŒæ¨¡å¼æ¶æ„è®¾è®¡

### æ¶æ„æ€»è§ˆ
```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚         _run_pipeline å…¥å£          â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚      Phase 1: æå–éŸ³é¢‘ (FFmpeg)     â”‚
                    â”‚         â†’ audio.wav                 â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚      ğŸ†• å†…å­˜æ£€æµ‹ä¸æ¨¡å¼å†³ç­–          â”‚
                    â”‚   _decide_processing_mode()         â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â†“              â†“
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   å†…å­˜æ¨¡å¼ (é»˜è®¤)   â”‚  â”‚  ç¡¬ç›˜æ¨¡å¼ (é™çº§)   â”‚
              â”‚  use_memory=True   â”‚  â”‚  use_memory=False  â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“                       â†“
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  whisperx.load_    â”‚  â”‚  ä¿ç•™åŸaudio.wav   â”‚
              â”‚  audio() åŠ è½½åˆ°    â”‚  â”‚  ä¸åŠ è½½åˆ°å†…å­˜      â”‚
              â”‚  audio_array       â”‚  â”‚                    â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“                       â†“
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ Phase 2: VADåˆ†æ®µ   â”‚  â”‚ Phase 2: pydubåˆ†æ®µ â”‚
              â”‚ _split_in_memory() â”‚  â”‚ _split_to_disk()   â”‚
              â”‚ çº¯å†…å­˜å…ƒæ•°æ®       â”‚  â”‚ segment_N.wavæ–‡ä»¶  â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“                       â†“
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â†“
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  ğŸ”’ å¼ºåˆ¶åˆ·æ–° checkpoint.jsonï¼ˆåˆ†æ®µå…ƒæ•°æ®ï¼‰  â”‚
              â”‚     ç¡®ä¿æ–­ç‚¹ç»­ä¼ çš„ç»å¯¹ä¸€è‡´æ€§                â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ Phase 3: å†…å­˜åˆ‡ç‰‡  â”‚  â”‚ Phase 3: æ–‡ä»¶è¯»å–  â”‚
              â”‚ è½¬å½• (Zero-copy)   â”‚  â”‚ è½¬å½•               â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“                       â†“
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â†“
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚     Phase 4: æ‰¹æ¬¡å¯¹é½ + SSEå®æ—¶è¿›åº¦æ¨é€     â”‚
              â”‚     _align_batched() + _push_align_progress â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚              Phase 5: ç”ŸæˆSRT               â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ Phase 1: éŸ³é¢‘æå–ï¼ˆä¿æŒä¸å˜ï¼‰

**ä½ç½®ï¼š** `transcription_service.py` â†’ `_extract_audio()`

æ­¤é˜¶æ®µé€»è¾‘ä¸å˜ï¼Œç»§ç»­ä½¿ç”¨FFmpegæå–éŸ³é¢‘ä¸º `audio.wav`ã€‚

**æµ‹è¯•ç‚¹ï¼š**

- âœ… FFmpegæ­£å¸¸æå–
- âœ… è¾“å‡ºæ–‡ä»¶å­˜åœ¨æ€§æ£€æŸ¥
- âœ… è¶…æ—¶å¤„ç†ï¼ˆ10åˆ†é’Ÿï¼‰

---

## ğŸ”§ Phase 2: æ™ºèƒ½æ¨¡å¼å†³ç­–ä¸åˆ†æ®µ

### 2.1 å†…å­˜æ£€æµ‹ä¸æ¨¡å¼å†³ç­–

**æ–°å¢æ–¹æ³•ï¼š** `_decide_processing_mode()`

```python
import psutil
from enum import Enum

class ProcessingMode(Enum):
    """å¤„ç†æ¨¡å¼æšä¸¾"""
    MEMORY = "memory"  # å†…å­˜æ¨¡å¼ï¼ˆé»˜è®¤ï¼Œé«˜æ€§èƒ½ï¼‰
    DISK = "disk"      # ç¡¬ç›˜æ¨¡å¼ï¼ˆé™çº§ï¼Œç¨³å®šæ€§ä¼˜å…ˆï¼‰


def _decide_processing_mode(self, audio_path: str, job: JobState) -> ProcessingMode:
    """
    æ™ºèƒ½å†³ç­–å¤„ç†æ¨¡å¼ï¼ˆå†…å­˜æ¨¡å¼ vs ç¡¬ç›˜æ¨¡å¼ï¼‰

    å†³ç­–é€»è¾‘ï¼š
    1. ä¼°ç®—éŸ³é¢‘å†…å­˜éœ€æ±‚
    2. æ£€æµ‹ç³»ç»Ÿå¯ç”¨å†…å­˜
    3. é¢„ç•™å®‰å…¨ä½™é‡ï¼ˆæ¨¡å‹ã€è½¬å½•ä¸­é—´å˜é‡ç­‰ï¼‰
    4. å†³å®šä½¿ç”¨å“ªç§æ¨¡å¼

    Args:
        audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        job: ä»»åŠ¡çŠ¶æ€å¯¹è±¡

    Returns:
        ProcessingMode: å¤„ç†æ¨¡å¼
    """
    # è·å–éŸ³é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰
    audio_duration_sec = self._get_audio_duration(audio_path)

    # ä¼°ç®—éŸ³é¢‘å†…å­˜éœ€æ±‚ (16kHz, float32)
    # å…¬å¼: duration * 16000 * 4 bytes
    estimated_audio_mb = (audio_duration_sec * 16000 * 4) / (1024 * 1024)

    # é¢„ç•™é¢å¤–å†…å­˜ï¼ˆæ¨¡å‹åŠ è½½ã€VADå¤„ç†ã€è½¬å½•ä¸­é—´å˜é‡ç­‰ï¼‰
    # ä¿å®ˆä¼°è®¡ï¼šéŸ³é¢‘å†…å­˜çš„2å€ + 500MBåŸºç¡€å¼€é”€
    total_estimated_mb = estimated_audio_mb * 2 + 500

    # è·å–ç³»ç»Ÿå¯ç”¨å†…å­˜
    mem_info = psutil.virtual_memory()
    available_mb = mem_info.available / (1024 * 1024)
    total_mb = mem_info.total / (1024 * 1024)

    # å®‰å…¨é˜ˆå€¼ï¼šè‡³å°‘ä¿ç•™ç³»ç»Ÿæ€»å†…å­˜çš„20%æˆ–2GBï¼ˆå–è¾ƒå¤§å€¼ï¼‰
    safety_reserve_mb = max(total_mb * 0.2, 2048)
    usable_mb = available_mb - safety_reserve_mb

    self.logger.info(f"ğŸ“Š å†…å­˜è¯„ä¼°:")
    self.logger.info(f"   éŸ³é¢‘æ—¶é•¿: {audio_duration_sec/60:.1f}åˆ†é’Ÿ")
    self.logger.info(f"   é¢„ä¼°éœ€æ±‚: {total_estimated_mb:.0f}MB")
    self.logger.info(f"   å¯ç”¨å†…å­˜: {available_mb:.0f}MB")
    self.logger.info(f"   å®‰å…¨ä½™é‡: {safety_reserve_mb:.0f}MB")
    self.logger.info(f"   å¯ç”¨äºå¤„ç†: {usable_mb:.0f}MB")

    # å†³ç­–
    if usable_mb >= total_estimated_mb:
        self.logger.info("âœ… é€‰æ‹©ã€å†…å­˜æ¨¡å¼ã€‘- å†…å­˜å……è¶³ï¼Œä½¿ç”¨é«˜æ€§èƒ½æ¨¡å¼")
        job.message = "å†…å­˜å……è¶³ï¼Œä½¿ç”¨é«˜æ€§èƒ½æ¨¡å¼"
        return ProcessingMode.MEMORY
    else:
        self.logger.warning(f"âš ï¸ é€‰æ‹©ã€ç¡¬ç›˜æ¨¡å¼ã€‘- å†…å­˜ä¸è¶³ï¼ˆéœ€è¦{total_estimated_mb:.0f}MBï¼Œå¯ç”¨{usable_mb:.0f}MBï¼‰")
        job.message = "å†…å­˜å—é™ï¼Œä½¿ç”¨ç¨³å®šæ¨¡å¼"
        return ProcessingMode.DISK


def _get_audio_duration(self, audio_path: str) -> float:
    """
    è·å–éŸ³é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰

    Args:
        audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„

    Returns:
        float: éŸ³é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰
    """
    try:
        # æ–¹æ³•1: ä½¿ç”¨pydubï¼ˆç²¾ç¡®ä½†è¾ƒæ…¢ï¼‰
        from pydub import AudioSegment
        audio = AudioSegment.from_wav(audio_path)
        return len(audio) / 1000.0
    except Exception as e:
        self.logger.warning(f"pydubè·å–æ—¶é•¿å¤±è´¥ï¼Œä½¿ç”¨æ–‡ä»¶å¤§å°ä¼°ç®—: {e}")
        # æ–¹æ³•2: æ ¹æ®æ–‡ä»¶å¤§å°ä¼°ç®—ï¼ˆ16kHz, 16bit, mono â‰ˆ 32KB/ç§’ï¼‰
        import os
        file_size = os.path.getsize(audio_path)
        return file_size / 32000
```

### 2.2 å®‰å…¨åŠ è½½éŸ³é¢‘åˆ°å†…å­˜

**æ–°å¢æ–¹æ³•ï¼š** `_safe_load_audio()`

```python
def _safe_load_audio(self, audio_path: str, job: JobState) -> Optional[np.ndarray]:
    """
    å®‰å…¨åŠ è½½éŸ³é¢‘åˆ°å†…å­˜ï¼ˆå¸¦å¼‚å¸¸å¤„ç†ï¼‰

    Args:
        audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        job: ä»»åŠ¡çŠ¶æ€å¯¹è±¡

    Returns:
        np.ndarray: éŸ³é¢‘æ•°ç»„ï¼Œå¤±è´¥è¿”å›None

    Raises:
        RuntimeError: éŸ³é¢‘åŠ è½½å¤±è´¥æ—¶æŠ›å‡ºï¼Œè§¦å‘é™çº§
    """
    try:
        self.logger.info(f"ğŸ”„ åŠ è½½éŸ³é¢‘åˆ°å†…å­˜: {audio_path}")
        audio_array = whisperx.load_audio(audio_path)

        # éªŒè¯åŠ è½½ç»“æœ
        if audio_array is None or len(audio_array) == 0:
            raise ValueError("éŸ³é¢‘æ•°ç»„ä¸ºç©º")

        # è®°å½•åŠ è½½ä¿¡æ¯
        duration_sec = len(audio_array) / 16000
        memory_mb = audio_array.nbytes / (1024 * 1024)
        self.logger.info(f"âœ… éŸ³é¢‘åŠ è½½æˆåŠŸ:")
        self.logger.info(f"   æ—¶é•¿: {duration_sec/60:.1f}åˆ†é’Ÿ")
        self.logger.info(f"   å†…å­˜å ç”¨: {memory_mb:.1f}MB")
        self.logger.info(f"   é‡‡æ ·ç‚¹æ•°: {len(audio_array):,}")

        return audio_array

    except MemoryError as e:
        self.logger.error(f"âŒ å†…å­˜ä¸è¶³ï¼Œæ— æ³•åŠ è½½éŸ³é¢‘: {e}")
        job.message = "å†…å­˜ä¸è¶³ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°ç¡¬ç›˜æ¨¡å¼"
        raise RuntimeError(f"å†…å­˜ä¸è¶³: {e}")

    except Exception as e:
        self.logger.error(f"âŒ éŸ³é¢‘åŠ è½½å¤±è´¥: {e}")
        job.message = f"éŸ³é¢‘åŠ è½½å¤±è´¥: {e}"
        raise RuntimeError(f"éŸ³é¢‘åŠ è½½å¤±è´¥ï¼ˆå¯èƒ½æ–‡ä»¶æŸåï¼‰: {e}")
```

### 2.3 VADæ¨¡å‹é…ç½®

#### VADæ¨¡å‹å¯¹æ¯”

| ç‰¹æ€§ | Silero VADï¼ˆé»˜è®¤ï¼‰ | Pyannote VADï¼ˆå¯é€‰ï¼‰ |
|------|-------------------|---------------------|
| è®¤è¯éœ€æ±‚ | **æ— éœ€è®¤è¯** | éœ€è¦HuggingFace Token |
| ä¸‹è½½æ–¹å¼ | torch.hubè‡ªåŠ¨ä¸‹è½½ | éœ€è¦æ¥å—åè®®åä¸‹è½½ |
| å‡†ç¡®åº¦ | è‰¯å¥½ | æ›´é«˜ |
| é€Ÿåº¦ | **æ›´å¿«** | è¾ƒæ…¢ |
| å†…å­˜å ç”¨ | **æ›´ä½** | GPUå ç”¨è¾ƒé«˜ |
| æ¨èåœºæ™¯ | é»˜è®¤ä½¿ç”¨ | è¿½æ±‚æœ€é«˜ç²¾åº¦æ—¶å¯ç”¨ |

#### VADé…ç½®æšä¸¾

```python
from enum import Enum

class VADMethod(Enum):
    """VADæ¨¡å‹é€‰æ‹©"""
    SILERO = "silero"      # é»˜è®¤ï¼Œæ— éœ€è®¤è¯ï¼Œé€Ÿåº¦å¿«
    PYANNOTE = "pyannote"  # å¯é€‰ï¼Œéœ€è¦HF Tokenï¼Œç²¾åº¦æ›´é«˜
```

#### VADé…ç½®æ•°æ®ç»“æ„

```python
from dataclasses import dataclass
from typing import Optional

@dataclass
class VADConfig:
    """VADé…ç½®ï¼ˆç”¨äºè®¾ç½®ç•Œé¢ï¼‰"""
    method: VADMethod = VADMethod.SILERO  # é»˜è®¤ä½¿ç”¨Silero
    hf_token: Optional[str] = None         # Pyannoteéœ€è¦çš„HF Token
    onset: float = 0.5                     # è¯­éŸ³å¼€å§‹é˜ˆå€¼
    offset: float = 0.363                  # è¯­éŸ³ç»“æŸé˜ˆå€¼
    chunk_size: int = 30                   # æœ€å¤§æ®µé•¿ï¼ˆç§’ï¼‰

    def validate(self) -> bool:
        """éªŒè¯é…ç½®æœ‰æ•ˆæ€§"""
        if self.method == VADMethod.PYANNOTE and not self.hf_token:
            return False  # Pyannoteéœ€è¦Token
        return True
```

#### å‰ç«¯è®¾ç½®ç•Œé¢æ¥å£ï¼ˆé¢„ç•™ï¼‰

**APIç«¯ç‚¹ï¼š** `POST /api/settings/vad`

```typescript
// å‰ç«¯è¯·æ±‚ä½“
interface VADSettingsRequest {
  method: "silero" | "pyannote";
  hf_token?: string;  // ä»…å½“method="pyannote"æ—¶éœ€è¦
  onset?: number;     // å¯é€‰ï¼Œé»˜è®¤0.5
  offset?: number;    // å¯é€‰ï¼Œé»˜è®¤0.363
}

// å‰ç«¯é€»è¾‘ï¼ˆä¼ªä»£ç ï¼‰
function onVADMethodChange(method: string) {
  if (method === "pyannote") {
    // å¼¹çª—æç¤ºè¾“å…¥HuggingFace Token
    showDialog({
      title: "å¯ç”¨Pyannote VAD",
      message: "Pyannote VADç²¾åº¦æ›´é«˜ï¼Œä½†éœ€è¦HuggingFace Tokenæ‰èƒ½ä¸‹è½½æ¨¡å‹ã€‚",
      input: {
        label: "HuggingFace Token",
        placeholder: "hf_xxxxxxxxxxxx",
        type: "password"
      },
      links: [
        { text: "å¦‚ä½•è·å–Token?", url: "https://huggingface.co/settings/tokens" }
      ],
      onConfirm: (token) => saveVADSettings({ method: "pyannote", hf_token: token }),
      onCancel: () => revertToSilero()
    });
  } else {
    // ç›´æ¥ä¿å­˜Sileroé…ç½®
    saveVADSettings({ method: "silero" });
  }
}
```

### 2.4 å†…å­˜æ¨¡å¼ï¼šVADåˆ†æ®µ

**æ–°å¢æ–¹æ³•ï¼š** `_split_audio_in_memory()`

```python
def _split_audio_in_memory(
    self,
    audio_array: np.ndarray,
    sr: int = 16000,
    vad_config: Optional[VADConfig] = None
) -> List[Dict]:
    """
    å†…å­˜VADåˆ†æ®µï¼ˆä¸äº§ç”Ÿç£ç›˜IOï¼‰

    é»˜è®¤ä½¿ç”¨Silero VADï¼ˆæ— éœ€è®¤è¯ï¼‰ï¼Œå¯é€šè¿‡é…ç½®åˆ‡æ¢åˆ°Pyannote VADã€‚

    Args:
        audio_array: å®Œæ•´éŸ³é¢‘æ•°ç»„ (np.ndarray, float32, 16kHz)
        sr: é‡‡æ ·ç‡ï¼ˆé»˜è®¤16000Hzï¼‰
        vad_config: VADé…ç½®ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨Sileroï¼‰

    Returns:
        List[Dict]: åˆ†æ®µå…ƒæ•°æ®åˆ—è¡¨
        [
            {"index": 0, "start": 0.0, "end": 30.5, "mode": "memory"},
            {"index": 1, "start": 30.5, "end": 58.2, "mode": "memory"},
            ...
        ]
    """
    import torch

    # ä½¿ç”¨é»˜è®¤é…ç½®
    if vad_config is None:
        vad_config = VADConfig()  # é»˜è®¤Silero

    self.logger.info(f"ğŸ” å¼€å§‹å†…å­˜VADåˆ†æ®µ (æ¨¡å‹: {vad_config.method.value})...")

    try:
        # æ ¹æ®é…ç½®é€‰æ‹©VADæ¨¡å‹
        if vad_config.method == VADMethod.SILERO:
            segments = self._vad_silero(audio_array, sr, vad_config)
        else:
            segments = self._vad_pyannote(audio_array, sr, vad_config)

        self.logger.info(f"âœ… VADåˆ†æ®µå®Œæˆ: {len(segments)}æ®µ (æ¨¡å‹: {vad_config.method.value})")
        return segments

    except Exception as e:
        self.logger.error(f"âŒ VADåˆ†æ®µå¤±è´¥: {e}")
        # é™çº§åˆ°ç®€æ˜“èƒ½é‡æ£€æµ‹
        self.logger.warning("âš ï¸ å°è¯•é™çº§åˆ°èƒ½é‡æ£€æµ‹åˆ†æ®µ...")
        return self._energy_based_split(audio_array, sr, vad_config.chunk_size)


def _vad_silero(
    self,
    audio_array: np.ndarray,
    sr: int,
    vad_config: VADConfig
) -> List[Dict]:
    """
    Silero VADåˆ†æ®µï¼ˆé»˜è®¤æ–¹æ¡ˆï¼Œæ— éœ€è®¤è¯ï¼‰

    ä¼˜ç‚¹ï¼š
    - æ— éœ€HuggingFace Token
    - é€šè¿‡torch.hubè‡ªåŠ¨ä¸‹è½½
    - é€Ÿåº¦å¿«ï¼Œå†…å­˜å ç”¨ä½
    """
    import torch

    self.logger.info("ğŸ“¦ åŠ è½½Silero VADæ¨¡å‹...")

    # ä»torch.hubåŠ è½½Silero VAD
    model, utils = torch.hub.load(
        repo_or_dir='snakers4/silero-vad',
        model='silero_vad',
        force_reload=False,
        onnx=False
    )

    (get_speech_timestamps, _, read_audio, _, _) = utils

    # è½¬æ¢ä¸ºtorch tensor
    audio_tensor = torch.from_numpy(audio_array)

    # è·å–è¯­éŸ³æ—¶é—´æˆ³
    speech_timestamps = get_speech_timestamps(
        audio_tensor,
        model,
        sampling_rate=sr,
        threshold=vad_config.onset,  # æ£€æµ‹é˜ˆå€¼
        min_speech_duration_ms=250,   # æœ€å°è¯­éŸ³æ®µé•¿åº¦
        min_silence_duration_ms=100,  # æœ€å°é™éŸ³é•¿åº¦
    )

    # åˆå¹¶åˆ†æ®µï¼ˆç¡®ä¿æ¯æ®µä¸è¶…è¿‡chunk_sizeç§’ï¼‰
    segments_metadata = []
    current_start = None
    current_end = None

    for ts in speech_timestamps:
        start_sec = ts['start'] / sr
        end_sec = ts['end'] / sr

        if current_start is None:
            current_start = start_sec
            current_end = end_sec
        elif (end_sec - current_start) <= vad_config.chunk_size:
            # å¯ä»¥åˆå¹¶
            current_end = end_sec
        else:
            # ä¿å­˜å½“å‰æ®µï¼Œå¼€å§‹æ–°æ®µ
            segments_metadata.append({
                "index": len(segments_metadata),
                "start": current_start,
                "end": current_end,
                "mode": "memory"
            })
            current_start = start_sec
            current_end = end_sec

    # ä¿å­˜æœ€åä¸€æ®µ
    if current_start is not None:
        segments_metadata.append({
            "index": len(segments_metadata),
            "start": current_start,
            "end": current_end,
            "mode": "memory"
        })

    return segments_metadata


def _vad_pyannote(
    self,
    audio_array: np.ndarray,
    sr: int,
    vad_config: VADConfig
) -> List[Dict]:
    """
    Pyannote VADåˆ†æ®µï¼ˆé«˜ç²¾åº¦æ–¹æ¡ˆï¼Œéœ€è¦HF Tokenï¼‰

    ä¼˜ç‚¹ï¼š
    - ç²¾åº¦æ›´é«˜
    - æ”¯æŒæ›´å¤æ‚çš„è¯­éŸ³æ´»åŠ¨æ£€æµ‹

    æ³¨æ„ï¼š
    - éœ€è¦HuggingFace Token
    - é¦–æ¬¡ä½¿ç”¨éœ€è¦æ¥å—æ¨¡å‹ä½¿ç”¨åè®®
    """
    import torch
    from whisperx.vads import Pyannote

    if not vad_config.hf_token:
        raise ValueError("Pyannote VADéœ€è¦HuggingFace Tokenï¼Œè¯·åœ¨è®¾ç½®ä¸­é…ç½®")

    self.logger.info("ğŸ“¦ åŠ è½½Pyannote VADæ¨¡å‹ï¼ˆéœ€è¦HF Tokenï¼‰...")

    # åˆå§‹åŒ–Pyannote VAD
    vad_model = Pyannote(
        vad_onset=vad_config.onset,
        vad_offset=vad_config.offset,
        use_auth_token=vad_config.hf_token,
        device=torch.device("cpu")  # ä½¿ç”¨CPUé¿å…å ç”¨GPUæ˜¾å­˜
    )

    # å‡†å¤‡è¾“å…¥
    audio_tensor = torch.from_numpy(audio_array).unsqueeze(0)

    # æ‰§è¡ŒVAD
    vad_segments = vad_model({
        "waveform": audio_tensor,
        "sample_rate": sr
    })

    # åˆå¹¶åˆ†æ®µ
    merged = Pyannote.merge_chunks(
        vad_segments,
        chunk_size=vad_config.chunk_size,
        onset=vad_config.onset,
        offset=vad_config.offset
    )

    # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
    segments_metadata = []
    for idx, seg in enumerate(merged):
        segments_metadata.append({
            "index": idx,
            "start": float(seg["start"]),
            "end": float(seg["end"]),
            "mode": "memory"
        })

    return segments_metadata


def _energy_based_split(
    self,
    audio_array: np.ndarray,
    sr: int,
    chunk_size: int = 30
) -> List[Dict]:
    """
    åŸºäºèƒ½é‡çš„ç®€æ˜“åˆ†æ®µï¼ˆé™çº§æ–¹æ¡ˆï¼‰

    å½“VADæ¨¡å‹åŠ è½½å¤±è´¥æ—¶ä½¿ç”¨ï¼ŒæŒ‰å›ºå®šæ—¶é•¿åˆ†æ®µã€‚
    """
    self.logger.warning("âš ï¸ ä½¿ç”¨èƒ½é‡æ£€æµ‹é™çº§åˆ†æ®µï¼ˆå›ºå®šæ—¶é•¿ï¼‰")

    total_duration = len(audio_array) / sr
    segments_metadata = []
    pos = 0.0

    while pos < total_duration:
        end = min(pos + chunk_size, total_duration)
        segments_metadata.append({
            "index": len(segments_metadata),
            "start": pos,
            "end": end,
            "mode": "memory"
        })
        pos = end

    return segments_metadata
```

### 2.5 ç¡¬ç›˜æ¨¡å¼ï¼šä¿ç•™åŸæœ‰pydubåˆ†æ®µ

**æ•´ç†ç°æœ‰æ–¹æ³•ï¼š** `_split_audio_to_disk()`

```python
def _split_audio_to_disk(self, audio_path: str) -> List[Dict]:
    """
    ç¡¬ç›˜åˆ†æ®µæ¨¡å¼ï¼ˆä¿ç•™åŸæœ‰é€»è¾‘ï¼‰

    ä½¿ç”¨pydubè¿›è¡Œé™éŸ³æ£€æµ‹ï¼Œç”Ÿæˆsegment_N.wavæ–‡ä»¶ã€‚
    é€‚ç”¨äºå†…å­˜ä¸è¶³çš„åœºæ™¯ã€‚

    Args:
        audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„

    Returns:
        List[Dict]: åˆ†æ®µä¿¡æ¯åˆ—è¡¨
        [
            {"index": 0, "file": "segment_0.wav", "start": 0.0, "end": 30.0, "mode": "disk"},
            ...
        ]
    """
    from pydub import AudioSegment, silence

    self.logger.info("ğŸ“€ å¼€å§‹ç¡¬ç›˜åˆ†æ®µï¼ˆpydubé™éŸ³æ£€æµ‹ï¼‰...")

    # ä½¿ç”¨é…ç½®ä¸­çš„éŸ³é¢‘å¤„ç†å‚æ•°
    audio_config = config.get_audio_config()
    SEGMENT_LEN_MS = audio_config['segment_length_ms']
    SILENCE_SEARCH_MS = audio_config['silence_search_ms']
    MIN_SILENCE_LEN_MS = audio_config['min_silence_len_ms']
    SILENCE_THRESH_DBFS = audio_config['silence_threshold_dbfs']

    audio = AudioSegment.from_wav(audio_path)
    length = len(audio)
    segments = []
    pos = 0
    idx = 0

    while pos < length:
        end = min(pos + SEGMENT_LEN_MS, length)

        # æ™ºèƒ½å¯»æ‰¾é™éŸ³ç‚¹
        if end < length and (end - pos) > SILENCE_SEARCH_MS:
            search_start = max(pos, end - SILENCE_SEARCH_MS)
            search_chunk = audio[search_start:end]

            try:
                silences = silence.detect_silence(
                    search_chunk,
                    min_silence_len=MIN_SILENCE_LEN_MS,
                    silence_thresh=SILENCE_THRESH_DBFS
                )
                if silences:
                    silence_start = silences[0][0]
                    new_end = search_start + silence_start
                    if new_end - pos > MIN_SILENCE_LEN_MS:
                        end = new_end
            except Exception as e:
                self.logger.warning(f"é™éŸ³æ£€æµ‹å¤±è´¥: {e}")

        # å¯¼å‡ºåˆ†æ®µæ–‡ä»¶
        chunk = audio[pos:end]
        seg_file = os.path.join(os.path.dirname(audio_path), f'segment_{idx}.wav')
        chunk.export(seg_file, format='wav')

        segments.append({
            'index': idx,
            'file': seg_file,
            'start': pos / 1000.0,       # è½¬æ¢ä¸ºç§’
            'end': end / 1000.0,         # è½¬æ¢ä¸ºç§’
            'mode': 'disk'               # æ ‡è®°æ¨¡å¼
        })

        pos = end
        idx += 1

    self.logger.info(f"âœ… ç¡¬ç›˜åˆ†æ®µå®Œæˆ: {len(segments)}æ®µ (ç”Ÿæˆsegmentæ–‡ä»¶)")
    return segments
```

### 2.6 åˆ†æ®µåå¼ºåˆ¶åˆ·æ–°Checkpoint

**å…³é”®è¦æ±‚ï¼š** VADåˆ†æ®µå®Œæˆåï¼Œå¿…é¡»**ç«‹å³**å°†åˆ†æ®µå…ƒæ•°æ®æŒä¹…åŒ–åˆ°ç£ç›˜ã€‚

```python
def _flush_checkpoint_after_split(
    self,
    job_dir: Path,
    job: JobState,
    segments: List[Dict],
    processing_mode: ProcessingMode
):
    """
    åˆ†æ®µå®Œæˆåå¼ºåˆ¶åˆ·æ–°checkpointï¼ˆç¡®ä¿æ–­ç‚¹ç»­ä¼ ä¸€è‡´æ€§ï¼‰

    âš ï¸ é‡è¦ï¼šè¿™æ˜¯æ–­ç‚¹ç»­ä¼ çš„å…³é”®èŠ‚ç‚¹ï¼
    åªæœ‰åˆ†æ®µå…ƒæ•°æ®è¢«æŒä¹…åŒ–åï¼Œåç»­çš„è½¬å½•ç´¢å¼•æ‰æœ‰æ„ä¹‰ã€‚

    Args:
        job_dir: ä»»åŠ¡ç›®å½•
        job: ä»»åŠ¡çŠ¶æ€å¯¹è±¡
        segments: åˆ†æ®µå…ƒæ•°æ®åˆ—è¡¨
        processing_mode: å½“å‰å¤„ç†æ¨¡å¼
    """
    checkpoint_data = {
        "job_id": job.job_id,
        "phase": "split_complete",  # æ˜ç¡®æ ‡è®°åˆ†æ®µå®Œæˆ
        "processing_mode": processing_mode.value,  # è®°å½•æ¨¡å¼
        "total_segments": len(segments),
        "processed_indices": [],
        "segments": segments,
        "unaligned_results": [],
        "timestamp": time.time()  # æ—¶é—´æˆ³ç”¨äºè°ƒè¯•
    }

    # å¼ºåˆ¶åŒæ­¥å†™å…¥ï¼ˆç¡®ä¿æ•°æ®è½ç›˜ï¼‰
    self._save_checkpoint(job_dir, checkpoint_data, job)

    # éªŒè¯å†™å…¥æˆåŠŸ
    saved_checkpoint = self._load_checkpoint(job_dir)
    if saved_checkpoint is None or saved_checkpoint.get('phase') != 'split_complete':
        raise RuntimeError("âŒ checkpointå†™å…¥éªŒè¯å¤±è´¥ï¼Œæ— æ³•ç»§ç»­")

    self.logger.info(f"ğŸ’¾ âœ… åˆ†æ®µcheckpointå·²å¼ºåˆ¶åˆ·æ–°å¹¶éªŒè¯ (æ¨¡å¼: {processing_mode.value})")
```

---

## ğŸ”§ Phase 3: è½¬å½•å¤„ç†

### 3.1 å†…å­˜æ¨¡å¼ï¼šåˆ‡ç‰‡è½¬å½•

**æ–°å¢æ–¹æ³•ï¼š** `_transcribe_segment_in_memory()`

```python
def _transcribe_segment_in_memory(
    self,
    audio_array: np.ndarray,
    seg_meta: Dict,
    model,
    job: JobState
) -> Optional[Dict]:
    """
    ä»å†…å­˜åˆ‡ç‰‡è½¬å½•ï¼ˆZero-copyï¼Œé«˜æ€§èƒ½ï¼‰

    Args:
        audio_array: å®Œæ•´éŸ³é¢‘æ•°ç»„
        seg_meta: åˆ†æ®µå…ƒæ•°æ® {"index": 0, "start": 0.0, "end": 30.5, "mode": "memory"}
        model: Whisperæ¨¡å‹
        job: ä»»åŠ¡çŠ¶æ€

    Returns:
        Dict: æœªå¯¹é½çš„è½¬å½•ç»“æœ
    """
    sr = 16000
    start_sample = int(seg_meta['start'] * sr)
    end_sample = int(seg_meta['end'] * sr)

    # Zero-copyåˆ‡ç‰‡ï¼ˆnumpy viewï¼Œä¸å¤åˆ¶æ•°æ®ï¼‰
    audio_slice = audio_array[start_sample:end_sample]

    try:
        # Whisperè½¬å½•
        rs = model.transcribe(
            audio_slice,
            batch_size=job.settings.batch_size,
            verbose=False,
            language=job.language
        )

        if not rs or 'segments' not in rs:
            return None

        # æ£€æµ‹è¯­è¨€
        if not job.language and 'language' in rs:
            job.language = rs['language']
            self.logger.info(f"ğŸŒ æ£€æµ‹åˆ°è¯­è¨€: {job.language}")

        # æ—¶é—´åç§»æ ¡æ­£
        start_offset = seg_meta['start']
        adjusted_segments = []

        for idx, s in enumerate(rs['segments']):
            adjusted_segments.append({
                'id': idx,
                'start': s.get('start', 0) + start_offset,
                'end': s.get('end', 0) + start_offset,
                'text': s.get('text', '').strip()
            })

        return {
            'segment_index': seg_meta['index'],
            'language': rs.get('language', job.language),
            'segments': adjusted_segments
        }

    finally:
        del audio_slice
        gc.collect()
```

### 3.2 ç¡¬ç›˜æ¨¡å¼ï¼šæ–‡ä»¶è½¬å½•ï¼ˆä¿ç•™åŸé€»è¾‘ï¼‰

**æ•´ç†ç°æœ‰æ–¹æ³•ï¼š** `_transcribe_segment_from_disk()`

```python
def _transcribe_segment_from_disk(
    self,
    seg: Dict,
    model,
    job: JobState
) -> Optional[Dict]:
    """
    ä»æ–‡ä»¶åŠ è½½è½¬å½•ï¼ˆç¡¬ç›˜æ¨¡å¼ï¼‰

    Args:
        seg: åˆ†æ®µä¿¡æ¯ {"file": "segment_0.wav", "start": 0.0, "end": 30.0, "mode": "disk"}
        model: Whisperæ¨¡å‹
        job: ä»»åŠ¡çŠ¶æ€

    Returns:
        Dict: æœªå¯¹é½çš„è½¬å½•ç»“æœ
    """
    audio = whisperx.load_audio(seg['file'])

    try:
        rs = model.transcribe(
            audio,
            batch_size=job.settings.batch_size,
            verbose=False,
            language=job.language
        )

        if not rs or 'segments' not in rs:
            return None

        if not job.language and 'language' in rs:
            job.language = rs['language']
            self.logger.info(f"ğŸŒ æ£€æµ‹åˆ°è¯­è¨€: {job.language}")

        start_offset = seg['start']
        adjusted_segments = []

        for idx, s in enumerate(rs['segments']):
            adjusted_segments.append({
                'id': idx,
                'start': s.get('start', 0) + start_offset,
                'end': s.get('end', 0) + start_offset,
                'text': s.get('text', '').strip()
            })

        return {
            'segment_index': seg['index'],
            'language': rs.get('language', job.language),
            'segments': adjusted_segments
        }

    finally:
        del audio
        gc.collect()
```

### 3.3 ç»Ÿä¸€è½¬å½•å…¥å£

```python
def _transcribe_segment(
    self,
    seg_meta: Dict,
    model,
    job: JobState,
    audio_array: Optional[np.ndarray] = None
) -> Optional[Dict]:
    """
    ç»Ÿä¸€è½¬å½•å…¥å£ï¼ˆæ ¹æ®æ¨¡å¼è‡ªåŠ¨é€‰æ‹©ï¼‰

    Args:
        seg_meta: åˆ†æ®µå…ƒæ•°æ®
        model: Whisperæ¨¡å‹
        job: ä»»åŠ¡çŠ¶æ€
        audio_array: éŸ³é¢‘æ•°ç»„ï¼ˆå†…å­˜æ¨¡å¼æ—¶å¿…é¡»æä¾›ï¼‰

    Returns:
        Dict: æœªå¯¹é½çš„è½¬å½•ç»“æœ
    """
    mode = seg_meta.get('mode', 'disk')

    if mode == 'memory':
        if audio_array is None:
            raise ValueError("å†…å­˜æ¨¡å¼éœ€è¦æä¾›audio_array")
        return self._transcribe_segment_in_memory(audio_array, seg_meta, model, job)
    else:
        return self._transcribe_segment_from_disk(seg_meta, model, job)
```

### 3.4 è½¬å½•è¿‡ç¨‹ä¸­çš„å†…å­˜ç›‘æ§

```python
def _check_memory_during_transcription(self, job: JobState) -> bool:
    """
    è½¬å½•è¿‡ç¨‹ä¸­æ£€æŸ¥å†…å­˜çŠ¶æ€

    å¦‚æœå†…å­˜ä¸¥é‡ä¸è¶³ï¼Œæš‚åœä»»åŠ¡å¹¶è­¦å‘Šç”¨æˆ·

    Returns:
        bool: True=ç»§ç»­å¤„ç†ï¼ŒFalse=éœ€è¦æš‚åœ
    """
    mem_info = psutil.virtual_memory()
    available_mb = mem_info.available / (1024 * 1024)
    percent_used = mem_info.percent

    # å±é™©é˜ˆå€¼ï¼šå¯ç”¨å†…å­˜<500MB æˆ– ä½¿ç”¨ç‡>95%
    if available_mb < 500 or percent_used > 95:
        self.logger.error(f"ğŸš¨ å†…å­˜ä¸¥é‡ä¸è¶³ï¼å¯ç”¨: {available_mb:.0f}MB, ä½¿ç”¨ç‡: {percent_used}%")
        job.status = 'paused'
        job.message = f"âš ï¸ å†…å­˜ä¸è¶³æš‚åœï¼ˆå¯ç”¨{available_mb:.0f}MBï¼‰ï¼Œè¯·å…³é—­å…¶ä»–ç¨‹åºåç»§ç»­"
        job.paused = True

        # æ¨é€è­¦å‘ŠSSE
        self._push_sse_signal(job, "memory_warning",
            f"å†…å­˜ä¸¥é‡ä¸è¶³ï¼ˆå¯ç”¨{available_mb:.0f}MBï¼‰ï¼Œä»»åŠ¡å·²æš‚åœ")

        return False

    # è­¦å‘Šé˜ˆå€¼ï¼šå¯ç”¨å†…å­˜<1GB æˆ– ä½¿ç”¨ç‡>90%
    if available_mb < 1024 or percent_used > 90:
        self.logger.warning(f"âš ï¸ å†…å­˜ç´§å¼ : å¯ç”¨{available_mb:.0f}MB, ä½¿ç”¨ç‡{percent_used}%")
        # ä¸æš‚åœï¼Œä½†è®°å½•è­¦å‘Š

    return True
```

---

## ğŸ”§ Phase 4: æ‰¹æ¬¡å¯¹é½ + SSEè¿›åº¦æ¨é€ï¼ˆå¿…è¦é¡¹ï¼‰

### 4.1 æ‰¹æ¬¡å¯¹é½å®ç°

**æ–°å¢æ–¹æ³•ï¼š** `_align_all_results_batched()`

```python
def _align_all_results_batched(
    self,
    unaligned_results: List[Dict],
    job: JobState,
    audio_source: Union[np.ndarray, str],  # å†…å­˜æ•°ç»„æˆ–æ–‡ä»¶è·¯å¾„
    processing_mode: ProcessingMode
) -> List[Dict]:
    """
    åˆ†æ‰¹å¯¹é½ï¼ˆå¿…è¦é¡¹ï¼‰- æ”¯æŒå®æ—¶SSEè¿›åº¦æ¨é€

    æ‰¹æ¬¡å¯¹é½çš„ä¼˜åŠ¿ï¼š
    1. é¿å…ä¸€æ¬¡æ€§å¯¹é½æ‰€æœ‰å†…å®¹å¯¼è‡´çš„é•¿æ—¶é—´å¡é¡¿
    2. æ”¯æŒå‰ç«¯è¿›åº¦æ¡å®æ—¶æ›´æ–°
    3. å†…å­˜ä½¿ç”¨æ›´å¯æ§

    Args:
        unaligned_results: æ‰€æœ‰æœªå¯¹é½çš„è½¬å½•ç»“æœ
        job: ä»»åŠ¡çŠ¶æ€å¯¹è±¡
        audio_source: éŸ³é¢‘æ¥æºï¼ˆå†…å­˜æ¨¡å¼ä¼ æ•°ç»„ï¼Œç¡¬ç›˜æ¨¡å¼ä¼ è·¯å¾„ï¼‰
        processing_mode: å½“å‰å¤„ç†æ¨¡å¼

    Returns:
        List[Dict]: å¯¹é½åçš„ç»“æœ
    """
    self.logger.info(f"ğŸ”§ å¼€å§‹æ‰¹æ¬¡å¯¹é½: {len(unaligned_results)}ä¸ªåˆ†æ®µ")

    # 1. åˆå¹¶æ‰€æœ‰segments
    all_segments = []
    for result in unaligned_results:
        all_segments.extend(result['segments'])

    if not all_segments:
        self.logger.warning("æ²¡æœ‰å¯å¯¹é½çš„å†…å®¹")
        return []

    # 2. åŠ è½½éŸ³é¢‘ï¼ˆæ ¹æ®æ¨¡å¼ï¼‰
    if processing_mode == ProcessingMode.MEMORY:
        audio_array = audio_source  # ç›´æ¥ä½¿ç”¨å†…å­˜æ•°ç»„
        self.logger.info("âœ… å¯¹é½é˜¶æ®µå¤ç”¨å†…å­˜ä¸­çš„éŸ³é¢‘æ•°ç»„")
    else:
        # ç¡¬ç›˜æ¨¡å¼ï¼šéœ€è¦åŠ è½½å®Œæ•´éŸ³é¢‘
        self.logger.info("ğŸ“€ å¯¹é½é˜¶æ®µåŠ è½½å®Œæ•´éŸ³é¢‘...")
        audio_array = whisperx.load_audio(audio_source)

    # 3. è·å–å¯¹é½æ¨¡å‹
    lang = job.language or unaligned_results[0].get('language', 'zh')
    align_model, metadata = self._get_align_model(lang, job.settings.device, job)

    # 4. åˆ†æ‰¹å¯¹é½
    BATCH_SIZE = 50  # æ¯æ‰¹50æ¡segment
    total_segments = len(all_segments)
    total_batches = math.ceil(total_segments / BATCH_SIZE)
    aligned_segments = []

    self.logger.info(f"ğŸ“Š å¯¹é½é…ç½®: æ€»{total_segments}æ¡, æ¯æ‰¹{BATCH_SIZE}æ¡, å…±{total_batches}æ‰¹")

    for batch_idx in range(total_batches):
        start_idx = batch_idx * BATCH_SIZE
        end_idx = min(start_idx + BATCH_SIZE, total_segments)
        batch = all_segments[start_idx:end_idx]

        # è®¡ç®—è¿›åº¦
        progress = batch_idx / total_batches

        # æ›´æ–°ä»»åŠ¡è¿›åº¦
        self._update_progress(
            job,
            'align',
            progress,
            f'å¯¹é½ä¸­ {batch_idx + 1}/{total_batches}æ‰¹'
        )

        # ğŸ†• æ¨é€å¯¹é½è¿›åº¦SSEï¼ˆä¸“ç”¨äº‹ä»¶ï¼‰
        self._push_sse_align_progress(
            job,
            batch_idx + 1,
            total_batches,
            len(aligned_segments),
            total_segments
        )

        # æ‰§è¡Œå¯¹é½
        try:
            aligned_batch = whisperx.align(
                batch,
                align_model,
                metadata,
                audio_array,
                job.settings.device
            )
            aligned_segments.extend(aligned_batch.get('segments', []))
            self.logger.debug(f"âœ… æ‰¹æ¬¡ {batch_idx + 1}/{total_batches} å®Œæˆ")

        except Exception as e:
            self.logger.error(f"âŒ æ‰¹æ¬¡ {batch_idx + 1} å¯¹é½å¤±è´¥: {e}")
            # ç»§ç»­å¤„ç†å…¶ä»–æ‰¹æ¬¡ï¼Œä¸ä¸­æ–­æ•´ä½“æµç¨‹
            continue

    # 5. å®Œæˆ
    self._update_progress(job, 'align', 1, 'å¯¹é½å®Œæˆ')
    self._push_sse_align_progress(job, total_batches, total_batches, total_segments, total_segments)

    self.logger.info(f"âœ… æ‰¹æ¬¡å¯¹é½å®Œæˆ: {len(aligned_segments)}æ¡")

    # å¦‚æœæ˜¯ç¡¬ç›˜æ¨¡å¼ï¼Œé‡Šæ”¾åŠ è½½çš„éŸ³é¢‘
    if processing_mode == ProcessingMode.DISK:
        del audio_array
        gc.collect()

    return [{
        'segments': aligned_segments,
        'word_segments': []
    }]
```

### 4.2 å¯¹é½è¿›åº¦SSEæ¨é€æ¥å£

**æ–°å¢æ–¹æ³•ï¼š** `_push_sse_align_progress()`

```python
def _push_sse_align_progress(
    self,
    job: JobState,
    current_batch: int,
    total_batches: int,
    aligned_count: int,
    total_count: int
):
    """
    æ¨é€å¯¹é½è¿›åº¦SSEäº‹ä»¶ï¼ˆå‰ç«¯è¿›åº¦æ¡å®æ—¶æ›´æ–°ï¼‰

    äº‹ä»¶ç±»å‹: "align_progress"

    Args:
        job: ä»»åŠ¡çŠ¶æ€å¯¹è±¡
        current_batch: å½“å‰æ‰¹æ¬¡å·ï¼ˆ1-basedï¼‰
        total_batches: æ€»æ‰¹æ¬¡æ•°
        aligned_count: å·²å¯¹é½çš„segmentæ•°é‡
        total_count: æ€»segmentæ•°é‡
    """
    try:
        from services.sse_service import get_sse_manager
        sse_manager = get_sse_manager()

        channel_id = f"job:{job.job_id}"

        # è®¡ç®—ç™¾åˆ†æ¯”
        batch_progress = (current_batch / total_batches) * 100 if total_batches > 0 else 0
        segment_progress = (aligned_count / total_count) * 100 if total_count > 0 else 0

        sse_manager.broadcast_sync(
            channel_id,
            "align_progress",  # ğŸ†• ä¸“ç”¨äº‹ä»¶ç±»å‹
            {
                "job_id": job.job_id,
                "phase": "align",
                "batch": {
                    "current": current_batch,
                    "total": total_batches,
                    "progress": round(batch_progress, 2)
                },
                "segments": {
                    "aligned": aligned_count,
                    "total": total_count,
                    "progress": round(segment_progress, 2)
                },
                "message": f"å¯¹é½ä¸­ {current_batch}/{total_batches}æ‰¹ ({aligned_count}/{total_count}æ¡)"
            }
        )

    except Exception as e:
        self.logger.debug(f"SSEå¯¹é½è¿›åº¦æ¨é€å¤±è´¥ï¼ˆéè‡´å‘½ï¼‰: {e}")
```

### 4.3 å‰ç«¯SSEäº‹ä»¶æ¥å£å®šä¹‰

**æ–°å¢SSEäº‹ä»¶ï¼š** `align_progress`

```typescript
// å‰ç«¯TypeScriptæ¥å£å®šä¹‰

interface AlignProgressEvent {
  job_id: string;
  phase: "align";
  batch: {
    current: number;   // å½“å‰æ‰¹æ¬¡ï¼ˆ1-basedï¼‰
    total: number;     // æ€»æ‰¹æ¬¡æ•°
    progress: number;  // æ‰¹æ¬¡è¿›åº¦ç™¾åˆ†æ¯” (0-100)
  };
  segments: {
    aligned: number;   // å·²å¯¹é½æ•°é‡
    total: number;     // æ€»æ•°é‡
    progress: number;  // å¯¹é½è¿›åº¦ç™¾åˆ†æ¯” (0-100)
  };
  message: string;     // ç”¨æˆ·å‹å¥½çš„æ¶ˆæ¯
}

// å‰ç«¯ç›‘å¬ç¤ºä¾‹
eventSource.addEventListener('align_progress', (event) => {
  const data: AlignProgressEvent = JSON.parse(event.data);
  // æ›´æ–°å¯¹é½è¿›åº¦æ¡
  updateAlignProgress(data.segments.progress);
  // æ›´æ–°çŠ¶æ€æ¶ˆæ¯
  setStatusMessage(data.message);
});
```

---

## ğŸ”§ Phase 5: ç”ŸæˆSRTï¼ˆä¿æŒä¸å˜ï¼‰

æ­¤é˜¶æ®µé€»è¾‘ä¸å˜ï¼Œç»§ç»­ä½¿ç”¨ç°æœ‰çš„ `_generate_srt()` æ–¹æ³•ã€‚

---

## ğŸ“ æ£€æŸ¥ç‚¹æ•°æ®ç»“æ„

### æ–°ç‰ˆcheckpoint.jsonç»“æ„

```json
{
  "job_id": "abc123",
  "phase": "transcribe",
  "processing_mode": "memory",
  "total_segments": 60,
  "processed_indices": [0, 1, 2, 3],
  "segments": [
    {
      "index": 0,
      "start": 0.0,
      "end": 28.5,
      "mode": "memory"
    },
    {
      "index": 1,
      "start": 28.5,
      "end": 55.2,
      "mode": "memory"
    }
  ],
  "unaligned_results": [
    {
      "segment_index": 0,
      "language": "zh",
      "segments": [...]
    }
  ],
  "timestamp": 1700000000.123,
  "original_settings": {
    "model": "medium",
    "device": "cuda",
    "word_timestamps": false,
    "compute_type": "float16",
    "batch_size": 16
  }
}
```

**å­—æ®µè¯´æ˜ï¼š**
- `processing_mode`: è®°å½•å¤„ç†æ¨¡å¼ï¼ˆmemory/diskï¼‰ï¼Œæ¢å¤æ—¶ä½¿ç”¨ç›¸åŒæ¨¡å¼
- `segments[].mode`: æ¯ä¸ªåˆ†æ®µçš„æ¨¡å¼æ ‡è®°
- `timestamp`: æœ€åæ›´æ–°æ—¶é—´æˆ³ï¼Œç”¨äºè°ƒè¯•

---

## ğŸš€ åˆ†é˜¶æ®µå¼€å‘è®¡åˆ’

### é˜¶æ®µåˆ’åˆ†åŸåˆ™

- æ¯ä¸ªé˜¶æ®µç‹¬ç«‹å¯æµ‹è¯•
- é˜¶æ®µä¹‹é—´æœ‰æ˜ç¡®çš„éªŒæ”¶æ ‡å‡†
- å‡ºé—®é¢˜å¯å¿«é€Ÿå®šä½åˆ°å…·ä½“é˜¶æ®µ

---

### ğŸ”¹ é˜¶æ®µAï¼šåŸºç¡€è®¾æ–½ï¼ˆ1-2å°æ—¶ï¼‰

**ç›®æ ‡ï¼š** æ·»åŠ å†…å­˜æ£€æµ‹å’Œæ¨¡å¼å†³ç­–åŸºç¡€èƒ½åŠ›

**å¼€å‘å†…å®¹ï¼š**

1. æ·»åŠ  `ProcessingMode` æšä¸¾
2. å®ç° `_get_audio_duration()` æ–¹æ³•
3. å®ç° `_decide_processing_mode()` æ–¹æ³•
4. æ·»åŠ  `psutil` ä¾èµ–

**éªŒæ”¶æ ‡å‡†ï¼š**
```python
# æµ‹è¯•ä»£ç 
mode = service._decide_processing_mode("/path/to/audio.wav", job)
print(f"å†³ç­–ç»“æœ: {mode}")
# åº”è¾“å‡º: ProcessingMode.MEMORY æˆ– ProcessingMode.DISK
```

**æµ‹è¯•ç‚¹ï¼š**
- [x] çŸ­è§†é¢‘ï¼ˆ10åˆ†é’Ÿï¼‰â†’ è¿”å› MEMORY
- [x] æ¨¡æ‹Ÿä½å†…å­˜ â†’ è¿”å› DISK
- [x] æ—¥å¿—è¾“å‡ºå†…å­˜è¯„ä¼°ä¿¡æ¯

---

### ğŸ”¹ é˜¶æ®µBï¼šå®‰å…¨éŸ³é¢‘åŠ è½½ï¼ˆ30åˆ†é’Ÿï¼‰

**ç›®æ ‡ï¼š** å®ç°å¸¦å¼‚å¸¸å¤„ç†çš„éŸ³é¢‘åŠ è½½

**å¼€å‘å†…å®¹ï¼š**
1. å®ç° `_safe_load_audio()` æ–¹æ³•
2. æ·»åŠ åŠ è½½å¤±è´¥çš„å¼‚å¸¸å¤„ç†
3. æ·»åŠ åŠ è½½æˆåŠŸçš„æ—¥å¿—è®°å½•

**éªŒæ”¶æ ‡å‡†ï¼š**
```python
# æ­£å¸¸åŠ è½½
audio_array = service._safe_load_audio("/path/to/valid.wav", job)
assert audio_array is not None
assert len(audio_array) > 0

# å¼‚å¸¸å¤„ç†ï¼ˆæŸåæ–‡ä»¶ï¼‰
try:
    service._safe_load_audio("/path/to/corrupted.wav", job)
except RuntimeError as e:
    print(f"æ­£ç¡®æ•è·å¼‚å¸¸: {e}")
```

**æµ‹è¯•ç‚¹ï¼š**
- [ ] æ­£å¸¸WAVæ–‡ä»¶åŠ è½½æˆåŠŸ
- [ ] æŸåæ–‡ä»¶æŠ›å‡ºRuntimeError
- [ ] ç©ºæ–‡ä»¶æŠ›å‡ºå¼‚å¸¸

---

### ğŸ”¹ é˜¶æ®µCï¼šå†…å­˜VADåˆ†æ®µï¼ˆ1å°æ—¶ï¼‰

**ç›®æ ‡ï¼š** å®ç°å†…å­˜æ¨¡å¼çš„VADåˆ†æ®µï¼ˆé»˜è®¤Sileroï¼Œé¢„ç•™Pyannoteæ¥å£ï¼‰

**å¼€å‘å†…å®¹ï¼š**
1. æ·»åŠ  `VADMethod` æšä¸¾å’Œ `VADConfig` æ•°æ®ç±»
2. å®ç° `_split_audio_in_memory()` æ–¹æ³•ï¼ˆç»Ÿä¸€å…¥å£ï¼‰
3. å®ç° `_vad_silero()` æ–¹æ³•ï¼ˆé»˜è®¤ï¼Œæ— éœ€è®¤è¯ï¼‰
4. å®ç° `_vad_pyannote()` æ–¹æ³•ï¼ˆé¢„ç•™ï¼Œéœ€HF Tokenï¼‰
5. å®ç° `_energy_based_split()` é™çº§æ–¹æ³•

**éªŒæ”¶æ ‡å‡†ï¼š**
```python
# åŠ è½½éŸ³é¢‘
audio_array = whisperx.load_audio("/path/to/audio.wav")

# é»˜è®¤ä½¿ç”¨Silero VAD
segments = service._split_audio_in_memory(audio_array)

# éªŒè¯
assert len(segments) > 0
assert all('index' in s and 'start' in s and 'end' in s for s in segments)
assert all(s['mode'] == 'memory' for s in segments)
print(f"åˆ†æ®µæ•°: {len(segments)}")
```

**æµ‹è¯•ç‚¹ï¼š**
- [ ] Silero VADé»˜è®¤åŠ è½½æˆåŠŸ
- [ ] åˆ†æ®µæ•°é‡åˆç†ï¼ˆ10åˆ†é’Ÿè§†é¢‘çº¦20-40æ®µï¼‰
- [ ] æ—¶é—´æˆ³è¿ç»­æ— é‡å 
- [ ] æ¯æ®µé•¿åº¦<=30ç§’
- [ ] VADå¤±è´¥æ—¶æ­£ç¡®é™çº§åˆ°èƒ½é‡æ£€æµ‹

---

### ğŸ”¹ é˜¶æ®µDï¼šç¡¬ç›˜åˆ†æ®µæ•´ç†ï¼ˆ30åˆ†é’Ÿï¼‰

**ç›®æ ‡ï¼š** æ•´ç†ç°æœ‰ç¡¬ç›˜åˆ†æ®µé€»è¾‘ï¼Œç»Ÿä¸€æ¥å£

**å¼€å‘å†…å®¹ï¼š**
1. å°†ç°æœ‰ `_split_audio()` é‡å‘½åä¸º `_split_audio_to_disk()`
2. ç»Ÿä¸€è¿”å›æ ¼å¼ï¼ˆæ·»åŠ  `index`, `mode` å­—æ®µï¼‰
3. ä¿æŒåŠŸèƒ½ä¸å˜

**éªŒæ”¶æ ‡å‡†ï¼š**
```python
segments = service._split_audio_to_disk("/path/to/audio.wav")

assert len(segments) > 0
assert all('index' in s and 'file' in s and 'mode' in s for s in segments)
assert all(s['mode'] == 'disk' for s in segments)
assert all(os.path.exists(s['file']) for s in segments)
```

**æµ‹è¯•ç‚¹ï¼š**
- [ ] ç”Ÿæˆsegment_N.wavæ–‡ä»¶
- [ ] è¿”å›æ ¼å¼ä¸å†…å­˜æ¨¡å¼ä¸€è‡´
- [ ] åŸæœ‰åŠŸèƒ½æ­£å¸¸

---

### ğŸ”¹ é˜¶æ®µEï¼šåˆ†æ®µcheckpointå¼ºåˆ¶åˆ·æ–°ï¼ˆ30åˆ†é’Ÿï¼‰

**ç›®æ ‡ï¼š** ç¡®ä¿åˆ†æ®µå®Œæˆåç«‹å³æŒä¹…åŒ–

**å¼€å‘å†…å®¹ï¼š**
1. å®ç° `_flush_checkpoint_after_split()` æ–¹æ³•
2. æ·»åŠ å†™å…¥éªŒè¯é€»è¾‘
3. åœ¨åˆ†æ®µå®Œæˆåè°ƒç”¨

**éªŒæ”¶æ ‡å‡†ï¼š**
```python
# åˆ†æ®µå
segments = service._split_audio_in_memory(audio_array)

# å¼ºåˆ¶åˆ·æ–°
service._flush_checkpoint_after_split(job_dir, job, segments, ProcessingMode.MEMORY)

# éªŒè¯
checkpoint = service._load_checkpoint(job_dir)
assert checkpoint['phase'] == 'split_complete'
assert checkpoint['processing_mode'] == 'memory'
assert len(checkpoint['segments']) == len(segments)
```

**æµ‹è¯•ç‚¹ï¼š**
- [ ] checkpointæ–‡ä»¶å­˜åœ¨
- [ ] phaseæ­£ç¡®æ ‡è®°ä¸ºsplit_complete
- [ ] segmentsæ•°æ®å®Œæ•´

---

### ğŸ”¹ é˜¶æ®µFï¼šåŒæ¨¡å¼è½¬å½•ï¼ˆ1å°æ—¶ï¼‰

**ç›®æ ‡ï¼š** å®ç°ç»Ÿä¸€çš„è½¬å½•å…¥å£ï¼Œæ”¯æŒåŒæ¨¡å¼

**å¼€å‘å†…å®¹ï¼š**
1. å®ç° `_transcribe_segment_in_memory()` æ–¹æ³•
2. æ•´ç† `_transcribe_segment_from_disk()` æ–¹æ³•
3. å®ç° `_transcribe_segment()` ç»Ÿä¸€å…¥å£
4. æ·»åŠ å†…å­˜ç›‘æ§ `_check_memory_during_transcription()`

**éªŒæ”¶æ ‡å‡†ï¼š**
```python
# å†…å­˜æ¨¡å¼
result = service._transcribe_segment(
    seg_meta, model, job, audio_array=audio_array
)
assert result['segment_index'] == seg_meta['index']

# ç¡¬ç›˜æ¨¡å¼
result = service._transcribe_segment(
    seg_meta_disk, model, job, audio_array=None
)
assert result['segment_index'] == seg_meta_disk['index']
```

**æµ‹è¯•ç‚¹ï¼š**
- [ ] å†…å­˜æ¨¡å¼è½¬å½•æ­£å¸¸
- [ ] ç¡¬ç›˜æ¨¡å¼è½¬å½•æ­£å¸¸
- [ ] æ—¶é—´åç§»æ ¡æ­£æ­£ç¡®
- [ ] å†…å­˜ç›‘æ§è§¦å‘è­¦å‘Š

---

### ğŸ”¹ é˜¶æ®µGï¼šæ‰¹æ¬¡å¯¹é½ + SSEè¿›åº¦ï¼ˆ1-2å°æ—¶ï¼‰

**ç›®æ ‡ï¼š** å®ç°å¿…è¦çš„æ‰¹æ¬¡å¯¹é½å’ŒSSEè¿›åº¦æ¨é€

**å¼€å‘å†…å®¹ï¼š**
1. å®ç° `_align_all_results_batched()` æ–¹æ³•
2. å®ç° `_push_sse_align_progress()` æ–¹æ³•
3. æ›´æ–°è¿›åº¦æƒé‡é…ç½®
4. æµ‹è¯•SSEäº‹ä»¶

**éªŒæ”¶æ ‡å‡†ï¼š**
```python
# æ‰¹æ¬¡å¯¹é½
aligned = service._align_all_results_batched(
    unaligned_results, job, audio_array, ProcessingMode.MEMORY
)

assert len(aligned) > 0
assert 'segments' in aligned[0]

# SSEäº‹ä»¶éªŒè¯ï¼ˆéœ€è¦å‰ç«¯é…åˆï¼‰
# åº”æ”¶åˆ°å¤šä¸ª align_progress äº‹ä»¶
```

**æµ‹è¯•ç‚¹ï¼š**
- [ ] æ‰¹æ¬¡æ•°é‡æ­£ç¡®
- [ ] è¿›åº¦ä»0%åˆ°100%
- [ ] SSEäº‹ä»¶æ­£å¸¸æ¨é€
- [ ] å‰ç«¯è¿›åº¦æ¡æ›´æ–°

---

### ğŸ”¹ é˜¶æ®µHï¼šä¸»æµç¨‹é›†æˆï¼ˆ1-2å°æ—¶ï¼‰

**ç›®æ ‡ï¼š** å°†æ‰€æœ‰ç»„ä»¶é›†æˆåˆ° `_run_pipeline()`

**å¼€å‘å†…å®¹ï¼š**
1. é‡æ„ `_run_pipeline()` ä¸»æµç¨‹
2. é›†æˆæ¨¡å¼å†³ç­–
3. é›†æˆæ™ºèƒ½é™çº§
4. ç«¯åˆ°ç«¯æµ‹è¯•

**éªŒæ”¶æ ‡å‡†ï¼š**
```bash
# å®Œæ•´è½¬å½•æµ‹è¯•
# ä¸Šä¼ è§†é¢‘ â†’ è‡ªåŠ¨é€‰æ‹©æ¨¡å¼ â†’ åˆ†æ®µ â†’ è½¬å½• â†’ å¯¹é½ â†’ ç”ŸæˆSRT
# è§‚å¯Ÿï¼š
# 1. æ—¥å¿—æ˜¾ç¤ºé€‰æ‹©çš„æ¨¡å¼
# 2. å¯¹é½è¿›åº¦SSEæ­£å¸¸
# 3. SRTæ–‡ä»¶æ­£ç¡®ç”Ÿæˆ
```

**æµ‹è¯•ç‚¹ï¼š**
- [ ] çŸ­è§†é¢‘ï¼ˆå†…å­˜æ¨¡å¼ï¼‰å®Œæ•´æµç¨‹
- [ ] é•¿è§†é¢‘ï¼ˆç¡¬ç›˜æ¨¡å¼ï¼‰å®Œæ•´æµç¨‹
- [ ] æ–­ç‚¹ç»­ä¼ æ­£å¸¸
- [ ] å†…å­˜ä¸è¶³è‡ªåŠ¨æš‚åœ

---

## ğŸ“Š è¿›åº¦æƒé‡é…ç½®æ›´æ–°

**ä½ç½®ï¼š** `core/config.py`

```python
# æ›´æ–°åçš„è¿›åº¦æƒé‡
self.PHASE_WEIGHTS = {
    "extract": 5,      # éŸ³é¢‘æå–å 5%
    "split": 5,        # éŸ³é¢‘åˆ†æ®µå 5%
    "transcribe": 60,  # è½¬å½•å¤„ç†å 60%ï¼ˆé™ä½ï¼Œå› å¯¹é½æƒé‡å¢åŠ ï¼‰
    "align": 20,       # å¯¹é½å¤„ç†å 20%ï¼ˆå¢åŠ ï¼Œå› ä¸ºæ˜¯æ‰¹æ¬¡å¯¹é½ï¼‰
    "srt": 10          # SRTç”Ÿæˆå 10%
}
```

---

## âš ï¸ é£é™©æ§åˆ¶

### å†…å­˜ä¸è¶³å¤„ç†æµç¨‹
```
æ£€æµ‹åˆ°å†…å­˜ç´§å¼ ï¼ˆå¯ç”¨<1GBï¼‰
        â†“
    è®°å½•è­¦å‘Šæ—¥å¿—
        â†“
ç»§ç»­å¤„ç†ï¼ˆå°è¯•å®Œæˆå½“å‰æ®µï¼‰
        â†“
æ£€æµ‹åˆ°å†…å­˜ä¸¥é‡ä¸è¶³ï¼ˆå¯ç”¨<500MBï¼‰
        â†“
    ç«‹å³æš‚åœä»»åŠ¡
        â†“
  æ¨é€SSEè­¦å‘Šäº‹ä»¶
        â†“
 æ›´æ–°jobçŠ¶æ€ä¸ºpaused
        â†“
  ç”¨æˆ·çœ‹åˆ°æ˜ç¡®è­¦å‘Š
        â†“
ç”¨æˆ·å…³é—­å…¶ä»–ç¨‹åºåæ¢å¤
```

### VADæ¨¡å‹å¤±è´¥é™çº§
```python
def _split_audio_in_memory(self, audio_array, sr=16000):
    try:
        # å°è¯•ä½¿ç”¨VADæ¨¡å‹
        return self._vad_split(audio_array, sr)
    except Exception as e:
        self.logger.warning(f"âš ï¸ VADæ¨¡å‹å¤±è´¥ï¼Œä½¿ç”¨èƒ½é‡æ£€æµ‹é™çº§: {e}")
        # é™çº§æ–¹æ¡ˆï¼šåŸºäºèƒ½é‡çš„ç®€æ˜“åˆ†æ®µ
        return self._energy_based_split(audio_array, sr)
```

---

## âœ… å¼€å‘æ£€æŸ¥æ¸…å•

### é˜¶æ®µAï¼šåŸºç¡€è®¾æ–½

- [ ] æ·»åŠ  ProcessingMode æšä¸¾
- [ ] å®ç° _get_audio_duration()
- [ ] å®ç° _decide_processing_mode()
- [ ] æµ‹è¯•é€šè¿‡

### é˜¶æ®µBï¼šå®‰å…¨éŸ³é¢‘åŠ è½½
- [ ] å®ç° _safe_load_audio()
- [ ] å¼‚å¸¸å¤„ç†å®Œæ•´
- [ ] æµ‹è¯•é€šè¿‡

### é˜¶æ®µCï¼šå†…å­˜VADåˆ†æ®µ
- [ ] æ·»åŠ  VADMethod æšä¸¾å’Œ VADConfig æ•°æ®ç±»
- [ ] å®ç° _split_audio_in_memory() ç»Ÿä¸€å…¥å£
- [ ] å®ç° _vad_silero() é»˜è®¤æ–¹æ³•
- [ ] å®ç° _vad_pyannote() é¢„ç•™æ–¹æ³•
- [ ] å®ç° _energy_based_split() é™çº§æ–¹æ³•
- [ ] æµ‹è¯•Silero VADåŠ è½½æˆåŠŸ
- [ ] æµ‹è¯•é€šè¿‡

### é˜¶æ®µDï¼šç¡¬ç›˜åˆ†æ®µæ•´ç†
- [ ] é‡å‘½åä¸º _split_audio_to_disk()
- [ ] ç»Ÿä¸€è¿”å›æ ¼å¼
- [ ] æµ‹è¯•é€šè¿‡

### é˜¶æ®µEï¼šcheckpointå¼ºåˆ¶åˆ·æ–°
- [ ] å®ç° _flush_checkpoint_after_split()
- [ ] æ·»åŠ å†™å…¥éªŒè¯
- [ ] æµ‹è¯•é€šè¿‡

### é˜¶æ®µFï¼šåŒæ¨¡å¼è½¬å½•
- [ ] å®ç° _transcribe_segment_in_memory()
- [ ] æ•´ç† _transcribe_segment_from_disk()
- [ ] å®ç°ç»Ÿä¸€å…¥å£
- [ ] æ·»åŠ å†…å­˜ç›‘æ§
- [ ] æµ‹è¯•é€šè¿‡

### é˜¶æ®µGï¼šæ‰¹æ¬¡å¯¹é½ + SSE
- [ ] å®ç° _align_all_results_batched()
- [ ] å®ç° _push_sse_align_progress()
- [ ] å‰ç«¯æ¥æ”¶äº‹ä»¶æ­£å¸¸
- [ ] æµ‹è¯•é€šè¿‡

### é˜¶æ®µHï¼šä¸»æµç¨‹é›†æˆ

- [ ] é‡æ„ _run_pipeline()
- [ ] ç«¯åˆ°ç«¯æµ‹è¯•é€šè¿‡
- [ ] æ–­ç‚¹ç»­ä¼ æµ‹è¯•
- [ ] å†…å­˜ä¸è¶³æµ‹è¯•

---

## ğŸ“š ä¾èµ–æ›´æ–°

### requirements.txt æ–°å¢
```txt
psutil>=5.9.0    # å†…å­˜ç›‘æ§
```

---

**æ–‡æ¡£ç‰ˆæœ¬ï¼š** V2.3
**æœ€åæ›´æ–°ï¼š** 2025-11-23
**çŠ¶æ€ï¼š** å¾…å®æ–½
**VADé»˜è®¤æ¨¡å¼ï¼š** Sileroï¼ˆæ— éœ€è®¤è¯ï¼‰
