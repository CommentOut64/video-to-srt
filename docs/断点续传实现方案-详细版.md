# Video-to-SRT æ–­ç‚¹ç»­ä¼ å®ç°æ–¹æ¡ˆï¼ˆç²¾ç®€å®æˆ˜ç‰ˆï¼‰

> **ç‰ˆæœ¬**: v2.0 (ç‹¬ç«‹å¼€å‘ä¼˜åŒ–ç‰ˆ)
> **æ—¥æœŸ**: 2025-01-20
> **ç›®æ ‡**: ä½ä»£ç é‡ã€é«˜å¯é æ€§ã€æ˜“äºç»´æŠ¤
> **æ ¸å¿ƒç­–ç•¥**: å•ä¸€ JSON æ–‡ä»¶ + åŸå­æ€§å†™å…¥ + å†…å­˜å¢é‡æ›´æ–°

-----

## ğŸ“‹ ç›®å½•

  - [ä¸€ã€æ ¸å¿ƒè®¾è®¡é€»è¾‘](https://www.google.com/search?q=%23%E4%B8%80%E6%A0%B8%E5%BF%83%E8%AE%BE%E8%AE%A1%E9%80%BB%E8%BE%91)
  - [äºŒã€æ•°æ®ç»“æ„è®¾è®¡](https://www.google.com/search?q=%23%E4%BA%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E8%AE%BE%E8%AE%A1)
  - [ä¸‰ã€åŸºç¡€å·¥å…·å‡½æ•°](https://www.google.com/search?q=%23%E4%B8%89%E5%9F%BA%E7%A1%80%E5%B7%A5%E5%85%B7%E5%87%BD%E6%95%B0)
  - [å››ã€é›†æˆåˆ°è½¬å½•æµç¨‹](https://www.google.com/search?q=%23%E5%9B%9B%E9%9B%86%E6%88%90%E5%88%B0%E8%BD%AC%E5%BD%95%E6%B5%81%E7%A8%8B)
  - [äº”ã€å‰ç«¯äº¤äº’è°ƒæ•´](https://www.google.com/search?q=%23%E4%BA%94%E5%89%8D%E7%AB%AF%E4%BA%A4%E4%BA%92%E8%B0%83%E6%95%B4)
  - [å…­ã€å®æ–½æ­¥éª¤](https://www.google.com/search?q=%23%E5%85%AD%E5%AE%9E%E6%96%BD%E6%AD%A5%E9%AA%A4)

-----

## ä¸€ã€æ ¸å¿ƒè®¾è®¡é€»è¾‘

é’ˆå¯¹æ¡Œé¢ç«¯å•æœºåº”ç”¨åœºæ™¯ï¼Œæˆ‘ä»¬é‡‡ç”¨ä»¥ä¸‹ç­–ç•¥ï¼š

1.  **æ–‡ä»¶å³çŠ¶æ€**: æ¯ä¸ªä»»åŠ¡ç›®å½•ä¸‹ä¸€ä¸ª `checkpoint.json` æ–‡ä»¶ï¼Œä»£è¡¨å½“å‰è¿›åº¦ã€‚
2.  **åŸå­æ€§ä¿è¯**: ä½¿ç”¨â€œå†™ä¸´æ—¶æ–‡ä»¶ -\> é‡å‘½åâ€ç­–ç•¥ï¼Œé˜²æ­¢ç¨‹åºå´©æºƒï¼ˆæ–­ç”µ/æ€è¿›ç¨‹ï¼‰å¯¼è‡´ JSON æŸåã€‚
3.  **å…³é”®åŸ‹ç‚¹**: ä»…åœ¨â€œåˆ†æ®µå®Œæˆâ€å’Œâ€œè½¬å½•å¾ªç¯ä¸­â€ä¿å­˜çŠ¶æ€ã€‚
4.  **å¯åŠ¨å³æ¢å¤**: ä»»åŠ¡å¯åŠ¨æ—¶æ£€æµ‹ `checkpoint.json`ï¼Œå­˜åœ¨åˆ™åŠ è½½å¹¶è·³è¿‡å·²å®Œæˆæ­¥éª¤ï¼Œä¸å­˜åœ¨åˆ™ä»å¤´å¼€å§‹ã€‚

-----

## äºŒã€æ•°æ®ç»“æ„è®¾è®¡

ä¸å†ä½¿ç”¨å¤æ‚çš„ Dataclass ç±»å®šä¹‰ï¼Œç›´æ¥ä½¿ç”¨ Python å­—å…¸ï¼ˆDictï¼‰ä¸ JSON ç»“æ„ä¸€ä¸€å¯¹åº”ã€‚

### 2.1 checkpoint.json ç»“æ„

```json
{
  "job_id": "task_123456",
  "phase": "transcribe",        // å½“å‰é˜¶æ®µ: extract, split, transcribe, finished
  "total_segments": 10,         // æ€»æ®µæ•°
  "processed_indices": [0, 1, 2], // å·²å®Œæˆçš„æ®µä¸‹æ ‡ (å…³é”®!)
  "segments": [                 // åˆ†æ®µä¿¡æ¯ (æŒä¹…åŒ–ï¼Œé¿å…é‡æ–°åˆ†æ®µ)
    {
      "index": 0,
      "file": "/path/to/segment_0.wav",
      "start_ms": 0,
      "duration_ms": 60000
    },
    ...
  ],
  "results": [                  // å·²ç”Ÿæˆçš„è½¬å½•ç»“æœ (å†…å­˜ä¸­ç´¯ç§¯ï¼Œå®šæœŸå†™å…¥)
    {
      "segment_index": 0,
      "text": "ä½ å¥½",
      "start": 0.0,
      "end": 2.0
    },
    ...
  ]
}
```

-----

## ä¸‰ã€åŸºç¡€å·¥å…·å‡½æ•°

å°†è¿™äº›é€»è¾‘ä½œä¸º `TranscriptionService` çš„ç§æœ‰æ–¹æ³•ï¼Œæ— éœ€å•ç‹¬åˆ›å»º Service ç±»ã€‚

### 3.1 åŸå­æ€§ä¿å­˜ (æ ¸å¿ƒ)

åˆ©ç”¨ `os.replace` çš„åŸå­ç‰¹æ€§ï¼Œç¡®ä¿æ–‡ä»¶è¦ä¹ˆå†™å…¥æˆåŠŸï¼Œè¦ä¹ˆä¿æŒåŸæ ·ï¼Œç»ä¸ä¼šå‡ºç°åªå†™äº†ä¸€åŠçš„åæ–‡ä»¶ã€‚

```python
import json
import os
from pathlib import Path

def _save_checkpoint(self, job_dir: Path, data: dict):
    """
    åŸå­æ€§ä¿å­˜æ£€æŸ¥ç‚¹
    """
    checkpoint_path = job_dir / "checkpoint.json"
    temp_path = checkpoint_path.with_suffix(".tmp")
    
    try:
        # 1. å†™å…¥ä¸´æ—¶æ–‡ä»¶
        with open(temp_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
            
        # 2. åŸå­æ›¿æ¢ (Windows/Linux/macOS å‡æ”¯æŒ)
        # å¦‚æœç¨‹åºåœ¨è¿™é‡Œå´©æºƒï¼Œcheckpoint.json ä¾ç„¶æ˜¯æ—§ç‰ˆæœ¬ï¼Œä¸ä¼šæŸå
        os.replace(temp_path, checkpoint_path)
        
    except Exception as e:
        self.logger.error(f"ä¿å­˜æ£€æŸ¥ç‚¹å¤±è´¥: {e}")
        # ä¿å­˜å¤±è´¥ä¸åº”ä¸­æ–­ä¸»æµç¨‹ï¼Œä»…è®°å½•æ—¥å¿—
```

### 3.2 åŠ è½½æ£€æŸ¥ç‚¹

```python
def _load_checkpoint(self, job_dir: Path) -> dict | None:
    """
    åŠ è½½æ£€æŸ¥ç‚¹ï¼Œå¦‚æœæ–‡ä»¶æŸååˆ™è¿”å› None
    """
    checkpoint_path = job_dir / "checkpoint.json"
    if not checkpoint_path.exists():
        return None
        
    try:
        with open(checkpoint_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except (json.JSONDecodeError, OSError):
        self.logger.warning(f"æ£€æŸ¥ç‚¹æ–‡ä»¶æŸåï¼Œå°†é‡æ–°å¼€å§‹ä»»åŠ¡: {checkpoint_path}")
        return None
```

-----

## å››ã€é›†æˆåˆ°è½¬å½•æµç¨‹

è¿™æ˜¯ä¿®æ”¹çš„æ ¸å¿ƒéƒ¨åˆ†ï¼Œåœ¨ `run_pipeline` ä¸­åµŒå…¥æ–­ç‚¹æ£€æŸ¥ã€‚

### 4.1 ä»£ç å®ç°

```python
# backend/app/services/transcription_service.py

def _run_pipeline(self, job: JobState):
    job_dir = Path(job.dir)
    
    # ==========================================
    # 1. å°è¯•æ¢å¤çŠ¶æ€
    # ==========================================
    checkpoint = self._load_checkpoint(job_dir)
    
    # åˆå§‹åŒ–å†…å­˜çŠ¶æ€
    processed_indices = set()
    results = []
    current_segments = []
    
    if checkpoint:
        self.logger.info(f"ğŸ”„ å‘ç°æ£€æŸ¥ç‚¹ï¼Œä» {checkpoint['phase']} é˜¶æ®µæ¢å¤")
        # æ¢å¤æ•°æ®åˆ°å†…å­˜
        processed_indices = set(checkpoint.get('processed_indices', []))
        results = checkpoint.get('results', [])
        current_segments = checkpoint.get('segments', [])
        # æ¢å¤ä»»åŠ¡åŸºæœ¬ä¿¡æ¯
        job.total = checkpoint.get('total_segments', 0)
        job.processed = len(processed_indices)
    
    # ==========================================
    # 2. é˜¶æ®µä¸€ï¼šéŸ³é¢‘æå– (Extract)
    # ==========================================
    audio_path = job_dir / 'audio.wav'
    
    # åªæœ‰å½“éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæˆ–è€…æˆ‘ä»¬è¦ä»å¤´å¼€å§‹æ—¶ï¼Œæ‰æ‰§è¡Œæå–
    if not audio_path.exists() or (checkpoint is None):
        self._update_progress(job, 'extract', 0, 'æå–éŸ³é¢‘')
        self._extract_audio(job.source_path, str(audio_path))
        # æå–å®Œä¸éœ€è¦ç«‹åˆ»å­˜checkpointï¼Œå› ä¸ºåˆ†æ®µå¾ˆå¿«å°±ä¼šå‘ç”Ÿ
    
    # ==========================================
    # 3. é˜¶æ®µäºŒï¼šåˆ†æ®µ (Split)
    # ==========================================
    # å¦‚æœæ£€æŸ¥ç‚¹é‡Œæ²¡æœ‰åˆ†æ®µä¿¡æ¯ï¼Œè¯´æ˜ä¸Šæ¬¡æ²¡è·‘åˆ°åˆ†æ®µå®Œæˆ
    if not current_segments:
        self._update_progress(job, 'split', 0, 'éŸ³é¢‘åˆ†æ®µ')
        current_segments = self._split_audio(str(audio_path))
        job.segments = current_segments
        job.total = len(current_segments)
        
        # ã€å…³é”®åŸ‹ç‚¹ 1ã€‘åˆ†æ®µå®Œæˆåç«‹å³ä¿å­˜
        checkpoint_data = {
            "job_id": job.job_id,
            "phase": "split",
            "total_segments": job.total,
            "processed_indices": [],
            "segments": current_segments, # ä¿å­˜åˆ†æ®µç»“æœ
            "results": []
        }
        self._save_checkpoint(job_dir, checkpoint_data)
    else:
        self.logger.info("âœ… è·³è¿‡åˆ†æ®µï¼Œä½¿ç”¨æ£€æŸ¥ç‚¹æ•°æ®")
        job.segments = current_segments # æ¢å¤åˆ° job å¯¹è±¡

    # ==========================================
    # 4. é˜¶æ®µä¸‰ï¼šè½¬å½• (Transcribe) - æ ¸å¿ƒå¾ªç¯
    # ==========================================
    self._update_progress(job, 'transcribe', 0, 'åŠ è½½æ¨¡å‹')
    model = self._load_model(job.settings)
    
    # è¿‡æ»¤å‡ºéœ€è¦å¤„ç†çš„æ®µ
    todo_segments = [
        seg for i, seg in enumerate(current_segments) 
        if i not in processed_indices
    ]
    
    self.logger.info(f"ğŸ“ å‰©ä½™ {len(todo_segments)}/{len(current_segments)} æ®µéœ€è¦è½¬å½•")

    for i, segment in enumerate(current_segments):
        # å¦‚æœå·²ç»åœ¨ processed_indices é‡Œï¼Œç›´æ¥è·³è¿‡
        if i in processed_indices:
            continue

        # æ£€æŸ¥ä»»åŠ¡å–æ¶ˆ
        if job.canceled:
            raise RuntimeError("ä»»åŠ¡å·²å–æ¶ˆ")

        # --- æ‰§è¡Œè½¬å½• ---
        segment_result = self._transcribe_segment(model, segment)
        
        # --- æ›´æ–°å†…å­˜çŠ¶æ€ ---
        results.append(segment_result)
        processed_indices.add(i)
        job.processed = len(processed_indices)
        
        # --- æ›´æ–°è¿›åº¦æ¡ ---
        progress = len(processed_indices) / len(current_segments)
        self._update_progress(job, 'transcribe', progress, f"è½¬å½•ä¸­ {len(processed_indices)}/{len(current_segments)}")

        # ã€å…³é”®åŸ‹ç‚¹ 2ã€‘æ¯å¤„ç†ä¸€æ®µï¼ˆæˆ–æ¯Næ®µï¼‰ä¿å­˜ä¸€æ¬¡
        # å•æœºç‰ˆæ¯æ®µä¿å­˜å¼€é”€å¾ˆå°ï¼Œå»ºè®®ç›´æ¥æ¯æ®µä¿å­˜ï¼Œä½“éªŒæœ€å¥½
        checkpoint_data = {
            "job_id": job.job_id,
            "phase": "transcribe",
            "total_segments": len(current_segments),
            "processed_indices": list(processed_indices), # setè½¬list
            "segments": current_segments,
            "results": results
        }
        self._save_checkpoint(job_dir, checkpoint_data)

    # ==========================================
    # 5. é˜¶æ®µå››ï¼šç”Ÿæˆ SRT (Finish)
    # ==========================================
    self._generate_srt(results, job.output_path)
    
    # ã€æ¸…ç†ã€‘ä»»åŠ¡æˆåŠŸå®Œæˆåï¼Œåˆ é™¤ checkpoint
    try:
        (job_dir / "checkpoint.json").unlink(missing_ok=True)
    except:
        pass
        
    job.status = 'finished'
```

### 4.2 æ¢å¤é€»è¾‘çš„è¾¹ç•Œå¤„ç†

  * **éŸ³é¢‘æ–‡ä»¶ä¸¢å¤±**: å¦‚æœ `checkpoint.json` å­˜åœ¨ï¼Œä½† `audio.wav` è¢«åˆ äº†ï¼Œ`extract` é˜¶æ®µçš„æ£€æŸ¥ä¼šå‘ç°æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä»£ç éœ€è¦åšä¸€ç‚¹å¾®è°ƒï¼šåœ¨æ¢å¤åˆ†æ®µä¿¡æ¯å‰ï¼Œå…ˆæ£€æŸ¥ `audio.wav` æ˜¯å¦å­˜åœ¨ã€‚å¦‚æœä¸å­˜åœ¨ï¼Œè™½ç„¶æœ‰ JSONï¼Œä¹Ÿåªèƒ½å¼ºè¡Œä»å¤´å¼€å§‹æˆ–è€…æŠ¥é”™ã€‚ç®€åŒ–èµ·è§ï¼Œå»ºè®®ï¼š**å¦‚æœå…³é”®æ–‡ä»¶ä¸¢å¤±ï¼Œè§†ä¸ºæ— æ£€æŸ¥ç‚¹å¤„ç†**ã€‚

-----

## äº”ã€å‰ç«¯äº¤äº’è°ƒæ•´

UI ä¸éœ€è¦å¤æ‚çš„â€œå¯æ¢å¤åˆ—è¡¨â€ï¼Œåªéœ€è¦åœ¨ç”¨æˆ·ç‚¹å‡»â€œå¼€å§‹â€æˆ–â€œé‡è¯•â€æ—¶ç»™ä¸ªåé¦ˆå³å¯ã€‚

### 5.1 ä»»åŠ¡åˆ—è¡¨ UI é€»è¾‘

åœ¨ä»»åŠ¡å¡ç‰‡ä¸Šï¼š

  * **çŠ¶æ€æ£€æµ‹**: æ¸²æŸ“åˆ—è¡¨æ—¶ï¼Œå¦‚æœä»»åŠ¡çŠ¶æ€æ˜¯ `failed` æˆ– `canceled`ï¼Œè°ƒç”¨åç«¯ API æ£€æŸ¥æ˜¯å¦å­˜åœ¨ `checkpoint.json`ã€‚
  * **æŒ‰é’®æ˜¾ç¤º**: å¦‚æœæœ‰æ£€æŸ¥ç‚¹ï¼Œæ˜¾ç¤ºâ€œğŸ”„ ç»§ç»­ä»»åŠ¡â€ï¼›å¦åˆ™æ˜¾ç¤ºâ€œğŸ”„ é‡è¯•â€ã€‚
  * **æç¤ºæ–‡æ¡ˆ**: â€œæ£€æµ‹åˆ°ä¸Šæ¬¡è¿›åº¦ (45%)ï¼Œå°†ä»æ–­ç‚¹ç»§ç»­ã€‚â€

### 5.2 API è°ƒæ•´

åªéœ€è¦ä¸€ä¸ªç®€å•çš„æ£€æŸ¥æ¥å£ï¼š

```python
@app.get("/api/jobs/{job_id}/check_resume")
def check_resume(job_id: str):
    job_dir = config.JOBS_DIR / job_id
    checkpoint_path = job_dir / "checkpoint.json"
    if checkpoint_path.exists():
        try:
            data = json.load(open(checkpoint_path))
            return {
                "can_resume": True,
                "progress": len(data['processed_indices']) / data['total_segments'] * 100
            }
        except:
            pass
    return {"can_resume": False}
```

-----

## å…­ã€å®æ–½æ­¥éª¤

è¿™æ˜¯ä¸€ä»½å¯ä»¥åœ¨ **3å°æ—¶å†…** å®Œæˆçš„å¼€å‘æ¸…å•ï¼š

1.  **åç«¯ (1.5h)**:

      * åœ¨ `TranscriptionService` ä¸­æ·»åŠ  `_save_checkpoint` å’Œ `_load_checkpoint` æ–¹æ³•ã€‚
      * ä¿®æ”¹ `run_pipeline` é€»è¾‘ï¼ŒåŠ å…¥â€œåŠ è½½æ£€æŸ¥ç‚¹â€å’Œâ€œè·³è¿‡å·²å¤„ç†å¾ªç¯â€çš„ä»£ç ã€‚
      * åœ¨åˆ†æ®µåã€è½¬å½•å¾ªç¯å†…æ·»åŠ  `_save_checkpoint` è°ƒç”¨ã€‚
      * ä»»åŠ¡å®Œæˆåæ·»åŠ åˆ é™¤ `checkpoint.json` çš„ä»£ç ã€‚

2.  **API (0.5h)**:

      * æ·»åŠ  `check_resume` æ¥å£ï¼ˆå¯é€‰ï¼Œå¦‚æœä¸æƒ³æ”¹å‰ç«¯ï¼Œåç«¯é™é»˜æ¢å¤ä¹Ÿå¯ä»¥ï¼Œå‰ç«¯åªéœ€å†æ¬¡ç‚¹å‡»â€œå¼€å§‹â€ï¼‰ã€‚

3.  **å‰ç«¯ (1h)**:

      * (å¯é€‰) åœ¨å¤±è´¥ä»»åŠ¡å¡ç‰‡ä¸Šæ˜¾ç¤ºâ€œå¯æ¢å¤â€æç¤ºã€‚
      * å¦‚æœä¸æ”¹ UIï¼Œç”¨æˆ·ç‚¹å‡»â€œé‡è¯•â€æ—¶ï¼Œåç«¯è‡ªåŠ¨æ£€æµ‹åˆ°æ–‡ä»¶å¹¶æ¢å¤ï¼Œç”¨æˆ·ä¼šå‘ç°è¿›åº¦æ¡ç›´æ¥è·³åˆ°äº† 50%ï¼Œä½“éªŒä¹Ÿæ˜¯ä¸€ç§æƒŠå–œã€‚

### æ€»ç»“

è¿™ä¸ªæ–¹æ¡ˆå»æ‰äº†æ‰€æœ‰ä¸ºäº†â€œé˜²å¾¡æå°æ¦‚ç‡äº‹ä»¶â€è€Œè®¾è®¡çš„å¤æ‚ä»£ç ã€‚å¯¹äºæ¡Œé¢è½¯ä»¶ï¼Œå¦‚æœåœ¨å†™å…¥é‚£å‡ æ¯«ç§’æ–­ç”µå¯¼è‡´ JSON æŸåï¼Œç”¨æˆ·å¤§ä¸äº†é‡è·‘ä¸€æ¬¡ä»»åŠ¡ï¼Œæˆæœ¬å®Œå…¨å¯æ§ã€‚**å…ˆè·‘é€šï¼Œå†å®Œç¾ã€‚**
