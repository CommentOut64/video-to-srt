# æ–­ç‚¹ç»­ä¼ å¢å¼ºåŠŸèƒ½ - å¼€å‘æ–‡æ¡£

## æ–‡æ¡£ç‰ˆæœ¬
- **ç‰ˆæœ¬**: v1.0
- **æ—¥æœŸ**: 2025-01-22
- **çŠ¶æ€**: å¾…å®æ–½

---

## ä¸€ã€æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†è¯´æ˜æ–­ç‚¹ç»­ä¼ åŠŸèƒ½çš„ä¸‰ä¸ªæ ¸å¿ƒå¢å¼ºéœ€æ±‚ï¼š
1. **æ”¯æŒæ–­ç‚¹æ¢å¤åä¿®æ”¹å‚æ•°**
2. **æ–­ç‚¹ä¿å­˜æœªå¯¹é½çš„è½¬å½•æ–‡å­—**
3. **å®ç°è½¬å½•æ–‡å­—çš„æµå¼è¾“å‡º**

---

## äºŒã€éœ€æ±‚1ï¼šæ–­ç‚¹æ¢å¤åæ”¯æŒä¿®æ”¹å‚æ•°

### 2.1 éœ€æ±‚åˆ†æ

**æ ¸å¿ƒè¯‰æ±‚**ï¼š

- ç”¨æˆ·åœ¨æ¢å¤æ–­ç‚¹ä»»åŠ¡æ—¶ï¼Œåº”è¯¥å¯ä»¥ä¿®æ”¹æŸäº›å‚æ•°ï¼Œä½†ä¸èƒ½ä¿®æ”¹ä¼šå¯¼è‡´ä¸å…¼å®¹çš„å‚æ•°
- æ¢å¤æ—¶å¼ºåˆ¶ä½¿ç”¨UIé¢æ¿çš„å½“å‰è®¾ç½®ï¼Œè€Œécheckpointä¸­ä¿å­˜çš„æ—§è®¾ç½®
- ä¿®æ”¹å‚æ•°æ—¶éœ€è¦æ˜ç¡®æç¤ºç”¨æˆ·å¯èƒ½çš„åæœ

### 2.2 å‚æ•°åˆ†ç±»

#### 2.2.1 **ç¦æ­¢ä¿®æ”¹çš„å‚æ•°**ï¼ˆä¼šå¯¼è‡´æ•°æ®ä¸ä¸€è‡´ï¼‰

| å‚æ•° | åŸå›  | å½±å“ |
|------|------|------|
| `device` | è™½ç„¶ç†è®ºä¸Šå¯ä»¥åˆ‡æ¢ï¼Œä½†ä¸åŒè®¾å¤‡çš„ç²¾åº¦å¯èƒ½æœ‰ç»†å¾®å·®å¼‚ | **ä¸­ç­‰** |
| `word_timestamps` | å¦‚æœå‰åŠæ®µå¼€å¯è¯çº§æ—¶é—´æˆ³ï¼ŒååŠæ®µå…³é—­ï¼Œä¼šå¯¼è‡´SRTæ ¼å¼ä¸ä¸€è‡´ | **ä¸¥é‡** |

#### 2.2.2 **å…è®¸ä¿®æ”¹ä½†éœ€è­¦å‘Šçš„å‚æ•°**ï¼ˆå¯èƒ½å¯¼è‡´è´¨é‡ä¸ä¸€è‡´ï¼‰

| å‚æ•° | åŸå›  | å½±å“ | è­¦å‘Šçº§åˆ« |
|------|------|------|----------|
| `model` | ä¸åŒæ¨¡å‹çš„è¾“å‡ºæ ¼å¼å’Œè´¨é‡å¯èƒ½ä¸åŒï¼Œæ··ç”¨ä¼šå¯¼è‡´å‰åå­—å¹•è´¨é‡ä¸ä¸€è‡´ã€‚é€‚ç”¨åœºæ™¯ï¼šç”¨æˆ·åœ¨è½¬å½•é•¿è§†é¢‘æ—¶å‘ç°ç”¨é”™äº†æ¨¡å‹ï¼Œéœ€è¦ä¸­é€”æ›´æ­£ | **é«˜** | **ä¸¥é‡è­¦å‘Š** |

#### 2.2.3 **å…è®¸ä¿®æ”¹çš„å‚æ•°**ï¼ˆä¸å½±å“å…¼å®¹æ€§ï¼‰

| å‚æ•° | åŸå›  | å½±å“ |
|------|------|------|
| `compute_type` | ä»…å½±å“è®¡ç®—ç²¾åº¦ï¼Œä¸å½±å“è¾“å‡ºæ ¼å¼ | **ä½** |
| `batch_size` | ä»…å½±å“å¤„ç†é€Ÿåº¦ï¼Œä¸å½±å“ç»“æœ | **æ— ** |
| `cpu_affinity_*` | ä»…å½±å“æ€§èƒ½ï¼Œä¸å½±å“è½¬å½•ç»“æœ | **æ— ** |

### 2.3 å®ç°æ–¹æ¡ˆ

#### 2.3.1 æ•°æ®ç»“æ„å˜æ›´

**checkpoint.json æ–°å¢å­—æ®µ**ï¼š

```json
{
  "job_id": "...",
  "phase": "transcribe",
  "total_segments": 100,
  "processed_indices": [0, 1, 2, ...],
  "segments": [...],
  "unaligned_results": [...],

  // æ–°å¢ï¼šä¿å­˜åŸå§‹è®¾ç½®ï¼ˆç”¨äºæ ¡éªŒå‚æ•°å…¼å®¹æ€§ï¼‰
  "original_settings": {
    "model": "medium",
    "device": "cuda",
    "word_timestamps": false,
    "compute_type": "float16",  // å¯ä¿®æ”¹
    "batch_size": 16            // å¯ä¿®æ”¹
  }
}
```

#### 2.3.2 åç«¯å®ç°

**æ–‡ä»¶**: `backend/app/services/transcription_service.py`

**ä¿®æ”¹ `_save_checkpoint` æ–¹æ³•**ï¼š

```python
def _save_checkpoint(self, job_dir: Path, data: dict, job: JobState):
    """
    åŸå­æ€§ä¿å­˜æ£€æŸ¥ç‚¹

    Args:
        job_dir: ä»»åŠ¡ç›®å½•
        data: æ£€æŸ¥ç‚¹æ•°æ®
        job: ä»»åŠ¡çŠ¶æ€å¯¹è±¡ï¼ˆç”¨äºè·å–settingsï¼‰
    """
    # æ·»åŠ åŸå§‹è®¾ç½®åˆ°checkpoint
    data["original_settings"] = {
        "model": job.settings.model,
        "device": job.settings.device,
        "word_timestamps": job.settings.word_timestamps,
        "compute_type": job.settings.compute_type,
        "batch_size": job.settings.batch_size
    }

    checkpoint_path = job_dir / "checkpoint.json"
    temp_path = checkpoint_path.with_suffix(".tmp")

    try:
        with open(temp_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        os.replace(temp_path, checkpoint_path)
    except Exception as e:
        self.logger.error(f"ä¿å­˜æ£€æŸ¥ç‚¹å¤±è´¥: {e}")
```

#### 2.3.3 APIå¥‘çº¦å®šä¹‰

**æ–°å¢ç«¯ç‚¹ï¼šè·å–Checkpointè®¾ç½®**

```
GET /api/checkpoint-settings/{job_id}
```

**å“åº”Schema**ï¼š

```json
{
  "has_checkpoint": true,
  "original_settings": {
    "model": "medium",
    "device": "cuda",
    "word_timestamps": false,
    "compute_type": "float16",
    "batch_size": 16
  },
  "progress": {
    "phase": "transcribe",
    "processed": 50,
    "total": 100
  }
}
```

**å®ç°ä»£ç **ï¼š

```python
# æ–‡ä»¶: backend/app/api/routes/transcription_routes.py

@router.get("/checkpoint-settings/{job_id}")
async def get_checkpoint_settings(job_id: str):
    """è·å–checkpointä¸­ä¿å­˜çš„åŸå§‹è®¾ç½®"""
    from pathlib import Path

    job = transcription_service.get_job(job_id)
    if not job:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡æœªæ‰¾åˆ°")

    job_dir = Path(job.dir)
    checkpoint_path = job_dir / "checkpoint.json"

    if not checkpoint_path.exists():
        return {"has_checkpoint": False}

    try:
        with open(checkpoint_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        return {
            "has_checkpoint": True,
            "original_settings": data.get("original_settings", {}),
            "progress": {
                "phase": data.get("phase"),
                "processed": len(data.get("processed_indices", [])),
                "total": data.get("total_segments", 0)
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è¯»å–æ£€æŸ¥ç‚¹å¤±è´¥: {str(e)}")
```

---

## ä¸‰ã€éœ€æ±‚2ï¼šæ–­ç‚¹ä¿å­˜æœªå¯¹é½çš„è½¬å½•æ–‡å­—

### 3.1 éœ€æ±‚åˆ†æ

**å½“å‰é—®é¢˜**ï¼š

- ç°æœ‰ä»£ç ä¸­ï¼Œ`_transcribe_segment` æ–¹æ³•åŒæ—¶æ‰§è¡Œäº†è½¬å½•ï¼ˆTranscriptionï¼‰å’Œå¯¹é½ï¼ˆAlignmentï¼‰
- checkpointä¿å­˜çš„æ˜¯å·²å¯¹é½çš„ç»“æœ
- æ— æ³•åœ¨æ–­ç‚¹ç»­ä¼ æ—¶è·³è¿‡å·²å®Œæˆçš„å¯¹é½å·¥ä½œ

**ç›®æ ‡**ï¼š

- å°†è½¬å½•å’Œå¯¹é½åˆ†ç¦»ä¸ºä¸¤ä¸ªç‹¬ç«‹é˜¶æ®µ
- æ–­ç‚¹ä¿å­˜æœªå¯¹é½çš„è½¬å½•æ–‡å­—ï¼ˆç²—ç•¥æ—¶é—´è½´ï¼‰
- æ¢å¤æ—¶ï¼šåŠ è½½æœªå¯¹é½æ–‡å­— â†’ ç»§ç»­è½¬å½• â†’ ç»Ÿä¸€å¯¹é½

### 3.2 WhisperXå·¥ä½œæµç¨‹åˆ†æ

**å½“å‰æµç¨‹**ï¼ˆåœ¨ `_transcribe_segment` ä¸­ï¼‰ï¼š
```python
# 1. Transcriptionï¼ˆè½¬å½•ï¼‰- è€—æ—¶90%
rs = model.transcribe(audio, batch_size=..., language=...)
# rs åŒ…å«: {segments: [{start, end, text}], language: 'zh'}
# æ­¤æ—¶çš„ start/end æ˜¯ç²—ç•¥çš„æ—¶é—´æˆ³

# 2. Alignmentï¼ˆå¯¹é½ï¼‰- è€—æ—¶10%
aligned = whisperx.align(
    rs['segments'],  # è¾“å…¥ç²—ç•¥æ–‡å­—
    align_model,
    metadata,
    audio,
    device
)
# aligned åŒ…å«: {segments: [{start, end, text}], word_segments: [...]}
# æ­¤æ—¶çš„ start/end æ˜¯ç²¾ç¡®çš„æ—¶é—´æˆ³
```

**æ–°æµç¨‹**ï¼ˆåˆ†ç¦»ï¼‰ï¼š
```
é˜¶æ®µ1: è½¬å½•ï¼ˆTranscriptionï¼‰
  å¯¹æ¯ä¸ªsegmentï¼š
    transcribe() â†’ ç²—ç•¥æ—¶é—´è½´çš„æ–‡å­—
    ä¿å­˜åˆ° checkpoint: unaligned_results

é˜¶æ®µ2: å¯¹é½ï¼ˆAlignmentï¼‰
  ç­‰æ‰€æœ‰segmentè½¬å½•å®Œæˆåï¼š
    åˆå¹¶æ‰€æœ‰ unaligned_results
    ä¸€æ¬¡æ€§è°ƒç”¨ align() å¯¹æ•´ä¸ªç»“æœå¯¹é½
    ç”Ÿæˆæœ€ç»ˆçš„ aligned_results
```

### 3.3 æ•°æ®ç»“æ„è®¾è®¡

#### 3.3.1 checkpoint.json ç»“æ„å˜æ›´

**æ–°å¢å­—æ®µ**ï¼š
```json
{
  "job_id": "...",
  "phase": "transcribe" | "align" | "split",
  "total_segments": 100,
  "processed_indices": [0, 1, 2, ...],
  "segments": [...],  // éŸ³é¢‘åˆ†æ®µä¿¡æ¯

  // æ–°å¢ï¼šæœªå¯¹é½çš„è½¬å½•ç»“æœï¼ˆåŸå§‹whisperè¾“å‡ºï¼‰
  "unaligned_results": [
    {
      "segment_index": 0,
      "language": "zh",
      "segments": [
        {
          "id": 0,
          "start": 10.5,    // ç²—ç•¥æ—¶é—´æˆ³
          "end": 15.2,      // ç²—ç•¥æ—¶é—´æˆ³
          "text": "è¿™æ˜¯ç¬¬ä¸€å¥è¯"
        }
      ]
    },
    // ...
  ],

  // åˆ é™¤æ—§å­—æ®µï¼šresultsï¼ˆå·²å¯¹é½çš„ç»“æœï¼‰
  // å¯¹é½ç»“æœä¸éœ€è¦ä¿å­˜åœ¨checkpointä¸­ï¼Œå› ä¸ºå¯ä»¥éšæ—¶é‡æ–°å¯¹é½

  "original_settings": { ... }
}
```

#### 3.3.2 è¿›åº¦é˜¶æ®µæ–°å¢

**æ—§é˜¶æ®µ**ï¼š
```
extract (5%) â†’ split (5%) â†’ transcribe (80%) â†’ srt (10%)
```

**æ–°é˜¶æ®µ**ï¼š
```
extract (5%) â†’ split (5%) â†’ transcribe (70%) â†’ align (10%) â†’ srt (10%)
```

### 3.4 åç«¯å®ç°

#### 3.4.1 ä¿®æ”¹ `_transcribe_segment` æ–¹æ³•

**æ–‡ä»¶**: `backend/app/services/transcription_service.py`

**é‡å‘½åå¹¶ç®€åŒ–**ï¼š
```python
def _transcribe_segment_unaligned(
    self,
    seg: Dict,
    model,
    job: JobState
) -> Optional[Dict]:
    """
    è½¬å½•å•ä¸ªéŸ³é¢‘æ®µï¼ˆä»…è½¬å½•ï¼Œä¸å¯¹é½ï¼‰

    Args:
        seg: æ®µä¿¡æ¯ {file, start_ms, duration_ms}
        model: Whisperæ¨¡å‹
        job: ä»»åŠ¡çŠ¶æ€

    Returns:
        Dict: æœªå¯¹é½çš„è½¬å½•ç»“æœ
        {
            "segment_index": 0,
            "language": "zh",
            "segments": [{"id": 0, "start": 10.5, "end": 15.2, "text": "..."}]
        }
    """
    audio = whisperx.load_audio(seg['file'])

    try:
        # ä»…è¿›è¡ŒTranscriptionï¼Œä¸è¿›è¡ŒAlignment
        rs = model.transcribe(
            audio,
            batch_size=job.settings.batch_size,
            verbose=False,
            language=job.language
        )

        if not rs or 'segments' not in rs:
            return None

        # æ£€æµ‹è¯­è¨€ï¼ˆé¦–æ¬¡ï¼‰
        if not job.language and 'language' in rs:
            job.language = rs['language']
            self.logger.info(f"ğŸŒ æ£€æµ‹åˆ°è¯­è¨€: {job.language}")

        # æ—¶é—´åç§»æ ¡æ­£ï¼ˆé’ˆå¯¹ç²—ç•¥æ—¶é—´æˆ³ï¼‰
        start_offset = seg['start_ms'] / 1000.0
        adjusted_segments = []

        for idx, s in enumerate(rs['segments']):
            adjusted_segments.append({
                'id': idx,
                'start': s.get('start', 0) + start_offset,
                'end': s.get('end', 0) + start_offset,
                'text': s.get('text', '').strip()
            })

        return {
            'segment_index': seg.get('index', 0),  # éœ€è¦åœ¨è°ƒç”¨æ—¶ä¼ å…¥
            'language': rs.get('language', job.language),
            'segments': adjusted_segments
        }

    finally:
        del audio
        gc.collect()
```

#### 3.4.2 æ–°å¢ `_align_all_results` æ–¹æ³•

```python
def _align_all_results(
    self,
    unaligned_results: List[Dict],
    job: JobState,
    audio_path: str
) -> List[Dict]:
    """
    å¯¹æ‰€æœ‰æœªå¯¹é½çš„è½¬å½•ç»“æœè¿›è¡Œç»Ÿä¸€å¯¹é½

    Args:
        unaligned_results: æ‰€æœ‰æœªå¯¹é½çš„è½¬å½•ç»“æœ
        job: ä»»åŠ¡çŠ¶æ€
        audio_path: å®Œæ•´éŸ³é¢‘æ–‡ä»¶è·¯å¾„

    Returns:
        List[Dict]: å¯¹é½åçš„ç»“æœ
    """
    self.logger.info(f"ğŸ”§ å¼€å§‹ç»Ÿä¸€å¯¹é½ {len(unaligned_results)} ä¸ªåˆ†æ®µçš„è½¬å½•ç»“æœ")

    # 1. åˆå¹¶æ‰€æœ‰segments
    all_segments = []
    for result in unaligned_results:
        all_segments.extend(result['segments'])

    if not all_segments:
        self.logger.warning("æ²¡æœ‰å¯å¯¹é½çš„å†…å®¹")
        return []

    # 2. åŠ è½½å®Œæ•´éŸ³é¢‘
    audio = whisperx.load_audio(audio_path)

    try:
        # 3. è·å–å¯¹é½æ¨¡å‹
        lang = job.language or unaligned_results[0].get('language', 'zh')
        align_model, metadata = self._get_align_model(lang, job.settings.device, job)

        # 4. æ‰§è¡Œå¯¹é½ï¼ˆä¸€æ¬¡æ€§å¤„ç†æ‰€æœ‰segmentsï¼‰
        self._update_progress(job, 'align', 0, 'æ­£åœ¨å¯¹é½æ—¶é—´è½´...')

        aligned = whisperx.align(
            all_segments,
            align_model,
            metadata,
            audio,
            job.settings.device
        )

        self._update_progress(job, 'align', 1, 'å¯¹é½å®Œæˆ')

        # 5. è¿”å›å¯¹é½åçš„ç»“æœ
        return [{
            'segments': aligned.get('segments', []),
            'word_segments': aligned.get('word_segments', [])
        }]

    finally:
        del audio
        gc.collect()
```

#### 3.4.3 ä¿®æ”¹ `_run_pipeline` æ–¹æ³•

```python
def _run_pipeline(self, job: JobState):
    """
    æ‰§è¡Œè½¬å½•å¤„ç†ç®¡é“ï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼  + åˆ†ç¦»è½¬å½•å’Œå¯¹é½ï¼‰
    """
    # ... å‰ç½®ä»£ç  ...

    try:
        # ==========================================
        # é˜¶æ®µ1-2: éŸ³é¢‘æå–å’Œåˆ†æ®µï¼ˆä¸å˜ï¼‰
        # ==========================================
        # ... ä»£ç çœç•¥ ...

        # ==========================================
        # é˜¶æ®µ3: è½¬å½•å¤„ç†ï¼ˆä»…è½¬å½•ï¼Œä¸å¯¹é½ï¼‰
        # ==========================================

        # åˆå§‹åŒ–æœªå¯¹é½ç»“æœ
        unaligned_results = []

        # å°è¯•ä»checkpointæ¢å¤
        if checkpoint and 'unaligned_results' in checkpoint:
            unaligned_results = checkpoint['unaligned_results']
            self.logger.info(f"âœ… ä»æ£€æŸ¥ç‚¹æ¢å¤ {len(unaligned_results)} ä¸ªå·²è½¬å½•æ®µ")

        self._update_progress(job, 'transcribe', 0, 'åŠ è½½æ¨¡å‹ä¸­')
        model = self._get_model(job.settings, job)

        # è¿‡æ»¤å‡ºéœ€è¦å¤„ç†çš„æ®µ
        for idx, seg in enumerate(current_segments):
            if idx in processed_indices:
                self.logger.debug(f"â­ï¸ è·³è¿‡å·²è½¬å½•æ®µ {idx}")
                continue

            if job.canceled or job.paused:
                raise RuntimeError('ä»»åŠ¡å·²å–æ¶ˆ' if job.canceled else 'ä»»åŠ¡å·²æš‚åœ')

            # æ·»åŠ segmentç´¢å¼•
            seg['index'] = idx

            # ä»…è½¬å½•ï¼Œä¸å¯¹é½
            result = self._transcribe_segment_unaligned(seg, model, job)

            if result:
                unaligned_results.append(result)

            # æ›´æ–°è¿›åº¦
            processed_indices.add(idx)
            job.processed = len(processed_indices)

            progress = len(processed_indices) / len(current_segments)
            self._update_progress(
                job, 'transcribe', progress,
                f'è½¬å½•ä¸­ {len(processed_indices)}/{len(current_segments)}'
            )

            # ä¿å­˜checkpointï¼ˆåŒ…å«æœªå¯¹é½ç»“æœï¼‰
            checkpoint_data = {
                "job_id": job.job_id,
                "phase": "transcribe",
                "total_segments": len(current_segments),
                "processed_indices": list(processed_indices),
                "segments": current_segments,
                "unaligned_results": unaligned_results  # ä¿å­˜æœªå¯¹é½ç»“æœ
            }
            self._save_checkpoint(job_dir, checkpoint_data, job)

        self._update_progress(job, 'transcribe', 1, 'è½¬å½•å®Œæˆ')

        # ==========================================
        # é˜¶æ®µ4: ç»Ÿä¸€å¯¹é½
        # ==========================================

        self._update_progress(job, 'align', 0, 'å‡†å¤‡å¯¹é½...')

        aligned_results = self._align_all_results(
            unaligned_results,
            job,
            str(audio_path)
        )

        # ==========================================
        # é˜¶æ®µ5: ç”ŸæˆSRT
        # ==========================================

        base_name = os.path.splitext(job.filename)[0]
        srt_path = job_dir / f'{base_name}.srt'

        self._update_progress(job, 'srt', 0, 'ç”Ÿæˆå­—å¹•æ–‡ä»¶...')

        self._generate_srt(
            aligned_results,
            str(srt_path),
            job.settings.word_timestamps
        )

        self._update_progress(job, 'srt', 1, 'å¤„ç†å®Œæˆ')

        job.srt_path = str(srt_path)

        # æ¸…ç†checkpoint
        try:
            checkpoint_file = job_dir / "checkpoint.json"
            checkpoint_file.unlink(missing_ok=True)
            self.logger.info("æ£€æŸ¥ç‚¹å·²æ¸…ç†")
        except Exception as e:
            self.logger.warning(f"æ¸…ç†æ£€æŸ¥ç‚¹å¤±è´¥: {e}")

        job.status = 'finished'
        job.message = 'å®Œæˆ'

    except Exception as e:
        # ... å¼‚å¸¸å¤„ç† ...
```

### 3.5 æ–°å¢APIç«¯ç‚¹ï¼šæå–è½¬å½•æ–‡å­—

**æ–‡ä»¶**: `backend/app/api/routes/transcription_routes.py`

```python
@router.get("/transcription-text/{job_id}")
async def get_transcription_text(job_id: str):
    """
    ä»checkpointä¸­æå–å·²å®Œæˆçš„è½¬å½•æ–‡å­—ï¼ˆæœªå¯¹é½ç‰ˆæœ¬ï¼‰

    è¿”å›æ ¼å¼ï¼š
    {
        "job_id": "...",
        "has_checkpoint": true,
        "language": "zh",
        "segments": [
            {"id": 0, "start": 10.5, "end": 15.2, "text": "ç¬¬ä¸€å¥è¯"},
            {"id": 1, "start": 15.2, "end": 20.0, "text": "ç¬¬äºŒå¥è¯"}
        ],
        "progress": {
            "processed": 50,
            "total": 100,
            "percentage": 50.0
        }
    }
    """
    from pathlib import Path

    job = transcription_service.get_job(job_id)
    if not job:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡æœªæ‰¾åˆ°")

    job_dir = Path(job.dir)
    checkpoint_path = job_dir / "checkpoint.json"

    if not checkpoint_path.exists():
        return {
            "job_id": job_id,
            "has_checkpoint": False,
            "message": "æ²¡æœ‰æ£€æŸ¥ç‚¹æ•°æ®"
        }

    try:
        with open(checkpoint_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        # æå–æœªå¯¹é½ç»“æœ
        unaligned_results = data.get("unaligned_results", [])

        # åˆå¹¶æ‰€æœ‰segments
        all_segments = []
        for result in unaligned_results:
            all_segments.extend(result.get('segments', []))

        # æŒ‰æ—¶é—´æ’åº
        all_segments.sort(key=lambda x: x.get('start', 0))

        # é‡æ–°ç¼–å·
        for idx, seg in enumerate(all_segments):
            seg['id'] = idx

        return {
            "job_id": job_id,
            "has_checkpoint": True,
            "language": data.get("unaligned_results", [{}])[0].get("language", "unknown"),
            "segments": all_segments,
            "progress": {
                "processed": len(data.get("processed_indices", [])),
                "total": data.get("total_segments", 0),
                "percentage": round(
                    len(data.get("processed_indices", [])) / max(1, data.get("total_segments", 1)) * 100,
                    2
                )
            }
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è¯»å–è½¬å½•æ–‡å­—å¤±è´¥: {str(e)}")
```

### 3.6 é…ç½®æ›´æ–°

**æ–‡ä»¶**: `backend/app/core/config.py`

```python
# è¿›åº¦æƒé‡é…ç½®ï¼ˆæ–°å¢aligné˜¶æ®µï¼‰
PHASE_WEIGHTS = {
    "extract": 5,
    "split": 5,
    "transcribe": 70,  # ä»80é™åˆ°70
    "align": 10,       # æ–°å¢
    "srt": 10
}
TOTAL_WEIGHT = sum(PHASE_WEIGHTS.values())  # 100
```

---

## å››ã€éœ€æ±‚3ï¼šå®ç°è½¬å½•æ–‡å­—çš„æµå¼è¾“å‡º

### 4.1 éœ€æ±‚åˆ†æ

**ç›®æ ‡**ï¼š
- è½¬å½•æ¯å®Œæˆä¸€ä¸ªç‰‡æ®µï¼Œç«‹å³å°†æœªå¯¹é½æ–‡å­—æ¨é€åˆ°å‰ç«¯
- ç”¨æˆ·å¯ä»¥å®æ—¶æŸ¥çœ‹å’Œä¿®æ”¹è½¬å½•æ–‡å­—
- å¯¹é½å®Œæˆåï¼Œç¬é—´æ›´æ–°æ‰€æœ‰æ–‡å­—ï¼ˆä¿ç•™ç”¨æˆ·ä¿®æ”¹ï¼‰

**æŠ€æœ¯é€‰å‹**ï¼š

- **é€šä¿¡æ–¹å¼**: SSE (Server-Sent Events)
- **å‰ç«¯å±•ç¤º**: è™šæ‹Ÿæ»šåŠ¨åˆ—è¡¨ (vue-virtual-scroller)
- **æ•°æ®ç®¡ç†**: Pinia store + shallowRef
- **ç”¨æˆ·ä¿®æ”¹**: is_modified è„æ ‡è®°æœºåˆ¶

### 4.2 æ¶æ„è®¾è®¡

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       åç«¯æ¶æ„                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  è½¬å½•å¾ªç¯                     SSEæ¨é€                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚ segment_0   â”‚â”€â”€è½¬å½•å®Œæˆâ”€â”€â†’â”‚ type: segment â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚ data: {...}   â”‚â”€â”€â”€æ¨é€â”€â”       â”‚
â”‚                             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚       â”‚
â”‚  â”‚ segment_1   â”‚â”€â”€è½¬å½•å®Œæˆâ”€â”€â†’â”‚ type: segment â”‚        â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚ data: {...}   â”‚â”€â”€â”€æ¨é€â”€â”¤       â”‚
â”‚                             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚       â”‚
â”‚       ...                         ...               â”‚       â”‚
â”‚                                                      â”‚       â”‚
â”‚  ç»Ÿä¸€å¯¹é½                                             â”‚       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚       â”‚
â”‚  â”‚ align_all   â”‚â”€â”€å¯¹é½å®Œæˆâ”€â”€â†’â”‚ type: aligned â”‚        â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚ data: [...]   â”‚â”€â”€â”€æ¨é€â”€â”¤       â”‚
â”‚                             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.3 åç«¯å®ç°

#### 4.3.1 SSEæ¨é€æœåŠ¡

**æ–‡ä»¶**: `backend/app/services/sse_service.py` (æ–°å»º)

```python
"""
SSE (Server-Sent Events) æ¨é€æœåŠ¡
"""
import asyncio
import json
import logging
from typing import Dict, Optional
from collections import defaultdict
from fastapi import Request

logger = logging.getLogger(__name__)


class SSEManager:
    """SSEè¿æ¥ç®¡ç†å™¨"""

    def __init__(self):
        # æ¯ä¸ªjob_idå¯èƒ½æœ‰å¤šä¸ªå®¢æˆ·ç«¯è¿æ¥
        self.connections: Dict[str, list] = defaultdict(list)

    async def subscribe(self, job_id: str, request: Request):
        """
        è®¢é˜…ä»»åŠ¡çš„SSEäº‹ä»¶æµ

        Args:
            job_id: ä»»åŠ¡ID
            request: FastAPIè¯·æ±‚å¯¹è±¡

        Yields:
            SSEæ ¼å¼çš„æ¶ˆæ¯
        """
        # åˆ›å»ºé˜Ÿåˆ—
        queue = asyncio.Queue()
        self.connections[job_id].append(queue)

        try:
            logger.info(f"SSEå®¢æˆ·ç«¯å·²è¿æ¥: job_id={job_id}")

            # å‘é€è¿æ¥æˆåŠŸæ¶ˆæ¯
            yield self._format_sse({
                "type": "connected",
                "job_id": job_id,
                "message": "SSEè¿æ¥å·²å»ºç«‹"
            })

            # æŒç»­æ¨é€æ¶ˆæ¯
            while True:
                # æ£€æŸ¥å®¢æˆ·ç«¯æ˜¯å¦æ–­å¼€
                if await request.is_disconnected():
                    logger.info(f"SSEå®¢æˆ·ç«¯å·²æ–­å¼€: job_id={job_id}")
                    break

                try:
                    # ç­‰å¾…æ–°æ¶ˆæ¯ï¼ˆè¶…æ—¶10ç§’å‘é€å¿ƒè·³ï¼‰
                    message = await asyncio.wait_for(queue.get(), timeout=10.0)
                    yield self._format_sse(message)
                except asyncio.TimeoutError:
                    # å‘é€å¿ƒè·³ä¿æŒè¿æ¥
                    yield ": heartbeat\n\n"

        finally:
            # æ¸…ç†è¿æ¥
            self.connections[job_id].remove(queue)
            if not self.connections[job_id]:
                del self.connections[job_id]
            logger.info(f"SSEè¿æ¥å·²æ¸…ç†: job_id={job_id}")

    async def broadcast(self, job_id: str, message: dict):
        """
        å‘æŒ‡å®šä»»åŠ¡çš„æ‰€æœ‰è®¢é˜…è€…å¹¿æ’­æ¶ˆæ¯

        Args:
            job_id: ä»»åŠ¡ID
            message: æ¶ˆæ¯å†…å®¹
        """
        if job_id not in self.connections:
            return

        for queue in self.connections[job_id]:
            try:
                await queue.put(message)
            except Exception as e:
                logger.error(f"SSEæ¨é€å¤±è´¥: {e}")

    def _format_sse(self, data: dict) -> str:
        """
        æ ¼å¼åŒ–ä¸ºSSEæ¶ˆæ¯æ ¼å¼

        Args:
            data: æ•°æ®å­—å…¸

        Returns:
            SSEæ ¼å¼å­—ç¬¦ä¸²
        """
        return f"data: {json.dumps(data, ensure_ascii=False)}\n\n"


# å…¨å±€å•ä¾‹
_sse_manager: Optional[SSEManager] = None


def get_sse_manager() -> SSEManager:
    """è·å–SSEç®¡ç†å™¨å•ä¾‹"""
    global _sse_manager
    if _sse_manager is None:
        _sse_manager = SSEManager()
    return _sse_manager
```

#### 4.3.2 é›†æˆSSEæ¨é€åˆ°è½¬å½•æœåŠ¡

**æ–‡ä»¶**: `backend/app/services/transcription_service.py`

```python
# åœ¨ __init__ ä¸­æ·»åŠ 
def __init__(self, jobs_root: str):
    # ... ç°æœ‰ä»£ç  ...

    # é›†æˆSSEç®¡ç†å™¨
    from services.sse_service import get_sse_manager
    self.sse_manager = get_sse_manager()


# åœ¨ _run_pipeline ä¸­çš„è½¬å½•å¾ªç¯æ·»åŠ æ¨é€
def _run_pipeline(self, job: JobState):
    # ... å‰ç½®ä»£ç  ...

    # åœ¨è½¬å½•å¾ªç¯ä¸­
    for idx, seg in enumerate(current_segments):
        if idx in processed_indices:
            continue

        # è½¬å½•
        result = self._transcribe_segment_unaligned(seg, model, job)

        if result:
            unaligned_results.append(result)

            # ã€æ–°å¢ã€‘ç«‹å³æ¨é€åˆ°å‰ç«¯
            asyncio.create_task(self.sse_manager.broadcast(
                job.job_id,
                {
                    "type": "segment",
                    "data": {
                        "segment_index": idx,
                        "segments": result['segments'],
                        "language": result.get('language'),
                        "progress": {
                            "processed": len(processed_indices) + 1,
                            "total": len(current_segments),
                            "percentage": round(
                                (len(processed_indices) + 1) / len(current_segments) * 100,
                                2
                            )
                        }
                    }
                }
            ))

        # æ›´æ–°processed_indiceså’Œä¿å­˜checkpoint
        processed_indices.add(idx)
        # ...

    # å¯¹é½å®Œæˆåæ¨é€
    aligned_results = self._align_all_results(...)

    # ã€æ–°å¢ã€‘æ¨é€å¯¹é½å®Œæˆäº‹ä»¶
    asyncio.create_task(self.sse_manager.broadcast(
        job.job_id,
        {
            "type": "aligned",
            "data": {
                "segments": aligned_results[0]['segments'],
                "word_segments": aligned_results[0].get('word_segments', []),
                "message": "å¯¹é½å®Œæˆ"
            }
        }
    ))
```

#### 4.3.3 SSE APIç«¯ç‚¹

**æ–‡ä»¶**: `backend/app/api/routes/transcription_routes.py`

```python
from fastapi import Request
from fastapi.responses import StreamingResponse
from services.sse_service import get_sse_manager

sse_manager = get_sse_manager()


@router.get("/stream/{job_id}")
async def stream_transcription(job_id: str, request: Request):
    """
    è®¢é˜…ä»»åŠ¡çš„SSEäº‹ä»¶æµ

    äº‹ä»¶ç±»å‹ï¼š
    - connected: è¿æ¥å»ºç«‹
    - segment: å•ä¸ªç‰‡æ®µè½¬å½•å®Œæˆ
    - aligned: å…¨éƒ¨å¯¹é½å®Œæˆ
    - error: é”™è¯¯äº‹ä»¶
    """
    job = transcription_service.get_job(job_id)
    if not job:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡æœªæ‰¾åˆ°")

    return StreamingResponse(
        sse_manager.subscribe(job_id, request),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"  # ç¦ç”¨nginxç¼“å†²
        }
    )
```

**æ³¨æ„**ï¼šå‰ç«¯å¦‚ä½•ä½¿ç”¨è¿™äº›APIè¿›è¡Œå‚æ•°æ ¡éªŒã€SSEç›‘å¬ã€å­—å¹•ç¼–è¾‘ç­‰åŠŸèƒ½ï¼Œè¯·å‚è€ƒã€Šæ–°ç•Œé¢å¼€å‘.mdã€‹æ–‡æ¡£ã€‚

---

## äº”ã€å®æ–½æ­¥éª¤

### 5.1 ä¼˜å…ˆçº§æ’åº

| åŠŸèƒ½ | ä¼˜å…ˆçº§ | é¢„è®¡å·¥æ—¶ | ä¾èµ– |
|------|--------|----------|------|
| éœ€æ±‚2ï¼šåˆ†ç¦»è½¬å½•å’Œå¯¹é½ | **P0** | 6å°æ—¶ | æ—  |
| éœ€æ±‚1ï¼šå‚æ•°ä¿®æ”¹æ ¡éªŒ | **P1** | 4å°æ—¶ | éœ€æ±‚2 |
| éœ€æ±‚3ï¼šåŸºç¡€SSEæ¨é€ | **P1** | 8å°æ—¶ | éœ€æ±‚2 |
| éœ€æ±‚3ï¼šæ€§èƒ½ä¼˜åŒ–ï¼ˆWorkerï¼‰ | **P3** | 4å°æ—¶ | éœ€æ±‚3å‰ç«¯ |

### 5.2 å®æ–½é¡ºåº

**ç¬¬ä¸€é˜¶æ®µï¼ˆæ ¸å¿ƒåŠŸèƒ½ï¼‰**ï¼š

1. ä¿®æ”¹checkpointæ•°æ®ç»“æ„ï¼Œæ·»åŠ `unaligned_results`å’Œ`original_settings`å­—æ®µ
2. é‡æ„`_transcribe_segment`ä¸º`_transcribe_segment_unaligned`
3. å®ç°`_align_all_results`æ–¹æ³•
4. ä¿®æ”¹`_run_pipeline`ï¼Œåˆ†ç¦»è½¬å½•å’Œå¯¹é½é˜¶æ®µ
5. æ›´æ–°è¿›åº¦æƒé‡é…ç½®
6. æµ‹è¯•æ–­ç‚¹ç»­ä¼ æ˜¯å¦æ­£å¸¸å·¥ä½œ

**ç¬¬äºŒé˜¶æ®µï¼ˆå‚æ•°æ ¡éªŒï¼‰**ï¼š
1. å®ç°åç«¯checkpointè®¾ç½®ä¿å­˜é€»è¾‘
2. æ·»åŠ `/checkpoint-settings/{job_id}`APIç«¯ç‚¹
3. å‰ç«¯å®ç°å‚æ•°æ ¡éªŒé€»è¾‘
4. é›†æˆåˆ°æ¢å¤ä»»åŠ¡æµç¨‹
5. æµ‹è¯•å‚æ•°ä¿®æ”¹æç¤ºå’Œæ ¡éªŒ

**ç¬¬ä¸‰é˜¶æ®µï¼ˆæµå¼è¾“å‡ºï¼‰**ï¼š
1. åˆ›å»ºSSEæœåŠ¡ï¼ˆ`sse_service.py`ï¼‰
2. åœ¨è½¬å½•æœåŠ¡ä¸­é›†æˆSSEæ¨é€
3. æ·»åŠ `/stream/{job_id}`APIç«¯ç‚¹

**ç¬¬å››é˜¶æ®µï¼ˆä¼˜åŒ–å’Œå®Œå–„ï¼‰**ï¼š

1. æ·»åŠ Web Workeræ”¯æŒï¼ˆå¯é€‰ï¼‰
2. æ€§èƒ½æµ‹è¯•å’Œä¼˜åŒ–
3. å®Œå–„é”™è¯¯å¤„ç†å’Œè¾¹ç•Œæƒ…å†µ

---

## å…­ã€æµ‹è¯•è®¡åˆ’

### 6.1 åŠŸèƒ½æµ‹è¯•

**éœ€æ±‚1ï¼šå‚æ•°ä¿®æ”¹**
- [ ] æ¢å¤ä»»åŠ¡æ—¶ä¿®æ”¹ç¦æ­¢å‚æ•°ï¼Œåº”å¼ºåˆ¶æ¢å¤åŸå€¼
- [ ] æ¢å¤ä»»åŠ¡æ—¶ä¿®æ”¹å…è®¸å‚æ•°ï¼Œåº”å¼¹å‡ºæç¤º
- [ ] ç”¨æˆ·ç¡®è®¤ä¿®æ”¹åï¼Œä½¿ç”¨æ–°å‚æ•°ç»§ç»­è½¬å½•
- [ ] ç”¨æˆ·å–æ¶ˆä¿®æ”¹ï¼Œæ¢å¤ä¸ºåŸå‚æ•°

**éœ€æ±‚2ï¼šè½¬å½•ä¿å­˜**
- [ ] è½¬å½•è¿‡ç¨‹ä¸­æ–­ï¼ŒcheckpointåŒ…å«æœªå¯¹é½ç»“æœ
- [ ] æ¢å¤ä»»åŠ¡åç»§ç»­è½¬å½•å‰©ä½™ç‰‡æ®µ
- [ ] æœ€åç»Ÿä¸€å¯¹é½æ‰€æœ‰ç»“æœ
- [ ] è°ƒç”¨`/transcription-text/{job_id}`èƒ½æ­£ç¡®æå–æ–‡å­—

**éœ€æ±‚3ï¼šæµå¼è¾“å‡º**

- [ ] SSEè¿æ¥æˆåŠŸå»ºç«‹
- [ ] æ¯è½¬å½•å®Œä¸€ä¸ªç‰‡æ®µç«‹å³æ¨é€åˆ°å‰ç«¯
- [ ] ç”¨æˆ·ä¿®æ”¹å­—å¹•åï¼Œis_modifiedæ ‡è®°æ­£ç¡®
- [ ] å¯¹é½å®Œæˆåï¼Œæœªä¿®æ”¹å­—å¹•æ›´æ–°ï¼Œå·²ä¿®æ”¹å­—å¹•ä¿ç•™
- [ ] å¯¼å‡ºSRTåŒ…å«ç”¨æˆ·çš„æ‰€æœ‰ä¿®æ”¹

### 6.2 æ€§èƒ½æµ‹è¯•

- [ ] 2å°æ—¶è§†é¢‘ï¼ˆçº¦2000æ¡å­—å¹•ï¼‰çš„æ¸²æŸ“æ€§èƒ½
- [ ] SSEæ¨é€é¢‘ç‡æµ‹è¯•ï¼ˆæ¯ç§’1-2æ¡æ¶ˆæ¯ï¼‰
- [ ] å¯¹é½å®Œæˆæ—¶çš„åˆå¹¶æ€§èƒ½ï¼ˆ2000æ¡æ•°æ®ï¼‰
- [ ] å†…å­˜å ç”¨ç›‘æ§

### 6.3 è¾¹ç•Œæµ‹è¯•

- [ ] SSEè¿æ¥æ„å¤–æ–­å¼€çš„å¤„ç†
- [ ] è½¬å½•è¿‡ç¨‹ä¸­åˆ‡æ¢ä»»åŠ¡
- [ ] æš‚åœåæ–­å¼€SSEï¼Œæ¢å¤åé‡æ–°è¿æ¥
- [ ] checkpointæ–‡ä»¶æŸåçš„å¤„ç†
- [ ] å‚æ•°æ ¡éªŒå¼‚å¸¸å¤„ç†

---

## ä¸ƒã€å…¼å®¹æ€§ä¿éšœ

### 7.1 å‘åå…¼å®¹

**æ—§checkpointæ ¼å¼å…¼å®¹**ï¼š
```python
# åŠ è½½checkpointæ—¶å…¼å®¹æ—§æ ¼å¼
checkpoint = self._load_checkpoint(job_dir)

if checkpoint:
    # æ—§æ ¼å¼ï¼šresultså­—æ®µï¼ˆå·²å¯¹é½ï¼‰
    if 'results' in checkpoint and 'unaligned_results' not in checkpoint:
        self.logger.warning("æ£€æµ‹åˆ°æ—§ç‰ˆcheckpointæ ¼å¼ï¼Œå°†è·³è¿‡å¯¹é½é˜¶æ®µ")
        # ç›´æ¥ä½¿ç”¨resultsä½œä¸ºæœ€ç»ˆç»“æœ
        final_results = checkpoint['results']
    # æ–°æ ¼å¼ï¼šunaligned_resultså­—æ®µ
    elif 'unaligned_results' in checkpoint:
        unaligned_results = checkpoint['unaligned_results']
        # ç»§ç»­æ–°æµç¨‹
```

### 7.2 æ¸è¿›å¼å¢å¼º

- SSEåŠŸèƒ½å¯é€‰ï¼šå¦‚æœå‰ç«¯ä¸è¿æ¥SSEï¼Œä¸å½±å“åŸºæœ¬è½¬å½•åŠŸèƒ½
- å­—å¹•ç¼–è¾‘å™¨å¯é€‰ï¼šå¯ä»¥ä¿ç•™æ—§çš„è¿›åº¦æ¡UIï¼Œæ–°å¢ç¼–è¾‘å™¨ä½œä¸ºå¯é€‰åŠŸèƒ½
- å‚æ•°æ ¡éªŒå¯é€‰ï¼šå¦‚æœå‰ç«¯ä¸è°ƒç”¨æ ¡éªŒAPIï¼Œåç«¯ä»æ­£å¸¸å·¥ä½œ

## ä¹ã€é™„å½•

### 9.1 ç›¸å…³æ–‡ä»¶æ¸…å•

**åç«¯æ–°å»ºæ–‡ä»¶**ï¼š
- `backend/app/services/sse_service.py` - SSEæ¨é€æœåŠ¡

**åç«¯ä¿®æ”¹æ–‡ä»¶**ï¼š
- `backend/app/services/transcription_service.py` - æ ¸å¿ƒè½¬å½•æœåŠ¡
- `backend/app/api/routes/transcription_routes.py` - APIè·¯ç”±
- `backend/app/core/config.py` - é…ç½®æ–‡ä»¶

**å‰ç«¯å®ç°**ï¼šæ‰€æœ‰å‰ç«¯æ–‡ä»¶çš„åˆ›å»ºå’Œä¿®æ”¹è¯·å‚è€ƒã€Šæ–°ç•Œé¢å¼€å‘.mdã€‹æ–‡æ¡£ã€‚

### 9.2 ä¾èµ–åŒ…

**å‰ç«¯æ–°å¢**ï¼š
```json
{
  "dependencies": {
    "vue-virtual-scroller": "^2.0.0-beta.8"
  }
}
```

**åç«¯æ— æ–°å¢ä¾èµ–**ï¼ˆä½¿ç”¨FastAPIå†…ç½®çš„StreamingResponseï¼‰

---

**æ–‡æ¡£ç»“æŸ**
