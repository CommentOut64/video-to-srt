### 问题 1：缺少关键的音频提取方法 ⚠️ **部分存在**

**现有实现：**

| 方法 | 状态 | 位置 |
|------|------|------|
| `_extract_audio(input_file, audio_out)` | ✅ 已存在 | `transcription_service.py:2822` |
| `_extract_audio_with_array()` | ❌ 不存在 | Phase3 文档中定义，需要新实现 |
| `_sensevoice_transcribe()` | ❌ 不存在 | 需要新实现，但底层服务 sensevoice_onnx_service.py 已存在 |
| `_split_sentences()` | ⚠️ 需要适配 | sentence_splitter.py 已存在，但需要包装 |
| `_generate_subtitle_from_sentences()` | ❌ 不存在 | 需要新实现 |

**结论**：底层组件存在，但**包装方法需要新实现**。
目前已经新增包装方法。

---

### 问题 2：SenseVoice ONNX 服务缺失 ✅ **已存在**

**实际情况**：

sensevoice_onnx_service.py **已经存在**且功能完整：
- 位置：sensevoice_onnx_service.py
- 关键方法：
  - `load_model()` - 加载模型
  - `transcribe(audio_path)` - 转录音频文件
  - `transcribe_audio_array(audio_array, sample_rate)` - 转录音频数组
- 单例获取：`get_sensevoice_service()`

---

### 问题 3：ProcessPhase 枚举不匹配 ✅ **不存在此问题**

**实际情况**：

progress_tracker.py 中的定义是正确的：
```python
class ProcessPhase(Enum):
    WHISPER_PATCH = "whisper"  # 枚举名是 WHISPER_PATCH，值是 "whisper"
```

Phase3 文档中使用 `ProcessPhase.WHISPER_PATCH` 是正确的用法，不会有问题。

---

### 问题 4：方案配置集成不明确 ⚠️ **需要扩展**

**现有实现**：

job_models.py 中的 `JobSettings` 结构：
```python
@dataclass
class JobSettings:
    model: str = "medium"
    compute_type: str = "float16"
    device: str = "cuda"
    batch_size: int = 16
    word_timestamps: bool = False
    cpu_affinity: Optional["CPUAffinityConfig"] = None
    demucs: DemucsSettings = field(default_factory=DemucsSettings)
```

**缺失字段**：
- `engine: str` - 选择转录引擎（whisper/sensevoice）
- `preset_id: str` - 预设方案ID
- `enhancement: str` - 增强模式
- `proofread: str` - 校对模式
- `translate: str` - 翻译模式

**结论**：需要扩展 `JobSettings` 以支持新架构。

目前已经完成字段扩展

---

### 问题 5：VAD 切分返回格式不明确 ✅ **格式已确认**

**实际返回格式**（来自 `_memory_vad_split` / `_vad_silero`）：
```python
[
    {"index": 0, "start": 0.0, "end": 30.5, "mode": "memory"},
    {"index": 1, "start": 30.5, "end": 58.2, "mode": "memory"},
    ...
]
```

这与 Phase3 文档假设的格式**完全一致**，不存在兼容性问题。

---

### 问题 6：音频数组的采样率假设 ⚠️ **需要注意**

**各组件的采样率要求**：

| 组件 | 要求采样率 | 说明 |
|------|-----------|------|
| `_extract_audio()` | 输出 16000 Hz | FFmpeg 命令中硬编码 `-ar 16000` |
| Silero VAD | 16000 Hz | 标准要求 |
| SenseVoice (funasr-onnx) | 16000 Hz | 标准要求 |
| Whisper | 16000 Hz | 标准要求 |
| Demucs | 44100 Hz | 内部会重采样 |

**结论**：
- 音频提取输出 16000 Hz（已硬编码）
- VAD 和转录都使用 16000 Hz
- Demucs 内部处理重采样（`separate_chunk` 方法已处理）
- **硬编码 `sr=16000` 是安全的**

---

以下特别补充：
2. **核心修改：重写 sensevoice_onnx_service.py**
   - 移除 `funasr-onnx` 依赖
   - 改为**纯 ONNX Runtime + 自研 CTC 解码器**
   - 新增 `CTCDecoder` 类，从 Logits 提取字级时间戳
   - `time_stride = 0.06`（60ms，因为 SenseVoice 有 6 倍下采样）
   - 动态计算 stride：`actual_stride = (input_frames * 0.01) / output_frames`

3. **修正 transcription_service.py 中的包装方法**：
   - `_sensevoice_transcribe()` 应返回带**真实字级时间戳**的结果
   - `_split_sentences()` 应基于真实时间戳切分，而不是伪对齐
   - 移除 `_generate_pseudo_word_timestamps()` 方法（不再需要）

4. **依赖变更**：
   - 移除：`funasr-onnx`
   - 保留：`onnxruntime` / `onnxruntime-gpu`, `numpy`, `librosa`


