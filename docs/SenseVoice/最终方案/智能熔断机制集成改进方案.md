# 智能熔断机制集成改进方案

> 基于现有Demucs集成架构，优化BGM检测流程，降低GPU依赖，提升整体性能

---

## 一、当前架构分析

### 1.1 现有BGM检测流程（已实现）

```
音频提取 → BGM检测（Demucs试分离）→ 策略解析 → [全局分离] → VAD分段 → 转录[按需分离]
            ↓                          ↓
      加载htdemucs               决定是否全局分离
      采样3个点检测              (NONE/LIGHT/HEAVY)
      基于RMS能量比
      卸载模型
```

**现有实现的优点**：
- ✅ 检测准确（基于实际分离效果）
- ✅ 支持分级策略（NONE/LIGHT/HEAVY）
- ✅ 完整的熔断机制（升级优先）
- ✅ 双模式分离（全局+按需）

**现有实现的痛点**：
- ❌ **检测成本高**：需要加载Demucs模型（约1.5GB显存）
- ❌ **显存浪费**：检测后需卸载，决定分离后再次加载
- ❌ **检测粒度粗**：全局检测无法处理局部BGM
- ❌ **SenseVoice集成后的瓶颈**：转录速度提升15倍，但BGM检测仍是瓶颈

### 1.2 智能熔断机制提案（新方案）

```
VAD分段 → 逐片段频谱分析 → 决策 → [按需分离] → 转录
          ↓                  ↓
    ZCR方差+谱质心      should_separate
    滑动窗口历史        (True/False)
    纯CPU运行
```

**新方案的优点**：
- ✅ **成本极低**：纯CPU，无需GPU
- ✅ **细粒度**：每个片段独立判断
- ✅ **惯性机制**：利用时间连续性
- ✅ **速度快**：频谱分析 < 10ms

**新方案的挑战**：
- ⚠️ **准确性未知**：频谱特征是否能准确识别BGM
- ⚠️ **参数调优**：阈值需要大量测试
- ⚠️ **边界情况**：低音量BGM可能漏检

---

## 二、核心问题识别

### 问题1：显存管理冲突 🔥

**现状**：
```
BGM检测: 加载Demucs(1.5GB) → 检测 → 卸载
全局分离: 加载Demucs(1.5GB) → 分离 → 卸载
转录: 加载SenseVoice(550MB) 或 Whisper(769MB) → 转录
对齐: 加载AlignModel → 对齐
```

**问题**：
- 如果检测判定需要全局分离，Demucs被加载/卸载**两次**
- 如果检测判定不需要分离，第一次加载Demucs完全浪费
- SenseVoice集成后，模型切换次数增加（SenseVoice ↔ Whisper ↔ Demucs）

### 问题2：检测粒度不匹配 🎯

**现状**：
- BGM检测是**全局的**（在3个采样点检测）
- 分离策略是**全局的**（要么全局分离，要么全部按需）

**场景**：
```
视频结构: [纯人声片段 30s] + [BGM+人声片段 60s] + [纯人声片段 30s]

当前处理:
- 全局检测 → LIGHT级别 → 全局分离 → 所有片段都被分离（浪费）

理想处理:
- 逐片段检测 → 只分离中间60s → 节省70%处理时间
```

### 问题3：进度反馈不精确 📊

**现状**：
- BGM检测阶段：2%（固定）
- Demucs全局分离：8%（固定）

**问题**：
- 如果只有少量片段需要分离，用户看到8%的进度但实际消耗时间很少
- 如果大量片段需要分离，8%的进度覆盖了大部分时间

**理想**：
- 动态权重：根据实际需要分离的片段数量调整权重
- 细粒度进度：分离过程中实时更新进度

### 问题4：与SenseVoice集成的不协调 ⚡

**SenseVoice集成后的理想流程**：
```
VAD分段 → 轻量级检测 → 按需分离 → SenseVoice快速转录
          ↓              ↓             ↓
       CPU分析        仅必要片段      15倍速度
       < 10ms        节省显存       < 1s/10s音频
```

**当前流程的不协调**：
```
BGM检测 → 全局分离 → VAD分段 → SenseVoice转录
  ↓          ↓                    ↓
GPU+1.5GB   GPU+1.5GB          GPU+550MB
需加载2次   全部分离           速度快但被前置步骤拖累
```

---

## 三、改进方案设计

### 方案：可配置分层检测架构（最终方案）⭐

**核心设计原则**：
- ✅ **默认模式**：完全信任频谱检测（极速模式）
- ✅ **可选模式**：频谱预判 + Demucs验证（精确模式）
- ✅ **后备方案**：保留原有全局BGM检测（遗留模式）
- ✅ **显存管理**：严格串行化，任何时刻只加载一个模型
- ✅ **验证模型**：使用mdx_extra高质量模型

#### 3.1 整体流程

**模式1：极速模式（默认）**

```
                    音频提取
                       ↓
        ┌──────────────────────────┐
        │    VAD语音活动检测        │
        │  输出: segments列表       │
        └──────────────────────────┘
                       ↓
        ┌──────────────────────────┐
        │   频谱指纹预判            │
        │  - 纯CPU，极速（<1s）     │
        │  - 逐片段分析             │
        │  - 输出: 是否需要分离     │
        └──────────────────────────┘
                       ↓
              ╔═══════════════╗
              ║  需要分离？    ║
              ╚═══════════════╝
               /              \
            YES               NO
             ↓                 ↓
  ┌─────────────────┐   ┌──────────────┐
  │  按需分离        │   │  直接转录     │
  │- 加载mdx_extra  │   │  (无需分离)  │
  │- 仅必要片段     │   └──────────────┘
  │- 卸载模型       │
  └─────────────────┘
             ↓
        加载SenseVoice
             ↓
        逐片段转录
             ↓
        卸载SenseVoice
             ↓
      （需要Whisper补刀？）
             ↓
      加载Whisper → 补刀 → 卸载
```

**模式2：精确模式（可选）**

```
                    VAD分段
                       ↓
        ┌──────────────────────────┐
        │   第一层：频谱预判        │
        │  输出: 可疑片段列表       │
        └──────────────────────────┘
                       ↓
        ┌──────────────────────────┐
        │  第二层：Demucs验证       │
        │  - 仅验证可疑片段         │
        │  - 使用mdx_extra          │
        │  - 确认BGM级别            │
        └──────────────────────────┘
                       ↓
           按需分离 → 转录
```

**模式3：遗留模式（后备）**

```
     音频提取 → 全局BGM检测 → [全局分离] → VAD → 转录
                 (现有逻辑)
```

#### 3.2 核心组件设计

##### 3.2.1 频谱指纹检测器（第一层）

**文件**：`backend/app/services/audio_circuit_breaker.py` (新增)

```python
from dataclasses import dataclass
from typing import List
import numpy as np
from collections import deque


@dataclass
class CircuitBreakerDecision:
    """熔断器决策结果"""
    segment_index: int
    should_separate: bool        # 是否需要分离（极速模式）
    should_verify: bool          # 是否需要验证（精确模式）
    confidence: float            # 置信度评分
    reason: str                  # 决策原因
    spectral_score: float        # 频谱音乐性评分


class AudioCircuitBreaker:
    """
    音频熔断器 - 轻量级BGM预判

    功能:
    1. 逐片段频谱分析（ZCR方差 + 谱质心标准差）
    2. 滑动窗口历史惯性机制
    3. 支持极速模式（直接决策）和精确模式（需验证）
    """

    def __init__(self, config: dict = None, mode: str = 'turbo'):
        """
        Args:
            config: 配置参数
            mode: 'turbo'（极速模式） | 'precise'（精确模式）
        """
        self.config = config or self._default_config()
        self.mode = mode
        self.history = deque(maxlen=self.config['history_size'])

    def _default_config(self) -> dict:
        return {
            # 基础参数
            'sr': 16000,
            'n_fft': 512,
            'hop_length': 256,

            # 历史惯性参数
            'history_size': 5,
            'history_threshold': 0.6,      # 60%历史为BGM则触发惯性

            # 决策阈值
            'music_score_threshold': 0.35, # 音乐性评分阈值
            'reset_score': 0.15,           # 极度干净的阈值

            # 精确模式专用
            'verify_threshold': 0.5        # 需要验证的置信度阈值
        }

    def analyze_segment(
        self,
        audio_chunk: np.ndarray,
        segment_index: int
    ) -> CircuitBreakerDecision:
        """
        分析单个音频片段

        Args:
            audio_chunk: 音频数组（16kHz, float32）
            segment_index: 片段索引

        Returns:
            CircuitBreakerDecision: 决策结果
        """
        # 1. 计算频谱特征
        music_score = self._compute_spectral_score(audio_chunk)

        # 2. 极度干净判断（重置惯性）
        if music_score < self.config['reset_score']:
            self._update_history(False)
            return CircuitBreakerDecision(
                segment_index=segment_index,
                should_separate=False,
                should_verify=False,
                confidence=1.0 - music_score,
                reason='clean_reset',
                spectral_score=music_score
            )

        # 3. 计算历史惯性
        history_confidence = self._get_history_confidence()

        # 4. 决策逻辑
        if len(self.history) >= 3 and history_confidence >= self.config['history_threshold']:
            # 惯性触发：历史显示有BGM
            should_separate = True
            reason = 'history_inertia'
            confidence = history_confidence
        else:
            # 无惯性：依赖当前检测
            should_separate = music_score > self.config['music_score_threshold']
            reason = 'fingerprint_detection'
            confidence = music_score

        # 5. 模式判断
        if self.mode == 'turbo':
            # 极速模式：直接决策，不验证
            should_verify = False
        elif self.mode == 'precise':
            # 精确模式：置信度不足时需要验证
            if should_separate and confidence < self.config['verify_threshold']:
                should_verify = True
                reason = f'{reason}_needs_verification'
            else:
                should_verify = False
        else:
            should_verify = False

        self._update_history(should_separate)

        return CircuitBreakerDecision(
            segment_index=segment_index,
            should_separate=should_separate,
            should_verify=should_verify,
            confidence=confidence,
            reason=reason,
            spectral_score=music_score
        )

    def _compute_spectral_score(self, audio_chunk: np.ndarray) -> float:
        """
        计算频谱音乐性评分

        基于:
        - ZCR方差：音乐的ZCR变化通常比语音平滑
        - 谱质心标准差：音乐的频率中心波动较小
        """
        if len(audio_chunk) < self.config['n_fft']:
            return 0.0

        y = audio_chunk + 1e-10  # 防止除零

        # 计算ZCR方差
        zcr = np.abs(np.diff(np.signbit(y))).sum() / (len(y) - 1)

        # 分帧计算频谱特征
        n_fft = self.config['n_fft']
        hop_length = self.config['hop_length']
        num_frames = (len(y) - n_fft) // hop_length + 1

        if num_frames <= 0:
            return 0.0

        frame_zcrs = []
        centroids = []

        # 采样策略：最多50帧
        step = max(1, num_frames // 50)

        for i in range(0, num_frames, step):
            start = i * hop_length
            end = start + n_fft
            frame = y[start:end] * np.hanning(n_fft)

            # 帧ZCR
            frame_zcr = np.sum(np.abs(np.diff(np.signbit(frame)))) / len(frame)
            frame_zcrs.append(frame_zcr)

            # 频谱质心
            spectrum = np.abs(np.fft.rfft(frame))
            freqs = np.fft.rfftfreq(n_fft, 1/self.config['sr'])
            centroid = np.sum(freqs * spectrum) / (np.sum(spectrum) + 1e-10)
            centroids.append(centroid)

        # 计算统计量
        zcr_var = np.var(frame_zcrs)
        centroid_std = np.std(centroids)

        # 融合打分（音乐特征越明显，分数越高）
        score = 0.0

        # 判据1: ZCR极度稳定
        if zcr_var < 0.0015:
            score += 0.5
        elif zcr_var < 0.003:
            score += 0.2

        # 判据2: 频率中心稳定
        if centroid_std < 500:
            score += 0.4
        elif centroid_std < 900:
            score += 0.2

        return min(1.0, score)

    def _get_history_confidence(self) -> float:
        """计算历史惯性置信度"""
        if not self.history:
            return 0.0
        return sum(self.history) / len(self.history)

    def _update_history(self, decision: bool):
        """更新历史"""
        self.history.append(decision)

    def reset(self):
        """重置历史（处理新视频时调用）"""
        self.history.clear()
```

##### 3.2.2 集成到转录服务

**修改文件**：`backend/app/services/transcription_service.py`

```python
class TranscriptionService:
    def __init__(self, ...):
        # 现有初始化...

        # 新增：音频熔断器（默认极速模式）
        self.circuit_breaker = None  # 延迟初始化

    async def _process_with_smart_separation(
        self,
        job: JobState,
        segments: List[Dict],
        audio_array: np.ndarray,
        settings: JobSettings
    ):
        """
        智能分离流程（集成频谱预判）

        支持三种模式:
        1. turbo（极速）: 完全信任频谱检测
        2. precise（精确）: 频谱预判 + Demucs验证
        3. legacy（遗留）: 原有全局BGM检测
        """
        # 0. 根据设置选择模式
        bgm_mode = settings.bgm_detection_mode  # 'turbo' | 'precise' | 'legacy'

        if bgm_mode == 'legacy':
            # 使用原有全局检测逻辑
            return await self._process_with_legacy_bgm_detection(
                job, segments, audio_array, settings
            )

        # 1. 初始化熔断器
        if self.circuit_breaker is None or self.circuit_breaker.mode != bgm_mode:
            self.circuit_breaker = AudioCircuitBreaker(
                config=settings.circuit_breaker_config,
                mode=bgm_mode
            )
        self.circuit_breaker.reset()

        # 2. 频谱预判（极速）
        self._update_progress(job, 'bgm_detect', 0, 'BGM智能检测中...')

        segment_decisions = []
        for i, seg in enumerate(segments):
            # 加载片段音频
            audio_segment = self._load_segment_audio(seg, audio_array)

            # 频谱分析
            decision = self.circuit_breaker.analyze_segment(
                audio_segment,
                segment_index=i
            )
            segment_decisions.append(decision)

            # 进度更新
            progress = (i + 1) / len(segments)
            self._update_progress(
                job, 'bgm_detect', progress,
                f'频谱分析 {i+1}/{len(segments)}'
            )

        # 3. 统计结果
        if bgm_mode == 'turbo':
            # 极速模式：直接使用频谱检测结果
            segments_to_separate = [
                i for i, dec in enumerate(segment_decisions)
                if dec.should_separate
            ]
            self.logger.info(
                f"频谱预判完成: {len(segments)}个片段, "
                f"{len(segments_to_separate)}个需要分离"
            )

        elif bgm_mode == 'precise':
            # 精确模式：需要验证的片段进行Demucs验证
            needs_verify = [
                (i, seg) for i, (seg, dec) in enumerate(zip(segments, segment_decisions))
                if dec.should_verify
            ]

            segments_to_separate = [
                i for i, dec in enumerate(segment_decisions)
                if dec.should_separate and not dec.should_verify
            ]

            if needs_verify:
                self._update_progress(
                    job, 'bgm_detect', 1.0,
                    f'Demucs验证中 ({len(needs_verify)}个片段)...'
                )

                # 加载Demucs模型（使用mdx_extra高质量模型）
                demucs_service = get_demucs_service()
                demucs_service.set_model(settings.verify_model or 'mdx_extra')

                for idx, (seg_idx, seg) in enumerate(needs_verify):
                    # 试分离验证
                    bgm_level = await self._verify_bgm_with_demucs(
                        seg,
                        audio_array,
                        demucs_service
                    )

                    if bgm_level != BGMLevel.NONE:
                        segments_to_separate.append(seg_idx)

                    # 进度更新
                    progress = (idx + 1) / len(needs_verify)
                    self._update_progress(
                        job, 'bgm_detect', progress,
                        f'深度验证 {idx+1}/{len(needs_verify)}'
                    )

                # 严格串行化：卸载Demucs
                demucs_service.unload_model()
                gc.collect()
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()

            self.logger.info(
                f"精确检测完成: {len(segments_to_separate)}个片段确认需要分离"
            )

        # 4. 按需分离（仅必要片段，使用mdx_extra）
        if segments_to_separate:
            # 加载Demucs分离模型
            demucs_service = get_demucs_service()
            demucs_service.set_model(settings.separation_model or 'mdx_extra')

            separated_segments = await self._separate_segments_batch(
                job,
                [segments[i] for i in segments_to_separate],
                audio_array,
                settings,
                demucs_service
            )

            # 更新segments
            for seg_idx, separated_seg in zip(segments_to_separate, separated_segments):
                segments[seg_idx]['file'] = separated_seg['file']

            # 严格串行化：卸载Demucs，为转录模型腾出空间
            demucs_service.unload_model()
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()

        # 5. 转录（严格串行化）
        # 此时Demucs已卸载，可以安全加载SenseVoice
        return await self._do_transcription_sensevoice(
            job,
            segments,
            settings,
            audio_array
        )
```

#### 3.3 动态权重调整

**修改**：`backend/app/core/config.py`

```python
class ProjectConfig:
    def get_dynamic_phase_weights(
        self,
        engine: str,
        total_segments: int,
        segments_to_separate: int
    ) -> Dict[str, int]:
        """
        动态权重计算

        Args:
            engine: 转录引擎
            total_segments: 总片段数
            segments_to_separate: 需要分离的片段数

        Returns:
            动态权重配置
        """
        base_weights = self.get_phase_weights(engine)

        # 计算分离比例
        separation_ratio = segments_to_separate / total_segments if total_segments > 0 else 0

        # 动态调整demucs权重
        # 如果只有10%片段需要分离，demucs权重降低到原来的10%
        demucs_weight = int(base_weights['demucs_global'] * separation_ratio)

        # 将节省的权重分配给转录阶段
        saved_weight = base_weights['demucs_global'] - demucs_weight

        dynamic_weights = base_weights.copy()
        dynamic_weights['demucs_global'] = demucs_weight
        dynamic_weights['transcribe'] += saved_weight

        return dynamic_weights
```

#### 3.4 SSE事件扩展

**新增事件类型**：

```python
# 频谱预判完成事件
{
    "event": "circuit_breaker_analysis",
    "data": {
        "total_segments": 100,
        "clean_segments": 70,
        "needs_verification": 30,
        "confidence_avg": 0.62
    }
}

# 深度验证完成事件
{
    "event": "bgm_verification",
    "data": {
        "verified_segments": 30,
        "confirmed_bgm": 12,
        "separation_ratio": 0.12
    }
}
```

---

## 四、最终决策与配置说明 ✅

### 4.1 核心决策

| 问题 | 决策 | 说明 |
|------|------|------|
| **检测模式** | 可配置（默认极速） | 三种模式：turbo（极速）、precise（精确）、legacy（遗留） |
| **默认模式** | 完全信任频谱检测 | 速度优先，纯CPU，无GPU开销 |
| **验证模型** | mdx_extra | 精确模式下使用高质量模型验证 |
| **分离模型** | mdx_extra | 所有分离操作使用高质量模型 |
| **显存管理** | 严格串行化 | 任何时刻只加载一个模型，确保4GB显存可运行 |
| **向后兼容** | 保留遗留模式 | 原全局BGM检测作为后备方案 |
| **参数配置** | 预设 + 高级参数 | 双层设计，满足普通用户和高级用户 |

### 4.2 配置结构设计

#### 4.2.1 数据模型（backend/app/models/job_models.py）

```python
from enum import Enum
from dataclasses import dataclass
from typing import Optional, Dict

class BGMDetectionMode(Enum):
    """BGM检测模式"""
    TURBO = "turbo"        # 极速模式（默认）
    PRECISE = "precise"    # 精确模式
    LEGACY = "legacy"      # 遗留模式

class BGMDetectionPreset(Enum):
    """预设配置"""
    ULTRA_FAST = "ultra_fast"     # 超快（高阈值，少分离）
    BALANCED = "balanced"          # 平衡（推荐）
    HIGH_QUALITY = "high_quality"  # 高质量（低阈值，多分离）
    CUSTOM = "custom"              # 自定义

@dataclass
class CircuitBreakerConfig:
    """熔断器配置（高级参数）"""
    # 基础参数
    sr: int = 16000
    n_fft: int = 512
    hop_length: int = 256

    # 历史惯性
    history_size: int = 5
    history_threshold: float = 0.6

    # 决策阈值
    music_score_threshold: float = 0.35
    reset_score: float = 0.15
    verify_threshold: float = 0.5  # 精确模式专用

@dataclass
class JobSettings:
    # ... 现有字段 ...

    # BGM检测配置
    bgm_detection_mode: BGMDetectionMode = BGMDetectionMode.TURBO
    bgm_detection_preset: BGMDetectionPreset = BGMDetectionPreset.BALANCED

    # 模型配置
    verify_model: str = "mdx_extra"      # 验证模型
    separation_model: str = "mdx_extra"  # 分离模型

    # 高级参数（可选，None则使用预设）
    circuit_breaker_config: Optional[CircuitBreakerConfig] = None

    @classmethod
    def get_preset_config(cls, preset: BGMDetectionPreset) -> CircuitBreakerConfig:
        """根据预设返回配置"""
        presets = {
            BGMDetectionPreset.ULTRA_FAST: CircuitBreakerConfig(
                music_score_threshold=0.50,  # 高阈值
                history_threshold=0.7,
                verify_threshold=0.6
            ),
            BGMDetectionPreset.BALANCED: CircuitBreakerConfig(
                music_score_threshold=0.35,  # 默认
                history_threshold=0.6,
                verify_threshold=0.5
            ),
            BGMDetectionPreset.HIGH_QUALITY: CircuitBreakerConfig(
                music_score_threshold=0.25,  # 低阈值
                history_threshold=0.5,
                verify_threshold=0.4
            )
        }
        return presets.get(preset, presets[BGMDetectionPreset.BALANCED])
```

#### 4.2.2 前端配置界面

**基础设置面板（简化模式）**：

```vue
<div class="bgm-detection-settings">
  <h3>BGM检测模式</h3>

  <!-- 模式选择 -->
  <select v-model="settings.bgm_detection_mode">
    <option value="turbo">极速模式（推荐）</option>
    <option value="precise">精确模式</option>
    <option value="legacy">兼容模式</option>
  </select>

  <!-- 预设选择（非遗留模式） -->
  <div v-if="settings.bgm_detection_mode !== 'legacy'">
    <h4>质量预设</h4>
    <div class="preset-buttons">
      <button @click="settings.preset = 'ultra_fast'">超快</button>
      <button @click="settings.preset = 'balanced'" class="active">平衡</button>
      <button @click="settings.preset = 'high_quality'">高质量</button>
      <button @click="showAdvanced = true">自定义</button>
    </div>
  </div>
</div>
```

**高级设置面板（展开后）**：

```vue
<div v-if="showAdvanced" class="advanced-settings">
  <h4>高级参数</h4>

  <label>音乐性阈值</label>
  <input type="range" v-model.number="config.music_score_threshold"
         min="0.1" max="0.9" step="0.05" />
  <span>{{ config.music_score_threshold }}</span>

  <label>历史惯性阈值</label>
  <input type="range" v-model.number="config.history_threshold"
         min="0.3" max="0.9" step="0.05" />
  <span>{{ config.history_threshold }}</span>

  <label>历史窗口大小</label>
  <input type="number" v-model.number="config.history_size"
         min="3" max="10" />

  <div v-if="settings.bgm_detection_mode === 'precise'">
    <label>验证阈值</label>
    <input type="range" v-model.number="config.verify_threshold"
           min="0.3" max="0.8" step="0.05" />
    <span>{{ config.verify_threshold }}</span>
  </div>

  <button @click="resetToPreset">恢复预设</button>
</div>
```

---

## 五、实施路径（渐进式集成）

### 5.1 总体规划

**总工期**：5-7天
**目标**：分阶段集成，确保核心功能可用，不需要大量测试

| 阶段 | 工期 | 关键交付物 | 验收标准 |
|------|-----|------------|----------|
| **Phase 1** | 1-2天 | 核心组件实现 | 熔断器可运行，基础测试通过 |
| **Phase 2** | 2-3天 | 服务集成 | 三种模式均可用，显存管理正常 |
| **Phase 3** | 1-2天 | 前端与完善 | 配置界面完整，文档齐全 |

### 5.2 Phase 1：核心组件实现（1-2天）

**目标**：实现`AudioCircuitBreaker`并验证基本功能

#### 任务清单：

1. **创建核心文件**
   - `backend/app/services/audio_circuit_breaker.py`
   - 实现`AudioCircuitBreaker`类
   - 实现`CircuitBreakerDecision`数据类
   - 实现频谱分析核心算法

2. **单元测试（轻量）**
   - 测试纯人声片段（应输出should_separate=False）
   - 测试BGM片段（应输出should_separate=True）
   - 测试历史惯性机制
   - **不需要大量测试**，确保基础功能即可

3. **本地验证**
   - 准备2-3个典型视频（纯人声、有BGM、混合）
   - 运行熔断器，观察输出
   - 粗略调整阈值参数

**验收标准**：
- ✅ 熔断器可正常运行
- ✅ 输出决策合理
- ✅ 无崩溃或异常

---

### 5.3 Phase 2：服务集成与显存管理（2-3天）

**目标**：集成到转录服务，实现三种模式，确保显存安全

#### 任务清单：

1. **修改数据模型**
   - `backend/app/models/job_models.py`
   - 新增`BGMDetectionMode`枚举
   - 新增`BGMDetectionPreset`枚举
   - 扩展`JobSettings`
   - 实现预设配置方法

2. **集成到转录服务**
   - `backend/app/services/transcription_service.py`
   - 实现`_process_with_smart_separation()`方法
   - 实现三种模式分支（turbo/precise/legacy）
   - **严格串行化显存管理**：
     - 每个模型加载前，确保前一个模型已卸载
     - 添加`gc.collect() + torch.cuda.empty_cache()`
     - 日志记录显存状态

3. **Demucs服务扩展**
   - `backend/app/services/demucs_service.py`
   - 新增`separate_segments_batch()`方法（如果不存在）
   - 确保支持mdx_extra模型
   - 添加显存安全检查

4. **动态权重调整**
   - `backend/app/core/config.py`
   - 实现`get_dynamic_phase_weights()`方法

5. **SSE事件扩展**
   - 新增`circuit_breaker_analysis`事件
   - 新增`bgm_verification`事件（精确模式）

6. **集成测试（中等量）**
   - 测试极速模式完整流程
   - 测试精确模式完整流程
   - 测试遗留模式（确保兼容）
   - 测试显存管理（模型切换不OOM）
   - 准备3-5个视频测试即可

**验收标准**：
- ✅ 三种模式均可正常运行
- ✅ 显存管理安全（4GB显存可运行）
- ✅ 进度反馈正常
- ✅ SSE事件正常推送

---

### 5.4 Phase 3：前端UI与文档（1-2天）

**目标**：提供完整的用户界面和文档

#### 任务清单：

1. **前端配置界面**
   - 修改`frontend/src/views/TaskListView.vue`
   - 新增BGM检测模式选择器
   - 新增预设按钮组
   - 新增高级参数折叠面板
   - **样式美化**（可选，时间充裕再做）

2. **前端API扩展**
   - `frontend/src/services/api/index.js`
   - 确保配置正确传递到后端

3. **用户文档**
   - `docs/user-guide/bgm-detection.md`
   - 说明三种模式的区别
   - 说明预设配置的含义
   - 常见问题FAQ

4. **开发文档**
   - 更新现有技术文档
   - 说明频谱检测原理
   - 说明参数调优方法

5. **简单测试**
   - 测试前端配置界面
   - 测试配置持久化
   - 端到端测试2-3个视频

**验收标准**：
- ✅ 前端配置界面完整可用
- ✅ 配置可正确传递和保存
- ✅ 用户文档齐全
- ✅ 至少2个完整的端到端测试通过

---

### 5.5 关键注意事项

#### 显存管理关键点：

```python
# 模型切换标准流程
def switch_model(from_model, to_model):
    # 1. 卸载旧模型
    if from_model:
        from_model.unload()
        del from_model

    # 2. 强制清理
    gc.collect()
    torch.cuda.empty_cache()
    torch.cuda.synchronize()  # 等待GPU操作完成

    # 3. 验证显存（可选）
    if torch.cuda.is_available():
        free_mem = torch.cuda.memory_stats()['reserved_bytes.all.current']
        logger.info(f"可用显存: {free_mem / 1024**3:.2f} GB")

    # 4. 加载新模型
    to_model = load_new_model()
    return to_model
```

#### 不需要过多测试的原因：

1. **核心算法简单**：频谱分析是成熟的信号处理技术
2. **模式隔离**：三种模式独立，互不影响
3. **向后兼容**：遗留模式保证了后路
4. **用户可选**：默认模式失效，用户可切换

#### 风险控制：

- **默认启用极速模式**：如果效果不佳，用户可手动切换
- **保留遗留模式**：作为最后的后备方案
- **渐进推广**：先小范围测试，再全面推广

---

## 六、总结

### 6.1 核心价值

| 指标 | 原有方案 | 新方案（极速模式） | 提升 |
|------|---------|------------------|------|
| **BGM检测时间** | 需加载Demucs，约3-5秒 | 纯CPU频谱分析，<1秒 | **5倍+** |
| **显存开销** | 需加载Demucs（1.5GB） | 无需GPU | **节省1.5GB** |
| **检测粒度** | 全局采样（3个点） | 逐片段检测 | **细粒度** |
| **过度分离** | 可能全局分离 | 仅必要片段 | **节省处理时间** |
| **用户选择** | 无 | 三种模式 | **灵活可配** |

### 6.2 技术亮点

1. **可配置架构**：
   - 三种模式（极速/精确/遗留）满足不同需求
   - 预设+高级参数双层配置，兼顾易用性和专业性

2. **严格串行化显存管理**：
   - 确保任何时刻只加载一个模型
   - 4GB显存即可运行完整流程
   - 模型切换有标准流程，避免OOM

3. **向后兼容**：
   - 保留原有全局BGM检测作为遗留模式
   - 如果新方案效果不佳，用户可随时切换

4. **渐进式实施**：
   - 分3个阶段，5-7天完成
   - 不需要大量测试，核心功能验证即可
   - 风险可控，用户可选

### 6.3 关键决策总结

| 维度 | 决策 |
|------|------|
| **默认模式** | 极速模式（完全信任频谱检测） |
| **验证模型** | mdx_extra（精确模式专用） |
| **分离模型** | mdx_extra（所有分离操作） |
| **显存策略** | 严格串行化 |
| **向后兼容** | 保留遗留模式 |
| **用户界面** | 预设+高级参数 |
| **实施方式** | 渐进式集成（3阶段） |

### 6.4 风险评估与应对

| 风险 | 概率 | 应对措施 |
|------|-----|---------|
| 频谱检测准确性不足 | 中 | 提供精确模式（Demucs验证） |
| 用户不接受新方案 | 低 | 保留遗留模式，用户可切换 |
| 显存管理出错 | 低 | 严格串行化+充分日志 |
| 实施时间超期 | 低 | 分阶段交付，核心功能优先 |

### 6.5 成功标准

**Phase 1**：
- ✅ 熔断器可运行，输出合理

**Phase 2**：
- ✅ 三种模式均可用
- ✅ 显存安全（4GB可运行）
- ✅ 进度反馈正常

**Phase 3**：
- ✅ 前端配置完整
- ✅ 文档齐全
- ✅ 至少2个端到端测试通过

**最终目标**：
- 🎯 BGM检测速度提升5倍以上
- 🎯 显存占用减少（无需Demucs检测）
- 🎯 用户体验提升（细粒度检测，减少过度分离）
- 🎯 完全向后兼容

---

## 附录

### 附录A：文件变更清单

| 文件 | 变更类型 | 说明 |
|------|---------|------|
| `backend/app/services/audio_circuit_breaker.py` | 新增 | 音频熔断器核心组件 |
| `backend/app/models/job_models.py` | 修改 | 新增BGM检测配置枚举和字段 |
| `backend/app/services/transcription_service.py` | 大幅修改 | 集成三种模式，严格串行化 |
| `backend/app/services/demucs_service.py` | 小修改 | 新增批量分离方法（如需） |
| `backend/app/core/config.py` | 小修改 | 动态权重方法 |
| `frontend/src/views/TaskListView.vue` | 修改 | 新增BGM检测配置界面 |
| `frontend/src/services/api/index.js` | 小修改 | 配置传递 |
| `docs/user-guide/bgm-detection.md` | 新增 | 用户文档 |

### 附录B：参考资料

1. **智能熔断机制原始文档**：`F:\video_to_srt_gpu\docs\SenseVoice\智能熔断机制最终方案.md`
2. **Demucs集成调查报告**：`F:\video_to_srt_gpu\llmdoc\agent\demucs_integration_investigation.md`
3. **SenseVoice集成计划**：`F:\video_to_srt_gpu\docs\SenseVoice\SenseVoice_Development_Plan.md`
4. **SSE流式输出调研**：`F:\video_to_srt_gpu\llmdoc\agent\sse_and_subtitle_streaming_investigation_report.md`
