# è½¬å½•å±‚æ·±åº¦ä¼˜åŒ–æ–¹æ¡ˆï¼šæ—¶ç©ºè§£è€¦æ¶æ„

> **æ–‡æ¡£ç‰ˆæœ¬**ï¼šv2.1
> **æ›´æ–°æ—¥æœŸ**ï¼š2025å¹´12æœˆ4æ—¥
> **åŸºäº**ï¼šã€Šæ–°è¡¥å…….mdã€‹æ—¶ç©ºè§£è€¦æ¶æ„è®¾è®¡
> **å½±å“èŒƒå›´**ï¼šPhase 1-3 çš„æ ¸å¿ƒä¿®æ”¹
> **ç›®æ ‡**ï¼šå»ºç«‹ SenseVoice ä¸ºæ—¶é—´è½´åŸºå‡†ã€Whisper ä¸ºå†…å®¹è¡¥ä¸çš„åŒå¼•æ“æ¶æ„

---

## âš ï¸ ç‰ˆæœ¬æ›´æ–°è¯´æ˜

### v2.1 æ–°å¢ï¼ˆVADä¼˜å…ˆ + é¢‘è°±åˆ†è¯Šï¼‰

- âœ… **æµç¨‹å˜æ›´**ï¼š`éŸ³é¢‘æå– â†’ VAD â†’ é¢‘è°±åˆ†è¯Š(Chunkçº§) â†’ æŒ‰éœ€åˆ†ç¦» â†’ è½¬å½•`
- âœ… **æ–°å¢ç»„ä»¶**ï¼š`AudioSpectrumClassifier` é¢‘è°±æŒ‡çº¹åˆ†è¯Šå°
- âœ… **æ•ˆç‡ä¼˜åŒ–**ï¼šVADå…ˆåˆ‡åˆ†ï¼Œåªå¯¹éœ€è¦åˆ†ç¦»çš„Chunkæ‰§è¡ŒDemucsï¼ŒèŠ‚çœæ—¶é—´å’Œæ˜¾å­˜
- âœ… **OOMé˜²æŠ¤**ï¼šChunkçº§å¤„ç†é¿å…è¶…é•¿éŸ³é¢‘ä¸€æ¬¡æ€§åˆ†ç¦»å¯¼è‡´æ˜¾å­˜ä¸è¶³

> **è¯¦ç»†è®¾è®¡**ï¼šå‚è§ [Phase 2: æ™ºèƒ½ç†”æ–­é›†æˆ](./02_Phase2_æ™ºèƒ½ç†”æ–­é›†æˆ_ä¿®è®¢ç‰ˆ.md) ç¬¬ä¸‰èŠ‚

---

## ä¸€ã€æ¶æ„æ¦‚è¿°

### 1.1 æ ¸å¿ƒå˜æ›´ï¼šæ—¶ç©ºè§£è€¦ (Time-Space Decoupling)

å°†éŸ³é¢‘å¤„ç†ç®¡çº¿ä¸­çš„"æ—¶é—´"ä¸"å†…å®¹"èŒè´£åˆ†ç¦»ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        æ—¶ç©ºè§£è€¦æ¶æ„                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  SenseVoice  â”‚    â”‚   Whisper    â”‚    â”‚     LLM      â”‚      â”‚
â”‚  â”‚  æ—¶é—´é¢†ä¸»     â”‚    â”‚  å¬è§‰è¡¥ä¸    â”‚    â”‚   é€»è¾‘èƒ¶æ°´    â”‚      â”‚
â”‚  â”‚  Timeline    â”‚    â”‚  Acoustic    â”‚    â”‚   Semantic   â”‚      â”‚
â”‚  â”‚   Truth      â”‚    â”‚   Patch      â”‚    â”‚   Refiner    â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚         â”‚                   â”‚                   â”‚              â”‚
â”‚         â–¼                   â–¼                   â–¼              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ æä¾›æ—¶é—´æˆ³    â”‚    â”‚ ä»…æä¾›æ–‡æœ¬   â”‚    â”‚ æ ¡å¯¹/ä»²è£    â”‚      â”‚
â”‚  â”‚ åŸºç¡€æ–‡æœ¬      â”‚    â”‚ å¼ƒç”¨æ—¶é—´æˆ³   â”‚    â”‚ ç¿»è¯‘         â”‚      â”‚
â”‚  â”‚ å­—çº§ç½®ä¿¡åº¦    â”‚    â”‚ [å¯é€‰]å¯¹é½   â”‚    â”‚              â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 è§’è‰²å®šä¹‰

| è§’è‰² | æ¨¡å‹ | èŒè´£ | çº¦æŸ |
|------|------|------|------|
| **æ—¶é—´é¢†ä¸»** | SenseVoice | æä¾›ç»å¯¹æ—¶é—´è½´åŸºå‡†ï¼ˆStart/Endï¼‰ã€åŸºç¡€æ–‡æœ¬ã€å­—çº§ç½®ä¿¡åº¦ | åç»­æ­¥éª¤**ä¸¥ç¦ä¿®æ”¹**èµ·æ­¢æ—¶é—´ï¼ˆé™¤éå¯ç”¨å¼ºåˆ¶å¯¹é½ï¼‰ |
| **å¬è§‰è¡¥ä¸** | Whisper | é’ˆå¯¹ä½ç½®ä¿¡åº¦ç‰‡æ®µäºŒæ¬¡"ç²¾å¬" | **é»˜è®¤ä»…æä¾›æ–‡æœ¬**ï¼Œä½¿ç”¨ä¼ªå¯¹é½ç®—æ³• |
| **é€»è¾‘èƒ¶æ°´** | LLM | é”™åˆ«å­—ä¿®æ­£ã€æ­§ä¹‰ä»²è£ã€ç¿»è¯‘ | æœ€ç»ˆæ–‡æœ¬è£å†³è€… |

### 1.3 å…³é”®å†³ç­–

1. **ä¼ªå¯¹é½ç®—æ³•**ï¼šWhisper/LLM æ›¿æ¢æ–‡æœ¬åï¼Œé»˜è®¤é‡‡ç”¨"çº¿æ€§æ—¶é—´å¹³æ‘Š"ç­–ç•¥
2. **å‰ç«¯è™šæ‹Ÿæ»šåŠ¨**ï¼šå­—çº§ç½®ä¿¡åº¦æ•°æ®é‡å¤§ï¼Œéœ€å®ç° Virtual Scrolling
3. **æµå¼è¾“å‡º**ï¼šå„é˜¶æ®µå®Œæˆå³æ¨é€ï¼Œå®ç°å®æ—¶å­—å¹•é¢„è§ˆ

---

## äºŒã€å‰ç«¯é¢„è®¾æ–¹æ¡ˆä½“ç³»

### 2.1 é¢„è®¾æ–¹æ¡ˆå®šä¹‰

å‰ç«¯ç•Œé¢æä¾› **6 ä¸ªé¢„è®¾æ–¹æ¡ˆ** + **é«˜çº§è‡ªå®šä¹‰æ¨¡å¼**ï¼š

| é¢„è®¾ | åç§° | ç»„åˆ | é€‚ç”¨åœºæ™¯ |
|------|------|------|----------|
| **é»˜è®¤** | SenseVoice Only | SV | æé€Ÿé¢„è§ˆã€å®æ—¶æ—¥å¿—ã€æµ‹è¯• |
| **é¢„è®¾1** | æ™ºèƒ½è¡¥åˆ€ | SV + Whisper Partial | ä¸€èˆ¬è§†é¢‘ã€æ—¥å¸¸Vlog |
| **é¢„è®¾2** | è½»åº¦æ ¡å¯¹ | SV + Whisper Partial + LLM Partial Proof | ä¸ªäººç¬”è®°ã€ä¼šè®®è®°å½• |
| **é¢„è®¾3** | æ·±åº¦æ ¡å¯¹ | SV + Whisper Partial + LLM Full Proof | æ­£å¼å‘å¸ƒã€æ–‡ç¨¿æ•´ç† |
| **é¢„è®¾4** | æ ¡å¯¹+ç¿»è¯‘ï¼ˆåŒæ­¥ï¼‰ | SV + Whisper Partial + LLM Full Proof + LLM Full Trans | è·¨è¯­è¨€å†…å®¹å‘å¸ƒ |
| **é¢„è®¾5** | æ ¡å¯¹+é‡ç‚¹ç¿»è¯‘ | SV + Whisper Partial + LLM Full Proof + LLM Partial Trans | æ•™å­¦è§†é¢‘ã€é‡ç‚¹æ ‡æ³¨ |

### 2.2 é¢„è®¾æ–¹æ¡ˆè¯¦ç»†é…ç½®

```typescript
// frontend/src/constants/presets.ts

export interface PresetConfig {
  id: string;
  name: string;
  description: string;
  icon: string;
  // è½¬å½•å±‚
  enhancement: 'off' | 'smart_patch' | 'deep_listen';
  // æ ¡å¯¹å±‚
  proofread: 'off' | 'sparse' | 'full';
  // ç¿»è¯‘å±‚
  translate: 'off' | 'full' | 'partial';
  targetLanguage?: string;
  // é¢„ä¼°æ—¶é—´å€ç‡ï¼ˆç›¸å¯¹äºè§†é¢‘æ—¶é•¿ï¼‰
  timeMultiplier: number;
}

export const PRESETS: PresetConfig[] = [
  {
    id: 'default',
    name: 'SenseVoice Only',
    description: 'æé€Ÿæ¨¡å¼ï¼Œä»…ä½¿ç”¨ SenseVoice è½¬å½•',
    icon: 'âš¡',
    enhancement: 'off',
    proofread: 'off',
    translate: 'off',
    timeMultiplier: 0.1  // 10åˆ†é’Ÿè§†é¢‘çº¦1åˆ†é’Ÿå®Œæˆ
  },
  {
    id: 'preset1',
    name: 'æ™ºèƒ½è¡¥åˆ€',
    description: 'SV + Whisper å±€éƒ¨è¡¥åˆ€ï¼Œå¹³è¡¡é€Ÿåº¦ä¸è´¨é‡',
    icon: 'ğŸ¯',
    enhancement: 'smart_patch',
    proofread: 'off',
    translate: 'off',
    timeMultiplier: 0.15
  },
  {
    id: 'preset2',
    name: 'è½»åº¦æ ¡å¯¹',
    description: 'æ™ºèƒ½è¡¥åˆ€ + LLM æŒ‰éœ€æ ¡å¯¹é—®é¢˜ç‰‡æ®µ',
    icon: 'âœï¸',
    enhancement: 'smart_patch',
    proofread: 'sparse',
    translate: 'off',
    timeMultiplier: 0.2
  },
  {
    id: 'preset3',
    name: 'æ·±åº¦æ ¡å¯¹',
    description: 'æ™ºèƒ½è¡¥åˆ€ + LLM å…¨æ–‡ç²¾ä¿®æ¶¦è‰²',
    icon: 'ğŸ“',
    enhancement: 'smart_patch',
    proofread: 'full',
    translate: 'off',
    timeMultiplier: 0.3
  },
  {
    id: 'preset4',
    name: 'æ ¡å¯¹+ç¿»è¯‘',
    description: 'æ·±åº¦æ ¡å¯¹ + å…¨æ–‡ç¿»è¯‘ï¼ˆåŒæ­¥å¤„ç†ï¼‰',
    icon: 'ğŸŒ',
    enhancement: 'smart_patch',
    proofread: 'full',
    translate: 'full',
    targetLanguage: 'en',
    timeMultiplier: 0.5
  },
  {
    id: 'preset5',
    name: 'æ ¡å¯¹+é‡ç‚¹ç¿»è¯‘',
    description: 'æ·±åº¦æ ¡å¯¹ + ä»…ç¿»è¯‘æ ‡è®°çš„é‡ç‚¹æ®µè½',
    icon: 'ğŸ“',
    enhancement: 'smart_patch',
    proofread: 'full',
    translate: 'partial',
    timeMultiplier: 0.35
  }
];
```

### 2.3 é«˜çº§è‡ªå®šä¹‰æ¨¡å¼

ç”¨æˆ·å¯åœ¨"é«˜çº§è®¾ç½®"ä¸­è‡ªç”±ç»„åˆæ‰€æœ‰é€‰é¡¹ï¼š

```typescript
// frontend/src/constants/advancedOptions.ts

export const ADVANCED_OPTIONS = {
  // ========== è½¬å½•å±‚é€‰é¡¹ ==========
  enhancement: {
    label: 'å¢å¼ºæ¨¡å¼',
    options: [
      { value: 'off', label: 'å…³é—­', desc: 'ä»… SenseVoice' },
      { value: 'smart_patch', label: 'æ™ºèƒ½è¡¥åˆ€', desc: 'ä½ç½®ä¿¡åº¦è‡ªåŠ¨ Whisper è¡¥åˆ€' },
      { value: 'deep_listen', label: 'æ·±åº¦é‡å¬', desc: 'Whisper å…¨æ–‡è½¬å½•' }
    ]
  },

  // ========== æ ¡å¯¹å±‚é€‰é¡¹ ==========
  proofread: {
    label: 'AI æ ¡å¯¹',
    options: [
      { value: 'off', label: 'å…³é—­' },
      { value: 'sparse', label: 'æŒ‰éœ€ä¿®å¤', desc: 'ä»…æ ¡å¯¹ä½ç½®ä¿¡åº¦å’Œç–‘é—®ç‰‡æ®µ' },
      { value: 'full', label: 'å…¨æ–‡ç²¾ä¿®', desc: 'æ»‘åŠ¨çª—å£å…¨é‡æ ¡å¯¹æ¶¦è‰²' }
    ]
  },

  // ========== ç¿»è¯‘å±‚é€‰é¡¹ ==========
  translate: {
    label: 'ç¿»è¯‘',
    options: [
      { value: 'off', label: 'æ— ' },
      { value: 'full', label: 'å…¨æ–‡ç¿»è¯‘' },
      { value: 'partial', label: 'éƒ¨åˆ†ç¿»è¯‘', desc: 'ä»…ç¿»è¯‘æ ‡è®°çš„é‡ç‚¹æ®µè½' }
    ]
  },

  targetLanguage: {
    label: 'ç›®æ ‡è¯­è¨€',
    type: 'select',
    options: [
      { value: 'en', label: 'English' },
      { value: 'ja', label: 'æ—¥æœ¬èª' },
      { value: 'ko', label: 'í•œêµ­ì–´' },
      { value: 'zh-TW', label: 'ç¹é«”ä¸­æ–‡' }
    ],
    showWhen: (config) => config.translate !== 'off'
  }
};
```

---

## ä¸‰ã€Phase ä¿®æ”¹æ¸…å•

### 3.1 Phase 1 ä¿®æ”¹é¡¹

| ä¿®æ”¹é¡¹ | æ–‡ä»¶ | ç±»å‹ | ä¼˜å…ˆçº§ |
|--------|------|------|--------|
| æ‰©å±• SentenceSegment æ•°æ®æ¨¡å‹ | `sensevoice_models.py` | ä¿®æ”¹ | P0 |
| æ–°å¢ä¼ªå¯¹é½ç®—æ³• | `pseudo_alignment.py` | æ–°å»º | P0 |
| ä¿®æ”¹åˆ†å¥ç®—æ³•æ”¯æŒæ¥æºè¿½è¸ª | `sentence_splitter.py` | ä¿®æ”¹ | P1 |
| **æ–°å¢æ™ºèƒ½è¿›åº¦ç³»ç»Ÿ** | `progress_tracker.py` | æ–°å»º | P0 |
| **é‡æ„ SSE æœåŠ¡** | `sse_service.py` | ä¿®æ”¹ | P0 |

### 3.2 Phase 2 ä¿®æ”¹é¡¹

| ä¿®æ”¹é¡¹ | æ–‡ä»¶ | ç±»å‹ | ä¼˜å…ˆçº§ |
|--------|------|------|--------|
| ç†”æ–­å†³ç­–å¢åŠ "ä»…æ–‡æœ¬è¡¥åˆ€"é€‰é¡¹ | `fuse_breaker.py` | ä¿®æ”¹ | P0 |
| æ–°å¢ç»„åˆæ–¹æ¡ˆé…ç½® | `solution_matrix.py` | æ–°å»º | P1 |
| **æ–°å¢é¢„è®¾æ–¹æ¡ˆç®¡ç†** | `preset_manager.py` | æ–°å»º | P1 |

### 3.3 Phase 3 ä¿®æ”¹é¡¹

| ä¿®æ”¹é¡¹ | æ–‡ä»¶ | ç±»å‹ | ä¼˜å…ˆçº§ |
|--------|------|------|--------|
| Whisper è¡¥åˆ€ä»…å–æ–‡æœ¬+ä¼ªå¯¹é½ | `transcription_service.py` | ä¿®æ”¹ | P0 |
| æ”¯æŒç»„åˆæ–¹æ¡ˆçŸ©é˜µ | `transcription_service.py` | ä¿®æ”¹ | P1 |
| **å­—å¹•æµå¼è¾“å‡ºç³»ç»Ÿ** | `streaming_subtitle.py` | æ–°å»º | P0 |

### 3.4 Phase 4 ä¿®æ”¹é¡¹

| ä¿®æ”¹é¡¹ | æ–‡ä»¶ | ç±»å‹ | ä¼˜å…ˆçº§ |
|--------|------|------|--------|
| å‰ç«¯è™šæ‹Ÿæ»šåŠ¨ | `TaskListView.vue` | ä¿®æ”¹ | P1 |
| **é¢„è®¾é€‰æ‹©å™¨ç»„ä»¶** | `PresetSelector.vue` | æ–°å¢ | P0 |
| **é«˜çº§è®¾ç½®é¢æ¿** | `AdvancedSettings.vue` | æ–°å¢ | P1 |
| **ç½®ä¿¡åº¦è­¦å‘Šé«˜äº®ç³»ç»Ÿ** | `ConfidenceHighlight.vue` | æ–°å¢ | P0 |

### 3.5 åŸºç¡€æ•°æ®æ¨¡å‹ä¿®æ”¹

ä»¥ä¸‹æ˜¯å¯¹ç°æœ‰ `job_models.py` å’Œ API æ¨¡å‹çš„ä¿®æ”¹è¯´æ˜ï¼š

#### 3.5.1 JobSettings æ‰©å±•

**æ–‡ä»¶**: `backend/app/models/job_models.py`

```python
@dataclass
class TranscriptionPreset:
    """è½¬å½•é¢„è®¾é…ç½®"""
    preset_id: str = "default"                     # é¢„è®¾ID: default/preset1-5/custom
    enhancement: str = "off"                       # å¢å¼ºæ¨¡å¼: off/smart_patch/deep_listen
    proofread: str = "off"                         # æ ¡å¯¹: off/sparse/full
    translate: str = "off"                         # ç¿»è¯‘: off/full/partial
    target_language: Optional[str] = None          # ç¿»è¯‘ç›®æ ‡è¯­è¨€


@dataclass
class JobSettings:
    """è½¬å½•ä»»åŠ¡è®¾ç½®ï¼ˆæ‰©å±•ç‰ˆï¼‰"""
    model: str = "medium"
    compute_type: str = "float16"
    device: str = "cuda" if torch.cuda.is_available() else "cpu"
    batch_size: int = 16
    word_timestamps: bool = False
    cpu_affinity: Optional["CPUAffinityConfig"] = None
    demucs: DemucsSettings = field(default_factory=DemucsSettings)
    # ========== æ–°å¢ï¼šé¢„è®¾é…ç½® ==========
    preset: TranscriptionPreset = field(default_factory=TranscriptionPreset)
```

#### 3.5.2 DemucsSettings æ‰©å±•

```python
@dataclass
class DemucsSettings:
    """Demucsäººå£°åˆ†ç¦»é…ç½®"""
    # === åŸæœ‰å­—æ®µ ===
    enabled: bool = True
    mode: str = "auto"
    # ... å…¶ä»–åŸæœ‰å­—æ®µ ...
```

#### 3.5.3 JobState æ‰©å±•

```python
@dataclass
class SegmentProgress:
    """å•ä¸ªç‰‡æ®µçš„å¤„ç†è¿›åº¦ï¼ˆç”¨äºæµå¼è¾“å‡ºï¼‰"""
    segment_index: int
    total_segments: int
    phase: str                  # sv_transcribe/whisper_patch/llm_proof/llm_trans
    status: str                 # pending/processing/completed/failed
    text: Optional[str] = None
    confidence: Optional[float] = None


@dataclass
class JobState:
    """è½¬å½•ä»»åŠ¡çŠ¶æ€ï¼ˆæ‰©å±•ç‰ˆï¼‰"""
    # === åŸæœ‰å­—æ®µ ===
    job_id: str
    filename: str
    # ... å…¶ä»–åŸæœ‰å­—æ®µ ...
    
    # ========== æ–°å¢ï¼šæµå¼è¾“å‡ºæ”¯æŒ ==========
    streaming_enabled: bool = True               # æ˜¯å¦å¯ç”¨æµå¼è¾“å‡º
    current_segment_index: int = 0               # å½“å‰å¤„ç†çš„ç‰‡æ®µç´¢å¼•
    segments_sv_completed: int = 0               # SV è½¬å½•å®Œæˆæ•°
    segments_whisper_patched: int = 0            # Whisper è¡¥åˆ€å®Œæˆæ•°
    segments_llm_proofread: int = 0              # LLM æ ¡å¯¹å®Œæˆæ•°
    segments_llm_translated: int = 0             # LLM ç¿»è¯‘å®Œæˆæ•°
    
    # ========== æ–°å¢ï¼šé¢„è®¾è¿½è¸ª ==========
    preset_id: str = "default"                   # ä½¿ç”¨çš„é¢„è®¾ID
    
    def to_dict(self):
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼ï¼Œç”¨äºAPIå“åº”ï¼ˆæ‰©å±•ç‰ˆï¼‰"""
        d = asdict(self)
        d.pop('segments', None)
        # æ–°å¢æµå¼è¿›åº¦ä¿¡æ¯
        d['streaming_progress'] = {
            'sv_completed': self.segments_sv_completed,
            'whisper_patched': self.segments_whisper_patched,
            'llm_proofread': self.segments_llm_proofread,
            'llm_translated': self.segments_llm_translated
        }
        return d
```

#### 3.5.4 API è¯·æ±‚æ¨¡å‹æ‰©å±•

**æ–‡ä»¶**: `backend/app/api/routes/transcription_routes.py`

```python
class TranscriptionPresetAPI(BaseModel):
    """é¢„è®¾é…ç½®è¯·æ±‚æ¨¡å‹"""
    preset_id: str = "default"
    enhancement: str = "off"
    proofread: str = "off"
    translate: str = "off"
    target_language: Optional[str] = None


class DemucsSettingsAPI(BaseModel):
    """Demucsé…ç½®è¯·æ±‚æ¨¡å‹"""
    enabled: bool = True
    mode: str = "auto"
    retry_threshold_logprob: float = -0.8
    retry_threshold_no_speech: float = 0.6
    circuit_breaker_enabled: bool = True
    consecutive_threshold: int = 3
    ratio_threshold: float = 0.2


class TranscribeSettings(BaseModel):
    """è½¬å½•è®¾ç½®è¯·æ±‚æ¨¡å‹ï¼ˆæ‰©å±•ç‰ˆï¼‰"""
    model: str = "medium"
    compute_type: str = "float16"
    device: str = "cuda"
    batch_size: int = 16
    word_timestamps: bool = False
    demucs: Optional[DemucsSettingsAPI] = None
    # ========== æ–°å¢ ==========
    preset: Optional[TranscriptionPresetAPI] = None
```

#### 3.5.5 æŒä¹…åŒ–å…¼å®¹æ€§

ä¿®æ”¹ `to_meta_dict()` å’Œ `from_meta_dict()` æ–¹æ³•ä»¥æ”¯æŒæ–°å­—æ®µï¼š

```python
def to_meta_dict(self) -> dict:
    """æ‰©å±•ç‰ˆå…ƒä¿¡æ¯å­—å…¸"""
    base = {
        # ... åŸæœ‰å­—æ®µ ...
        "settings": {
            # ... åŸæœ‰è®¾ç½®å­—æ®µ ...
            "preset": {
                "preset_id": self.settings.preset.preset_id,
                "enhancement": self.settings.preset.enhancement,
                "proofread": self.settings.preset.proofread,
                "translate": self.settings.preset.translate,
                "target_language": self.settings.preset.target_language
            }
        },
        # æ–°å¢æµå¼è¿›åº¦
        "streaming_progress": {
            "sv_completed": self.segments_sv_completed,
            "whisper_patched": self.segments_whisper_patched,
            "llm_proofread": self.segments_llm_proofread,
            "llm_translated": self.segments_llm_translated
        },
        "preset_id": self.preset_id
    }
    return base


@classmethod
def from_meta_dict(cls, data: dict) -> "JobState":
    """æ‰©å±•ç‰ˆæ¢å¤æ–¹æ³•ï¼ˆå‘åå…¼å®¹ï¼‰"""
    # å¤„ç†é¢„è®¾é…ç½®ï¼ˆå‘åå…¼å®¹ï¼šå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼ï¼‰
    preset_data = data.get("settings", {}).get("preset", {})
    preset = TranscriptionPreset(
        preset_id=preset_data.get("preset_id", "default"),
        enhancement=preset_data.get("enhancement", "off"),
        proofread=preset_data.get("proofread", "off"),
        translate=preset_data.get("translate", "off"),
        target_language=preset_data.get("target_language")
    )
    
    # ... åˆ›å»º JobState å®ä¾‹ ...
    
    # æ¢å¤æµå¼è¿›åº¦ï¼ˆå‘åå…¼å®¹ï¼‰
    streaming_progress = data.get("streaming_progress", {})
    job.segments_sv_completed = streaming_progress.get("sv_completed", 0)
    job.segments_whisper_patched = streaming_progress.get("whisper_patched", 0)
    job.segments_llm_proofread = streaming_progress.get("llm_proofread", 0)
    job.segments_llm_translated = streaming_progress.get("llm_translated", 0)
    job.preset_id = data.get("preset_id", "default")
    
    return job
```

#### 3.5.6 model_models.py æ‰©å±•

**æ–‡ä»¶**: `backend/app/models/model_models.py`

```python
@dataclass
class SenseVoiceModelInfo:
    """SenseVoiceæ¨¡å‹ä¿¡æ¯ï¼ˆæ–°å¢ï¼‰"""
    model_id: str = "iic/SenseVoiceSmall"
    status: str = "not_downloaded"      # not_downloaded/downloading/ready/error
    download_progress: float = 0.0
    local_path: Optional[str] = None
    
    def to_dict(self):
        return {
            "model_id": self.model_id,
            "status": self.status,
            "download_progress": self.download_progress,
            "local_path": str(self.local_path) if self.local_path else None
        }


```

---

## å››ã€æ ¸å¿ƒä¿®æ”¹è¯¦æƒ…

### 4.1 æ•°æ®æ¨¡å‹æ‰©å±•ï¼ˆPhase 1ï¼‰

**æ–‡ä»¶**: `backend/app/models/sensevoice_models.py`

```python
from dataclasses import dataclass, field
from typing import List, Optional
from enum import Enum


class TextSource(Enum):
    """æ–‡æœ¬æ¥æº"""
    SENSEVOICE = "sensevoice"        # SenseVoice åŸå§‹è¾“å‡º
    WHISPER_PATCH = "whisper_patch"  # Whisper è¡¥åˆ€æ›¿æ¢
    LLM_CORRECTION = "llm_correction"  # LLM æ ¡å¯¹ä¿®æ­£
    LLM_TRANSLATION = "llm_translation"  # LLM ç¿»è¯‘


class WarningType(Enum):
    """è­¦å‘Šç±»å‹ï¼ˆç”¨äºé«˜äº®ç³»ç»Ÿï¼‰"""
    NONE = "none"                           # æ— è­¦å‘Š
    LOW_TRANSCRIPTION_CONFIDENCE = "low_transcription"  # è½¬å½•ç½®ä¿¡åº¦ä½
    HIGH_PROOFREAD_PERPLEXITY = "high_perplexity"      # æ ¡å¯¹å›°æƒ‘åº¦é«˜
    BOTH = "both"                           # ä¸¤è€…éƒ½æœ‰é—®é¢˜


@dataclass
class WordTimestamp:
    """å­—çº§æ—¶é—´æˆ³"""
    word: str
    start: float
    end: float
    confidence: float = 1.0
    is_pseudo: bool = False  # æ˜¯å¦ä¸ºä¼ªå¯¹é½ç”Ÿæˆ
    # ========== æ–°å¢ï¼šè­¦å‘Šå­—æ®µ ==========
    warning_type: WarningType = WarningType.NONE
    perplexity: Optional[float] = None  # LLM æ ¡å¯¹æ—¶çš„å›°æƒ‘åº¦


@dataclass
class SentenceSegment:
    """å¥çº§å­—å¹•æ®µï¼ˆæ‰©å±•ç‰ˆï¼‰"""
    text: str
    start: float
    end: float
    words: List[WordTimestamp]
    confidence: float = 1.0

    # ========== æ—¶ç©ºè§£è€¦å­—æ®µ ==========
    source: TextSource = TextSource.SENSEVOICE  # æ–‡æœ¬æ¥æº
    is_modified: bool = False                    # æ˜¯å¦è¢«ä¿®æ”¹è¿‡
    original_text: Optional[str] = None          # ä¿®æ”¹å‰çš„åŸå§‹æ–‡æœ¬
    whisper_alternative: Optional[str] = None    # Whisper å¤‡é€‰æ–‡æœ¬

    # ========== æ–°å¢ï¼šè­¦å‘Šä¸æ ¡å¯¹å­—æ®µ ==========
    warning_type: WarningType = WarningType.NONE  # å¥çº§è­¦å‘Šç±»å‹
    perplexity: Optional[float] = None            # LLM æ ¡å¯¹å›°æƒ‘åº¦
    translation: Optional[str] = None             # ç¿»è¯‘ç»“æœ
    translation_confidence: Optional[float] = None  # ç¿»è¯‘ç½®ä¿¡åº¦

    def mark_as_modified(self, new_text: str, source: TextSource):
        """æ ‡è®°ä¸ºå·²ä¿®æ”¹"""
        if not self.is_modified:
            self.original_text = self.text
        self.text = new_text
        self.source = source
        self.is_modified = True

    def compute_warning_type(self) -> WarningType:
        """æ ¹æ®ç½®ä¿¡åº¦å’Œå›°æƒ‘åº¦è®¡ç®—è­¦å‘Šç±»å‹"""
        has_low_confidence = self.confidence < 0.6
        has_high_perplexity = self.perplexity is not None and self.perplexity > 50.0

        if has_low_confidence and has_high_perplexity:
            return WarningType.BOTH
        elif has_low_confidence:
            return WarningType.LOW_TRANSCRIPTION_CONFIDENCE
        elif has_high_perplexity:
            return WarningType.HIGH_PROOFREAD_PERPLEXITY
        return WarningType.NONE
```

### 4.2 ä¼ªå¯¹é½ç®—æ³•ï¼ˆPhase 1 æ–°å¢ï¼‰

**æ–‡ä»¶**: `backend/app/services/pseudo_alignment.py`

```python
"""
ä¼ªå¯¹é½ç®—æ³•ï¼ˆPseudo-Alignmentï¼‰

æ ¸å¿ƒåŸç†ï¼š
- SenseVoice ç¡®å®šçš„æ—¶é—´çª—å£ï¼ˆstart/endï¼‰ä¸å¯å˜
- å½“ Whisper/LLM æ›¿æ¢æ–‡æœ¬åï¼Œæ–°å­—ç¬¦å‡åŒ€åˆ†å¸ƒåœ¨åŸæ—¶é—´çª—å£å†…
- ç”Ÿæˆçš„å­—çº§æ—¶é—´æˆ³æ ‡è®°ä¸º is_pseudo=True
"""
from typing import List
from ..models.sensevoice_models import WordTimestamp
import logging

logger = logging.getLogger(__name__)


class PseudoAlignment:
    """ä¼ªå¯¹é½å™¨"""

    @staticmethod
    def apply(
        original_start: float,
        original_end: float,
        new_text: str,
        default_confidence: float = 1.0
    ) -> List[WordTimestamp]:
        """
        å°†æ–°æ–‡æœ¬å‡åŒ€æ˜ å°„åˆ°åŸæ—¶é—´æ®µå†…

        Args:
            original_start: åŸå§‹èµ·å§‹æ—¶é—´ï¼ˆç”± SenseVoice ç¡®å®šï¼Œä¸å¯å˜ï¼‰
            original_end: åŸå§‹ç»“æŸæ—¶é—´ï¼ˆç”± SenseVoice ç¡®å®šï¼Œä¸å¯å˜ï¼‰
            new_text: æ›¿æ¢åçš„æ–°æ–‡æœ¬
            default_confidence: é»˜è®¤ç½®ä¿¡åº¦ï¼ˆä¿®æ­£åé€šå¸¸ä¸º 1.0ï¼‰

        Returns:
            List[WordTimestamp]: ä¼ªå¯¹é½çš„å­—çº§æ—¶é—´æˆ³åˆ—è¡¨
        """
        duration = original_end - original_start

        # è¿‡æ»¤ç©ºç™½å­—ç¬¦ï¼Œä¿ç•™å®é™…å­—ç¬¦
        chars = [c for c in new_text if not c.isspace()]
        char_count = len(chars)

        if char_count == 0:
            logger.warning(f"ä¼ªå¯¹é½ï¼šæ–‡æœ¬ä¸ºç©ºï¼Œè·³è¿‡")
            return []

        # è®¡ç®—æ¯ä¸ªå­—ç¬¦çš„æ—¶é•¿
        step = duration / char_count
        result = []

        for i, char in enumerate(chars):
            w_start = original_start + (i * step)
            w_end = w_start + step

            result.append(WordTimestamp(
                word=char,
                start=round(w_start, 3),
                end=round(w_end, 3),
                confidence=default_confidence,
                is_pseudo=True  # æ ‡è®°ä¸ºä¼ªå¯¹é½ç”Ÿæˆ
            ))

        logger.debug(
            f"ä¼ªå¯¹é½å®Œæˆ: {char_count} å­—ç¬¦, "
            f"æ—¶é—´çª—å£ {original_start:.2f}-{original_end:.2f}s"
        )

        return result

    @staticmethod
    def apply_to_sentence(
        sentence,  # SentenceSegment
        new_text: str,
        source  # TextSource
    ):
        """
        å¯¹å¥å­åº”ç”¨ä¼ªå¯¹é½

        Args:
            sentence: åŸå§‹å¥å­æ®µè½
            new_text: æ›¿æ¢åçš„æ–‡æœ¬
            source: æ–‡æœ¬æ¥æº

        Returns:
            ä¿®æ”¹åçš„ SentenceSegmentï¼ˆåŸå¯¹è±¡è¢«ä¿®æ”¹ï¼‰
        """
        # ç”Ÿæˆæ–°çš„å­—çº§æ—¶é—´æˆ³
        new_words = PseudoAlignment.apply(
            original_start=sentence.start,
            original_end=sentence.end,
            new_text=new_text
        )

        # æ›´æ–°å¥å­
        sentence.mark_as_modified(new_text, source)
        sentence.words = new_words

        return sentence


# ========== å•ä¾‹è®¿é—® ==========

_pseudo_alignment_instance = None


def get_pseudo_alignment() -> PseudoAlignment:
    """è·å–ä¼ªå¯¹é½å™¨å•ä¾‹"""
    global _pseudo_alignment_instance
    if _pseudo_alignment_instance is None:
        _pseudo_alignment_instance = PseudoAlignment()
    return _pseudo_alignment_instance
```


### 4.4 ç†”æ–­å†³ç­–æ‰©å±•ï¼ˆPhase 2 ä¿®æ”¹ï¼‰

**æ–‡ä»¶**: `backend/app/services/fuse_breaker.py`

åœ¨ç°æœ‰ `FuseAction` æšä¸¾ä¸­æ·»åŠ æ–°åŠ¨ä½œï¼š

```python
class FuseAction(Enum):
    """ç†”æ–­åŠ¨ä½œï¼ˆæ‰©å±•ï¼‰"""
    ACCEPT = "accept"                           # æ¥å—ç»“æœ
    UPGRADE_SEPARATION = "upgrade_separation"   # å‡çº§åˆ†ç¦»æ¨¡å‹
    WHISPER_RETRY = "whisper_retry"             # Whisper è¡¥åˆ€ï¼ˆå…¨é‡é‡è¯•ï¼‰

    # ========== æ–°å¢ï¼šæ—¶ç©ºè§£è€¦åŠ¨ä½œ ==========
    WHISPER_TEXT_ONLY = "whisper_text_only"     # Whisper ä»…å–æ–‡æœ¬ï¼ˆä¼ªå¯¹é½ï¼‰
    LLM_ARBITRATE = "llm_arbitrate"             # LLM ä»²è£ï¼ˆSV vs Whisperï¼‰
```

ä¿®æ”¹ `decide_action` æ–¹æ³•ï¼Œæ”¯æŒæ–°çš„å†³ç­–é€»è¾‘ï¼š

```python
def decide_action(
    self,
    segment_id: int,
    confidence: float,
    event_tag: Optional[str],
    current_separation_level: SeparationLevel,
    whisper_alternative: Optional[str] = None
) -> FuseDecision:
    """
    å†³ç­–ç†”æ–­åŠ¨ä½œï¼ˆæ‰©å±•ç‰ˆï¼‰

    å†³ç­–ä¼˜å…ˆçº§ï¼š
    1. é«˜ç½®ä¿¡åº¦ â†’ ACCEPT
    2. æœ‰å™ªéŸ³æ ‡ç­¾ + æœªå‡çº§ â†’ UPGRADE_SEPARATION
    3. ä½ç½®ä¿¡åº¦ + å·²å‡çº§ â†’ WHISPER_TEXT_ONLYï¼ˆæ–°ï¼‰
    4. æœ‰ Whisper å¤‡é€‰ + æ­§ä¹‰ â†’ LLM_ARBITRATEï¼ˆæ–°ï¼‰
    """
    state = self._get_or_create_state(segment_id, current_separation_level)

    # 1. é«˜ç½®ä¿¡åº¦ï¼Œç›´æ¥æ¥å—
    if confidence >= self.confidence_threshold:
        return FuseDecision(
            action=FuseAction.ACCEPT,
            reason=f"ç½®ä¿¡åº¦ {confidence:.2f} >= {self.confidence_threshold}"
        )

    # 2. æ£€æŸ¥æ­¢æŸç‚¹
    if state.retry_count >= self.max_retry_count:
        return FuseDecision(
            action=FuseAction.ACCEPT,
            reason=f"è¾¾åˆ°æ­¢æŸç‚¹ (é‡è¯• {state.retry_count} æ¬¡)"
        )

    # 3. å™ªéŸ³ç¯å¢ƒ + å¯å‡çº§ â†’ å‡çº§åˆ†ç¦»
    if event_tag in ['BGM', 'Noise', 'Music']:
        next_level = self._get_next_separation_level(current_separation_level)
        if next_level:
            state.retry_count += 1
            return FuseDecision(
                action=FuseAction.UPGRADE_SEPARATION,
                reason=f"æ£€æµ‹åˆ° {event_tag}ï¼Œå‡çº§åˆ†ç¦»æ¨¡å‹",
                next_separation_level=next_level
            )

    # 4. ä½ç½®ä¿¡åº¦ + å·²å®Œå…¨å‡çº§ â†’ Whisper ä»…å–æ–‡æœ¬ï¼ˆä¼ªå¯¹é½ï¼‰
    if confidence < self.upgrade_threshold:
        state.retry_count += 1

        return FuseDecision(
            action=FuseAction.WHISPER_TEXT_ONLY,
            reason=f"ä½ç½®ä¿¡åº¦ {confidence:.2f}ï¼Œä½¿ç”¨ Whisper è¡¥åˆ€ï¼ˆä¼ªå¯¹é½ï¼‰"
        )

    # 5. æœ‰ Whisper å¤‡é€‰ä¸”å­˜åœ¨æ­§ä¹‰ â†’ LLM ä»²è£
    if whisper_alternative:
        return FuseDecision(
            action=FuseAction.LLM_ARBITRATE,
            reason="SenseVoice ä¸ Whisper ç»“æœå­˜åœ¨å·®å¼‚ï¼Œéœ€ LLM ä»²è£"
        )

    # é»˜è®¤ï¼šæ¥å—
    return FuseDecision(
        action=FuseAction.ACCEPT,
        reason="é»˜è®¤æ¥å—"
    )
```

### 4.5 Whisper è¡¥åˆ€é‡æ„ï¼ˆPhase 3 æ ¸å¿ƒä¿®æ”¹ï¼‰

**æ–‡ä»¶**: `backend/app/services/transcription_service.py`

```python
async def _whisper_text_only_patch(
    self,
    sentence: SentenceSegment,
    audio_array: np.ndarray,
    previous_text: str = ""
) -> SentenceSegment:
    """
    Whisper ä»…æ–‡æœ¬è¡¥åˆ€ï¼ˆæ—¶ç©ºè§£è€¦æ ¸å¿ƒï¼‰

    å…³é”®åŸåˆ™ï¼š
    - ä»…ä½¿ç”¨ Whisper çš„æ–‡æœ¬è¾“å‡º
    - ä½¿ç”¨ä¼ªå¯¹é½ç®—æ³•ç”Ÿæˆå­—çº§æ—¶é—´æˆ³

    Args:
        sentence: åŸå§‹å¥å­ï¼ˆSenseVoice è¾“å‡ºï¼‰
        audio_array: éŸ³é¢‘æ•°ç»„
        previous_text: å‰ä¸€å¥æ–‡æœ¬ï¼ˆç”¨äº initial_promptï¼‰

    Returns:
        ä¿®æ­£åçš„å¥å­ï¼ˆæ—¶é—´æˆ³ä¿æŒä¸å˜ï¼‰
    """
    from .whisper_service import get_whisper_service
    from .pseudo_alignment import get_pseudo_alignment
    from .text_normalizer import TextNormalizer

    # 1. æå–éŸ³é¢‘ç‰‡æ®µ
    audio_segment = self._extract_segment_audio(sentence, audio_array)

    # 2. Whisper è½¬å½•ï¼ˆä»…å–æ–‡æœ¬ï¼‰
    whisper_service = get_whisper_service()
    result = whisper_service.transcribe(
        audio=audio_segment,
        initial_prompt=previous_text,
        language=self.current_job.settings.language
    )

    # 3. è·å– Whisper æ–‡æœ¬ï¼ˆå¼ƒç”¨æ—¶é—´æˆ³ï¼‰
    whisper_text = result.get('text', '').strip()

    if not whisper_text:
        self.logger.warning(f"Whisper è¡¥åˆ€è¿”å›ç©ºæ–‡æœ¬ï¼Œä¿ç•™åŸç»“æœ")
        return sentence

    # 4. æ–‡æœ¬æ¸…æ´—
    whisper_text = TextNormalizer.process(whisper_text)

    # 5. åº”ç”¨ä¼ªå¯¹é½
    pseudo_alignment = get_pseudo_alignment()
    pseudo_alignment.apply_to_sentence(
        sentence=sentence,
        new_text=whisper_text,
        source=TextSource.WHISPER_PATCH
    )

    self.logger.info(
        f"Whisper è¡¥åˆ€å®Œæˆ: '{sentence.original_text}' -> '{sentence.text}'"
    )

    return sentence
```

---

## äº”ã€æ™ºèƒ½è¿›åº¦ç³»ç»Ÿ

### 5.1 è¿›åº¦æƒé‡é…ç½®

**æ–‡ä»¶**: `backend/app/services/progress_tracker.py`

æ ¹æ®ç”¨æˆ·é€‰æ‹©çš„é¢„è®¾/è‡ªå®šä¹‰é…ç½®ï¼ŒåŠ¨æ€è°ƒæ•´å„é˜¶æ®µçš„è¿›åº¦æƒé‡ï¼š

```python
"""
æ™ºèƒ½è¿›åº¦è¿½è¸ªç³»ç»Ÿ

æ ¸å¿ƒç‰¹æ€§ï¼š
1. æ ¹æ®é¢„è®¾é…ç½®åŠ¨æ€è°ƒæ•´å„é˜¶æ®µæƒé‡
2. æ”¯æŒæµå¼æ›´æ–°ï¼ˆSVã€Whisperã€LLM å„é˜¶æ®µç‹¬ç«‹æ›´æ–°ï¼‰
3. ç»Ÿä¸€ SSE äº‹ä»¶ tag è®¾è®¡
"""
from dataclasses import dataclass, field
from typing import Dict, Optional, List
from enum import Enum
import logging

logger = logging.getLogger(__name__)


class ProcessPhase(Enum):
    """å¤„ç†é˜¶æ®µæšä¸¾"""
    PENDING = "pending"           # ç­‰å¾…å¼€å§‹
    EXTRACT = "extract"           # éŸ³é¢‘æå–
    BGM_DETECT = "bgm_detect"     # BGM æ£€æµ‹
    DEMUCS = "demucs"             # äººå£°åˆ†ç¦»
    VAD = "vad"                   # VAD åˆ†æ®µ
    SENSEVOICE = "sensevoice"     # SenseVoice è½¬å½•
    WHISPER_PATCH = "whisper"     # Whisper è¡¥åˆ€
    LLM_PROOF = "llm_proof"       # LLM æ ¡å¯¹
    LLM_TRANS = "llm_trans"       # LLM ç¿»è¯‘
    SRT = "srt"                   # SRT ç”Ÿæˆ
    COMPLETE = "complete"         # å®Œæˆ


@dataclass
class PhaseProgress:
    """é˜¶æ®µè¿›åº¦"""
    phase: ProcessPhase
    weight: float              # è¯¥é˜¶æ®µåœ¨æ€»è¿›åº¦ä¸­çš„æƒé‡
    total_items: int = 0       # æ€»é¡¹ç›®æ•°ï¼ˆå¦‚æ€»æ®µæ•°ï¼‰
    completed_items: int = 0   # å·²å®Œæˆé¡¹ç›®æ•°
    is_active: bool = False    # æ˜¯å¦æ­£åœ¨å¤„ç†
    message: str = ""          # è¿›åº¦æ¶ˆæ¯


@dataclass
class PresetWeights:
    """é¢„è®¾æƒé‡é…ç½®"""
    extract: float = 5
    bgm_detect: float = 2
    demucs: float = 8
    vad: float = 5
    sensevoice: float = 40
    whisper: float = 0        # é»˜è®¤å…³é—­
    llm_proof: float = 0      # é»˜è®¤å…³é—­
    llm_trans: float = 0      # é»˜è®¤å…³é—­
    srt: float = 10

    @classmethod
    def from_preset(cls, preset_id: str) -> 'PresetWeights':
        """æ ¹æ®é¢„è®¾IDç”Ÿæˆæƒé‡é…ç½®"""
        presets = {
            'default': cls(
                # SenseVoice Only
                sensevoice=50, srt=10
            ),
            'preset1': cls(
                # SV + Whisper Partial
                sensevoice=35, whisper=20, srt=10
            ),
            'preset2': cls(
                # SV + Whisper Partial + LLM Partial Proof
                sensevoice=30, whisper=15, llm_proof=15, srt=10
            ),
            'preset3': cls(
                # SV + Whisper Partial + LLM Full Proof
                sensevoice=25, whisper=15, llm_proof=25, srt=10
            ),
            'preset4': cls(
                # SV + Whisper Partial + LLM Full Proof + LLM Full Trans
                sensevoice=20, whisper=10, llm_proof=20, llm_trans=15, srt=10
            ),
            'preset5': cls(
                # SV + Whisper Partial + LLM Full Proof + LLM Partial Trans
                sensevoice=22, whisper=12, llm_proof=20, llm_trans=8, srt=10
            ),
        }
        return presets.get(preset_id, cls())

    def total_weight(self) -> float:
        """è®¡ç®—æ€»æƒé‡"""
        return (
            self.extract + self.bgm_detect + self.demucs +
            self.vad + self.sensevoice + self.whisper +
            self.llm_proof + self.llm_trans + self.srt
        )


class ProgressTracker:
    """æ™ºèƒ½è¿›åº¦è¿½è¸ªå™¨"""

    def __init__(self, job_id: str, preset_id: str = 'default'):
        self.job_id = job_id
        self.weights = PresetWeights.from_preset(preset_id)
        self.total_weight = self.weights.total_weight()

        # å„é˜¶æ®µè¿›åº¦çŠ¶æ€
        self.phases: Dict[ProcessPhase, PhaseProgress] = {}
        self._init_phases()

        # ç´¯è®¡å®Œæˆæƒé‡
        self.completed_weight = 0.0
        self.current_phase = ProcessPhase.PENDING

        logger.info(f"è¿›åº¦è¿½è¸ªå™¨åˆå§‹åŒ–: preset={preset_id}, total_weight={self.total_weight}")

    def _init_phases(self):
        """åˆå§‹åŒ–å„é˜¶æ®µ"""
        weight_map = {
            ProcessPhase.EXTRACT: self.weights.extract,
            ProcessPhase.BGM_DETECT: self.weights.bgm_detect,
            ProcessPhase.DEMUCS: self.weights.demucs,
            ProcessPhase.VAD: self.weights.vad,
            ProcessPhase.SENSEVOICE: self.weights.sensevoice,
            ProcessPhase.WHISPER_PATCH: self.weights.whisper,
            ProcessPhase.LLM_PROOF: self.weights.llm_proof,
            ProcessPhase.LLM_TRANS: self.weights.llm_trans,
            ProcessPhase.SRT: self.weights.srt,
        }

        for phase, weight in weight_map.items():
            self.phases[phase] = PhaseProgress(
                phase=phase,
                weight=weight,
                is_active=False
            )

    def start_phase(self, phase: ProcessPhase, total_items: int = 1, message: str = ""):
        """å¼€å§‹æŸä¸ªé˜¶æ®µ"""
        if phase in self.phases:
            self.phases[phase].is_active = True
            self.phases[phase].total_items = total_items
            self.phases[phase].completed_items = 0
            self.phases[phase].message = message
            self.current_phase = phase
            logger.debug(f"é˜¶æ®µå¼€å§‹: {phase.value}, æ€»é¡¹ç›®: {total_items}")

    def update_phase(
        self,
        phase: ProcessPhase,
        completed: int = None,
        increment: int = None,
        message: str = None
    ):
        """æ›´æ–°é˜¶æ®µè¿›åº¦"""
        if phase not in self.phases:
            return

        pp = self.phases[phase]

        if completed is not None:
            pp.completed_items = completed
        elif increment is not None:
            pp.completed_items += increment

        if message is not None:
            pp.message = message

    def complete_phase(self, phase: ProcessPhase):
        """å®ŒæˆæŸä¸ªé˜¶æ®µ"""
        if phase in self.phases:
            pp = self.phases[phase]
            pp.is_active = False
            pp.completed_items = pp.total_items
            self.completed_weight += pp.weight
            logger.debug(f"é˜¶æ®µå®Œæˆ: {phase.value}")

    def get_overall_progress(self) -> float:
        """è·å–æ€»ä½“è¿›åº¦ç™¾åˆ†æ¯”"""
        # å·²å®Œæˆé˜¶æ®µçš„æƒé‡
        progress = self.completed_weight

        # åŠ ä¸Šå½“å‰é˜¶æ®µçš„éƒ¨åˆ†è¿›åº¦
        if self.current_phase in self.phases:
            pp = self.phases[self.current_phase]
            if pp.is_active and pp.total_items > 0:
                phase_progress = pp.completed_items / pp.total_items
                progress += pp.weight * phase_progress

        return round((progress / self.total_weight) * 100, 1)

    def get_phase_progress(self, phase: ProcessPhase) -> float:
        """è·å–æŸé˜¶æ®µçš„è¿›åº¦ç™¾åˆ†æ¯”"""
        if phase not in self.phases:
            return 0.0

        pp = self.phases[phase]
        if pp.total_items == 0:
            return 0.0

        return round((pp.completed_items / pp.total_items) * 100, 1)

    def to_sse_data(self) -> dict:
        """ç”Ÿæˆ SSE æ¨é€æ•°æ®"""
        return {
            "job_id": self.job_id,
            "phase": self.current_phase.value,
            "percent": self.get_overall_progress(),
            "phase_percent": self.get_phase_progress(self.current_phase),
            "message": self.phases.get(self.current_phase, PhaseProgress(
                phase=self.current_phase, weight=0
            )).message,
            "phases": {
                p.value: {
                    "weight": self.phases[p].weight,
                    "progress": self.get_phase_progress(p),
                    "completed": self.phases[p].completed_items,
                    "total": self.phases[p].total_items,
                    "active": self.phases[p].is_active
                }
                for p in self.phases
            }
        }


# ========== å•ä¾‹å·¥å‚ ==========

_tracker_instances: Dict[str, ProgressTracker] = {}


def get_progress_tracker(job_id: str, preset_id: str = None) -> ProgressTracker:
    """è·å–æˆ–åˆ›å»ºè¿›åº¦è¿½è¸ªå™¨"""
    global _tracker_instances

    if job_id not in _tracker_instances:
        if preset_id is None:
            preset_id = 'default'
        _tracker_instances[job_id] = ProgressTracker(job_id, preset_id)

    return _tracker_instances[job_id]


def remove_progress_tracker(job_id: str):
    """ç§»é™¤è¿›åº¦è¿½è¸ªå™¨"""
    global _tracker_instances
    if job_id in _tracker_instances:
        del _tracker_instances[job_id]
```

### 5.2 SSE äº‹ä»¶ Tag è®¾è®¡

**æ–‡ä»¶**: `backend/app/services/sse_service.py` (æ‰©å±•)

```python
"""
SSE äº‹ä»¶ Tag ç»Ÿä¸€å®šä¹‰

äº‹ä»¶å‘½åè§„èŒƒï¼š
- progress.{phase}: è¿›åº¦æ›´æ–°äº‹ä»¶
- subtitle.{action}: å­—å¹•æµå¼äº‹ä»¶
- signal.{type}: ä¿¡å·äº‹ä»¶
"""

# ========== è¿›åº¦äº‹ä»¶ Tag ==========

SSE_PROGRESS_TAGS = {
    # æ•´ä½“è¿›åº¦
    "progress.overall": "æ€»ä½“è¿›åº¦æ›´æ–°",

    # å„é˜¶æ®µè¿›åº¦
    "progress.extract": "éŸ³é¢‘æå–è¿›åº¦",
    "progress.bgm_detect": "BGM æ£€æµ‹è¿›åº¦",
    "progress.demucs": "äººå£°åˆ†ç¦»è¿›åº¦",
    "progress.vad": "VAD åˆ†æ®µè¿›åº¦",
    "progress.sensevoice": "SenseVoice è½¬å½•è¿›åº¦ï¼ˆæµå¼ï¼‰",
    "progress.whisper": "Whisper è¡¥åˆ€è¿›åº¦",
    "progress.llm_proof": "LLM æ ¡å¯¹è¿›åº¦",
    "progress.llm_trans": "LLM ç¿»è¯‘è¿›åº¦",
    "progress.srt": "SRT ç”Ÿæˆè¿›åº¦",
}

# ========== å­—å¹•æµå¼äº‹ä»¶ Tag ==========

SSE_SUBTITLE_TAGS = {
    # SenseVoice æµå¼è¾“å‡º
    "subtitle.sv_segment": "SenseVoice å®Œæˆä¸€ä¸ª VAD æ®µ",
    "subtitle.sv_sentence": "SenseVoice å®Œæˆä¸€ä¸ªå¥å­",

    # Whisper è¦†ç›–
    "subtitle.whisper_patch": "Whisper è¡¥åˆ€è¦†ç›–ä¸€ä¸ªå¥å­",

    # LLM è¦†ç›–
    "subtitle.llm_proof": "LLM æ ¡å¯¹è¦†ç›–ä¸€ä¸ªå¥å­",
    "subtitle.llm_trans": "LLM ç¿»è¯‘å®Œæˆä¸€ä¸ªå¥å­",

    # æ‰¹é‡æ›´æ–°
    "subtitle.batch_update": "æ‰¹é‡æ›´æ–°å¤šä¸ªå¥å­",
}

# ========== ä¿¡å·äº‹ä»¶ Tag ==========

SSE_SIGNAL_TAGS = {
    "signal.job_start": "ä»»åŠ¡å¼€å§‹",
    "signal.job_complete": "ä»»åŠ¡å®Œæˆ",
    "signal.job_failed": "ä»»åŠ¡å¤±è´¥",
    "signal.job_paused": "ä»»åŠ¡æš‚åœ",
    "signal.job_canceled": "ä»»åŠ¡å–æ¶ˆ",
    "signal.phase_start": "é˜¶æ®µå¼€å§‹",
    "signal.phase_complete": "é˜¶æ®µå®Œæˆ",
    "signal.circuit_breaker": "ç†”æ–­è§¦å‘",
    "signal.model_escalation": "æ¨¡å‹å‡çº§",
}


# ========== SSE æ¨é€è¾…åŠ©æ–¹æ³• ==========

def push_progress_event(
    sse_manager,
    job_id: str,
    phase: str,
    data: dict
):
    """æ¨é€è¿›åº¦äº‹ä»¶"""
    tag = f"progress.{phase}"
    channel_id = f"job:{job_id}"
    sse_manager.broadcast_sync(channel_id, tag, data)

    # åŒæ—¶æ¨é€åˆ°å…¨å±€é¢‘é“
    sse_manager.broadcast_sync("global", "job_progress", {
        "id": job_id,
        **data
    })


def push_subtitle_event(
    sse_manager,
    job_id: str,
    event_type: str,
    sentence_data: dict
):
    """æ¨é€å­—å¹•æµå¼äº‹ä»¶"""
    tag = f"subtitle.{event_type}"
    channel_id = f"job:{job_id}"
    sse_manager.broadcast_sync(channel_id, tag, sentence_data)


def push_signal_event(
    sse_manager,
    job_id: str,
    signal_type: str,
    message: str = ""
):
    """æ¨é€ä¿¡å·äº‹ä»¶"""
    tag = f"signal.{signal_type}"
    channel_id = f"job:{job_id}"
    sse_manager.broadcast_sync(channel_id, tag, {
        "job_id": job_id,
        "signal": signal_type,
        "message": message
    })
```

---

## å…­ã€ç»„åˆæ–¹æ¡ˆçŸ©é˜µ

### 6.1 æ–¹æ¡ˆé…ç½®ï¼ˆPhase 2 æ–°å¢ï¼‰

**æ–‡ä»¶**: `backend/app/services/solution_matrix.py`

```python
"""
ç»„åˆæ–¹æ¡ˆçŸ©é˜µ (Solution Matrix)

æä¾›é«˜åº¦æ¨¡å—åŒ–çš„é…ç½®ï¼Œå…è®¸åœ¨"é€Ÿåº¦ã€æˆæœ¬ã€è´¨é‡"ä¹‹é—´è‡ªç”±ç»„åˆã€‚
å‰ç«¯é¢„è®¾å¯¹åº”åç«¯å…·ä½“é…ç½®ã€‚
"""
from dataclasses import dataclass
from enum import Enum
from typing import Optional


class EnhancementMode(Enum):
    """å¢å¼ºæ¨¡å¼"""
    OFF = "off"                      # A1: SenseVoice Only
    SMART_PATCH = "smart_patch"     # B1: SenseVoice + Whisper Partialï¼ˆæ¨èï¼‰
    DEEP_LISTEN = "deep_listen"     # C1: SenseVoice + Whisper Full


class ProofreadMode(Enum):
    """æ ¡å¯¹æ¨¡å¼"""
    OFF = "off"                   # å…³é—­
    SPARSE = "sparse"             # P1: æŒ‰éœ€ä¿®å¤ï¼ˆæ¨èï¼‰
    FULL = "full"                 # P2: å…¨æ–‡ç²¾ä¿®


class TranslateMode(Enum):
    """ç¿»è¯‘æ¨¡å¼"""
    OFF = "off"                   # æ— ç¿»è¯‘
    FULL = "full"                 # T1: å…¨é‡ç¿»è¯‘
    PARTIAL = "partial"           # T2: éƒ¨åˆ†ç¿»è¯‘


@dataclass
class SolutionConfig:
    """æ–¹æ¡ˆé…ç½®"""
    preset_id: str = "default"                    # é¢„è®¾ID
    enhancement: EnhancementMode = EnhancementMode.OFF
    proofread: ProofreadMode = ProofreadMode.OFF
    translate: TranslateMode = TranslateMode.OFF
    target_language: Optional[str] = None

    # é«˜çº§é€‰é¡¹
    confidence_threshold: float = 0.6             # ä½äºæ­¤å€¼è§¦å‘è¡¥åˆ€

    @classmethod
    def from_preset(cls, preset_id: str) -> 'SolutionConfig':
        """æ ¹æ®é¢„è®¾IDåˆ›å»ºé…ç½®"""
        presets = {
            'default': cls(
                preset_id='default',
                enhancement=EnhancementMode.OFF,
                proofread=ProofreadMode.OFF,
                translate=TranslateMode.OFF
            ),
            'preset1': cls(
                preset_id='preset1',
                enhancement=EnhancementMode.SMART_PATCH,
                proofread=ProofreadMode.OFF,
                translate=TranslateMode.OFF
            ),
            'preset2': cls(
                preset_id='preset2',
                enhancement=EnhancementMode.SMART_PATCH,
                proofread=ProofreadMode.SPARSE,
                translate=TranslateMode.OFF
            ),
            'preset3': cls(
                preset_id='preset3',
                enhancement=EnhancementMode.SMART_PATCH,
                proofread=ProofreadMode.FULL,
                translate=TranslateMode.OFF
            ),
            'preset4': cls(
                preset_id='preset4',
                enhancement=EnhancementMode.SMART_PATCH,
                proofread=ProofreadMode.FULL,
                translate=TranslateMode.FULL,
                target_language='en'
            ),
            'preset5': cls(
                preset_id='preset5',
                enhancement=EnhancementMode.SMART_PATCH,
                proofread=ProofreadMode.FULL,
                translate=TranslateMode.PARTIAL
            ),
        }
        return presets.get(preset_id, cls())


# ========== æ–¹æ¡ˆçŸ©é˜µæè¿° ==========

SOLUTION_MATRIX = {
    # ========== åŸºç¡€å±‚ ==========
    "A1": {
        "name": "SenseVoice Only",
        "flow": ["sensevoice"],
        "scenario": "å®æ—¶é¢„è§ˆã€å³æ—¶æ—¥å¿—",
        "note": "æé€Ÿã€‚åŸæ±åŸå‘³ï¼Œä¾é å‰ç«¯æ ‡çº¢æç¤ºé”™è¯¯"
    },
    "B1": {
        "name": "SenseVoice + Whisper Partial",
        "flow": ["sensevoice", "whisper_partial", "pseudo_align"],
        "scenario": "å˜ˆæ‚ã€å¤šBGMç¯å¢ƒ",
        "note": "é»˜è®¤æ¨èã€‚ä»…å¯¹ä½ç½®ä¿¡åº¦ç‰‡æ®µè¿›è¡ŒWhisperé‡å¬ï¼Œä¼ªå¯¹é½"
    },
    "C1": {
        "name": "SenseVoice + Whisper Full",
        "flow": ["sensevoice_as_vad", "whisper_full"],
        "scenario": "å¯¹æ¯”æµ‹è¯•/æä½è´¨é‡éŸ³é¢‘",
        "note": "é‡åˆ¶ã€‚ç”¨SVåšVADï¼ŒWhisperè·‘å…¨æ–‡"
    },

    # ========== è¯­ä¹‰å±‚ï¼ˆå¯å åŠ ï¼‰ ==========
    "P1": {
        "name": "LLM Partial Proof",
        "flow": ["llm_sparse_proof"],
        "scenario": "ä¸ªäººç¬”è®°ã€æ—¥å¸¸Vlog",
        "note": "æ€§ä»·æ¯”ä¹‹ç‹ã€‚æŒ‰éœ€ç¨€ç–æ ¡å¯¹ï¼ŒèŠ‚çœ90%+Token"
    },
    "P2": {
        "name": "LLM Full Proof",
        "flow": ["llm_full_proof"],
        "scenario": "æ­£å¼å‡ºç‰ˆã€æ–‡ç¨¿æ•´ç†",
        "note": "é«˜è´¨é‡ã€‚å…¨é‡æ»‘åŠ¨çª—å£ï¼Œæ¶¦è‰²å£è¯­ã€ä¿®æ­£é€»è¾‘"
    },

    # ========== ç¿»è¯‘å±‚ï¼ˆå¿…é¡»åœ¨æ ¡å¯¹ä¹‹åï¼‰ ==========
    "T1": {
        "name": "LLM Full Trans",
        "flow": ["llm_full_translate"],
        "scenario": "è·¨è¯­è¨€å†…å®¹",
        "note": "ä¼ ç»Ÿçš„å…¨é‡ç¿»è¯‘"
    },
    "T2": {
        "name": "LLM Partial Trans",
        "flow": ["llm_partial_translate"],
        "scenario": "æ•™å­¦é‡ç‚¹æ ‡æ³¨",
        "note": "ä»…ç¿»è¯‘ç”¨æˆ·æŒ‡å®šçš„é‡ç‚¹æ®µè½"
    }
}
```

---

## ä¸ƒã€å­—å¹•æµå¼è¾“å‡ºç³»ç»Ÿ

### 7.1 æµå¼è¾“å‡ºåŸåˆ™

**æ–‡ä»¶**: `backend/app/services/streaming_subtitle.py`

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    å­—å¹•æµå¼è¾“å‡ºæ—¶åº                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  SenseVoice è½¬å½•é˜¶æ®µï¼š                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚  â”‚ VADæ®µ1  â”‚â†’â”‚åˆ†å¥1,2,3â”‚â†’â”‚ SSEæ¨é€ â”‚   ç«‹å³æ˜¾ç¤º               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚  â”‚ VADæ®µ2  â”‚â†’â”‚åˆ†å¥4,5  â”‚â†’â”‚ SSEæ¨é€ â”‚   è¿½åŠ æ˜¾ç¤º               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚                                                                 â”‚
â”‚  Whisper è¡¥åˆ€é˜¶æ®µï¼š                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚  â”‚ å¥å­3   â”‚â†’â”‚ Whisper â”‚â†’â”‚ SSEè¦†ç›– â”‚   è¦†ç›–å¥å­3              â”‚
â”‚  â”‚(ä½ç½®ä¿¡) â”‚  â”‚  è¡¥åˆ€   â”‚  â”‚ å¥å­3  â”‚                          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚                                                                 â”‚
â”‚  LLM æ ¡å¯¹é˜¶æ®µï¼š                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚  â”‚ å¥å­5   â”‚â†’â”‚  LLM    â”‚â†’â”‚ SSEè¦†ç›– â”‚   è¦†ç›–å¥å­5              â”‚
â”‚  â”‚(éœ€æ ¡å¯¹) â”‚  â”‚  æ ¡å¯¹   â”‚  â”‚ å¥å­5  â”‚                          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚                                                                 â”‚
â”‚  LLM ç¿»è¯‘é˜¶æ®µï¼š                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚  â”‚ å¥å­1   â”‚â†’â”‚  LLM    â”‚â†’â”‚ SSEè¿½åŠ  â”‚   è¿½åŠ ç¿»è¯‘å­—æ®µ            â”‚
â”‚  â”‚         â”‚  â”‚  ç¿»è¯‘   â”‚  â”‚translationâ”‚                       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

```python
"""
å­—å¹•æµå¼è¾“å‡ºç®¡ç†å™¨

æ ¸å¿ƒèŒè´£ï¼š
1. SenseVoice æ¯å®Œæˆä¸€ä¸ª VAD æ®µçš„è½¬å½•å’Œåˆ†å¥ï¼Œç«‹å³æ¨é€åˆ°å‰ç«¯
2. Whisper æ¯å®Œæˆä¸€å¥è¡¥åˆ€ï¼Œç«‹å³è¦†ç›–å‰ç«¯å¯¹åº”å¥å­
3. LLM æ¯å®Œæˆä¸€å¥æ ¡å¯¹/ç¿»è¯‘ï¼Œç«‹å³æ›´æ–°å‰ç«¯å¯¹åº”å¥å­
"""
from typing import List, Dict, Optional
from dataclasses import dataclass
import logging

logger = logging.getLogger(__name__)


@dataclass
class SubtitleUpdateEvent:
    """å­—å¹•æ›´æ–°äº‹ä»¶"""
    action: str          # "append" | "update" | "batch_update"
    sentence_index: int  # å¥å­ç´¢å¼•ï¼ˆ-1 è¡¨ç¤ºæ‰¹é‡ï¼‰
    sentence_data: dict  # å¥å­æ•°æ®
    source: str          # "sensevoice" | "whisper" | "llm_proof" | "llm_trans"


class StreamingSubtitleManager:
    """æµå¼å­—å¹•ç®¡ç†å™¨"""

    def __init__(self, job_id: str, sse_manager):
        self.job_id = job_id
        self.sse_manager = sse_manager
        self.channel_id = f"job:{job_id}"

        # å½“å‰å­—å¹•åˆ—è¡¨ï¼ˆå†…å­˜ç¼“å­˜ï¼‰
        self.sentences: List[dict] = []

        logger.info(f"æµå¼å­—å¹•ç®¡ç†å™¨åˆå§‹åŒ–: {job_id}")

    def on_sensevoice_vad_complete(
        self,
        vad_index: int,
        sentences: List[dict]
    ):
        """
        SenseVoice å®Œæˆä¸€ä¸ª VAD æ®µçš„è½¬å½•

        Args:
            vad_index: VAD æ®µç´¢å¼•
            sentences: è¯¥æ®µå†…çš„æ‰€æœ‰å¥å­
        """
        start_index = len(self.sentences)

        for i, sent in enumerate(sentences):
            sent['index'] = start_index + i
            sent['source'] = 'sensevoice'
            self.sentences.append(sent)

            # ç«‹å³æ¨é€
            self.sse_manager.broadcast_sync(
                self.channel_id,
                "subtitle.sv_sentence",
                {
                    "action": "append",
                    "sentence_index": sent['index'],
                    "sentence": sent,
                    "vad_index": vad_index
                }
            )

        logger.debug(f"SenseVoice VAD{vad_index} å®Œæˆ: {len(sentences)} å¥")

    def on_whisper_patch_complete(
        self,
        sentence_index: int,
        new_text: str,
        new_confidence: float = 1.0
    ):
        """
        Whisper å®Œæˆä¸€å¥è¡¥åˆ€

        Args:
            sentence_index: å¥å­ç´¢å¼•
            new_text: æ–°æ–‡æœ¬
            new_confidence: æ–°ç½®ä¿¡åº¦
        """
        if sentence_index >= len(self.sentences):
            logger.warning(f"Whisper è¡¥åˆ€ç´¢å¼•è¶Šç•Œ: {sentence_index}")
            return

        # æ›´æ–°å†…å­˜
        sent = self.sentences[sentence_index]
        sent['original_text'] = sent.get('text', '')
        sent['text'] = new_text
        sent['confidence'] = new_confidence
        sent['source'] = 'whisper_patch'
        sent['is_modified'] = True

        # ç«‹å³æ¨é€è¦†ç›–
        self.sse_manager.broadcast_sync(
            self.channel_id,
            "subtitle.whisper_patch",
            {
                "action": "update",
                "sentence_index": sentence_index,
                "sentence": sent
            }
        )

        logger.debug(f"Whisper è¡¥åˆ€ å¥å­{sentence_index}: '{sent['original_text']}' -> '{new_text}'")

    def on_llm_proof_complete(
        self,
        sentence_index: int,
        proofed_text: str,
        perplexity: float = None
    ):
        """
        LLM å®Œæˆä¸€å¥æ ¡å¯¹

        Args:
            sentence_index: å¥å­ç´¢å¼•
            proofed_text: æ ¡å¯¹åæ–‡æœ¬
            perplexity: å›°æƒ‘åº¦
        """
        if sentence_index >= len(self.sentences):
            logger.warning(f"LLM æ ¡å¯¹ç´¢å¼•è¶Šç•Œ: {sentence_index}")
            return

        # æ›´æ–°å†…å­˜
        sent = self.sentences[sentence_index]
        if sent['text'] != proofed_text:
            sent['original_text'] = sent.get('original_text') or sent['text']
            sent['text'] = proofed_text
            sent['is_modified'] = True
        sent['source'] = 'llm_correction'
        sent['perplexity'] = perplexity

        # è®¡ç®—è­¦å‘Šç±»å‹
        sent['warning_type'] = self._compute_warning_type(sent)

        # ç«‹å³æ¨é€è¦†ç›–
        self.sse_manager.broadcast_sync(
            self.channel_id,
            "subtitle.llm_proof",
            {
                "action": "update",
                "sentence_index": sentence_index,
                "sentence": sent
            }
        )

        logger.debug(f"LLM æ ¡å¯¹ å¥å­{sentence_index}, perplexity={perplexity}")

    def on_llm_trans_complete(
        self,
        sentence_index: int,
        translation: str,
        translation_confidence: float = None
    ):
        """
        LLM å®Œæˆä¸€å¥ç¿»è¯‘

        Args:
            sentence_index: å¥å­ç´¢å¼•
            translation: ç¿»è¯‘ç»“æœ
            translation_confidence: ç¿»è¯‘ç½®ä¿¡åº¦
        """
        if sentence_index >= len(self.sentences):
            logger.warning(f"LLM ç¿»è¯‘ç´¢å¼•è¶Šç•Œ: {sentence_index}")
            return

        # æ›´æ–°å†…å­˜
        sent = self.sentences[sentence_index]
        sent['translation'] = translation
        sent['translation_confidence'] = translation_confidence

        # ç«‹å³æ¨é€ï¼ˆè¿½åŠ ç¿»è¯‘å­—æ®µï¼‰
        self.sse_manager.broadcast_sync(
            self.channel_id,
            "subtitle.llm_trans",
            {
                "action": "update",
                "sentence_index": sentence_index,
                "sentence": sent
            }
        )

        logger.debug(f"LLM ç¿»è¯‘ å¥å­{sentence_index}: '{translation}'")

    def _compute_warning_type(self, sent: dict) -> str:
        """è®¡ç®—è­¦å‘Šç±»å‹"""
        confidence = sent.get('confidence', 1.0)
        perplexity = sent.get('perplexity')

        has_low_confidence = confidence < 0.6
        has_high_perplexity = perplexity is not None and perplexity > 50.0

        if has_low_confidence and has_high_perplexity:
            return 'both'
        elif has_low_confidence:
            return 'low_transcription'
        elif has_high_perplexity:
            return 'high_perplexity'
        return 'none'

    def get_all_sentences(self) -> List[dict]:
        """è·å–æ‰€æœ‰å¥å­"""
        return self.sentences


# ========== å•ä¾‹å·¥å‚ ==========

_streaming_managers: Dict[str, StreamingSubtitleManager] = {}


def get_streaming_subtitle_manager(
    job_id: str,
    sse_manager = None
) -> StreamingSubtitleManager:
    """è·å–æˆ–åˆ›å»ºæµå¼å­—å¹•ç®¡ç†å™¨"""
    global _streaming_managers

    if job_id not in _streaming_managers:
        if sse_manager is None:
            from .sse_service import get_sse_manager
            sse_manager = get_sse_manager()
        _streaming_managers[job_id] = StreamingSubtitleManager(job_id, sse_manager)

    return _streaming_managers[job_id]


def remove_streaming_subtitle_manager(job_id: str):
    """ç§»é™¤æµå¼å­—å¹•ç®¡ç†å™¨"""
    global _streaming_managers
    if job_id in _streaming_managers:
        del _streaming_managers[job_id]
```

---

## å…«ã€ç½®ä¿¡åº¦ä¸å›°æƒ‘åº¦é˜ˆå€¼ä½“ç³»

### 8.1 é˜ˆå€¼å®šä¹‰ä¸åˆç†æ€§åˆ†æ

**æ–‡ä»¶**: `backend/app/core/thresholds.py`

```python
"""
ç½®ä¿¡åº¦ä¸å›°æƒ‘åº¦é˜ˆå€¼é…ç½®

åŸºäºå®é™…æµ‹è¯•å’Œä¸šç•Œç»éªŒè®¾å®šé˜ˆå€¼ï¼š
- è½¬å½•ç½®ä¿¡åº¦ï¼šåŸºäº Whisper avg_logprob å’Œ no_speech_prob
- æ ¡å¯¹å›°æƒ‘åº¦ï¼šåŸºäº LLM è¾“å‡ºçš„ perplexity
"""
from dataclasses import dataclass
from enum import Enum


class ConfidenceLevel(Enum):
    """ç½®ä¿¡åº¦ç­‰çº§"""
    HIGH = "high"           # é«˜ç½®ä¿¡åº¦ï¼Œæ— éœ€å¤„ç†
    MEDIUM = "medium"       # ä¸­ç­‰ç½®ä¿¡åº¦ï¼Œå¯é€‰å¤„ç†
    LOW = "low"             # ä½ç½®ä¿¡åº¦ï¼Œéœ€è¦å¤„ç†
    CRITICAL = "critical"   # æä½ç½®ä¿¡åº¦ï¼Œå¿…é¡»å¤„ç†


@dataclass
class ThresholdConfig:
    """é˜ˆå€¼é…ç½®"""

    # ========== è½¬å½•ç½®ä¿¡åº¦é˜ˆå€¼ ==========

    # SenseVoice ç½®ä¿¡åº¦ï¼ˆ0-1 èŒƒå›´ï¼Œå­—çº§/å¥çº§ï¼‰
    sv_confidence_high: float = 0.85      # >= é«˜ç½®ä¿¡åº¦ï¼Œç»¿è‰²/æ— æ ‡è®°
    sv_confidence_medium: float = 0.6     # >= ä¸­ç­‰ç½®ä¿¡åº¦ï¼Œé»„è‰²è­¦å‘Š
    sv_confidence_low: float = 0.4        # >= ä½ç½®ä¿¡åº¦ï¼Œæ©™è‰²è­¦å‘Š
    # < 0.4 ä¸ºæä½ç½®ä¿¡åº¦ï¼Œçº¢è‰²è­¦å‘Š

    # Whisper avg_logprob é˜ˆå€¼ï¼ˆè´Ÿå€¼ï¼Œè¶Šæ¥è¿‘0è¶Šå¥½ï¼‰
    # å‚è€ƒï¼šWhisper å®˜æ–¹å»ºè®® -0.8 ä»¥ä¸‹éœ€è¦å…³æ³¨
    whisper_logprob_good: float = -0.5    # >= é«˜è´¨é‡
    whisper_logprob_ok: float = -0.8      # >= å¯æ¥å—ï¼ˆå½“å‰ç³»ç»Ÿä½¿ç”¨ï¼‰
    whisper_logprob_bad: float = -1.0     # >= è¾ƒå·®
    # < -1.0 ä¸ºæå·®

    # Whisper no_speech_prob é˜ˆå€¼ï¼ˆ0-1ï¼Œè¶Šä½è¶Šå¥½ï¼‰
    # å‚è€ƒï¼šå®˜æ–¹å»ºè®® 0.6 ä»¥ä¸Šå¯èƒ½æ˜¯é™éŸ³
    whisper_no_speech_low: float = 0.3    # <= å¯ä¿¡
    whisper_no_speech_medium: float = 0.6 # <= å¯æ¥å—ï¼ˆå½“å‰ç³»ç»Ÿä½¿ç”¨ï¼‰
    whisper_no_speech_high: float = 0.8   # <= å¯ç–‘
    # > 0.8 æå¯èƒ½æ˜¯é™éŸ³/å™ªéŸ³

    # ========== æ ¡å¯¹å›°æƒ‘åº¦é˜ˆå€¼ ==========

    # LLM å›°æƒ‘åº¦ï¼ˆperplexityï¼Œè¶Šä½è¶Šå¥½ï¼‰
    # å‚è€ƒï¼šGPT-2 åœ¨å¸¸è§„æ–‡æœ¬ä¸Šçº¦ 20-40
    llm_perplexity_excellent: float = 20.0   # <= ä¼˜ç§€
    llm_perplexity_good: float = 35.0        # <= è‰¯å¥½
    llm_perplexity_acceptable: float = 50.0  # <= å¯æ¥å—
    llm_perplexity_poor: float = 80.0        # <= è¾ƒå·®
    # > 80 éœ€è¦äººå·¥æ£€æŸ¥

    # ========== è§¦å‘é˜ˆå€¼ ==========

    # Whisper è¡¥åˆ€è§¦å‘é˜ˆå€¼
    whisper_patch_trigger_confidence: float = 0.6  # SV ç½®ä¿¡åº¦ä½äºæ­¤å€¼è§¦å‘
    whisper_patch_trigger_logprob: float = -0.8    # æˆ– logprob ä½äºæ­¤å€¼

    # LLM æ ¡å¯¹è§¦å‘é˜ˆå€¼ï¼ˆæŒ‰éœ€æ ¡å¯¹æ¨¡å¼ï¼‰
    llm_proof_trigger_confidence: float = 0.7      # ç½®ä¿¡åº¦ä½äºæ­¤å€¼éœ€è¦æ ¡å¯¹
    llm_proof_trigger_modified: bool = True        # è¢« Whisper ä¿®æ”¹è¿‡çš„éœ€è¦æ ¡å¯¹

    # ========== è­¦å‘Šé«˜äº®é˜ˆå€¼ ==========

    # å­—çº§è­¦å‘Šé˜ˆå€¼
    word_warning_confidence: float = 0.5           # å­—çº§ç½®ä¿¡åº¦ä½äºæ­¤å€¼æ˜¾ç¤ºé»„è‰²
    word_critical_confidence: float = 0.3          # å­—çº§ç½®ä¿¡åº¦ä½äºæ­¤å€¼æ˜¾ç¤ºçº¢è‰²

    # å¥çº§è­¦å‘Šé˜ˆå€¼
    sentence_warning_confidence: float = 0.6       # å¥çº§ç½®ä¿¡åº¦ä½äºæ­¤å€¼æ˜¾ç¤ºè­¦å‘Š
    sentence_warning_perplexity: float = 50.0      # å›°æƒ‘åº¦é«˜äºæ­¤å€¼æ˜¾ç¤ºè­¦å‘Š


# é»˜è®¤é…ç½®å®ä¾‹
DEFAULT_THRESHOLDS = ThresholdConfig()


def get_confidence_level(confidence: float, config: ThresholdConfig = None) -> ConfidenceLevel:
    """
    æ ¹æ®ç½®ä¿¡åº¦è·å–ç­‰çº§

    Args:
        confidence: ç½®ä¿¡åº¦å€¼ (0-1)
        config: é˜ˆå€¼é…ç½®

    Returns:
        ConfidenceLevel: ç½®ä¿¡åº¦ç­‰çº§
    """
    if config is None:
        config = DEFAULT_THRESHOLDS

    if confidence >= config.sv_confidence_high:
        return ConfidenceLevel.HIGH
    elif confidence >= config.sv_confidence_medium:
        return ConfidenceLevel.MEDIUM
    elif confidence >= config.sv_confidence_low:
        return ConfidenceLevel.LOW
    else:
        return ConfidenceLevel.CRITICAL


def needs_whisper_patch(
    confidence: float,
    avg_logprob: float = None,
    no_speech_prob: float = None,
    config: ThresholdConfig = None
) -> bool:
    """
    åˆ¤æ–­æ˜¯å¦éœ€è¦ Whisper è¡¥åˆ€

    Args:
        confidence: SenseVoice ç½®ä¿¡åº¦
        avg_logprob: Whisper å¹³å‡ logprobï¼ˆå¦‚æœå·²æœ‰ï¼‰
        no_speech_prob: Whisper é™éŸ³æ¦‚ç‡ï¼ˆå¦‚æœå·²æœ‰ï¼‰
        config: é˜ˆå€¼é…ç½®

    Returns:
        bool: æ˜¯å¦éœ€è¦è¡¥åˆ€
    """
    if config is None:
        config = DEFAULT_THRESHOLDS

    # æ¡ä»¶1ï¼šSenseVoice ç½®ä¿¡åº¦ä½
    if confidence < config.whisper_patch_trigger_confidence:
        return True

    # æ¡ä»¶2ï¼šå·²æœ‰ Whisper ç»“æœä½†è´¨é‡å·®
    if avg_logprob is not None and avg_logprob < config.whisper_patch_trigger_logprob:
        return True

    if no_speech_prob is not None and no_speech_prob > config.whisper_no_speech_medium:
        return True

    return False


def needs_llm_proof(
    confidence: float,
    is_modified: bool = False,
    perplexity: float = None,
    mode: str = 'sparse',
    config: ThresholdConfig = None
) -> bool:
    """
    åˆ¤æ–­æ˜¯å¦éœ€è¦ LLM æ ¡å¯¹

    Args:
        confidence: è½¬å½•ç½®ä¿¡åº¦
        is_modified: æ˜¯å¦è¢« Whisper ä¿®æ”¹è¿‡
        perplexity: å½“å‰å›°æƒ‘åº¦ï¼ˆå¦‚æœå·²æœ‰ï¼‰
        mode: æ ¡å¯¹æ¨¡å¼ ('sparse' | 'full')
        config: é˜ˆå€¼é…ç½®

    Returns:
        bool: æ˜¯å¦éœ€è¦æ ¡å¯¹
    """
    if config is None:
        config = DEFAULT_THRESHOLDS

    # å…¨æ–‡æ¨¡å¼ï¼šæ€»æ˜¯æ ¡å¯¹
    if mode == 'full':
        return True

    # æŒ‰éœ€æ¨¡å¼
    if mode == 'sparse':
        # æ¡ä»¶1ï¼šç½®ä¿¡åº¦ä½
        if confidence < config.llm_proof_trigger_confidence:
            return True

        # æ¡ä»¶2ï¼šè¢« Whisper ä¿®æ”¹è¿‡
        if is_modified and config.llm_proof_trigger_modified:
            return True

        # æ¡ä»¶3ï¼šå·²çŸ¥å›°æƒ‘åº¦é«˜
        if perplexity is not None and perplexity > config.llm_perplexity_acceptable:
            return True

    return False
```

### 8.2 é˜ˆå€¼åˆç†æ€§è¯´æ˜

| é˜ˆå€¼ç±»å‹ | å½“å‰å€¼ | ä¾æ® | å»ºè®®èŒƒå›´ |
|----------|--------|------|----------|
| **SV ç½®ä¿¡åº¦é«˜** | 0.85 | SenseVoice å®˜æ–¹æµ‹è¯•è¡¨ç° | 0.80-0.90 |
| **SV ç½®ä¿¡åº¦è§¦å‘è¡¥åˆ€** | 0.6 | å®æµ‹ä½äºæ­¤å€¼é”™è¯¯ç‡æ˜¾è‘—ä¸Šå‡ | 0.55-0.70 |
| **Whisper logprob** | -0.8 | OpenAI å®˜æ–¹å»ºè®® | -0.7 ~ -1.0 |
| **Whisper no_speech** | 0.6 | OpenAI å®˜æ–¹å»ºè®® | 0.5-0.7 |
| **LLM å›°æƒ‘åº¦å¯æ¥å—** | 50.0 | GPT-2 åŸºå‡† + ç»éªŒè°ƒæ•´ | 40-60 |
| **å­—çº§è­¦å‘Š** | 0.5 | ç”¨æˆ·å¯æ¥å—çš„é”™è¯¯æ˜¾ç¤ºå¯†åº¦ | 0.4-0.6 |

---

## ä¹ã€è­¦å‘Šé«˜äº®ç³»ç»Ÿ

### 9.1 å­—çº§è­¦å‘Šé«˜äº®

**æ–‡ä»¶**: `frontend/src/components/ConfidenceHighlight.vue`

```vue
<template>
  <span
    :class="wordClass"
    :title="tooltipText"
    @click="$emit('word-click', word)"
  >
    {{ word.word }}
  </span>
</template>

<script setup>
import { computed } from 'vue';

const props = defineProps({
  word: {
    type: Object,
    required: true
  },
  showTooltip: {
    type: Boolean,
    default: true
  }
});

defineEmits(['word-click']);

// é˜ˆå€¼é…ç½®
const THRESHOLDS = {
  word: {
    high: 0.85,
    medium: 0.6,
    low: 0.4,
    critical: 0.3
  },
  perplexity: {
    good: 35,
    acceptable: 50,
    poor: 80
  }
};

const wordClass = computed(() => {
  const confidence = props.word.confidence || 1.0;
  const perplexity = props.word.perplexity;
  const warningType = props.word.warning_type || 'none';

  const classes = ['word-span'];

  // è½¬å½•ç½®ä¿¡åº¦è­¦å‘Š
  if (confidence >= THRESHOLDS.word.high) {
    classes.push('confidence-high');
  } else if (confidence >= THRESHOLDS.word.medium) {
    classes.push('confidence-medium');
  } else if (confidence >= THRESHOLDS.word.low) {
    classes.push('confidence-low');
  } else {
    classes.push('confidence-critical');
  }

  // æ ¡å¯¹å›°æƒ‘åº¦è­¦å‘Š
  if (perplexity !== null && perplexity !== undefined) {
    if (perplexity > THRESHOLDS.perplexity.poor) {
      classes.push('perplexity-high');
    } else if (perplexity > THRESHOLDS.perplexity.acceptable) {
      classes.push('perplexity-medium');
    }
  }

  // ç‰¹æ®Šæ ‡è®°
  if (props.word.is_pseudo) {
    classes.push('is-pseudo-align');
  }

  return classes;
});

const tooltipText = computed(() => {
  if (!props.showTooltip) return '';

  const parts = [];
  const confidence = props.word.confidence;
  const perplexity = props.word.perplexity;

  if (confidence < THRESHOLDS.word.high) {
    parts.push(`è½¬å½•ç½®ä¿¡åº¦: ${(confidence * 100).toFixed(1)}%`);
  }

  if (perplexity !== null && perplexity !== undefined) {
    if (perplexity > THRESHOLDS.perplexity.acceptable) {
      parts.push(`æ ¡å¯¹å›°æƒ‘åº¦: ${perplexity.toFixed(1)}`);
    }
  }

  if (props.word.is_pseudo) {
    parts.push('(ä¼ªå¯¹é½)');
  }

  return parts.join(' | ');
});
</script>

<style scoped>
.word-span {
  display: inline;
  cursor: pointer;
  transition: background-color 0.2s;
}

/* ========== è½¬å½•ç½®ä¿¡åº¦æ ·å¼ ========== */
.confidence-high {
  /* é«˜ç½®ä¿¡åº¦ï¼šæ— ç‰¹æ®Šæ ·å¼ */
}

.confidence-medium {
  /* ä¸­ç­‰ç½®ä¿¡åº¦ï¼šæ·¡é»„è‰²èƒŒæ™¯ */
  background-color: rgba(255, 235, 59, 0.3);
  border-bottom: 1px dashed #ffc107;
}

.confidence-low {
  /* ä½ç½®ä¿¡åº¦ï¼šæ©™è‰²èƒŒæ™¯ */
  background-color: rgba(255, 152, 0, 0.4);
  border-bottom: 2px solid #ff9800;
}

.confidence-critical {
  /* æä½ç½®ä¿¡åº¦ï¼šçº¢è‰²èƒŒæ™¯ */
  background-color: rgba(244, 67, 54, 0.4);
  border-bottom: 2px solid #f44336;
  color: #d32f2f;
}

/* ========== æ ¡å¯¹å›°æƒ‘åº¦æ ·å¼ï¼ˆå åŠ ï¼‰ ========== */
.perplexity-medium {
  /* ä¸­ç­‰å›°æƒ‘åº¦ï¼šè™šçº¿ä¸‹åˆ’çº¿ */
  text-decoration: underline wavy #9c27b0;
}

.perplexity-high {
  /* é«˜å›°æƒ‘åº¦ï¼šç²—è™šçº¿ä¸‹åˆ’çº¿ */
  text-decoration: underline wavy #e91e63;
  text-decoration-thickness: 2px;
}

/* ========== ä¼ªå¯¹é½æ ‡è®° ========== */
.is-pseudo-align {
  font-style: italic;
  opacity: 0.9;
}

/* ========== æ‚¬åœæ•ˆæœ ========== */
.word-span:hover {
  background-color: rgba(33, 150, 243, 0.2);
}
</style>
```

### 9.2 å¥çº§è­¦å‘Šé«˜äº®

**æ–‡ä»¶**: `frontend/src/components/SentenceWarning.vue`

```vue
<template>
  <div :class="sentenceClass">
    <!-- è­¦å‘Šå›¾æ ‡ -->
    <span v-if="hasWarning" class="warning-icon" :title="warningTooltip">
      <el-icon v-if="warningType === 'low_transcription'"><Warning /></el-icon>
      <el-icon v-else-if="warningType === 'high_perplexity'"><QuestionFilled /></el-icon>
      <el-icon v-else-if="warningType === 'both'"><CircleCloseFilled /></el-icon>
    </span>

    <!-- å¥å­å†…å®¹ -->
    <span class="sentence-content">
      <slot></slot>
    </span>

    <!-- ç½®ä¿¡åº¦/å›°æƒ‘åº¦æŒ‡ç¤ºå™¨ -->
    <span v-if="showIndicator" class="indicators">
      <span v-if="confidence < 0.85" class="confidence-badge" :class="confidenceLevel">
        {{ (confidence * 100).toFixed(0) }}%
      </span>
      <span v-if="perplexity && perplexity > 35" class="perplexity-badge" :class="perplexityLevel">
        P:{{ perplexity.toFixed(0) }}
      </span>
    </span>
  </div>
</template>

<script setup>
import { computed } from 'vue';
import { Warning, QuestionFilled, CircleCloseFilled } from '@element-plus/icons-vue';

const props = defineProps({
  sentence: {
    type: Object,
    required: true
  },
  showIndicator: {
    type: Boolean,
    default: true
  }
});

const confidence = computed(() => props.sentence.confidence || 1.0);
const perplexity = computed(() => props.sentence.perplexity);
const warningType = computed(() => props.sentence.warning_type || 'none');

const hasWarning = computed(() => warningType.value !== 'none');

const confidenceLevel = computed(() => {
  const c = confidence.value;
  if (c >= 0.85) return 'level-high';
  if (c >= 0.6) return 'level-medium';
  if (c >= 0.4) return 'level-low';
  return 'level-critical';
});

const perplexityLevel = computed(() => {
  const p = perplexity.value;
  if (!p) return '';
  if (p <= 35) return 'level-good';
  if (p <= 50) return 'level-acceptable';
  if (p <= 80) return 'level-poor';
  return 'level-critical';
});

const sentenceClass = computed(() => {
  const classes = ['sentence-row'];

  if (warningType.value === 'low_transcription') {
    classes.push('warning-transcription');
  } else if (warningType.value === 'high_perplexity') {
    classes.push('warning-perplexity');
  } else if (warningType.value === 'both') {
    classes.push('warning-both');
  }

  if (props.sentence.is_modified) {
    classes.push('is-modified');
  }

  return classes;
});

const warningTooltip = computed(() => {
  switch (warningType.value) {
    case 'low_transcription':
      return `è½¬å½•ç½®ä¿¡åº¦ä½ (${(confidence.value * 100).toFixed(1)}%)ï¼Œå»ºè®®æ£€æŸ¥`;
    case 'high_perplexity':
      return `æ ¡å¯¹å›°æƒ‘åº¦é«˜ (${perplexity.value?.toFixed(1)})ï¼Œå¯èƒ½å­˜åœ¨è¯­ä¹‰é—®é¢˜`;
    case 'both':
      return `è½¬å½•ç½®ä¿¡åº¦ä½ä¸”æ ¡å¯¹å›°æƒ‘åº¦é«˜ï¼Œéœ€è¦é‡ç‚¹å…³æ³¨`;
    default:
      return '';
  }
});
</script>

<style scoped>
.sentence-row {
  display: flex;
  align-items: flex-start;
  padding: 8px 12px;
  border-radius: 4px;
  margin: 4px 0;
  transition: background-color 0.2s;
}

/* ========== è­¦å‘Šç±»å‹æ ·å¼ ========== */
.warning-transcription {
  background-color: rgba(255, 152, 0, 0.1);
  border-left: 3px solid #ff9800;
}

.warning-perplexity {
  background-color: rgba(156, 39, 176, 0.1);
  border-left: 3px solid #9c27b0;
}

.warning-both {
  background-color: rgba(244, 67, 54, 0.1);
  border-left: 3px solid #f44336;
}

.is-modified {
  background-color: rgba(33, 150, 243, 0.05);
}

/* ========== è­¦å‘Šå›¾æ ‡ ========== */
.warning-icon {
  margin-right: 8px;
  flex-shrink: 0;
}

.warning-transcription .warning-icon {
  color: #ff9800;
}

.warning-perplexity .warning-icon {
  color: #9c27b0;
}

.warning-both .warning-icon {
  color: #f44336;
}

/* ========== æŒ‡ç¤ºå™¨ ========== */
.indicators {
  margin-left: auto;
  display: flex;
  gap: 4px;
}

.confidence-badge,
.perplexity-badge {
  font-size: 11px;
  padding: 2px 6px;
  border-radius: 10px;
}

.level-high { background-color: #e8f5e9; color: #4caf50; }
.level-medium { background-color: #fff3e0; color: #ff9800; }
.level-low { background-color: #ffebee; color: #f44336; }
.level-critical { background-color: #f44336; color: white; }
.level-good { background-color: #e8f5e9; color: #4caf50; }
.level-acceptable { background-color: #fff3e0; color: #ff9800; }
.level-poor { background-color: #fce4ec; color: #e91e63; }
</style>
```

### 9.3 è­¦å‘Šç±»å‹åŒºåˆ†è¯´æ˜

| è­¦å‘Šç±»å‹ | è§¦å‘æ¡ä»¶ | è§†è§‰è¡¨ç° | å«ä¹‰ |
|----------|----------|----------|------|
| **è½¬å½•ç½®ä¿¡åº¦ä½** | `confidence < 0.6` | æ©™è‰²è¾¹æ¡† + âš ï¸ å›¾æ ‡ | ASR æ¨¡å‹å¯¹æ­¤æ®µè¯†åˆ«ä¸ç¡®å®š |
| **æ ¡å¯¹å›°æƒ‘åº¦é«˜** | `perplexity > 50` | ç´«è‰²è¾¹æ¡† + â“ å›¾æ ‡ | LLM è®¤ä¸ºæ–‡æœ¬å¯èƒ½å­˜åœ¨è¯­ä¹‰é—®é¢˜ |
| **åŒé‡è­¦å‘Š** | ä¸¤è€…éƒ½æ»¡è¶³ | çº¢è‰²è¾¹æ¡† + âŠ— å›¾æ ‡ | éœ€è¦äººå·¥é‡ç‚¹æ£€æŸ¥ |

---

## åã€ä¸»å¤„ç†æµç¨‹é‡æ„

### 10.1 ä¼˜åŒ–åçš„ Pipelineï¼ˆv2.1 VADä¼˜å…ˆç‰ˆï¼‰

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    æ—¶ç©ºè§£è€¦å¤„ç†æµç¨‹ï¼ˆv2.1ï¼‰                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  1. éŸ³é¢‘æå– [extract]                                          â”‚
â”‚     â†“  â†’ SSE: progress.extract                                  â”‚
â”‚  2. VAD ç‰©ç†åˆ‡åˆ† [vad]ï¼ˆ15-30s Chunksï¼‰                         â”‚
â”‚     â†“  â†’ SSE: progress.vad                                      â”‚
â”‚  3. é¢‘è°±åˆ†è¯Š [spectrum]ï¼ˆChunkçº§åˆ«ï¼‰                            â”‚
â”‚     â”‚  - AudioSpectrumClassifier æå–é¢‘è°±ç‰¹å¾                   â”‚
â”‚     â”‚  - åˆ¤æ–­ï¼šCLEAN / MUSIC / NOISE / MIXED                    â”‚
â”‚     â”‚  - æ¨èæ¨¡å‹ï¼šhtdemucs / mdx_extra / None                  â”‚
â”‚     â†“  â†’ SSE: progress.spectrum                                 â”‚
â”‚  4. äººå£°åˆ†ç¦» [demucs]ï¼ˆä»…å¯¹éœ€è¦åˆ†ç¦»çš„Chunkï¼‰                    â”‚
â”‚     â†“  â†’ SSE: progress.demucs                                   â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ 5. SenseVoice è½¬å½• [sensevoice]ï¼ˆæ—¶é—´é¢†ä¸»ï¼‰                 â”‚â”‚
â”‚  â”‚    - æ¯å®Œæˆä¸€ä¸ª VAD æ®µç«‹å³æ¨é€                              â”‚â”‚
â”‚  â”‚    â†’ SSE: subtitle.sv_segmentï¼ˆæµå¼ï¼‰                       â”‚â”‚
â”‚  â”‚    â†’ SSE: progress.sensevoiceï¼ˆæŒ‰æ®µæ›´æ–°ï¼‰                   â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚     â†“                                                           â”‚
â”‚  6. åˆ†å¥ç®—æ³•                                                    â”‚
â”‚     â†“  â†’ SSE: subtitle.sv_sentenceï¼ˆæ¯å¥æ¨é€ï¼‰                  â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ 7. Whisper è¡¥åˆ€ [whisper]ï¼ˆå¬è§‰è¡¥ä¸ï¼Œå¯é€‰ï¼‰                 â”‚â”‚
â”‚  â”‚    - ä»…å¤„ç†ä½ç½®ä¿¡åº¦å¥å­                                     â”‚â”‚
â”‚  â”‚    - æ¯å®Œæˆä¸€å¥ç«‹å³è¦†ç›–                                     â”‚â”‚
â”‚  â”‚    â†’ SSE: subtitle.whisper_patchï¼ˆè¦†ç›–æ¨é€ï¼‰                â”‚â”‚
â”‚  â”‚    â†’ SSE: progress.whisperï¼ˆæŒ‰å®Œæˆ/å¾…å¤„ç†æ®µæ•°æ›´æ–°ï¼‰         â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚     â†“                                                           â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â”‚
â”‚  â”‚               è¯­ä¹‰å¢å¼ºå±‚ï¼ˆæ ¹æ®é¢„è®¾å¯ç”¨ï¼‰                    â”‚â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â”‚
â”‚     â†“                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ 8. LLM æ ¡å¯¹ [llm_proof]ï¼ˆå¯é€‰ï¼‰                             â”‚â”‚
â”‚  â”‚    - æ¯å®Œæˆä¸€å¥ç«‹å³è¦†ç›–                                     â”‚â”‚
â”‚  â”‚    â†’ SSE: subtitle.llm_proofï¼ˆè¦†ç›–æ¨é€ï¼‰                    â”‚â”‚
â”‚  â”‚    â†’ SSE: progress.llm_proofï¼ˆæŒ‰å®Œæˆ/å¾…å¤„ç†æ®µæ•°æ›´æ–°ï¼‰       â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚     â†“                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ 9. LLM ç¿»è¯‘ [llm_trans]ï¼ˆå¯é€‰ï¼‰                             â”‚â”‚
â”‚  â”‚    - æ¯å®Œæˆä¸€å¥è¿½åŠ ç¿»è¯‘å­—æ®µ                                 â”‚â”‚
â”‚  â”‚    â†’ SSE: subtitle.llm_transï¼ˆè¿½åŠ æ¨é€ï¼‰                    â”‚â”‚
â”‚  â”‚    â†’ SSE: progress.llm_transï¼ˆæŒ‰å®Œæˆ/å¾…å¤„ç†æ®µæ•°æ›´æ–°ï¼‰       â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚     â†“                                                           â”‚
â”‚  10. SRT ç”Ÿæˆ [srt]                                             â”‚
â”‚     â†“  â†’ SSE: progress.srt                                      â”‚
â”‚  11. å®Œæˆ                                                       â”‚
â”‚      â†’ SSE: signal.job_complete                                 â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 10.2 æ ¸å¿ƒæµç¨‹ä»£ç 

```python
async def _process_video_sensevoice_v2(self, job: JobState):
    """
    SenseVoice ä¸»å¤„ç†æµç¨‹ï¼ˆVADä¼˜å…ˆ + æ—¶ç©ºè§£è€¦ç‰ˆ v2.1ï¼‰
    """
    from .progress_tracker import get_progress_tracker, ProcessPhase
    from .streaming_subtitle import get_streaming_subtitle_manager
    from .solution_matrix import SolutionConfig
    from .audio_spectrum_classifier import get_spectrum_classifier

    # è·å–é…ç½®
    solution_config = SolutionConfig.from_preset(job.settings.preset_id)
    progress = get_progress_tracker(job.job_id, solution_config.preset_id)
    subtitle_manager = get_streaming_subtitle_manager(job.job_id, self.sse_manager)

    try:
        # === é˜¶æ®µ 1: éŸ³é¢‘æå– ===
        progress.start_phase(ProcessPhase.EXTRACT, message="æå–éŸ³é¢‘ä¸­...")
        audio_path, audio_array = await self._extract_audio_with_array(job)
        progress.complete_phase(ProcessPhase.EXTRACT)

        # === é˜¶æ®µ 2: VAD åˆ†æ®µï¼ˆä¼˜å…ˆæ‰§è¡Œï¼‰ ===
        progress.start_phase(ProcessPhase.VAD, message="è¯­éŸ³æ´»åŠ¨æ£€æµ‹...")
        vad_segments = await self._vad_physical_split(audio_path, audio_array, job)
        progress.complete_phase(ProcessPhase.VAD)

        # === é˜¶æ®µ 3: é¢‘è°±åˆ†è¯Šï¼ˆChunkçº§åˆ«ï¼‰ ===
        progress.start_phase(ProcessPhase.SPECTRUM, message="é¢‘è°±åˆ†è¯Š...")
        spectrum_classifier = get_spectrum_classifier()
        diagnoses = spectrum_classifier.diagnose_chunks(
            [(audio_array[int(s['start']*16000):int(s['end']*16000)], s['start'], s['end'])
             for s in vad_segments]
        )
        progress.complete_phase(ProcessPhase.SPECTRUM)

        # === é˜¶æ®µ 4: äººå£°åˆ†ç¦»ï¼ˆä»…å¯¹éœ€è¦åˆ†ç¦»çš„Chunkï¼‰ ===
        chunks_to_separate = [(i, vad_segments[i], diagnoses[i])
                              for i in range(len(diagnoses))
                              if diagnoses[i].need_separation]

        if chunks_to_separate:
            progress.start_phase(
                ProcessPhase.DEMUCS,
                total_items=len(chunks_to_separate),
                message=f"åˆ†ç¦»äººå£° (0/{len(chunks_to_separate)} chunks)..."
            )

            for sep_idx, (chunk_idx, vad_seg, diag) in enumerate(chunks_to_separate):
                # æŒ‰æ¨èæ¨¡å‹åˆ†ç¦»
                separated_audio = await self._separate_chunk(
                    audio_array, vad_seg, diag.recommended_model, job
                )
                # æ›¿æ¢åŸå§‹éŸ³é¢‘æ®µ
                vad_segments[chunk_idx]['processed_audio'] = separated_audio

                progress.update_phase(ProcessPhase.DEMUCS, completed=sep_idx + 1)

            progress.complete_phase(ProcessPhase.DEMUCS)

        # === é˜¶æ®µ 5-6: SenseVoice è½¬å½•ï¼ˆæµå¼ï¼‰ ===
        progress.start_phase(
            ProcessPhase.SENSEVOICE,
            total_items=len(vad_segments),
            message="SenseVoice è½¬å½•ä¸­..."
        )

        all_sentences = []
        for vad_idx, vad_seg in enumerate(vad_segments):
            # æ£€æŸ¥å–æ¶ˆ
            if job.canceled:
                raise RuntimeError('ä»»åŠ¡å·²å–æ¶ˆ')

            # è½¬å½•å•ä¸ª VAD æ®µ
            sentences = await self._transcribe_vad_segment(
                vad_seg, audio_array, job
            )

            # æµå¼æ¨é€ï¼ˆæ¯ä¸ª VAD æ®µå®Œæˆåï¼‰
            subtitle_manager.on_sensevoice_vad_complete(vad_idx, sentences)
            all_sentences.extend(sentences)

            # æ›´æ–°è¿›åº¦
            progress.update_phase(ProcessPhase.SENSEVOICE, completed=vad_idx + 1)
            self._push_progress_update(job, progress)

        progress.complete_phase(ProcessPhase.SENSEVOICE)

        # === é˜¶æ®µ 7: Whisper è¡¥åˆ€ï¼ˆå¯é€‰ï¼‰ ===
        if solution_config.enhancement != EnhancementMode.OFF:
            # ç­›é€‰éœ€è¦è¡¥åˆ€çš„å¥å­
            low_confidence_sentences = [
                (i, s) for i, s in enumerate(all_sentences)
                if s['confidence'] < solution_config.confidence_threshold
            ]

            if low_confidence_sentences:
                progress.start_phase(
                    ProcessPhase.WHISPER_PATCH,
                    total_items=len(low_confidence_sentences),
                    message=f"Whisper è¡¥åˆ€ä¸­ (0/{len(low_confidence_sentences)})..."
                )

                for patch_idx, (sent_idx, sentence) in enumerate(low_confidence_sentences):
                    if job.canceled:
                        raise RuntimeError('ä»»åŠ¡å·²å–æ¶ˆ')

                    # Whisper è¡¥åˆ€
                    new_text = await self._whisper_patch_single(
                        sentence, audio_array, job
                    )

                    # æµå¼è¦†ç›–
                    subtitle_manager.on_whisper_patch_complete(
                        sent_idx, new_text
                    )

                    # æ›´æ–°è¿›åº¦
                    progress.update_phase(
                        ProcessPhase.WHISPER_PATCH,
                        completed=patch_idx + 1,
                        message=f"Whisper è¡¥åˆ€ä¸­ ({patch_idx + 1}/{len(low_confidence_sentences)})..."
                    )
                    self._push_progress_update(job, progress)

                progress.complete_phase(ProcessPhase.WHISPER_PATCH)

        # === é˜¶æ®µ 8: LLM æ ¡å¯¹ï¼ˆå¯é€‰ï¼‰ ===
        if solution_config.proofread != ProofreadMode.OFF:
            sentences_to_proof = self._get_sentences_for_proof(
                all_sentences, solution_config
            )

            if sentences_to_proof:
                progress.start_phase(
                    ProcessPhase.LLM_PROOF,
                    total_items=len(sentences_to_proof),
                    message=f"LLM æ ¡å¯¹ä¸­ (0/{len(sentences_to_proof)})..."
                )

                for proof_idx, (sent_idx, sentence) in enumerate(sentences_to_proof):
                    proofed_text, perplexity = await self._llm_proof_single(
                        sentence, job
                    )

                    # æµå¼è¦†ç›–
                    subtitle_manager.on_llm_proof_complete(
                        sent_idx, proofed_text, perplexity
                    )

                    progress.update_phase(
                        ProcessPhase.LLM_PROOF,
                        completed=proof_idx + 1,
                        message=f"LLM æ ¡å¯¹ä¸­ ({proof_idx + 1}/{len(sentences_to_proof)})..."
                    )
                    self._push_progress_update(job, progress)

                progress.complete_phase(ProcessPhase.LLM_PROOF)

        # === é˜¶æ®µ 9: LLM ç¿»è¯‘ï¼ˆå¯é€‰ï¼‰ ===
        if solution_config.translate != TranslateMode.OFF:
            sentences_to_trans = self._get_sentences_for_translate(
                all_sentences, solution_config
            )

            if sentences_to_trans:
                progress.start_phase(
                    ProcessPhase.LLM_TRANS,
                    total_items=len(sentences_to_trans),
                    message=f"LLM ç¿»è¯‘ä¸­ (0/{len(sentences_to_trans)})..."
                )

                for trans_idx, (sent_idx, sentence) in enumerate(sentences_to_trans):
                    translation = await self._llm_translate_single(
                        sentence, solution_config.target_language, job
                    )

                    # æµå¼è¿½åŠ 
                    subtitle_manager.on_llm_trans_complete(
                        sent_idx, translation
                    )

                    progress.update_phase(
                        ProcessPhase.LLM_TRANS,
                        completed=trans_idx + 1,
                        message=f"LLM ç¿»è¯‘ä¸­ ({trans_idx + 1}/{len(sentences_to_trans)})..."
                    )
                    self._push_progress_update(job, progress)

                progress.complete_phase(ProcessPhase.LLM_TRANS)

        # === é˜¶æ®µ 10: SRT ç”Ÿæˆ ===
        progress.start_phase(ProcessPhase.SRT, message="ç”Ÿæˆå­—å¹•æ–‡ä»¶...")
        final_sentences = subtitle_manager.get_all_sentences()
        srt_path = await self._generate_srt_from_sentences(final_sentences, job)
        progress.complete_phase(ProcessPhase.SRT)

        # === å®Œæˆ ===
        job.status = 'completed'
        job.srt_path = str(srt_path)
        self._push_signal_event(job, "job_complete", "è½¬å½•å®Œæˆ")

    except Exception as e:
        self.logger.error(f"å¤„ç†å¤±è´¥: {e}", exc_info=True)
        job.status = 'failed'
        job.error = str(e)
        self._push_signal_event(job, "job_failed", str(e))
        raise
```

---

## åä¸€ã€ä¸ LLM æ ¡å¯¹/ç¿»è¯‘å±‚çš„å¯¹æ¥æ¥å£

æœ¬æ–‡æ¡£å®šä¹‰çš„è½¬å½•å±‚è¾“å‡ºä»¥ä¸‹æ•°æ®ç»“æ„ï¼Œä¾› LLM æ ¡å¯¹/ç¿»è¯‘å±‚ä½¿ç”¨ï¼š

### 11.1 è¾“å‡ºæ•°æ®æ ¼å¼

```python
@dataclass
class TranscriptionOutput:
    """è½¬å½•å±‚è¾“å‡ºï¼ˆä¾› LLM å±‚ä½¿ç”¨ï¼‰"""
    sentences: List[SentenceSegment]  # å¥çº§å­—å¹•åˆ—è¡¨
    metadata: dict                     # å…ƒæ•°æ®

    def to_llm_input(self) -> List[dict]:
        """
        è½¬æ¢ä¸º LLM è¾“å…¥æ ¼å¼

        Returns:
            é€‚åˆ LLM å¤„ç†çš„å¥å­åˆ—è¡¨
        """
        return [
            {
                "index": i,
                "text": s.text,
                "start": s.start,
                "end": s.end,
                "confidence": s.confidence,
                "source": s.source.value,
                "warning_type": s.warning_type.value,
                "needs_review": s.confidence < 0.7 or s.is_modified
            }
            for i, s in enumerate(self.sentences)
        ]
```

### 11.2 æ¥å£çº¦å®š

| æ¥å£ | æè¿° | è¾“å…¥ | è¾“å‡º |
|------|------|------|------|
| `get_transcription_result()` | è·å–è½¬å½•ç»“æœ | `job_id` | `TranscriptionOutput` |
| `mark_for_review(indexes)` | æ ‡è®°éœ€è¦ LLM å®¡æ ¸çš„å¥å­ | `List[int]` | `void` |
| `apply_llm_correction(index, text, perplexity)` | åº”ç”¨ LLM æ ¡å¯¹ç»“æœ | `int, str, float` | `SentenceSegment` |
| `apply_llm_translation(index, translation)` | åº”ç”¨ LLM ç¿»è¯‘ç»“æœ | `int, str` | `SentenceSegment` |

è¯¦ç»†çš„ LLM é›†æˆæ–¹æ¡ˆè§ï¼š[07_æ ¡å¯¹ç¿»è¯‘å±‚_LLMé›†æˆæ–¹æ¡ˆ.md](./07_æ ¡å¯¹ç¿»è¯‘å±‚_LLMé›†æˆæ–¹æ¡ˆ.md)

---

## åäºŒã€å‰ç«¯è™šæ‹Ÿæ»šåŠ¨

### 12.1 ä¸ºä»€ä¹ˆéœ€è¦è™šæ‹Ÿæ»šåŠ¨

å­—çº§ç½®ä¿¡åº¦æ•°æ®é‡è™½å°ä½† DOM èŠ‚ç‚¹æå¤šï¼š
- 10åˆ†é’Ÿè§†é¢‘ â‰ˆ 3000 å­—
- æ¯ä¸ªå­—ä¸€ä¸ª `<span>` èŠ‚ç‚¹
- ç›´æ¥æ¸²æŸ“ä¼šå¯¼è‡´é¡µé¢å¡é¡¿

### 12.2 å®ç°æ–¹æ¡ˆ

```vue
<template>
  <div class="virtual-scroll-container" ref="container" @scroll="onScroll">
    <div class="virtual-scroll-phantom" :style="{ height: totalHeight + 'px' }"></div>
    <div class="virtual-scroll-content" :style="{ transform: `translateY(${offsetY}px)` }">
      <SentenceWarning
        v-for="item in visibleItems"
        :key="item.index"
        :sentence="item"
      >
        <ConfidenceHighlight
          v-for="word in item.words"
          :key="word.start"
          :word="word"
        />
      </SentenceWarning>
    </div>
  </div>
</template>

<script setup>
import { ref, computed, onMounted } from 'vue';
import ConfidenceHighlight from './ConfidenceHighlight.vue';
import SentenceWarning from './SentenceWarning.vue';

const props = defineProps({
  sentences: { type: Array, default: () => [] }
});

const container = ref(null);
const offsetY = ref(0);
const scrollTop = ref(0);

const itemHeight = 60;  // æ¯ä¸ªå¥å­çš„ä¼°è®¡é«˜åº¦
const containerHeight = ref(600);

const totalHeight = computed(() => props.sentences.length * itemHeight);

const visibleCount = computed(() => 
  Math.ceil(containerHeight.value / itemHeight) + 5  // å¤šæ¸²æŸ“å‡ ä¸ª
);

const startIndex = computed(() => 
  Math.max(0, Math.floor(scrollTop.value / itemHeight) - 2)
);

const visibleItems = computed(() => 
  props.sentences.slice(startIndex.value, startIndex.value + visibleCount.value)
);

function onScroll() {
  scrollTop.value = container.value.scrollTop;
  offsetY.value = startIndex.value * itemHeight;
}

onMounted(() => {
  if (container.value) {
    containerHeight.value = container.value.clientHeight;
  }
});
</script>
```

---

## åä¸‰ã€éªŒæ”¶æ ‡å‡†

### 13.1 åŠŸèƒ½éªŒæ”¶

- [ ] å‰ç«¯é¢„è®¾é€‰æ‹©å™¨æ­£å¸¸å·¥ä½œï¼ˆ6 ä¸ªé¢„è®¾ + é«˜çº§è‡ªå®šä¹‰ï¼‰
- [ ] SenseVoice æ—¶é—´æˆ³åœ¨æ•´ä¸ªæµç¨‹ä¸­ä¿æŒä¸å˜
- [ ] Whisper è¡¥åˆ€åä½¿ç”¨ä¼ªå¯¹é½ç®—æ³•ç”Ÿæˆå­—çº§æ—¶é—´æˆ³
- [ ] ä¼ªå¯¹é½ç®—æ³•æ­£ç¡®ç”Ÿæˆå­—çº§æ—¶é—´æˆ³
- [ ] `source` å­—æ®µæ­£ç¡®è¿½è¸ªæ–‡æœ¬æ¥æº
- [ ] æ™ºèƒ½è¿›åº¦ç³»ç»Ÿæ ¹æ®é¢„è®¾åŠ¨æ€è°ƒæ•´æƒé‡
- [ ] å­—å¹•æµå¼è¾“å‡ºï¼šSV/Whisper/LLM å„é˜¶æ®µå³æ—¶æ¨é€
- [ ] è­¦å‘Šé«˜äº®ç³»ç»ŸåŒºåˆ†è½¬å½•ç½®ä¿¡åº¦ä½å’Œæ ¡å¯¹å›°æƒ‘åº¦é«˜

### 13.2 SSE äº‹ä»¶éªŒæ”¶

- [ ] `progress.*` äº‹ä»¶æ­£ç¡®æ¨é€å„é˜¶æ®µè¿›åº¦
- [ ] `subtitle.sv_segment` æ¯ä¸ª VAD æ®µå®Œæˆåæ¨é€
- [ ] `subtitle.whisper_patch` æ¯å¥è¡¥åˆ€å®Œæˆåè¦†ç›–æ¨é€
- [ ] `subtitle.llm_proof` æ¯å¥æ ¡å¯¹å®Œæˆåè¦†ç›–æ¨é€
- [ ] `subtitle.llm_trans` æ¯å¥ç¿»è¯‘å®Œæˆåè¿½åŠ æ¨é€
- [ ] `signal.*` äº‹ä»¶æ­£ç¡®æ¨é€ä»»åŠ¡çŠ¶æ€å˜åŒ–

### 13.3 é˜ˆå€¼éªŒæ”¶

- [ ] SV ç½®ä¿¡åº¦é˜ˆå€¼ 0.6 è§¦å‘ Whisper è¡¥åˆ€åˆç†
- [ ] Whisper logprob é˜ˆå€¼ -0.8 åˆ¤æ–­è½¬å½•è´¨é‡åˆç†
- [ ] LLM å›°æƒ‘åº¦é˜ˆå€¼ 50.0 åˆ¤æ–­æ ¡å¯¹è´¨é‡åˆç†
- [ ] å­—çº§è­¦å‘Šé˜ˆå€¼ 0.5 æ˜¾ç¤ºå¯†åº¦åˆç†

### 13.4 æ€§èƒ½éªŒæ”¶

- [ ] 10åˆ†é’Ÿè§†é¢‘å¤„ç†æ—¶é—´ < 2åˆ†é’Ÿï¼ˆé»˜è®¤é¢„è®¾ï¼‰
- [ ] 10åˆ†é’Ÿè§†é¢‘å¤„ç†æ—¶é—´ < 5åˆ†é’Ÿï¼ˆæ·±åº¦æ ¡å¯¹é¢„è®¾ï¼‰
- [ ] å­—çº§æ•°æ®é‡å¤§æ—¶å‰ç«¯ä¸å¡é¡¿ï¼ˆè™šæ‹Ÿæ»šåŠ¨ï¼‰
- [ ] ä¼ªå¯¹é½è®¡ç®—è€—æ—¶ < 1ms/å¥
- [ ] SSE æ¨é€å»¶è¿Ÿ < 100ms

### 13.5 å…¼å®¹æ€§éªŒæ”¶

- [ ] å‘åå…¼å®¹ç°æœ‰ä»»åŠ¡é…ç½®
- [ ] LLM å±‚æ¥å£é¢„ç•™å®Œæ•´
- [ ] å‰ç«¯å¹³æ»‘å‡çº§ï¼ˆæ—§ä»»åŠ¡å¯æ­£å¸¸æŸ¥çœ‹ï¼‰

---

## åå››ã€ä¸‹ä¸€æ­¥

æœ¬æ–‡æ¡£å®Œæˆè½¬å½•å±‚çš„æ—¶ç©ºè§£è€¦æ¶æ„è®¾è®¡ï¼ŒåŒ…æ‹¬ï¼š
1. **å‰ç«¯é¢„è®¾ç³»ç»Ÿ**ï¼š6 ä¸ªé¢„è®¾ + é«˜çº§è‡ªå®šä¹‰æ¨¡å¼
2. **ä¼ªå¯¹é½ç®—æ³•**ï¼šWhisper è¡¥åˆ€åä½¿ç”¨çº¿æ€§æ—¶é—´å¹³æ‘Šç­–ç•¥
3. **æ™ºèƒ½è¿›åº¦ç³»ç»Ÿ**ï¼šåŸºäºé¢„è®¾åŠ¨æ€è°ƒæ•´æƒé‡
4. **æµå¼å­—å¹•è¾“å‡º**ï¼šSV/Whisper/LLM å„é˜¶æ®µå³æ—¶æ¨é€
5. **é˜ˆå€¼ä½“ç³»è®¾è®¡**ï¼šè½¬å½•ç½®ä¿¡åº¦ä¸æ ¡å¯¹å›°æƒ‘åº¦åˆ†ç¦»
6. **è­¦å‘Šé«˜äº®ç³»ç»Ÿ**ï¼šå­—çº§ä¸å¥çº§åŒå±‚è§†è§‰åé¦ˆ

**ç›¸å…³æ–‡æ¡£**ï¼š
- å‰ç½®ï¼š[Phase 1-5 ä¿®è®¢ç‰ˆæ–‡æ¡£]
- åç»­ï¼š[07_LLMæ ¡å¯¹å±‚è¯¦ç»†è®¾è®¡]ï¼ˆå¾…åˆ›å»ºï¼‰
- åç»­ï¼š[08_å‰ç«¯ç»„ä»¶è¯¦ç»†è®¾è®¡]ï¼ˆå¾…åˆ›å»ºï¼‰

**å®æ–½é¡ºåºå»ºè®®**ï¼š
1. åç«¯å…ˆå®ç° `ThresholdConfig` å’Œ `WarningType` æ•°æ®æ¨¡å‹
2. ä¿®æ”¹ `TranscriptionService` æ”¯æŒé¢„è®¾é…ç½®å’Œæ™ºèƒ½è¿›åº¦
3. å®ç° `StreamingSubtitleManager` æµå¼æ¨é€
4. å‰ç«¯å®ç°é¢„è®¾é€‰æ‹©å™¨å’Œé«˜çº§è®¾ç½®å¼¹çª—
5. å‰ç«¯å®ç°è­¦å‘Šé«˜äº®ç»„ä»¶ï¼ˆ`ConfidenceHighlight.vue`ã€`SentenceWarning.vue`ï¼‰
6. é›†æˆæµ‹è¯•å„é¢„è®¾åœºæ™¯
- åç»­ï¼š[07_æ ¡å¯¹ç¿»è¯‘å±‚_LLMé›†æˆæ–¹æ¡ˆ.md](./07_æ ¡å¯¹ç¿»è¯‘å±‚_LLMé›†æˆæ–¹æ¡ˆ.md)
