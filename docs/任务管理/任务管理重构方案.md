# 任务管理重构方案

> **目标读者**: 独立开发者
> **核心目标**: 解决多任务并发导致的OOM崩溃问题，逐步引入队列管理
> **实施原则**: 小步快跑，每个阶段都可独立运行和测试

---

## 📋 核心问题

### 当前痛点 (V2.1)

1. **🔴 严重**: 多次点击"开始"会并发执行多个任务 → **显存OOM崩溃**
2. **🟡 中等**: 程序重启后，队列丢失（只能通过checkpoint手动恢复）
3. **🟡 中等**: 无法"暂停任务A，优先跑任务B"
4. **🟢 轻微**: `self.jobs`字典永不清理，长期运行内存泄漏

### 解决方案概览

```
V2.1 (现状) → V2.2 (串行队列) → V2.3 (持久化) → V2.4 (插队) → V3.0 (全局SSE)
    ⬇️           ⬇️                ⬇️              ⬇️            ⬇️
  并发崩溃      单线程稳定        重启恢复        灵活调度      列表实时更新
```

---

## 🎯 阶段1: V2.2 核心稳定版 (最小可行方案)

**目标**: 只解决OOM问题，不做其他任何功能
**工作量**: 1-2天（基础版1天 + 资源清理增强0.5-1天）
**前端改动**: 零

### 实施路径

```
Step 1.1-1.4: 实现队列基础功能 (必做，1天)
    ↓
Step 1.5: 资源清理增强 - LRU (强烈推荐，0.5-1小时)
    ↓
Step 1.6: 测试
    ↓
Step 1.7: 验收
```

**⚠️ 重要**:
- **Step 1.1-1.4** 包含基础资源清理（GC + CUDA），可先快速完成并测试
- **Step 1.5** 是资源清理的增强版（LRU保留对齐模型），立即完成，避免显存泄漏

---

### 1.1 实施步骤

#### Step 1.1: 创建队列服务骨架

**新建文件**: `backend/app/services/job_queue_service.py`

```python
"""
任务队列管理服务 - V2.2
核心功能: 串行执行，防止并发OOM
"""
import threading
import time
import logging
import gc
from collections import deque
from typing import Dict, Optional
import torch

from models.job_models import JobState
from services.sse_service import get_sse_manager

logger = logging.getLogger(__name__)


class JobQueueService:
    """
    任务队列管理器

    职责:
    1. 维护任务队列 (FIFO)
    2. 单线程Worker循环
    3. 串行执行任务（同一时间只有1个running）
    """

    def __init__(self, transcription_service):
        """
        初始化队列服务

        Args:
            transcription_service: 转录服务实例
        """
        # 核心数据结构
        self.jobs: Dict[str, JobState] = {}  # 任务注册表 {job_id: JobState}
        self.queue: deque = deque()           # 等待队列 [job_id1, job_id2, ...]
        self.running_job_id: Optional[str] = None  # 当前正在执行的任务ID

        # 依赖服务
        self.transcription_service = transcription_service
        self.sse_manager = get_sse_manager()

        # 控制信号
        self.stop_event = threading.Event()
        self.lock = threading.Lock()  # 保护queue和running_job_id

        # 启动Worker线程
        self.worker_thread = threading.Thread(
            target=self._worker_loop,
            daemon=True,
            name="JobQueueWorker"
        )
        self.worker_thread.start()
        logger.info("✅ 任务队列Worker线程已启动")

    def add_job(self, job: JobState):
        """
        添加任务到队列

        Args:
            job: 任务状态对象
        """
        with self.lock:
            self.jobs[job.job_id] = job
            self.queue.append(job.job_id)
            job.status = "queued"
            job.message = f"排队中 (位置: {len(self.queue)})"

        logger.info(f"📥 任务已加入队列: {job.job_id} (队列长度: {len(self.queue)})")

    def get_job(self, job_id: str) -> Optional[JobState]:
        """获取任务状态"""
        return self.jobs.get(job_id)

    def pause_job(self, job_id: str) -> bool:
        """
        暂停任务

        Args:
            job_id: 任务ID

        Returns:
            bool: 是否成功设置暂停标志
        """
        job = self.jobs.get(job_id)
        if not job:
            return False

        with self.lock:
            if job_id == self.running_job_id:
                # 正在执行的任务：设置暂停标志（pipeline会自己检测并保存checkpoint）
                job.paused = True
                job.message = "暂停中..."
                logger.info(f"⏸️ 设置暂停标志: {job_id}")
            elif job_id in self.queue:
                # 还在排队的任务：直接从队列移除
                self.queue.remove(job_id)
                job.status = "paused"
                job.message = "已暂停（未开始）"
                logger.info(f"⏸️ 从队列移除: {job_id}")

        return True

    def cancel_job(self, job_id: str, delete_data: bool = False) -> bool:
        """
        取消任务

        Args:
            job_id: 任务ID
            delete_data: 是否删除任务数据

        Returns:
            bool: 是否成功
        """
        job = self.jobs.get(job_id)
        if not job:
            return False

        with self.lock:
            # 设置取消标志
            job.canceled = True
            job.message = "取消中..."

            # 如果在队列中，移除
            if job_id in self.queue:
                self.queue.remove(job_id)
                job.status = "canceled"
                job.message = "已取消（未开始）"

        # 如果需要删除数据，调用transcription_service的清理逻辑
        if delete_data:
            # 这里复用原有的清理逻辑
            return self.transcription_service.cancel_job(job_id, delete_data=True)

        return True

    def _worker_loop(self):
        """
        Worker线程主循环

        核心逻辑:
        1. 从队列取任务
        2. 执行任务（阻塞）
        3. 清理资源
        4. 循环
        """
        logger.info("🔄 Worker循环已启动")

        while not self.stop_event.is_set():
            try:
                # 1. 检查队列是否为空
                with self.lock:
                    if not self.queue:
                        # 队列为空，休眠1秒
                        pass
                    else:
                        # 取队头任务（不移除，防止出错丢失）
                        job_id = self.queue[0]
                        job = self.jobs.get(job_id)

                        # 验证任务有效性
                        if not job:
                            logger.warning(f"⚠️ 任务不存在，跳过: {job_id}")
                            self.queue.popleft()
                            continue

                        if job.status in ["paused", "canceled"]:
                            logger.info(f"⏭️ 跳过已暂停/取消的任务: {job_id}")
                            self.queue.popleft()
                            continue

                        # 正式从队列移除
                        self.queue.popleft()
                        self.running_job_id = job_id
                        job.status = "processing"
                        job.message = "开始处理"

                # 2. 如果没有任务，休眠后继续
                if self.running_job_id is None:
                    time.sleep(1)
                    continue

                # 3. 执行任务（阻塞，直到完成/失败/暂停/取消）
                job = self.jobs[self.running_job_id]
                logger.info(f" 开始执行任务: {self.running_job_id}")

                try:
                    # 调用原有的转录流程（会阻塞到任务结束）
                    self.transcription_service._run_pipeline(job)

                    # 检查最终状态
                    if job.canceled:
                        job.status = "canceled"
                        job.message = "已取消"
                    elif job.paused:
                        job.status = "paused"
                        job.message = "已暂停"
                    else:
                        job.status = "finished"
                        job.message = "完成"
                        logger.info(f"✅ 任务完成: {self.running_job_id}")

                except Exception as e:
                    job.status = "failed"
                    job.message = f"失败: {e}"
                    job.error = str(e)
                    logger.error(f"❌ 任务执行失败: {self.running_job_id} - {e}", exc_info=True)

                finally:
                    # 4. 清理资源（关键！）
                    with self.lock:
                        self.running_job_id = None

                    # 🔥 资源大清洗
                    self._cleanup_resources()

                    # 推送任务结束信号
                    self.sse_manager.broadcast_sync(
                        f"job:{job.job_id}",
                        "signal",
                        {
                            "code": f"job_{job.status}",
                            "message": job.message,
                            "status": job.status
                        }
                    )

            except Exception as e:
                logger.error(f"Worker循环异常: {e}", exc_info=True)
                time.sleep(1)

        logger.info("🛑 Worker循环已停止")

    def _cleanup_resources(self):
        """
        资源大清洗（基础版）

        V2.2 基础版本：只做 GC + CUDA 清理
        改进版本请参考 Step 1.6（强烈推荐）

        基础清理：
        1. Python垃圾回收
        2. CUDA显存清理
        """
        logger.info("开始资源清理...")

        # 1. Python垃圾回收
        gc.collect()
        logger.debug("  - Python GC 完成")

        # 2. CUDA显存清理
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            torch.cuda.synchronize()  # 确保所有CUDA操作完成
            logger.debug("  - CUDA缓存已清空")

        # 3. 等待资源释放
        time.sleep(1)

        logger.info("✅ 资源清理完成")

        # ⚠️ 注意: 此版本未清理模型缓存，可能导致显存泄漏
        # 建议完成 Step 1.6 的资源清理增强

    def shutdown(self):
        """停止Worker线程"""
        logger.info("🛑 停止队列服务...")
        self.stop_event.set()
        self.worker_thread.join(timeout=5)
        logger.info("✅ 队列服务已停止")


# ========== 单例模式 ==========

_queue_service_instance: Optional[JobQueueService] = None


def get_queue_service(transcription_service=None) -> JobQueueService:
    """
    获取队列服务单例

    Args:
        transcription_service: 首次调用时必须提供

    Returns:
        JobQueueService: 队列服务实例
    """
    global _queue_service_instance
    if _queue_service_instance is None:
        if transcription_service is None:
            raise RuntimeError("首次调用必须提供transcription_service")
        _queue_service_instance = JobQueueService(transcription_service)
    return _queue_service_instance
```

#### Step 1.2: 修改应用启动逻辑

**修改文件**: `backend/app/main.py`

```python
# 在现有代码基础上添加

from services.job_queue_service import get_queue_service

# ... (原有代码)

# 在创建transcription_service之后，初始化队列服务
@app.on_event("startup")
async def startup_event():
    """应用启动事件"""
    # 设置SSE管理器的事件循环
    loop = asyncio.get_running_loop()
    sse_manager = get_sse_manager()
    sse_manager.set_event_loop(loop)
    logger.info("✅ SSE管理器事件循环已设置")

    # 初始化队列服务（新增）
    from services.transcription_service import get_transcription_service
    from core.config import config
    transcription_service = get_transcription_service(str(config.JOBS_DIR))
    queue_service = get_queue_service(transcription_service)
    logger.info("✅ 任务队列服务已启动")


@app.on_event("shutdown")
async def shutdown_event():
    """应用关闭事件"""
    # 停止队列服务（新增）
    from services.job_queue_service import get_queue_service
    try:
        queue_service = get_queue_service()
        queue_service.shutdown()
    except:
        pass
    logger.info("✅ 应用已关闭")
```

#### Step 1.3: 修改API路由（使用队列）

**修改文件**: `backend/app/api/routes/transcription_routes.py`

```python
# 在文件开头添加导入
from services.job_queue_service import get_queue_service

# 修改现有的 upload_file 函数
@router.post("/upload")
async def upload_file(file: UploadFile = File(...)):
    """上传文件并自动创建转录任务（V2.2: 加入队列）"""
    try:
        # ... (原有的文件保存逻辑不变)

        # 创建任务（原有逻辑）
        job_id = uuid.uuid4().hex
        settings = JobSettings()
        job = transcription_service.create_job(original_filename, input_path, settings, job_id=job_id)

        # 🔥 新增: 加入队列（而非直接启动）
        queue_service = get_queue_service()
        queue_service.add_job(job)

        return {
            "job_id": job_id,
            "filename": original_filename,
            "original_name": file.filename,
            "message": "文件上传成功，已加入转录队列",
            "queue_position": len(queue_service.queue)  # 新增: 队列位置
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"上传文件失败: {str(e)}")


# 修改 start_job 函数
@router.post("/start")
async def start_job(job_id: str = Form(...), settings: str = Form(...)):
    """启动转录任务（V2.2: 加入队列而非直接启动）"""
    try:
        settings_obj = TranscribeSettings(**json.loads(settings))

        # 获取队列服务
        queue_service = get_queue_service()
        job = queue_service.get_job(job_id)

        if not job:
            raise HTTPException(status_code=404, detail="无效 job_id")

        # 应用设置（原有逻辑）
        job.settings = JobSettings(**settings_obj.dict())

        # 🔥 关键改动: 如果任务不在队列中，加入队列
        with queue_service.lock:
            if job.status == "paused" or job.status == "failed":
                # 恢复任务：重新加入队列
                job.canceled = False
                job.paused = False
                job.error = None
                queue_service.queue.append(job_id)
                job.status = "queued"
                job.message = f"已加入队列 (位置: {len(queue_service.queue)})"
            elif job.status == "uploaded":
                # 新任务：加入队列
                queue_service.queue.append(job_id)
                job.status = "queued"
                job.message = f"已加入队列 (位置: {len(queue_service.queue)})"

        return {
            "job_id": job_id,
            "started": True,
            "queue_position": len(queue_service.queue)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"启动任务失败: {str(e)}")


# 修改 pause_job 和 cancel_job（使用队列服务）
@router.post("/pause/{job_id}")
async def pause_job(job_id: str):
    """暂停转录任务"""
    queue_service = get_queue_service()
    ok = queue_service.pause_job(job_id)
    if not ok:
        raise HTTPException(status_code=404, detail="任务未找到")
    return {"job_id": job_id, "paused": ok}


@router.post("/cancel/{job_id}")
async def cancel_job(job_id: str, delete_data: bool = False):
    """取消转录任务"""
    queue_service = get_queue_service()
    ok = queue_service.cancel_job(job_id, delete_data=delete_data)
    if not ok:
        raise HTTPException(status_code=404, detail="任务未找到")
    return {"job_id": job_id, "canceled": ok, "data_deleted": delete_data}


# 修改 get_job_status（从队列服务获取）
@router.get("/status/{job_id}")
async def get_job_status(job_id: str):
    """获取任务状态"""
    queue_service = get_queue_service()
    job = queue_service.get_job(job_id)
    if not job:
        raise HTTPException(status_code=404, detail="任务未找到")

    # 返回状态（新增queue_position字段）
    result = job.to_dict()

    # 计算队列位置
    with queue_service.lock:
        if job_id in queue_service.queue:
            result["queue_position"] = list(queue_service.queue).index(job_id) + 1
        elif job_id == queue_service.running_job_id:
            result["queue_position"] = 0  # 0表示正在执行
        else:
            result["queue_position"] = -1  # -1表示不在队列中

    return result
```

#### Step 1.4: 修改TranscriptionService（移除自动启动）

**修改文件**: `backend/app/services/transcription_service.py`

```python
# 找到 start_job 方法，注释掉自动启动逻辑

def start_job(self, job_id: str):
    """
    启动转录任务（V2.2: 废弃，由队列服务调用_run_pipeline）

    注意: 此方法保留是为了向后兼容，但不再自动创建线程
    """
    # 🔥 关键改动: 不再自动创建线程，由队列服务统一管理
    # 原有代码:
    # threading.Thread(target=self._run_pipeline, args=(job,), daemon=True).start()

    # 新逻辑: 只更新状态，实际执行由队列服务控制
    job = self.get_job(job_id)
    if not job:
        return

    job.canceled = False
    job.paused = False
    job.error = None
    # 状态由队列服务设置，这里不改

    self.logger.warning(f"⚠️ start_job已废弃，请使用队列服务: {job_id}")
```

---

### 1.5 资源清理增强

**为什么需要**: Step 1.1 的基础清理只做了 GC + CUDA，但模型对象仍在全局缓存中，会导致显存泄漏。

**收益**:
- ✅ 彻底释放显存（避免多任务后OOM）
- ✅ 同语言任务复用对齐模型（节省80%加载时间）
- ✅ 显存节省80%，时间节省80%

**工作量**: 30分钟-1小时

#### Step 1.5.1: 修改全局缓存定义

**修改文件**: `backend/app/services/transcription_service.py`

在文件开头找到全局变量定义，修改为：

```python
from collections import OrderedDict

# 全局模型缓存 (按 (model, compute_type, device) 键)
_model_cache: Dict[Tuple[str, str, str], object] = {}

# 对齐模型缓存（改为OrderedDict，支持LRU）
_align_model_cache: OrderedDict[str, Tuple[object, object]] = OrderedDict()
_MAX_ALIGN_MODELS = 3  # 最多缓存3种语言的对齐模型

_model_lock = threading.Lock()
_align_lock = threading.Lock()
```

#### Step 1.5.2: 添加清理方法

**修改文件**: `backend/app/services/transcription_service.py`

在文件中添加新方法（建议放在文件末尾）：

```python
def clear_model_cache(self):
    """
    清空模型缓存（供队列服务调用）

    策略:
    - 总是清理 Whisper 模型（显存占用大，1-3GB）
    - 保留对齐模型的 LRU 缓存（占用小，每个~200MB）
    """
    global _model_cache, _align_model_cache

    # 1. 总是清理 Whisper 模型
    with _model_lock:
        for key in list(_model_cache.keys()):
            try:
                del _model_cache[key]
            except:
                pass
        _model_cache.clear()
        self.logger.info("Whisper模型缓存已清空")

    # 2. 保留对齐模型（记录当前缓存状态）
    with _align_lock:
        cached_langs = list(_align_model_cache.keys())
        if cached_langs:
            self.logger.debug(f"🔄 保留对齐模型缓存 (LRU): {cached_langs}")
        else:
            self.logger.debug("🔄 对齐模型缓存为空")
```

#### Step 1.5.3: 实现 LRU 对齐模型加载

**修改文件**: `backend/app/services/transcription_service.py`

找到 `_get_align_model` 方法，在方法开头添加LRU逻辑：

```python
def _get_align_model(self, lang: str, device: str, job: Optional[JobState] = None):
    """获取对齐模型（带LRU缓存）"""
    global _align_model_cache, _MAX_ALIGN_MODELS

    with _align_lock:
        # 1. 检查缓存命中
        if lang in _align_model_cache:
            # 命中：移到末尾（标记为最近使用）
            _align_model_cache.move_to_end(lang)
            self.logger.debug(f"✅ 命中对齐模型缓存: {lang} (缓存: {list(_align_model_cache.keys())})")
            if job:
                job.message = "使用缓存的对齐模型"
            return _align_model_cache[lang]

        # 2. 缓存未命中，检查是否需要淘汰
        if len(_align_model_cache) >= _MAX_ALIGN_MODELS:
            # 缓存已满，删除最久未使用的（队首）
            oldest_lang, (oldest_model, _) = _align_model_cache.popitem(last=False)
            self.logger.info(f"🗑️ 淘汰最久未用的对齐模型: {oldest_lang} (为 {lang} 腾出空间)")

            # 显式删除模型对象
            try:
                del oldest_model
            except:
                pass

    # 3. 加载新模型（保留原有的下载和加载逻辑）
    self.logger.info(f"🔍 加载对齐模型: {lang}")
    if job:
        job.message = f"加载对齐模型 {lang}"

    # ... (保留原有的模型检查、下载、加载逻辑) ...

    # 4. 加载完成后，加入缓存
    # 在原有的 whisperx.load_align_model() 之后添加：
    with _align_lock:
        _align_model_cache[lang] = (am, meta)
        self.logger.info(f"✅ 对齐模型已缓存: {lang} (当前缓存: {list(_align_model_cache.keys())})")

    return am, meta
```

**完整版本参考**: 详细的实现代码请参考文档末尾的"附录"部分。

#### Step 1.5.4: 更新队列服务的清理方法

**修改文件**: `backend/app/services/job_queue_service.py`

找到 `_cleanup_resources` 方法，替换为：

```python
def _cleanup_resources(self):
    """
    资源大清洗（增强版）

    策略:
    1. 清理 Whisper 模型（1-3GB）
    2. 保留最近使用的3个对齐模型（LRU，共~600MB）
    3. GC + CUDA 清理
    """
    logger.info("开始资源清理（增强版）...")

    # 1. 清空 Whisper 模型缓存
    try:
        self.transcription_service.clear_model_cache()
    except Exception as e:
        logger.warning(f"清空模型缓存失败: {e}")

    # 2. Python垃圾回收
    gc.collect()
    logger.debug("  - Python GC 完成")

    # 3. CUDA显存清理
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        torch.cuda.synchronize()

        # 记录显存状态（调试用）
        try:
            memory_allocated = torch.cuda.memory_allocated() / 1024**3
            memory_reserved = torch.cuda.memory_reserved() / 1024**3
            logger.debug(f"  - 显存: 已分配 {memory_allocated:.2f}GB, 已保留 {memory_reserved:.2f}GB")
        except:
            pass

        logger.debug("  - CUDA缓存已清空")

    # 4. 等待资源释放
    time.sleep(1)

    logger.info("✅ 资源清理完成")
```

#### Step 1.5.5: 验证效果

```bash
# 1. 处理2个同语言视频
# 上传2个中文视频，依次启动

# 2. 观察日志
# 第一个任务:
#   🔍 加载对齐模型: zh
#   ✅ 对齐模型已缓存: zh (当前缓存: ['zh'])
#   Whisper模型缓存已清空
#   🔄 保留对齐模型缓存 (LRU): ['zh']

# 第二个任务:
#   ✅ 命中对齐模型缓存: zh (缓存: ['zh'])  ← 直接复用，节省30秒！
#   Whisper模型缓存已清空
#   🔄 保留对齐模型缓存 (LRU): ['zh']

# ✅ 如果看到"命中对齐模型缓存"，说明LRU生效了！
```

**预期收益**:
```
场景: 5个中文视频

基础版（不保留对齐模型）:
- 5次加载 AlignModel(zh) → 浪费 150秒

增强版（LRU保留）:
- 1次加载 AlignModel(zh) → 只需 30秒 ✅
- 节省时间: 80%
- 显存占用: 只增加 200MB
```

---

### 1.6 基础功能测试（独立开发者简化版）

```bash
# 1. 启动后端
cd backend
python -m uvicorn app.main:app --reload

# 2. 观察日志，确认Worker启动
# 应该看到: "✅ 任务队列Worker线程已启动"

# 3. 打开前端（不修改代码）

# 4. 快速测试
# 4.1 上传3个小视频文件
# 4.2 快速点击3次"开始"
# 4.3 观察后端日志:
#     - 应该看到: "📥 任务已加入队列"
#     - 应该看到: " 开始执行任务: xxx" (只有1个)
#     - 应该看到: 其他2个任务在排队

# 4.4 等待第一个任务完成
#     - 观察日志: "✅ 任务完成"
#     - 观察日志: "开始资源清理..."
#     - 观察日志: " 开始执行任务: yyy" (自动开始第二个)

# 5. 测试暂停
# 5.1 在第二个任务执行时，点击"暂停"
# 5.2 观察日志: "⏸️ 设置暂停标志"
# 5.3 等待当前batch结束，任务应变为paused
# 5.4 第三个任务应自动开始

# 6. 测试取消
# 6.1 点击某个排队中的任务的"取消"
# 6.2 观察日志: "⏭️ 跳过已暂停/取消的任务"

# ✅ 如果以上都正常，V2.2完成！
```

### 1.7 预期效果

**成功标志**:

- ✅ 同一时间只有1个任务显示"processing"
- ✅ 其他任务显示"queued"，且有queue_position
- ✅ 无论点多少次"开始"，不会OOM崩溃
- ✅ 任务按FIFO顺序自动执行
- ✅ 暂停/取消功能正常

**前端表现** (无需修改前端代码):

- 任务状态会变成"queued" → "processing" → "finished"
- SSE进度推送正常
- 按钮状态正常

---

## 🎯 阶段2: V2.3 队列持久化

**目标**: 程序重启后恢复队列
**工作量**: 0.5-1天
**前提**: V2.2已稳定运行

### 2.1 实施步骤

#### Step 2.1: 添加持久化逻辑

**修改文件**: `backend/app/services/job_queue_service.py`

```python
# 在 __init__ 方法中添加
from pathlib import Path
import json

def __init__(self, transcription_service):
    # ... (原有代码)

    # 持久化文件路径
    from core.config import config
    self.queue_file = config.JOBS_DIR / "queue_state.json"

    # 启动时恢复队列
    self._load_state()

    # ... (原有Worker启动代码)


def _save_state(self):
    """
    持久化队列状态到磁盘

    格式:
    {
      "queue": ["job_id1", "job_id2"],
      "running": "job_id3",
      "timestamp": 1234567890.0
    }
    """
    with self.lock:
        state = {
            "queue": list(self.queue),
            "running": self.running_job_id,
            "timestamp": time.time()
        }

    try:
        # 原子写入（临时文件 + rename）
        temp_path = self.queue_file.with_suffix(".tmp")
        with open(temp_path, 'w', encoding='utf-8') as f:
            json.dump(state, f, indent=2)

        # 原子替换
        import os
        os.replace(temp_path, self.queue_file)
        logger.debug("队列状态已保存")
    except Exception as e:
        logger.error(f"保存队列状态失败: {e}")


def _load_state(self):
    """
    启动时恢复队列状态

    恢复逻辑:
    1. 读取queue_state.json
    2. 如果有running任务，检查checkpoint是否存在
    3. 恢复running任务为paused，放队列头部
    4. 恢复队列中的其他任务
    """
    if not self.queue_file.exists():
        logger.info("无队列状态文件，从空队列启动")
        return

    try:
        with open(self.queue_file, 'r', encoding='utf-8') as f:
            state = json.load(f)

        logger.info(f"📂 加载队列状态: {state}")

        # 1. 恢复running任务（如果有）
        running_id = state.get("running")
        if running_id:
            # 尝试从checkpoint恢复
            job = self.transcription_service.restore_job_from_checkpoint(running_id)
            if job:
                # 安全起见，改为paused，不自动开始
                job.status = "paused"
                job.message = "程序重启，任务已暂停"
                self.jobs[running_id] = job
                self.queue.appendleft(running_id)  # 放队头
                logger.info(f"🔄 恢复中断任务到队头: {running_id}")
            else:
                logger.warning(f"⚠️ 无法恢复running任务: {running_id}")

        # 2. 恢复队列中的任务
        for job_id in state.get("queue", []):
            # 避免重复（running任务已经加入队列了）
            if job_id == running_id:
                continue

            # 尝试恢复任务
            job = self.transcription_service.restore_job_from_checkpoint(job_id)
            if job:
                self.jobs[job_id] = job
                job.status = "queued"
                job.message = f"排队中 (位置: {len(self.queue) + 1})"
                self.queue.append(job_id)
                logger.info(f"📥 恢复排队任务: {job_id}")
            else:
                logger.warning(f"⚠️ 跳过无效任务: {job_id}")

        logger.info(f"✅ 队列恢复完成: {len(self.queue)}个任务")

    except Exception as e:
        logger.error(f"恢复队列状态失败: {e}")


# 在 add_job, pause_job, cancel_job 方法末尾添加:
def add_job(self, job: JobState):
    # ... (原有代码)
    self._save_state()  # 新增

def pause_job(self, job_id: str) -> bool:
    # ... (原有代码)
    self._save_state()  # 新增
    return True

def cancel_job(self, job_id: str, delete_data: bool = False) -> bool:
    # ... (原有代码)
    self._save_state()  # 新增
    return True


# 在 _worker_loop 中，任务执行完后保存状态
def _worker_loop(self):
    while not self.stop_event.is_set():
        try:
            # ... (原有代码)

            finally:
                # ... (原有清理代码)

                # 保存队列状态
                self._save_state()

        except Exception as e:
            # ...
```

### 2.2 测试步骤

```bash
# 1. 添加3个任务到队列
# 2. 等待第一个任务开始执行
# 3. 观察queue_state.json文件生成
cat backend/data/jobs/queue_state.json

# 应该看到:
# {
#   "queue": ["job_B", "job_C"],
#   "running": "job_A",
#   "timestamp": 1234567890.0
# }

# 4. 强制杀死后端进程 (Ctrl+C)
# 5. 重新启动后端
python -m uvicorn app.main:app --reload

# 6. 观察日志:
# - "🔄 恢复中断任务到队头: job_A"
# - "📥 恢复排队任务: job_B"
# - "📥 恢复排队任务: job_C"

# 7. 打开前端，查看未完成任务列表
# 应该看到3个任务都在，job_A状态为"paused"

# 8. 手动点击job_A的"继续"
# 任务应该从上次进度恢复

# ✅ 如果以上正常，V2.3完成！
```

---

## 🎯 阶段3: V2.4 插队功能

**目标**: 支持"暂停A，优先跑B"
**工作量**: 0.5-1天
**前提**: V2.3已稳定运行

### 3.1 实施步骤

#### Step 3.1: 添加插队方法

**修改文件**: `backend/app/services/job_queue_service.py`

```python
def prioritize_job(self, job_id: str, auto_pause_current: bool = False) -> bool:
    """
    将任务移到队列头部（插队）

    Args:
        job_id: 要优先的任务ID
        auto_pause_current: 是否自动暂停当前正在执行的任务

    Returns:
        bool: 是否成功

    注意 (基于建议B):
    - 如果auto_pause_current=True，会暂停当前任务
    - 但当前任务不会立即停止，需要等待其保存checkpoint并退出
    - Worker会等待当前任务真正退出后，才取下一个任务
    """
    job = self.jobs.get(job_id)
    if not job:
        return False

    with self.lock:
        # 1. 如果任务已经在跑，无法插队
        if job_id == self.running_job_id:
            logger.info(f"⚠️ 任务已在执行，无需插队: {job_id}")
            return False

        # 2. 如果任务在队列中，移除
        if job_id in self.queue:
            self.queue.remove(job_id)

        # 3. 插到队头
        self.queue.appendleft(job_id)
        job.status = "queued"
        job.message = "优先执行（队列第1位）"
        logger.info(f"⚡ 任务已插队到队头: {job_id}")

        # 4. 可选: 暂停当前任务
        if auto_pause_current and self.running_job_id:
            current_job = self.jobs.get(self.running_job_id)
            if current_job:
                current_job.paused = True
                current_job.message = "被插队暂停..."
                logger.info(f"⏸️ 暂停当前任务以让位: {self.running_job_id}")

    self._save_state()
    return True
```

#### Step 3.2: 添加API路由

**修改文件**: `backend/app/api/routes/transcription_routes.py`

```python
@router.post("/prioritize/{job_id}")
async def prioritize_job(job_id: str, auto_pause: bool = False):
    """
    将任务移到队列头部（插队）

    Args:
        job_id: 任务ID
        auto_pause: 是否自动暂停当前正在执行的任务
    """
    queue_service = get_queue_service()
    ok = queue_service.prioritize_job(job_id, auto_pause_current=auto_pause)

    if not ok:
        raise HTTPException(status_code=400, detail="无法优先此任务（可能已在执行）")

    return {
        "job_id": job_id,
        "prioritized": True,
        "auto_pause": auto_pause
    }
```

### 3.2 测试步骤

```bash
# 1. 添加3个任务: A, B, C
# 2. 等待A开始执行
# 3. 使用API将C插队:
curl -X POST "http://localhost:8000/api/prioritize/job_C?auto_pause=false"

# 4. 观察日志:
# - "⚡ 任务已插队到队头: job_C"
# - A执行完后，应该跑C（而非B）

# 5. 测试auto_pause:
# 5.1 重新添加3个任务
# 5.2 等待A开始执行
# 5.3 将C插队并暂停A:
curl -X POST "http://localhost:8000/api/prioritize/job_C?auto_pause=true"

# 5.4 观察日志:
# - "⏸️ 暂停当前任务以让位: job_A"
# - 等待A保存checkpoint并退出
# - " 开始执行任务: job_C"

# ✅ 如果以上正常，V2.4完成！
```

---

## 🎯 阶段4: V3.0 全局SSE

**目标**: 任务列表页实时更新
**工作量**: 1-2天
**前提**: V2.4已稳定运行
**前端改动**: 需要（但向后兼容）

### 4.1 实施步骤

#### Step 4.1: 添加全局SSE端点

**修改文件**: `backend/app/api/routes/transcription_routes.py`

```python
@router.get("/events/global")
async def stream_global_events(request: Request):
    """
    全局SSE流 - 推送所有任务的状态变化

    事件类型:
    - queue_update: 队列顺序变化
    - job_status: 任务状态变化
    - job_progress: 任务进度更新（低频，节省带宽）

    注意 (基于建议C):
    - initial_state只返回精简列表（避免数据膨胀）
    - 详细信息由前端按需查询
    """
    from services.job_queue_service import get_queue_service
    queue_service = get_queue_service()
    sse_manager = get_sse_manager()

    def get_initial_state():
        """返回精简版任务列表"""
        with queue_service.lock:
            return {
                "queue": list(queue_service.queue),
                "running": queue_service.running_job_id,
                "jobs": [
                    {
                        "id": jid,
                        "status": job.status,
                        "progress": job.progress,
                        "filename": job.filename
                        # 注意: 不返回segments等大数据
                    }
                    for jid, job in queue_service.jobs.items()
                ]
            }

    return StreamingResponse(
        sse_manager.subscribe("global", request, initial_state_callback=get_initial_state),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"
        }
    )
```

#### Step 4.2: 在队列服务中推送事件

**修改文件**: `backend/app/services/job_queue_service.py`

```python
def _notify_queue_change(self):
    """推送队列变化事件"""
    with self.lock:
        data = {
            "queue": list(self.queue),
            "running": self.running_job_id,
            "timestamp": time.time()
        }

    self.sse_manager.broadcast_sync("global", "queue_update", data)


def _notify_job_status(self, job_id: str, status: str):
    """推送任务状态变化"""
    job = self.jobs.get(job_id)
    if not job:
        return

    self.sse_manager.broadcast_sync("global", "job_status", {
        "id": job_id,
        "status": status,
        "progress": job.progress,
        "message": job.message
    })


# 在关键方法中调用通知
def add_job(self, job: JobState):
    # ... (原有代码)
    self._notify_queue_change()  # 新增

def prioritize_job(self, job_id: str, auto_pause_current: bool = False) -> bool:
    # ... (原有代码)
    self._notify_queue_change()  # 新增

def _worker_loop(self):
    # 在任务开始时
    self._notify_job_status(job_id, "processing")

    # 在任务结束时
    self._notify_job_status(job.job_id, job.status)
```

### 4.2 前端集成（可选升级）

**新建文件**: `frontend/src/services/queueService.js`

```javascript
/**
 * 队列管理服务（可选）
 */
export class QueueService {
  constructor() {
    this.eventSource = null
    this.listeners = new Map()
  }

  /**
   * 连接全局SSE
   */
  connect() {
    if (this.eventSource) {
      this.disconnect()
    }

    this.eventSource = new EventSource('/api/events/global')

    // 队列更新事件
    this.eventSource.addEventListener('queue_update', (e) => {
      const data = JSON.parse(e.data)
      this._emit('queue_update', data)
    })

    // 任务状态事件
    this.eventSource.addEventListener('job_status', (e) => {
      const data = JSON.parse(e.data)
      this._emit('job_status', data)
    })

    // 初始状态
    this.eventSource.addEventListener('initial_state', (e) => {
      const data = JSON.parse(e.data)
      this._emit('initial_state', data)
    })

    console.log('[QueueService] 全局SSE已连接')
  }

  disconnect() {
    if (this.eventSource) {
      this.eventSource.close()
      this.eventSource = null
    }
  }

  on(event, callback) {
    if (!this.listeners.has(event)) {
      this.listeners.set(event, [])
    }
    this.listeners.get(event).push(callback)
  }

  _emit(event, data) {
    const callbacks = this.listeners.get(event) || []
    callbacks.forEach(cb => cb(data))
  }
}
```

**修改文件**: `frontend/src/App.vue`（可选，向后兼容）

```javascript
// 在 <script setup> 中添加
import { QueueService } from './services/queueService'

// 检测是否支持全局SSE
const queueService = ref(null)

onMounted(async () => {
  // 尝试连接全局SSE（可选，降级到单任务模式）
  try {
    const resp = await fetch('/api/events/global', { method: 'HEAD' })
    if (resp.ok) {
      queueService.value = new QueueService()
      queueService.value.connect()

      queueService.value.on('initial_state', (data) => {
        console.log('[全局SSE] 初始状态:', data)
        // 更新任务列表
      })

      queueService.value.on('queue_update', (data) => {
        console.log('[全局SSE] 队列更新:', data)
        // 更新队列显示
      })

      queueService.value.on('job_status', (data) => {
        console.log('[全局SSE] 任务状态:', data)
        // 更新任务状态
      })
    }
  } catch (e) {
    console.log('[全局SSE] 不支持，使用单任务模式')
  }
})

onUnmounted(() => {
  if (queueService.value) {
    queueService.value.disconnect()
  }
})
```

---

## 📦 附录: 完整的 LRU 对齐模型加载实现

> 注意: Step 1.5.3 中已经包含了核心逻辑，这里提供完整版本供参考。

**完整的 `_get_align_model` 方法** (包含下载逻辑):

```python
def _get_align_model(self, lang: str, device: str, job: Optional[JobState] = None):
    """
    获取对齐模型（带LRU缓存）

    策略:
    - 缓存命中：移到末尾（标记为最近使用）
    - 缓存已满：删除最久未使用的模型
    - 最多缓存3种语言

    Args:
        lang: 语言代码
        device: 设备 (cuda/cpu)
        job: 任务状态对象(可选,用于更新下载进度)

    Returns:
        Tuple[model, metadata]: 对齐模型和元数据
    """
    global _align_model_cache, _MAX_ALIGN_MODELS

    with _align_lock:
        # 1. 检查缓存命中
        if lang in _align_model_cache:
            # 命中：移到末尾（最近使用）
            _align_model_cache.move_to_end(lang)
            self.logger.debug(f"✅ 命中对齐模型缓存: {lang} (缓存: {list(_align_model_cache.keys())})")
            if job:
                job.message = "使用缓存的对齐模型"
            return _align_model_cache[lang]

        # 2. 缓存未命中，检查是否需要淘汰
        if len(_align_model_cache) >= _MAX_ALIGN_MODELS:
            # 缓存已满，删除最久未使用的（队首）
            oldest_lang, (oldest_model, _) = _align_model_cache.popitem(last=False)
            self.logger.info(f"🗑️ 淘汰最久未用的对齐模型: {oldest_lang} (为 {lang} 腾出空间)")

            # 显式删除模型对象
            try:
                del oldest_model
            except:
                pass

        # 3. 加载新模型（保留原有的下载逻辑）
        self.logger.info(f"🔍 加载对齐模型: {lang}")
        if job:
            job.message = f"加载对齐模型 {lang}"

        # 检查模型是否需要下载（使用模型管理服务）
        try:
            from services.model_manager_service import get_model_manager
            model_mgr = get_model_manager()
            align_model_info = model_mgr.align_models.get(lang)

            if align_model_info and (align_model_info.status == "not_downloaded" or align_model_info.status == "incomplete"):
                # 模型未下载，触发下载（原有逻辑保持不变）
                download_msg = "当前下载模型大于1GB (约1.2GB),请耐心等待"
                self.logger.info(f"📦 {download_msg}")
                self.logger.info(f" 自动触发下载对齐模型: {lang}")

                if job:
                    job.message = download_msg

                # 触发下载
                success = model_mgr.download_align_model(lang)
                if not success:
                    self.logger.warning(f"⚠️ 模型管理器下载失败或已在下载中,回退到whisperx")
                    raise RuntimeError("模型管理器下载失败")

                # 等待下载完成（最多等待10分钟）
                import time
                max_wait_time = 600
                wait_interval = 5
                elapsed = 0

                while elapsed < max_wait_time:
                    time.sleep(wait_interval)
                    elapsed += wait_interval

                    current_status = model_mgr.align_models[lang].status
                    progress = model_mgr.align_models[lang].download_progress

                    if current_status == "ready":
                        self.logger.info(f"✅ 对齐模型下载完成: {lang}")
                        if job:
                            job.message = "对齐模型下载完成,准备加载"
                        break
                    elif current_status == "error":
                        self.logger.error(f"❌ 模型管理器下载失败,回退到whisperx")
                        raise RuntimeError(f"对齐模型下载失败: {lang}")
                    else:
                        # 定期提醒用户耐心等待(每30秒)
                        if elapsed % 30 == 0:
                            wait_msg = f"当前下载模型大于1GB,请耐心等待... {progress:.1f}% ({elapsed}s/{max_wait_time}s)"
                            self.logger.info(f"⏳ {wait_msg}")
                            if job:
                                job.message = wait_msg
                        else:
                            wait_msg = f"等待对齐模型下载... {progress:.1f}%"
                            self.logger.info(f"⏳ {wait_msg} ({elapsed}s/{max_wait_time}s)")
                            if job:
                                job.message = wait_msg

                if elapsed >= max_wait_time:
                    self.logger.error(f"❌ 模型下载超时,回退到whisperx")
                    raise TimeoutError(f"对齐模型下载超时: {lang}")

        except Exception as e:
            self.logger.warning(f"⚠️ 模型管理服务检查失败,回退到whisperx: {e}")

        # 加载模型
        try:
            from core.config import config
            am, meta = whisperx.load_align_model(
                language_code=lang,
                device=device,
                model_dir=str(config.HF_CACHE_DIR)
            )

            # 加入缓存（自动放在末尾，标记为最近使用）
            _align_model_cache[lang] = (am, meta)
            self.logger.info(f"✅ 对齐模型已缓存: {lang} (当前缓存: {list(_align_model_cache.keys())})")

            if job:
                job.message = "对齐模型加载完成"

            return am, meta

        except Exception as e:
            self.logger.warning(f"⚠️ 本地加载对齐模型失败,允许whisperx下载: {e}")
            if job:
                job.message = "本地对齐模型不存在,使用whisperx下载"

            # 允许whisperx下载
            am, meta = whisperx.load_align_model(
                language_code=lang,
                device=device
            )

            # 加入缓存
            _align_model_cache[lang] = (am, meta)
            self.logger.info(f"✅ 对齐模型已下载并缓存: {lang}")

            if job:
                job.message = "对齐模型下载并加载完成"

            return am, meta
```

---

##  快速启动指南（独立开发者）

### 最小实施方案（只做V2.2）

```bash
# 1. 创建新文件
touch backend/app/services/job_queue_service.py

# 2. 复制上面的代码到job_queue_service.py

# 3. 修改3个文件:
#    - main.py (添加startup/shutdown事件)
#    - transcription_routes.py (修改upload/start/pause/cancel)
#    - transcription_service.py (注释start_job的线程创建)

# 4. 启动测试
cd backend
python -m uvicorn app.main:app --reload

# 5. 观察日志，看到"✅ 任务队列Worker线程已启动"即成功

# 6. 打开前端，快速点击3次开始，验证只有1个任务在跑

# ✅ 完成！现在你的系统不会再OOM崩溃了
```

### 完整实施建议

```
第1周: V2.2 (核心稳定版)
第2周: V2.3 (持久化) + V2.4 (插队)
第3周: V3.0 (全局SSE，可选)
```

---

## 🐛 常见问题

### Q1: Worker线程启动后立即退出？
检查日志中是否有异常。确认`transcription_service`已正确初始化。

### Q2: 任务一直显示"queued"，不开始执行？
检查Worker循环是否正常。在`_worker_loop`中添加日志确认循环在运行。

### Q3: 暂停后，任务无法恢复？
确认`start_job` API已修改为将paused任务重新加入队列。

### Q4: 重启后队列没恢复？
检查`queue_state.json`是否生成。确认`_load_state`被调用。

### Q5: 插队不生效？
检查任务是否已经在执行（running任务无法插队）。

### Q6: 为什么要保留对齐模型，不全部清理？
**对齐模型的特点**:
- 占用小（每个~200MB，3个才~600MB）
- 加载慢（每次~30秒）
- 复用价值高（同语言视频很常见）

**实际效果对比**:
```
不保留对齐模型（旧方案）:
- 5个中文视频 → 5次加载AlignModel(zh) → 浪费150秒

保留对齐模型（LRU方案）:
- 5个中文视频 → 1次加载AlignModel(zh) → 只需30秒 ✅
```

**显存影响**:
- Whisper模型: 1-3GB（必须清理）
- 对齐模型缓存: 最多600MB（可以保留）
- 总节省: 显存释放 > 80%，时间节省 > 80%

### Q7: LRU 缓存3个语言够用吗？
**够用！** 绝大多数场景：
- 个人用户: 通常只用1-2种语言（中英、中日等）
- 企业用户: 常用语言不超过3种

**特殊场景**（需要处理5+种语言）:
- 调整 `_MAX_ALIGN_MODELS = 5`（改一行代码）
- 或使用 `/admin/clear-all-cache` 手动清理

### Q8: 如何知道对齐模型缓存状态？
观察日志:
```
✅ 命中对齐模型缓存: zh (缓存: ['zh', 'en', 'ja'])
🗑️ 淘汰最久未用的对齐模型: en (为 ko 腾出空间)
🔄 保留对齐模型缓存 (LRU): ['zh', 'ja', 'ko']
```

---

## 📝 后续优化方向

1. **任务优先级系统**: 引入priority字段，支持高/中/低优先级
2. **资源预检**: 启动任务前检查显存是否足够
3. **任务分组**: 支持"批量转录"功能
4. **定时任务**: 支持"每天凌晨3点开始"
5. **Web UI增强**: 拖拽排序、批量操作

---

## ✅ 总结

**核心价值**:
- V2.2 解决了最严重的OOM问题（必做）
- V2.3 提升了可靠性（推荐）
- V2.4 提升了用户体验（可选）
- V3.0 提升了前端体验（可选）

**实施策略**:
- 小步快跑，每个阶段都可独立运行
- 前端无感知，向后兼容
- 专为独立开发者设计，无需复杂测试

**开始行动**:
1. 先做V2.2（1-2天）
2. 观察稳定性1周
3. 根据需求决定是否继续V2.3/V2.4

祝开发顺利！
